[09:46:23,349] INFO  {SparkContext} Running Spark version 2.0.1
[09:46:23,813] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:46:23,980] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 130.229.178.24 instead (on interface wlp4s0)
[09:46:23,981] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:46:24,087] INFO  {SecurityManager} Changing view acls to: victor
[09:46:24,088] INFO  {SecurityManager} Changing modify acls to: victor
[09:46:24,089] INFO  {SecurityManager} Changing view acls groups to: 
[09:46:24,090] INFO  {SecurityManager} Changing modify acls groups to: 
[09:46:24,090] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:46:24,631] INFO  {Utils} Successfully started service 'sparkDriver' on port 44397.
[09:46:24,660] INFO  {SparkEnv} Registering MapOutputTracker
[09:46:24,683] INFO  {SparkEnv} Registering BlockManagerMaster
[09:46:24,701] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-11b7f6aa-b9f3-4069-9019-380f938ebaf1
[09:46:24,727] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:46:24,830] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:46:24,975] INFO  {log} Logging initialized @2687ms
[09:46:25,197] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:46:25,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1e8ce150{/jobs,null,AVAILABLE}
[09:46:25,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@604f2bd2{/jobs/json,null,AVAILABLE}
[09:46:25,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d3ac898{/jobs/job,null,AVAILABLE}
[09:46:25,233] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b73be9f{/jobs/job/json,null,AVAILABLE}
[09:46:25,233] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@628c4ac0{/stages,null,AVAILABLE}
[09:46:25,233] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7b84fcf8{/stages/json,null,AVAILABLE}
[09:46:25,233] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30b19518{/stages/stage,null,AVAILABLE}
[09:46:25,234] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@363042d7{/stages/stage/json,null,AVAILABLE}
[09:46:25,234] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@366ac49b{/stages/pool,null,AVAILABLE}
[09:46:25,234] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ad59d92{/stages/pool/json,null,AVAILABLE}
[09:46:25,235] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56f0cc85{/storage,null,AVAILABLE}
[09:46:25,235] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62e20a76{/storage/json,null,AVAILABLE}
[09:46:25,235] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2cc44ad{/storage/rdd,null,AVAILABLE}
[09:46:25,236] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@44b3606b{/storage/rdd/json,null,AVAILABLE}
[09:46:25,236] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1477089c{/environment,null,AVAILABLE}
[09:46:25,236] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@663411de{/environment/json,null,AVAILABLE}
[09:46:25,236] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@63dd899{/executors,null,AVAILABLE}
[09:46:25,237] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59d2400d{/executors/json,null,AVAILABLE}
[09:46:25,237] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@75cd8043{/executors/threadDump,null,AVAILABLE}
[09:46:25,237] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@33b1c5c5{/executors/threadDump/json,null,AVAILABLE}
[09:46:25,245] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5b202a3a{/static,null,AVAILABLE}
[09:46:25,245] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10b9db7b{/,null,AVAILABLE}
[09:46:25,246] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@9ef8eb7{/api,null,AVAILABLE}
[09:46:25,247] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@34cdeda2{/stages/stage/kill,null,AVAILABLE}
[09:46:25,256] INFO  {ServerConnector} Started ServerConnector@2d1dee39{HTTP/1.1}{0.0.0.0:4040}
[09:46:25,257] INFO  {Server} Started @2970ms
[09:46:25,257] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:46:25,259] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://130.229.178.24:4040
[09:46:25,435] INFO  {Executor} Starting executor ID driver on host localhost
[09:46:25,481] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37605.
[09:46:25,482] INFO  {NettyBlockTransferService} Server created on 130.229.178.24:37605
[09:46:25,485] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 130.229.178.24, 37605)
[09:46:25,489] INFO  {BlockManagerMasterEndpoint} Registering block manager 130.229.178.24:37605 with 1128.9 MB RAM, BlockManagerId(driver, 130.229.178.24, 37605)
[09:46:25,501] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 130.229.178.24, 37605)
[09:46:25,742] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[09:46:25,802] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:46:25,811] INFO  {ServerConnector} Stopped ServerConnector@2d1dee39{HTTP/1.1}{0.0.0.0:4040}
[09:46:25,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@34cdeda2{/stages/stage/kill,null,UNAVAILABLE}
[09:46:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@9ef8eb7{/api,null,UNAVAILABLE}
[09:46:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10b9db7b{/,null,UNAVAILABLE}
[09:46:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5b202a3a{/static,null,UNAVAILABLE}
[09:46:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@33b1c5c5{/executors/threadDump/json,null,UNAVAILABLE}
[09:46:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@75cd8043{/executors/threadDump,null,UNAVAILABLE}
[09:46:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59d2400d{/executors/json,null,UNAVAILABLE}
[09:46:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@63dd899{/executors,null,UNAVAILABLE}
[09:46:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@663411de{/environment/json,null,UNAVAILABLE}
[09:46:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1477089c{/environment,null,UNAVAILABLE}
[09:46:25,817] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@44b3606b{/storage/rdd/json,null,UNAVAILABLE}
[09:46:25,817] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2cc44ad{/storage/rdd,null,UNAVAILABLE}
[09:46:25,817] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@62e20a76{/storage/json,null,UNAVAILABLE}
[09:46:25,817] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56f0cc85{/storage,null,UNAVAILABLE}
[09:46:25,817] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6ad59d92{/stages/pool/json,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@366ac49b{/stages/pool,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@363042d7{/stages/stage/json,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@30b19518{/stages/stage,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7b84fcf8{/stages/json,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@628c4ac0{/stages,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1b73be9f{/jobs/job/json,null,UNAVAILABLE}
[09:46:25,819] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d3ac898{/jobs/job,null,UNAVAILABLE}
[09:46:25,819] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@604f2bd2{/jobs/json,null,UNAVAILABLE}
[09:46:25,819] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1e8ce150{/jobs,null,UNAVAILABLE}
[09:46:25,823] INFO  {SparkUI} Stopped Spark web UI at http://130.229.178.24:4040
[09:46:25,847] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:46:25,859] INFO  {MemoryStore} MemoryStore cleared
[09:46:25,860] INFO  {BlockManager} BlockManager stopped
[09:46:25,869] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:46:25,874] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:46:25,895] INFO  {SparkContext} Successfully stopped SparkContext
[09:46:25,896] INFO  {ShutdownHookManager} Shutdown hook called
[09:46:25,898] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-8702c5f0-7507-4165-affb-1bac1255d128
[08:43:45,742] INFO  {SparkContext} Running Spark version 2.0.1
[08:43:46,353] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:43:46,600] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:43:46,601] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:43:46,760] INFO  {SecurityManager} Changing view acls to: victor
[08:43:46,775] INFO  {SecurityManager} Changing modify acls to: victor
[08:43:46,776] INFO  {SecurityManager} Changing view acls groups to: 
[08:43:46,777] INFO  {SecurityManager} Changing modify acls groups to: 
[08:43:46,779] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:43:47,348] INFO  {Utils} Successfully started service 'sparkDriver' on port 42575.
[08:43:47,442] INFO  {SparkEnv} Registering MapOutputTracker
[08:43:47,520] INFO  {SparkEnv} Registering BlockManagerMaster
[08:43:47,546] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e954d319-02fd-444e-8703-dd8a78526d8a
[08:43:47,598] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:43:47,722] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:43:47,960] INFO  {log} Logging initialized @3935ms
[08:43:48,103] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:43:48,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:43:48,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:43:48,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:43:48,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:43:48,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:43:48,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:43:48,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:43:48,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:43:48,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:43:48,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:43:48,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:43:48,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:43:48,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:43:48,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:43:48,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:43:48,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:43:48,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:43:48,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:43:48,138] INFO  {ServerConnector} Started ServerConnector@716d7f02{HTTP/1.1}{0.0.0.0:4040}
[08:43:48,138] INFO  {Server} Started @4114ms
[08:43:48,138] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:43:48,141] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:43:48,375] INFO  {Executor} Starting executor ID driver on host localhost
[08:43:48,413] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36609.
[08:43:48,414] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:36609
[08:43:48,421] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 36609)
[08:43:48,432] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:36609 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 36609)
[08:43:48,439] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 36609)
[08:43:48,615] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[08:43:48,843] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:43:48,856] INFO  {ServerConnector} Stopped ServerConnector@716d7f02{HTTP/1.1}{0.0.0.0:4040}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:43:48,861] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:43:48,861] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:43:48,862] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:43:48,871] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:43:48,875] INFO  {MemoryStore} MemoryStore cleared
[08:43:48,876] INFO  {BlockManager} BlockManager stopped
[08:43:48,993] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:43:49,007] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:43:49,009] INFO  {SparkContext} Successfully stopped SparkContext
[08:43:49,019] INFO  {ShutdownHookManager} Shutdown hook called
[08:43:49,020] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f7d8bbd9-2dba-483c-a46c-788a2d3a2e8f
[08:45:29,117] INFO  {SparkContext} Running Spark version 2.0.1
[08:45:29,323] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:45:29,417] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:45:29,418] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:45:29,476] INFO  {SecurityManager} Changing view acls to: victor
[08:45:29,476] INFO  {SecurityManager} Changing modify acls to: victor
[08:45:29,477] INFO  {SecurityManager} Changing view acls groups to: 
[08:45:29,478] INFO  {SecurityManager} Changing modify acls groups to: 
[08:45:29,478] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:45:29,848] INFO  {Utils} Successfully started service 'sparkDriver' on port 33095.
[08:45:29,866] INFO  {SparkEnv} Registering MapOutputTracker
[08:45:29,882] INFO  {SparkEnv} Registering BlockManagerMaster
[08:45:29,894] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-d6480a92-1a0d-425a-a570-f8717b0847f6
[08:45:29,908] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:45:29,961] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:45:30,038] INFO  {log} Logging initialized @1585ms
[08:45:30,139] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:45:30,156] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:45:30,156] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:45:30,156] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:45:30,156] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:45:30,156] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:45:30,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:45:30,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:45:30,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:45:30,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:45:30,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:45:30,158] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:45:30,158] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:45:30,158] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:45:30,158] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:45:30,158] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:45:30,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:45:30,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:45:30,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:45:30,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:45:30,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:45:30,165] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:45:30,165] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:45:30,166] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:45:30,166] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:45:30,172] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:45:30,173] INFO  {Server} Started @1721ms
[08:45:30,173] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:45:30,175] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:45:30,253] INFO  {Executor} Starting executor ID driver on host localhost
[08:45:30,277] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41087.
[08:45:30,278] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:41087
[08:45:30,280] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 41087)
[08:45:30,284] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:41087 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 41087)
[08:45:30,287] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 41087)
[08:45:30,412] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[08:45:30,457] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:45:30,464] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:45:30,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:45:30,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:45:30,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:45:30,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:45:30,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:45:30,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:45:30,469] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:45:30,469] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:45:30,469] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:45:30,469] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:45:30,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:45:30,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:45:30,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:45:30,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:45:30,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:45:30,472] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:45:30,472] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:45:30,472] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:45:30,475] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:45:30,487] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:45:30,494] INFO  {MemoryStore} MemoryStore cleared
[08:45:30,494] INFO  {BlockManager} BlockManager stopped
[08:45:30,500] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:45:30,505] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:45:30,506] INFO  {SparkContext} Successfully stopped SparkContext
[08:45:30,507] INFO  {ShutdownHookManager} Shutdown hook called
[08:45:30,508] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-8a2e4fdc-1dce-4380-8432-cb705a2eae7c
[08:45:54,292] INFO  {SparkContext} Running Spark version 2.0.1
[08:45:54,502] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:45:54,591] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:45:54,591] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:45:54,655] INFO  {SecurityManager} Changing view acls to: victor
[08:45:54,655] INFO  {SecurityManager} Changing modify acls to: victor
[08:45:54,656] INFO  {SecurityManager} Changing view acls groups to: 
[08:45:54,656] INFO  {SecurityManager} Changing modify acls groups to: 
[08:45:54,657] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:45:55,005] INFO  {Utils} Successfully started service 'sparkDriver' on port 39237.
[08:45:55,022] INFO  {SparkEnv} Registering MapOutputTracker
[08:45:55,044] INFO  {SparkEnv} Registering BlockManagerMaster
[08:45:55,062] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-a97d9f46-c0f0-427a-a02b-4912bfbc69c9
[08:45:55,076] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:45:55,124] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:45:55,196] INFO  {log} Logging initialized @1539ms
[08:45:55,302] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:45:55,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:45:55,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:45:55,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:45:55,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:45:55,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:45:55,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:45:55,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:45:55,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:45:55,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:45:55,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:45:55,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:45:55,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:45:55,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:45:55,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:45:55,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:45:55,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:45:55,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:45:55,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:45:55,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:45:55,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:45:55,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:45:55,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:45:55,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:45:55,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:45:55,339] INFO  {ServerConnector} Started ServerConnector@7fdeec44{HTTP/1.1}{0.0.0.0:4040}
[08:45:55,339] INFO  {Server} Started @1683ms
[08:45:55,339] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:45:55,342] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:45:55,431] INFO  {Executor} Starting executor ID driver on host localhost
[08:45:55,455] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38849.
[08:45:55,456] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:38849
[08:45:55,458] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 38849)
[08:45:55,461] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:38849 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 38849)
[08:45:55,464] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 38849)
[08:45:55,585] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[08:45:56,467] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[08:45:56,592] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[08:45:56,596] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:38849 (size: 14.3 KB, free: 1128.9 MB)
[08:45:56,626] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:24
[08:45:57,033] INFO  {FileInputFormat} Total input paths to process : 1
[08:45:57,072] INFO  {SparkContext} Starting job: top at Main.scala:27
[08:45:57,109] INFO  {DAGScheduler} Got job 0 (top at Main.scala:27) with 1 output partitions
[08:45:57,109] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:27)
[08:45:57,109] INFO  {DAGScheduler} Parents of final stage: List()
[08:45:57,119] INFO  {DAGScheduler} Missing parents: List()
[08:45:57,149] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27), which has no missing parents
[08:45:57,285] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[08:45:57,287] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[08:45:57,288] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:38849 (size: 2.1 KB, free: 1128.9 MB)
[08:45:57,289] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[08:45:57,292] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27)
[08:45:57,293] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[08:45:57,371] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:45:57,378] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[08:45:57,434] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:45:57,473] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[08:45:57,473] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[08:45:57,473] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[08:45:57,473] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[08:45:57,473] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[08:45:57,593] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[08:45:57,609] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 275 ms on localhost (1/1)
[08:45:57,610] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[08:45:57,615] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:27) finished in 0.313 s
[08:45:57,623] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:27, took 0.550697 s
[08:45:57,660] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:45:57,664] INFO  {ServerConnector} Stopped ServerConnector@7fdeec44{HTTP/1.1}{0.0.0.0:4040}
[08:45:57,666] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:45:57,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:45:57,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:45:57,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:45:57,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:45:57,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:45:57,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:45:57,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:45:57,671] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:45:57,680] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:45:57,684] INFO  {MemoryStore} MemoryStore cleared
[08:45:57,685] INFO  {BlockManager} BlockManager stopped
[08:45:57,689] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:45:57,691] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:45:57,692] INFO  {SparkContext} Successfully stopped SparkContext
[08:45:57,693] INFO  {ShutdownHookManager} Shutdown hook called
[08:45:57,693] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a65e21e4-917c-41b4-bd54-d1d708e042ba
[08:49:04,782] INFO  {SparkContext} Running Spark version 2.0.1
[08:49:05,016] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:49:05,166] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:49:05,167] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:49:05,264] INFO  {SecurityManager} Changing view acls to: victor
[08:49:05,265] INFO  {SecurityManager} Changing modify acls to: victor
[08:49:05,266] INFO  {SecurityManager} Changing view acls groups to: 
[08:49:05,267] INFO  {SecurityManager} Changing modify acls groups to: 
[08:49:05,267] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:49:05,666] INFO  {Utils} Successfully started service 'sparkDriver' on port 34185.
[08:49:05,683] INFO  {SparkEnv} Registering MapOutputTracker
[08:49:05,700] INFO  {SparkEnv} Registering BlockManagerMaster
[08:49:05,713] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e606bd99-df72-45bf-a583-8ccdc6957b0a
[08:49:05,729] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:49:05,786] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:49:05,863] INFO  {log} Logging initialized @1852ms
[08:49:05,980] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:49:05,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:49:05,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:49:05,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:49:05,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:49:05,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:49:05,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:49:05,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:49:05,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:49:06,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:49:06,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:49:06,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:49:06,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:49:06,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:49:06,002] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:49:06,009] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:49:06,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:49:06,012] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:49:06,013] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:49:06,021] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:49:06,022] INFO  {Server} Started @2012ms
[08:49:06,022] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:49:06,028] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:49:06,131] INFO  {Executor} Starting executor ID driver on host localhost
[08:49:06,162] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34249.
[08:49:06,163] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:34249
[08:49:06,166] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 34249)
[08:49:06,169] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:34249 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 34249)
[08:49:06,176] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 34249)
[08:49:06,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[08:49:06,476] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[08:49:06,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[08:49:06,478] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[08:49:06,479] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[08:49:06,481] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[08:49:06,513] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[08:49:09,393] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[08:49:09,441] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[08:49:09,443] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:34249 (size: 14.3 KB, free: 1128.9 MB)
[08:49:09,447] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:24
[08:49:09,824] INFO  {FileSourceStrategy} Pruning directories with: 
[08:49:09,827] INFO  {FileSourceStrategy} Post-Scan Filters: 
[08:49:09,831] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[08:49:09,832] INFO  {FileSourceStrategy} Pushed Filters: 
[08:49:09,840] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[08:49:09,852] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[08:49:09,854] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:34249 (size: 14.6 KB, free: 1128.9 MB)
[08:49:09,857] INFO  {SparkContext} Created broadcast 1 from foreach at Main.scala:33
[08:49:09,861] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[08:49:10,093] INFO  {FileSourceStrategy} Pruning directories with: 
[08:49:10,094] INFO  {FileSourceStrategy} Post-Scan Filters: 
[08:49:10,094] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[08:49:10,094] INFO  {FileSourceStrategy} Pushed Filters: 
[08:49:10,099] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[08:49:10,111] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[08:49:10,112] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:34249 (size: 14.6 KB, free: 1128.9 MB)
[08:49:10,114] INFO  {SparkContext} Created broadcast 2 from foreach at Main.scala:33
[08:49:10,114] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[08:49:10,635] INFO  {CodeGenerator} Code generated in 382.629725 ms
[08:49:10,653] INFO  {CodeGenerator} Code generated in 12.703581 ms
[08:49:10,749] INFO  {SparkContext} Starting job: foreach at Main.scala:33
[08:49:10,768] INFO  {DAGScheduler} Registering RDD 5 (foreach at Main.scala:33)
[08:49:10,770] INFO  {DAGScheduler} Got job 0 (foreach at Main.scala:33) with 1 output partitions
[08:49:10,771] INFO  {DAGScheduler} Final stage: ResultStage 1 (foreach at Main.scala:33)
[08:49:10,771] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 0)
[08:49:10,772] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 0)
[08:49:10,777] INFO  {DAGScheduler} Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at foreach at Main.scala:33), which has no missing parents
[08:49:10,835] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 8.8 KB, free 1128.5 MB)
[08:49:10,838] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.5 MB)
[08:49:10,839] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:34249 (size: 4.6 KB, free: 1128.9 MB)
[08:49:10,839] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[08:49:10,843] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at foreach at Main.scala:33)
[08:49:10,844] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[08:49:10,890] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[08:49:10,899] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[08:49:10,954] INFO  {ContextCleaner} Cleaned accumulator 2
[08:49:10,973] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[08:49:10,991] INFO  {CodeGenerator} Code generated in 13.25467 ms
[08:49:11,157] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
[08:49:11,167] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 299 ms on localhost (1/1)
[08:49:11,168] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[08:49:11,174] INFO  {DAGScheduler} ShuffleMapStage 0 (foreach at Main.scala:33) finished in 0.317 s
[08:49:11,174] INFO  {DAGScheduler} looking for newly runnable stages
[08:49:11,175] INFO  {DAGScheduler} running: Set()
[08:49:11,175] INFO  {DAGScheduler} waiting: Set(ResultStage 1)
[08:49:11,176] INFO  {DAGScheduler} failed: Set()
[08:49:11,177] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[9] at foreach at Main.scala:33), which has no missing parents
[08:49:11,210] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 12.2 KB, free 1128.5 MB)
[08:49:11,212] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1128.4 MB)
[08:49:11,213] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:34249 (size: 6.3 KB, free: 1128.8 MB)
[08:49:11,214] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[08:49:11,215] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at foreach at Main.scala:33)
[08:49:11,216] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[08:49:11,221] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5317 bytes)
[08:49:11,222] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[08:49:11,243] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[08:49:11,245] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[08:49:11,272] INFO  {CodeGenerator} Code generated in 10.663486 ms
[08:49:11,284] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1797 bytes result sent to driver
[08:49:11,287] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 68 ms on localhost (1/1)
[08:49:11,287] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[08:49:11,287] INFO  {DAGScheduler} ResultStage 1 (foreach at Main.scala:33) finished in 0.069 s
[08:49:11,295] INFO  {DAGScheduler} Job 0 finished: foreach at Main.scala:33, took 0.545768 s
[08:49:11,302] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:49:11,308] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:49:11,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:49:11,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:49:11,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:49:11,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:49:11,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:49:11,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:49:11,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:49:11,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:49:11,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:49:11,317] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:49:11,327] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:49:11,331] INFO  {MemoryStore} MemoryStore cleared
[08:49:11,331] INFO  {BlockManager} BlockManager stopped
[08:49:11,337] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:49:11,339] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:49:11,345] INFO  {SparkContext} Successfully stopped SparkContext
[08:49:11,346] INFO  {ShutdownHookManager} Shutdown hook called
[08:49:11,347] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-4cb8d534-cf10-4cdc-9142-416c2a05200d
[08:53:23,287] INFO  {SparkContext} Running Spark version 2.0.1
[08:53:23,488] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:53:23,592] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:53:23,592] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:53:23,661] INFO  {SecurityManager} Changing view acls to: victor
[08:53:23,661] INFO  {SecurityManager} Changing modify acls to: victor
[08:53:23,662] INFO  {SecurityManager} Changing view acls groups to: 
[08:53:23,663] INFO  {SecurityManager} Changing modify acls groups to: 
[08:53:23,664] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:53:24,007] INFO  {Utils} Successfully started service 'sparkDriver' on port 41773.
[08:53:24,023] INFO  {SparkEnv} Registering MapOutputTracker
[08:53:24,040] INFO  {SparkEnv} Registering BlockManagerMaster
[08:53:24,052] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-98928cdf-182b-493d-b25f-219f6c4f5982
[08:53:24,066] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:53:24,119] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:53:24,193] INFO  {log} Logging initialized @1518ms
[08:53:24,296] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:53:24,311] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[08:53:24,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[08:53:24,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[08:53:24,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[08:53:24,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[08:53:24,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[08:53:24,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[08:53:24,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[08:53:24,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[08:53:24,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[08:53:24,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[08:53:24,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[08:53:24,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[08:53:24,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[08:53:24,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[08:53:24,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[08:53:24,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[08:53:24,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[08:53:24,328] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[08:53:24,329] INFO  {Server} Started @1654ms
[08:53:24,329] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:53:24,331] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:53:24,406] INFO  {Executor} Starting executor ID driver on host localhost
[08:53:24,425] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46025.
[08:53:24,425] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:46025
[08:53:24,427] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 46025)
[08:53:24,430] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:46025 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 46025)
[08:53:24,433] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 46025)
[08:53:24,547] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[08:53:24,590] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[08:53:24,590] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[08:53:24,591] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[08:53:24,592] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[08:53:24,593] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[08:53:24,608] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[08:53:26,506] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[08:53:26,549] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[08:53:26,551] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:46025 (size: 14.3 KB, free: 1128.9 MB)
[08:53:26,554] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:24
[08:53:26,629] INFO  {FileInputFormat} Total input paths to process : 1
[08:53:26,641] INFO  {SparkContext} Starting job: top at Main.scala:27
[08:53:26,656] INFO  {DAGScheduler} Got job 0 (top at Main.scala:27) with 1 output partitions
[08:53:26,656] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:27)
[08:53:26,656] INFO  {DAGScheduler} Parents of final stage: List()
[08:53:26,658] INFO  {DAGScheduler} Missing parents: List()
[08:53:26,665] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27), which has no missing parents
[08:53:26,712] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[08:53:26,714] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[08:53:26,715] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:46025 (size: 2.1 KB, free: 1128.9 MB)
[08:53:26,716] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[08:53:26,719] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27)
[08:53:26,720] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[08:53:26,758] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:53:26,764] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[08:53:26,787] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:53:26,792] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[08:53:26,793] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[08:53:26,793] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[08:53:26,793] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[08:53:26,793] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[08:53:26,843] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[08:53:26,850] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 112 ms on localhost (1/1)
[08:53:26,852] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[08:53:26,854] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:27) finished in 0.125 s
[08:53:26,859] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:27, took 0.217079 s
[08:53:26,876] INFO  {SparkContext} Starting job: top at Main.scala:40
[08:53:26,877] INFO  {DAGScheduler} Got job 1 (top at Main.scala:40) with 1 output partitions
[08:53:26,877] INFO  {DAGScheduler} Final stage: ResultStage 1 (top at Main.scala:40)
[08:53:26,877] INFO  {DAGScheduler} Parents of final stage: List()
[08:53:26,877] INFO  {DAGScheduler} Missing parents: List()
[08:53:26,877] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[4] at top at Main.scala:40), which has no missing parents
[08:53:26,882] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 1128.8 MB)
[08:53:26,884] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1128.8 MB)
[08:53:26,885] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:46025 (size: 2.3 KB, free: 1128.9 MB)
[08:53:26,886] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[08:53:26,886] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at top at Main.scala:40)
[08:53:26,886] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[08:53:26,889] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:53:26,889] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[08:53:26,895] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:53:26,986] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1392 bytes result sent to driver
[08:53:26,990] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 102 ms on localhost (1/1)
[08:53:26,990] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[08:53:26,990] INFO  {DAGScheduler} ResultStage 1 (top at Main.scala:40) finished in 0.104 s
[08:53:26,991] INFO  {DAGScheduler} Job 1 finished: top at Main.scala:40, took 0.115049 s
[08:53:27,004] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:53:27,010] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[08:53:27,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[08:53:27,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[08:53:27,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[08:53:27,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[08:53:27,017] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[08:53:27,019] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:53:27,030] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:53:27,035] INFO  {MemoryStore} MemoryStore cleared
[08:53:27,035] INFO  {BlockManager} BlockManager stopped
[08:53:27,040] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:53:27,042] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:53:27,043] INFO  {SparkContext} Successfully stopped SparkContext
[08:53:27,044] INFO  {ShutdownHookManager} Shutdown hook called
[08:53:27,045] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-619101db-9c84-4d99-b556-dc6a9c7ad89f
[08:53:48,595] INFO  {SparkContext} Running Spark version 2.0.1
[08:53:48,833] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:53:48,928] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:53:48,928] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:53:48,981] INFO  {SecurityManager} Changing view acls to: victor
[08:53:48,982] INFO  {SecurityManager} Changing modify acls to: victor
[08:53:48,982] INFO  {SecurityManager} Changing view acls groups to: 
[08:53:48,983] INFO  {SecurityManager} Changing modify acls groups to: 
[08:53:48,983] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:53:49,327] INFO  {Utils} Successfully started service 'sparkDriver' on port 46685.
[08:53:49,343] INFO  {SparkEnv} Registering MapOutputTracker
[08:53:49,358] INFO  {SparkEnv} Registering BlockManagerMaster
[08:53:49,370] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-82a230cd-5786-495d-9c0c-4ae6271df88f
[08:53:49,385] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:53:49,443] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:53:49,517] INFO  {log} Logging initialized @1578ms
[08:53:49,624] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:53:49,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:53:49,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:53:49,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:53:49,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:53:49,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:53:49,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:53:49,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:53:49,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:53:49,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:53:49,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:53:49,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:53:49,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:53:49,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:53:49,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:53:49,650] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:53:49,650] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:53:49,651] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:53:49,651] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:53:49,657] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:53:49,658] INFO  {Server} Started @1720ms
[08:53:49,658] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:53:49,660] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:53:49,741] INFO  {Executor} Starting executor ID driver on host localhost
[08:53:49,765] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44509.
[08:53:49,765] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:44509
[08:53:49,767] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 44509)
[08:53:49,771] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:44509 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 44509)
[08:53:49,774] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 44509)
[08:53:49,894] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[08:53:49,936] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[08:53:49,937] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[08:53:49,938] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[08:53:49,938] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[08:53:49,940] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[08:53:49,953] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[08:53:51,872] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[08:53:51,915] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[08:53:51,917] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:44509 (size: 14.3 KB, free: 1128.9 MB)
[08:53:51,922] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:24
[08:53:51,997] INFO  {FileInputFormat} Total input paths to process : 1
[08:53:52,009] INFO  {SparkContext} Starting job: top at Main.scala:27
[08:53:52,024] INFO  {DAGScheduler} Got job 0 (top at Main.scala:27) with 1 output partitions
[08:53:52,024] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:27)
[08:53:52,025] INFO  {DAGScheduler} Parents of final stage: List()
[08:53:52,026] INFO  {DAGScheduler} Missing parents: List()
[08:53:52,033] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27), which has no missing parents
[08:53:52,075] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[08:53:52,076] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[08:53:52,077] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:44509 (size: 2.1 KB, free: 1128.9 MB)
[08:53:52,078] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[08:53:52,081] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27)
[08:53:52,082] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[08:53:52,123] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:53:52,129] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[08:53:52,158] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:53:52,164] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[08:53:52,164] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[08:53:52,164] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[08:53:52,165] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[08:53:52,165] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[08:53:52,230] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[08:53:52,236] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 133 ms on localhost (1/1)
[08:53:52,237] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[08:53:52,239] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:27) finished in 0.148 s
[08:53:52,243] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:27, took 0.234226 s
[08:53:52,263] INFO  {SparkContext} Starting job: top at Main.scala:40
[08:53:52,264] INFO  {DAGScheduler} Got job 1 (top at Main.scala:40) with 1 output partitions
[08:53:52,265] INFO  {DAGScheduler} Final stage: ResultStage 1 (top at Main.scala:40)
[08:53:52,265] INFO  {DAGScheduler} Parents of final stage: List()
[08:53:52,265] INFO  {DAGScheduler} Missing parents: List()
[08:53:52,265] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[4] at top at Main.scala:40), which has no missing parents
[08:53:52,270] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 1128.8 MB)
[08:53:52,271] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1128.8 MB)
[08:53:52,272] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:44509 (size: 2.3 KB, free: 1128.9 MB)
[08:53:52,273] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[08:53:52,273] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at top at Main.scala:40)
[08:53:52,273] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[08:53:52,276] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:53:52,277] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[08:53:52,283] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:53:52,365] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1392 bytes result sent to driver
[08:53:52,368] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 93 ms on localhost (1/1)
[08:53:52,368] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[08:53:52,368] INFO  {DAGScheduler} ResultStage 1 (top at Main.scala:40) finished in 0.094 s
[08:53:52,369] INFO  {DAGScheduler} Job 1 finished: top at Main.scala:40, took 0.105300 s
[08:53:52,377] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:53:52,381] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:53:52,383] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:53:52,383] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:53:52,383] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:53:52,383] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:53:52,383] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:53:52,386] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:53:52,387] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:53:52,398] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:53:52,405] INFO  {MemoryStore} MemoryStore cleared
[08:53:52,405] INFO  {BlockManager} BlockManager stopped
[08:53:52,410] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:53:52,412] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:53:52,414] INFO  {SparkContext} Successfully stopped SparkContext
[08:53:52,414] INFO  {ShutdownHookManager} Shutdown hook called
[08:53:52,415] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-8287ab6d-7325-407f-9374-7b305330899b
[08:56:02,508] INFO  {SparkContext} Running Spark version 2.0.1
[08:56:02,733] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:56:02,824] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:56:02,824] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:56:02,881] INFO  {SecurityManager} Changing view acls to: victor
[08:56:02,881] INFO  {SecurityManager} Changing modify acls to: victor
[08:56:02,882] INFO  {SecurityManager} Changing view acls groups to: 
[08:56:02,883] INFO  {SecurityManager} Changing modify acls groups to: 
[08:56:02,883] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:56:03,237] INFO  {Utils} Successfully started service 'sparkDriver' on port 36723.
[08:56:03,254] INFO  {SparkEnv} Registering MapOutputTracker
[08:56:03,269] INFO  {SparkEnv} Registering BlockManagerMaster
[08:56:03,281] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e7bf0abf-69b4-41d4-a93d-8a3cdfba8a58
[08:56:03,295] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:56:03,352] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:56:03,430] INFO  {log} Logging initialized @1506ms
[08:56:03,538] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:56:03,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:56:03,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:56:03,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:56:03,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:56:03,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:56:03,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:56:03,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:56:03,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:56:03,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:56:03,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:56:03,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:56:03,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:56:03,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:56:03,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:56:03,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:56:03,559] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:56:03,559] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:56:03,559] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:56:03,559] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:56:03,559] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:56:03,565] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:56:03,566] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:56:03,566] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:56:03,567] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:56:03,573] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:56:03,573] INFO  {Server} Started @1651ms
[08:56:03,573] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:56:03,575] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:56:03,649] INFO  {Executor} Starting executor ID driver on host localhost
[08:56:03,669] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40239.
[08:56:03,670] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:40239
[08:56:03,672] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 40239)
[08:56:03,675] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:40239 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 40239)
[08:56:03,677] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 40239)
[08:56:03,801] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[08:56:03,854] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[08:56:03,854] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[08:56:03,855] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[08:56:03,856] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[08:56:03,858] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[08:56:03,871] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[08:56:05,748] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[08:56:05,794] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[08:56:05,796] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:40239 (size: 14.3 KB, free: 1128.9 MB)
[08:56:05,800] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:24
[08:56:05,892] INFO  {FileInputFormat} Total input paths to process : 1
[08:56:05,904] INFO  {SparkContext} Starting job: top at Main.scala:27
[08:56:05,922] INFO  {DAGScheduler} Got job 0 (top at Main.scala:27) with 1 output partitions
[08:56:05,923] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:27)
[08:56:05,923] INFO  {DAGScheduler} Parents of final stage: List()
[08:56:05,925] INFO  {DAGScheduler} Missing parents: List()
[08:56:05,935] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27), which has no missing parents
[08:56:05,975] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[08:56:05,977] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[08:56:05,978] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:40239 (size: 2.1 KB, free: 1128.9 MB)
[08:56:05,979] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[08:56:05,982] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27)
[08:56:05,983] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[08:56:06,020] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:56:06,027] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[08:56:06,048] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:56:06,053] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[08:56:06,053] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[08:56:06,053] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[08:56:06,053] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[08:56:06,053] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[08:56:06,108] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[08:56:06,114] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 114 ms on localhost (1/1)
[08:56:06,115] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[08:56:06,118] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:27) finished in 0.126 s
[08:56:06,122] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:27, took 0.218351 s
[08:56:06,170] INFO  {SparkContext} Starting job: take at Main.scala:38
[08:56:06,171] INFO  {DAGScheduler} Got job 1 (take at Main.scala:38) with 1 output partitions
[08:56:06,171] INFO  {DAGScheduler} Final stage: ResultStage 1 (take at Main.scala:38)
[08:56:06,171] INFO  {DAGScheduler} Parents of final stage: List()
[08:56:06,171] INFO  {DAGScheduler} Missing parents: List()
[08:56:06,171] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[3] at map at Main.scala:37), which has no missing parents
[08:56:06,173] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 1128.8 MB)
[08:56:06,175] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 1979.0 B, free 1128.8 MB)
[08:56:06,176] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:40239 (size: 1979.0 B, free: 1128.9 MB)
[08:56:06,176] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[08:56:06,177] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at map at Main.scala:37)
[08:56:06,177] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[08:56:06,179] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5450 bytes)
[08:56:06,180] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[08:56:06,187] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:56:06,192] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2149 bytes result sent to driver
[08:56:06,194] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 17 ms on localhost (1/1)
[08:56:06,194] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[08:56:06,194] INFO  {DAGScheduler} ResultStage 1 (take at Main.scala:38) finished in 0.017 s
[08:56:06,195] INFO  {DAGScheduler} Job 1 finished: take at Main.scala:38, took 0.024843 s
[08:56:06,198] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:56:06,202] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:56:06,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:56:06,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:56:06,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:56:06,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:56:06,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:56:06,207] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:56:06,208] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:56:06,216] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:56:06,220] INFO  {MemoryStore} MemoryStore cleared
[08:56:06,221] INFO  {BlockManager} BlockManager stopped
[08:56:06,225] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:56:06,227] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:56:06,229] INFO  {SparkContext} Successfully stopped SparkContext
[08:56:06,230] INFO  {ShutdownHookManager} Shutdown hook called
[08:56:06,230] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-db9799d0-c79a-4ad0-a1cf-c4687a86b36f
[09:04:38,124] INFO  {SparkContext} Running Spark version 2.0.1
[09:04:38,344] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:04:38,432] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:04:38,433] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:04:38,499] INFO  {SecurityManager} Changing view acls to: victor
[09:04:38,499] INFO  {SecurityManager} Changing modify acls to: victor
[09:04:38,500] INFO  {SecurityManager} Changing view acls groups to: 
[09:04:38,500] INFO  {SecurityManager} Changing modify acls groups to: 
[09:04:38,501] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:04:38,892] INFO  {Utils} Successfully started service 'sparkDriver' on port 39321.
[09:04:38,912] INFO  {SparkEnv} Registering MapOutputTracker
[09:04:38,930] INFO  {SparkEnv} Registering BlockManagerMaster
[09:04:38,943] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-89e5c744-3d50-458d-baec-b69d6902de18
[09:04:38,957] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:04:39,015] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:04:39,094] INFO  {log} Logging initialized @1580ms
[09:04:39,200] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:04:39,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[09:04:39,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[09:04:39,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[09:04:39,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[09:04:39,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[09:04:39,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[09:04:39,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[09:04:39,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[09:04:39,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[09:04:39,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[09:04:39,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[09:04:39,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[09:04:39,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[09:04:39,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[09:04:39,225] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[09:04:39,225] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[09:04:39,226] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[09:04:39,226] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[09:04:39,232] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[09:04:39,233] INFO  {Server} Started @1720ms
[09:04:39,233] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:04:39,236] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:04:39,323] INFO  {Executor} Starting executor ID driver on host localhost
[09:04:39,349] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33443.
[09:04:39,350] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:33443
[09:04:39,352] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 33443)
[09:04:39,355] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:33443 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 33443)
[09:04:39,358] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 33443)
[09:04:39,482] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[09:04:39,924] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:04:39,992] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:04:39,995] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:33443 (size: 14.3 KB, free: 1128.9 MB)
[09:04:40,000] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:04:40,141] INFO  {FileInputFormat} Total input paths to process : 1
[09:04:40,162] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:04:40,175] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:04:40,176] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:04:40,177] INFO  {DAGScheduler} Parents of final stage: List()
[09:04:40,179] INFO  {DAGScheduler} Missing parents: List()
[09:04:40,188] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:04:40,238] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:04:40,241] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:04:40,242] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:33443 (size: 2.1 KB, free: 1128.9 MB)
[09:04:40,243] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:04:40,248] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:04:40,250] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:04:40,297] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:04:40,303] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:04:40,327] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:04:40,335] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:04:40,335] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:04:40,335] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:04:40,336] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:04:40,336] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:04:40,397] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[09:04:40,404] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 130 ms on localhost (1/1)
[09:04:40,405] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:04:40,410] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.148 s
[09:04:40,415] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.252677 s
[09:04:40,571] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:33443 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:04:41,965] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@13250132{/SQL,null,AVAILABLE}
[09:04:41,966] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a864d4d{/SQL/json,null,AVAILABLE}
[09:04:41,966] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7558c24b{/SQL/execution,null,AVAILABLE}
[09:04:41,967] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1f129467{/SQL/execution/json,null,AVAILABLE}
[09:04:41,968] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@501957bf{/static/sql,null,AVAILABLE}
[09:04:41,977] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:04:42,701] INFO  {CodeGenerator} Code generated in 182.626704 ms
[09:04:42,752] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:04:42,753] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:04:42,753] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:04:42,753] INFO  {DAGScheduler} Parents of final stage: List()
[09:04:42,753] INFO  {DAGScheduler} Missing parents: List()
[09:04:42,754] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:04:42,769] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 11.7 KB, free 1128.8 MB)
[09:04:42,771] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1128.7 MB)
[09:04:42,772] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:33443 (size: 5.8 KB, free: 1128.9 MB)
[09:04:42,773] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:04:42,773] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:04:42,773] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:04:42,792] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:04:42,792] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:04:42,807] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:04:42,826] INFO  {CodeGenerator} Code generated in 12.522918 ms
[09:04:42,863] INFO  {CodeGenerator} Code generated in 22.516055 ms
[09:04:42,867] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1485 bytes result sent to driver
[09:04:42,868] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 79 ms on localhost (1/1)
[09:04:42,869] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:04:42,869] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) finished in 0.096 s
[09:04:42,869] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:40, took 0.117552 s
[09:04:42,905] INFO  {CodeGenerator} Code generated in 13.870498 ms
[09:04:42,920] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:04:42,924] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[09:04:42,926] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[09:04:42,926] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[09:04:42,926] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[09:04:42,926] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[09:04:42,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[09:04:42,931] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:04:42,939] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:04:42,942] INFO  {MemoryStore} MemoryStore cleared
[09:04:42,943] INFO  {BlockManager} BlockManager stopped
[09:04:42,944] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:04:42,946] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:04:42,947] INFO  {SparkContext} Successfully stopped SparkContext
[09:04:42,948] INFO  {ShutdownHookManager} Shutdown hook called
[09:04:42,948] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-1ea605d7-1931-4c5e-92ac-f5c1c3666d09
[09:05:49,058] INFO  {SparkContext} Running Spark version 2.0.1
[09:05:49,270] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:05:49,348] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:05:49,349] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:05:49,427] INFO  {SecurityManager} Changing view acls to: victor
[09:05:49,428] INFO  {SecurityManager} Changing modify acls to: victor
[09:05:49,428] INFO  {SecurityManager} Changing view acls groups to: 
[09:05:49,429] INFO  {SecurityManager} Changing modify acls groups to: 
[09:05:49,429] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:05:49,790] INFO  {Utils} Successfully started service 'sparkDriver' on port 41629.
[09:05:49,813] INFO  {SparkEnv} Registering MapOutputTracker
[09:05:49,827] INFO  {SparkEnv} Registering BlockManagerMaster
[09:05:49,840] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-da686539-5bbc-4bc1-b211-37364746f4b4
[09:05:49,854] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:05:49,912] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:05:49,985] INFO  {log} Logging initialized @1490ms
[09:05:50,092] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:05:50,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:05:50,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:05:50,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:05:50,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:05:50,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:05:50,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:05:50,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:05:50,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:05:50,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:05:50,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:05:50,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:05:50,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:05:50,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:05:50,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:05:50,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:05:50,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:05:50,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:05:50,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:05:50,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:05:50,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:05:50,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:05:50,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:05:50,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:05:50,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:05:50,127] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:05:50,127] INFO  {Server} Started @1633ms
[09:05:50,128] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:05:50,130] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:05:50,206] INFO  {Executor} Starting executor ID driver on host localhost
[09:05:50,227] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35615.
[09:05:50,228] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:35615
[09:05:50,229] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 35615)
[09:05:50,232] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:35615 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 35615)
[09:05:50,236] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 35615)
[09:05:50,375] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:05:50,785] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:05:50,841] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:05:50,843] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:35615 (size: 14.3 KB, free: 1128.9 MB)
[09:05:50,849] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:05:50,971] INFO  {FileInputFormat} Total input paths to process : 1
[09:05:50,989] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:05:51,002] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:05:51,003] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:05:51,003] INFO  {DAGScheduler} Parents of final stage: List()
[09:05:51,004] INFO  {DAGScheduler} Missing parents: List()
[09:05:51,012] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:05:51,062] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:05:51,064] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:05:51,065] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:35615 (size: 2.1 KB, free: 1128.9 MB)
[09:05:51,066] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:05:51,069] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:05:51,070] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:05:51,114] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:05:51,123] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:05:51,148] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:05:51,158] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:05:51,158] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:05:51,158] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:05:51,159] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:05:51,159] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:05:51,231] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[09:05:51,239] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 147 ms on localhost (1/1)
[09:05:51,241] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:05:51,244] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.164 s
[09:05:51,249] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.259089 s
[09:05:51,366] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:35615 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:05:52,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3b10f4{/SQL,null,AVAILABLE}
[09:05:52,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@525647f3{/SQL/json,null,AVAILABLE}
[09:05:52,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@691541bc{/SQL/execution,null,AVAILABLE}
[09:05:52,727] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@43a4a9e5{/SQL/execution/json,null,AVAILABLE}
[09:05:52,728] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@f245bdd{/static/sql,null,AVAILABLE}
[09:05:52,738] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:05:53,440] INFO  {CodeGenerator} Code generated in 178.37186 ms
[09:05:53,468] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:05:53,469] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:05:53,470] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:05:53,470] INFO  {DAGScheduler} Parents of final stage: List()
[09:05:53,470] INFO  {DAGScheduler} Missing parents: List()
[09:05:53,471] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:05:53,492] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 11.5 KB, free 1128.8 MB)
[09:05:53,494] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1128.7 MB)
[09:05:53,495] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:35615 (size: 5.8 KB, free: 1128.9 MB)
[09:05:53,496] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:05:53,496] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:05:53,496] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:05:53,499] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:05:53,499] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:05:53,513] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:05:53,534] INFO  {CodeGenerator} Code generated in 14.026865 ms
[09:05:53,541] ERROR {Executor} Exception in task 0.0 in stage 1.0 (TID 1)
java.lang.NumberFormatException: For input string: "2001.0"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:241)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:30)
	at se.kth.spark.lab1.task1.Main$$anonfun$2.apply(Main.scala:35)
	at se.kth.spark.lab1.task1.Main$$anonfun$2.apply(Main.scala:34)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[09:05:53,562] WARN  {TaskSetManager} Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.NumberFormatException: For input string: "2001.0"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:241)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:30)
	at se.kth.spark.lab1.task1.Main$$anonfun$2.apply(Main.scala:35)
	at se.kth.spark.lab1.task1.Main$$anonfun$2.apply(Main.scala:34)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

[09:05:53,563] ERROR {TaskSetManager} Task 0 in stage 1.0 failed 1 times; aborting job
[09:05:53,564] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:05:53,567] INFO  {TaskSchedulerImpl} Cancelling stage 1
[09:05:53,568] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) failed in 0.070 s
[09:05:53,569] INFO  {DAGScheduler} Job 1 failed: show at Main.scala:40, took 0.100536 s
[09:05:53,576] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:05:53,583] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:05:53,585] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:05:53,585] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:05:53,587] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:05:53,587] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:05:53,587] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:05:53,587] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:05:53,587] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:05:53,589] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:05:53,589] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:05:53,589] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:05:53,589] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:05:53,591] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:05:53,615] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:05:53,620] INFO  {MemoryStore} MemoryStore cleared
[09:05:53,620] INFO  {BlockManager} BlockManager stopped
[09:05:53,622] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:05:53,624] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:05:53,626] INFO  {SparkContext} Successfully stopped SparkContext
[09:05:53,626] INFO  {ShutdownHookManager} Shutdown hook called
[09:05:53,627] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-e46e3af4-0b09-41c9-9ac7-16bb061fee2c
[09:06:28,096] INFO  {SparkContext} Running Spark version 2.0.1
[09:06:28,331] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:06:28,430] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:06:28,431] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:06:28,516] INFO  {SecurityManager} Changing view acls to: victor
[09:06:28,517] INFO  {SecurityManager} Changing modify acls to: victor
[09:06:28,518] INFO  {SecurityManager} Changing view acls groups to: 
[09:06:28,519] INFO  {SecurityManager} Changing modify acls groups to: 
[09:06:28,520] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:06:28,875] INFO  {Utils} Successfully started service 'sparkDriver' on port 45525.
[09:06:28,894] INFO  {SparkEnv} Registering MapOutputTracker
[09:06:28,910] INFO  {SparkEnv} Registering BlockManagerMaster
[09:06:28,922] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-2e6773bf-03b3-46e5-8d68-9ab83d02b520
[09:06:28,936] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:06:28,989] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:06:29,059] INFO  {log} Logging initialized @1602ms
[09:06:29,161] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:06:29,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:06:29,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:06:29,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:06:29,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:06:29,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:06:29,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:06:29,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:06:29,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:06:29,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:06:29,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:06:29,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:06:29,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:06:29,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:06:29,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:06:29,185] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:06:29,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:06:29,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:06:29,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:06:29,193] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:06:29,193] INFO  {Server} Started @1737ms
[09:06:29,193] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:06:29,195] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:06:29,275] INFO  {Executor} Starting executor ID driver on host localhost
[09:06:29,296] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33181.
[09:06:29,297] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:33181
[09:06:29,299] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 33181)
[09:06:29,302] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:33181 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 33181)
[09:06:29,305] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 33181)
[09:06:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:06:29,889] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:06:29,948] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:06:29,950] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:33181 (size: 14.3 KB, free: 1128.9 MB)
[09:06:29,956] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:06:30,079] INFO  {FileInputFormat} Total input paths to process : 1
[09:06:30,095] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:06:30,113] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:06:30,113] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:06:30,114] INFO  {DAGScheduler} Parents of final stage: List()
[09:06:30,116] INFO  {DAGScheduler} Missing parents: List()
[09:06:30,126] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:06:30,193] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:06:30,196] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:06:30,196] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:33181 (size: 2.1 KB, free: 1128.9 MB)
[09:06:30,197] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:06:30,201] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:06:30,202] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:06:30,260] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:06:30,266] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:06:30,292] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:06:30,307] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:06:30,308] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:06:30,308] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:06:30,308] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:06:30,308] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:06:30,367] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:06:30,376] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 148 ms on localhost (1/1)
[09:06:30,377] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:06:30,380] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.167 s
[09:06:30,384] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.289028 s
[09:06:30,489] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:33181 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:06:31,798] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,AVAILABLE}
[09:06:31,799] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@13250132{/SQL/json,null,AVAILABLE}
[09:06:31,799] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@44bc2449{/SQL/execution,null,AVAILABLE}
[09:06:31,800] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7558c24b{/SQL/execution/json,null,AVAILABLE}
[09:06:31,801] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2dff7085{/static/sql,null,AVAILABLE}
[09:06:31,810] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:06:32,534] INFO  {CodeGenerator} Code generated in 196.20034 ms
[09:06:32,561] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:06:32,562] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:06:32,562] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:06:32,562] INFO  {DAGScheduler} Parents of final stage: List()
[09:06:32,562] INFO  {DAGScheduler} Missing parents: List()
[09:06:32,563] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:06:32,578] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 11.7 KB, free 1128.8 MB)
[09:06:32,580] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1128.7 MB)
[09:06:32,581] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:33181 (size: 5.8 KB, free: 1128.9 MB)
[09:06:32,581] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:06:32,582] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:06:32,582] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:06:32,584] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:06:32,584] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:06:32,598] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:06:32,617] INFO  {CodeGenerator} Code generated in 12.23662 ms
[09:06:32,647] INFO  {CodeGenerator} Code generated in 19.677965 ms
[09:06:32,650] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1485 bytes result sent to driver
[09:06:32,652] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 70 ms on localhost (1/1)
[09:06:32,653] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:06:32,654] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) finished in 0.071 s
[09:06:32,654] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:40, took 0.093268 s
[09:06:32,683] INFO  {CodeGenerator} Code generated in 15.310861 ms
[09:06:32,698] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:06:32,703] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:06:32,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:06:32,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:06:32,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:06:32,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:06:32,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:06:32,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:06:32,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:06:32,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:06:32,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:06:32,709] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:06:32,717] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:06:32,721] INFO  {MemoryStore} MemoryStore cleared
[09:06:32,721] INFO  {BlockManager} BlockManager stopped
[09:06:32,722] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:06:32,724] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:06:32,726] INFO  {SparkContext} Successfully stopped SparkContext
[09:06:32,726] INFO  {ShutdownHookManager} Shutdown hook called
[09:06:32,727] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-74997ecb-eb48-4d37-b820-9ef9070a066d
[09:07:42,020] INFO  {SparkContext} Running Spark version 2.0.1
[09:07:42,261] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:07:42,356] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:07:42,356] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:07:42,427] INFO  {SecurityManager} Changing view acls to: victor
[09:07:42,428] INFO  {SecurityManager} Changing modify acls to: victor
[09:07:42,429] INFO  {SecurityManager} Changing view acls groups to: 
[09:07:42,430] INFO  {SecurityManager} Changing modify acls groups to: 
[09:07:42,430] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:07:42,786] INFO  {Utils} Successfully started service 'sparkDriver' on port 43115.
[09:07:42,803] INFO  {SparkEnv} Registering MapOutputTracker
[09:07:42,817] INFO  {SparkEnv} Registering BlockManagerMaster
[09:07:42,829] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-3647c375-5a2b-46d6-a459-ca9f5d9f1be4
[09:07:42,843] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:07:42,905] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:07:42,976] INFO  {log} Logging initialized @1566ms
[09:07:43,085] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:07:43,102] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:07:43,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:07:43,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:07:43,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:07:43,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:07:43,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:07:43,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:07:43,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:07:43,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:07:43,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:07:43,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:07:43,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:07:43,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:07:43,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:07:43,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:07:43,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:07:43,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:07:43,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:07:43,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:07:43,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:07:43,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:07:43,118] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:07:43,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:07:43,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:07:43,128] INFO  {ServerConnector} Started ServerConnector@1b7a28e6{HTTP/1.1}{0.0.0.0:4040}
[09:07:43,129] INFO  {Server} Started @1720ms
[09:07:43,129] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:07:43,131] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:07:43,227] INFO  {Executor} Starting executor ID driver on host localhost
[09:07:43,250] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38571.
[09:07:43,251] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:38571
[09:07:43,253] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 38571)
[09:07:43,257] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:38571 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 38571)
[09:07:43,260] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 38571)
[09:07:43,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:07:43,809] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:07:43,863] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:07:43,865] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:38571 (size: 14.3 KB, free: 1128.9 MB)
[09:07:43,870] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:07:43,990] INFO  {FileInputFormat} Total input paths to process : 1
[09:07:44,005] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:07:44,016] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:07:44,016] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:07:44,017] INFO  {DAGScheduler} Parents of final stage: List()
[09:07:44,018] INFO  {DAGScheduler} Missing parents: List()
[09:07:44,026] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:07:44,081] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:07:44,083] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:07:44,084] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:38571 (size: 2.1 KB, free: 1128.9 MB)
[09:07:44,085] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:07:44,089] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:07:44,093] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:07:44,156] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:07:44,165] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:07:44,196] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:07:44,207] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:07:44,207] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:07:44,207] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:07:44,207] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:07:44,207] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:07:44,280] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:07:44,286] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 169 ms on localhost (1/1)
[09:07:44,287] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:07:44,291] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.187 s
[09:07:44,297] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.291437 s
[09:07:44,400] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:38571 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:07:45,744] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a864d4d{/SQL,null,AVAILABLE}
[09:07:45,745] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46a123e4{/SQL/json,null,AVAILABLE}
[09:07:45,747] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1f129467{/SQL/execution,null,AVAILABLE}
[09:07:45,748] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@57151b3a{/SQL/execution/json,null,AVAILABLE}
[09:07:45,750] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@b30a50d{/static/sql,null,AVAILABLE}
[09:07:45,761] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:07:46,501] INFO  {CodeGenerator} Code generated in 202.15206 ms
[09:07:46,527] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:07:46,528] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:07:46,528] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:07:46,528] INFO  {DAGScheduler} Parents of final stage: List()
[09:07:46,529] INFO  {DAGScheduler} Missing parents: List()
[09:07:46,529] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:07:46,545] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 11.7 KB, free 1128.8 MB)
[09:07:46,547] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1128.7 MB)
[09:07:46,548] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:38571 (size: 5.8 KB, free: 1128.9 MB)
[09:07:46,548] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:07:46,548] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:07:46,549] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:07:46,552] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:07:46,553] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:07:46,568] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:07:46,588] INFO  {CodeGenerator} Code generated in 13.292013 ms
[09:07:46,618] INFO  {CodeGenerator} Code generated in 19.472299 ms
[09:07:46,621] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1485 bytes result sent to driver
[09:07:46,623] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 74 ms on localhost (1/1)
[09:07:46,623] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:07:46,624] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) finished in 0.075 s
[09:07:46,624] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:40, took 0.097065 s
[09:07:46,656] INFO  {CodeGenerator} Code generated in 19.364208 ms
[09:07:46,813] INFO  {CodeGenerator} Code generated in 13.342075 ms
[09:07:46,827] INFO  {CodeGenerator} Code generated in 9.381998 ms
[09:07:46,872] INFO  {SparkContext} Starting job: count at Main.scala:41
[09:07:46,876] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:41)
[09:07:46,877] INFO  {DAGScheduler} Got job 2 (count at Main.scala:41) with 1 output partitions
[09:07:46,877] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:41)
[09:07:46,877] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:07:46,878] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:07:46,879] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:41), which has no missing parents
[09:07:46,889] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 13.3 KB, free 1128.7 MB)
[09:07:46,891] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.7 KB, free 1128.7 MB)
[09:07:46,891] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:38571 (size: 6.7 KB, free: 1128.9 MB)
[09:07:46,892] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:07:46,893] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:41)
[09:07:46,894] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:07:46,896] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:07:46,897] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:07:46,905] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:07:46,986] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:07:46,989] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 94 ms on localhost (1/1)
[09:07:46,989] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:07:46,990] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:41) finished in 0.095 s
[09:07:46,990] INFO  {DAGScheduler} looking for newly runnable stages
[09:07:46,990] INFO  {DAGScheduler} running: Set()
[09:07:46,991] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:07:46,991] INFO  {DAGScheduler} failed: Set()
[09:07:46,992] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:41), which has no missing parents
[09:07:46,997] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:07:46,999] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:07:47,000] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:38571 (size: 3.7 KB, free: 1128.9 MB)
[09:07:47,000] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:07:47,000] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:41)
[09:07:47,000] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:07:47,005] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:07:47,005] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:07:47,018] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:07:47,020] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[09:07:47,031] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:07:47,033] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 30 ms on localhost (1/1)
[09:07:47,034] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:07:47,034] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:41) finished in 0.031 s
[09:07:47,035] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:41, took 0.163060 s
[09:07:47,161] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:38571 in memory (size: 6.7 KB, free: 1128.9 MB)
[09:07:47,162] INFO  {CodeGenerator} Code generated in 122.189716 ms
[09:07:47,163] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:38571 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:07:47,164] INFO  {ContextCleaner} Cleaned accumulator 44
[09:07:47,164] INFO  {ContextCleaner} Cleaned accumulator 45
[09:07:47,165] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:38571 in memory (size: 5.8 KB, free: 1128.9 MB)
[09:07:47,165] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:07:47,166] INFO  {ContextCleaner} Cleaned accumulator 90
[09:07:47,169] INFO  {ServerConnector} Stopped ServerConnector@1b7a28e6{HTTP/1.1}{0.0.0.0:4040}
[09:07:47,171] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:07:47,171] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:07:47,171] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:07:47,171] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:07:47,174] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:07:47,174] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:07:47,175] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:07:47,184] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:07:47,189] INFO  {MemoryStore} MemoryStore cleared
[09:07:47,190] INFO  {BlockManager} BlockManager stopped
[09:07:47,192] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:07:47,194] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:07:47,196] INFO  {SparkContext} Successfully stopped SparkContext
[09:07:47,196] INFO  {ShutdownHookManager} Shutdown hook called
[09:07:47,197] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-641aa216-243d-45fd-8cd6-474cd3396a7e
[09:08:51,293] INFO  {SparkContext} Running Spark version 2.0.1
[09:08:51,507] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:08:51,618] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:08:51,619] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:08:51,692] INFO  {SecurityManager} Changing view acls to: victor
[09:08:51,692] INFO  {SecurityManager} Changing modify acls to: victor
[09:08:51,693] INFO  {SecurityManager} Changing view acls groups to: 
[09:08:51,694] INFO  {SecurityManager} Changing modify acls groups to: 
[09:08:51,694] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:08:52,049] INFO  {Utils} Successfully started service 'sparkDriver' on port 35547.
[09:08:52,065] INFO  {SparkEnv} Registering MapOutputTracker
[09:08:52,080] INFO  {SparkEnv} Registering BlockManagerMaster
[09:08:52,092] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-22fd4c6e-c7ed-428a-9203-cd8ada0039f6
[09:08:52,106] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:08:52,162] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:08:52,231] INFO  {log} Logging initialized @1525ms
[09:08:52,332] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:08:52,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:08:52,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:08:52,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:08:52,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:08:52,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:08:52,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:08:52,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:08:52,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:08:52,357] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:08:52,358] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:08:52,358] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:08:52,359] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:08:52,365] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:08:52,365] INFO  {Server} Started @1660ms
[09:08:52,365] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:08:52,367] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:08:52,446] INFO  {Executor} Starting executor ID driver on host localhost
[09:08:52,471] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45197.
[09:08:52,472] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:45197
[09:08:52,474] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 45197)
[09:08:52,477] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:45197 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 45197)
[09:08:52,480] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 45197)
[09:08:52,605] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:08:53,034] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:08:53,090] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:08:53,092] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:45197 (size: 14.3 KB, free: 1128.9 MB)
[09:08:53,098] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:08:53,228] INFO  {FileInputFormat} Total input paths to process : 1
[09:08:53,245] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:08:53,262] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:08:53,262] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:08:53,263] INFO  {DAGScheduler} Parents of final stage: List()
[09:08:53,265] INFO  {DAGScheduler} Missing parents: List()
[09:08:53,277] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:08:53,335] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:08:53,337] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:08:53,338] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:45197 (size: 2.1 KB, free: 1128.9 MB)
[09:08:53,339] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:08:53,342] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:08:53,344] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:08:53,391] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:08:53,397] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:08:53,420] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:08:53,429] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:08:53,430] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:08:53,430] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:08:53,430] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:08:53,430] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:08:53,510] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:08:53,516] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 151 ms on localhost (1/1)
[09:08:53,517] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:08:53,520] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.168 s
[09:08:53,526] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.280128 s
[09:08:53,620] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:45197 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:08:54,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:08:54,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:08:54,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:08:54,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:08:54,931] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:08:54,941] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:08:55,645] INFO  {CodeGenerator} Code generated in 180.813275 ms
[09:08:55,680] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:08:55,682] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:08:55,682] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:08:55,682] INFO  {DAGScheduler} Parents of final stage: List()
[09:08:55,682] INFO  {DAGScheduler} Missing parents: List()
[09:08:55,683] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:08:55,699] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:08:55,714] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:08:55,715] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:45197 (size: 5.5 KB, free: 1128.9 MB)
[09:08:55,716] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:08:55,716] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:08:55,716] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:08:55,719] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:08:55,719] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:08:55,735] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:08:55,756] INFO  {CodeGenerator} Code generated in 14.46433 ms
[09:08:55,779] INFO  {CodeGenerator} Code generated in 14.41985 ms
[09:08:55,782] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:08:55,784] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 67 ms on localhost (1/1)
[09:08:55,784] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:08:55,785] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) finished in 0.068 s
[09:08:55,785] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:40, took 0.104298 s
[09:08:55,813] INFO  {CodeGenerator} Code generated in 16.748081 ms
[09:08:55,922] INFO  {CodeGenerator} Code generated in 14.922959 ms
[09:08:55,940] INFO  {CodeGenerator} Code generated in 13.111847 ms
[09:08:55,969] INFO  {SparkContext} Starting job: count at Main.scala:41
[09:08:55,972] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:41)
[09:08:55,972] INFO  {DAGScheduler} Got job 2 (count at Main.scala:41) with 1 output partitions
[09:08:55,972] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:41)
[09:08:55,973] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:08:55,973] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:08:55,974] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:41), which has no missing parents
[09:08:55,980] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:08:55,981] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:08:55,982] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:45197 (size: 6.6 KB, free: 1128.9 MB)
[09:08:55,982] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:08:55,984] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:41)
[09:08:55,984] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:08:55,987] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:08:55,987] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:08:55,995] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:08:56,107] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:08:56,109] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 124 ms on localhost (1/1)
[09:08:56,109] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:08:56,110] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:41) finished in 0.126 s
[09:08:56,111] INFO  {DAGScheduler} looking for newly runnable stages
[09:08:56,111] INFO  {DAGScheduler} running: Set()
[09:08:56,112] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:08:56,112] INFO  {DAGScheduler} failed: Set()
[09:08:56,113] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:41), which has no missing parents
[09:08:56,120] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:08:56,122] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:08:56,123] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:45197 (size: 3.7 KB, free: 1128.9 MB)
[09:08:56,123] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:08:56,124] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:41)
[09:08:56,124] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:08:56,129] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:08:56,129] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:08:56,146] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:08:56,148] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[09:08:56,161] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:08:56,165] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:41) finished in 0.038 s
[09:08:56,165] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 38 ms on localhost (1/1)
[09:08:56,165] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:41, took 0.195637 s
[09:08:56,165] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:08:56,176] INFO  {CodeGenerator} Code generated in 6.734554 ms
[09:08:56,179] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:08:56,183] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:08:56,189] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:08:56,298] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:08:56,302] INFO  {MemoryStore} MemoryStore cleared
[09:08:56,303] INFO  {BlockManager} BlockManager stopped
[09:08:56,304] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:08:56,306] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:08:56,308] INFO  {SparkContext} Successfully stopped SparkContext
[09:08:56,308] INFO  {ShutdownHookManager} Shutdown hook called
[09:08:56,309] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-454b0896-3001-4416-b9bc-e70992882f1c
[09:12:41,246] INFO  {SparkContext} Running Spark version 2.0.1
[09:12:41,460] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:12:41,561] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:12:41,561] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:12:41,625] INFO  {SecurityManager} Changing view acls to: victor
[09:12:41,626] INFO  {SecurityManager} Changing modify acls to: victor
[09:12:41,626] INFO  {SecurityManager} Changing view acls groups to: 
[09:12:41,627] INFO  {SecurityManager} Changing modify acls groups to: 
[09:12:41,628] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:12:41,989] INFO  {Utils} Successfully started service 'sparkDriver' on port 40039.
[09:12:42,009] INFO  {SparkEnv} Registering MapOutputTracker
[09:12:42,028] INFO  {SparkEnv} Registering BlockManagerMaster
[09:12:42,042] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-81e69e69-6f0f-454b-9495-74d964c90f79
[09:12:42,056] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:12:42,114] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:12:42,185] INFO  {log} Logging initialized @1541ms
[09:12:42,284] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:12:42,299] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:12:42,299] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:12:42,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:12:42,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:12:42,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:12:42,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:12:42,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:12:42,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:12:42,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:12:42,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:12:42,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:12:42,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:12:42,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:12:42,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:12:42,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:12:42,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:12:42,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:12:42,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:12:42,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:12:42,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:12:42,309] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:12:42,310] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:12:42,310] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:12:42,311] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:12:42,317] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:12:42,317] INFO  {Server} Started @1674ms
[09:12:42,318] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:12:42,320] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:12:42,407] INFO  {Executor} Starting executor ID driver on host localhost
[09:12:42,429] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37783.
[09:12:42,429] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:37783
[09:12:42,431] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 37783)
[09:12:42,435] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:37783 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 37783)
[09:12:42,438] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 37783)
[09:12:42,561] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:12:42,983] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:12:43,044] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:12:43,046] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:37783 (size: 14.3 KB, free: 1128.9 MB)
[09:12:43,052] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:12:43,174] INFO  {FileInputFormat} Total input paths to process : 1
[09:12:43,189] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:12:43,200] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:12:43,201] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:12:43,201] INFO  {DAGScheduler} Parents of final stage: List()
[09:12:43,202] INFO  {DAGScheduler} Missing parents: List()
[09:12:43,209] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:12:43,266] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:12:43,269] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:12:43,269] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:37783 (size: 2.1 KB, free: 1128.9 MB)
[09:12:43,270] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:12:43,273] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:12:43,275] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:12:43,330] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:12:43,337] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:12:43,363] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:12:43,373] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:12:43,373] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:12:43,373] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:12:43,373] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:12:43,373] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:12:43,442] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:12:43,449] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 152 ms on localhost (1/1)
[09:12:43,450] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:12:43,454] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.169 s
[09:12:43,460] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.270692 s
[09:12:43,569] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:37783 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:12:44,933] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:12:44,934] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:12:44,934] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:12:44,935] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:12:44,936] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:12:44,945] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:12:45,662] INFO  {CodeGenerator} Code generated in 200.16935 ms
[09:12:45,690] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:12:45,692] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:12:45,692] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:12:45,692] INFO  {DAGScheduler} Parents of final stage: List()
[09:12:45,692] INFO  {DAGScheduler} Missing parents: List()
[09:12:45,692] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:12:45,709] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:12:45,711] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:12:45,712] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:37783 (size: 5.5 KB, free: 1128.9 MB)
[09:12:45,712] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:12:45,713] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:12:45,713] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:12:45,715] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:12:45,715] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:12:45,727] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:12:45,747] INFO  {CodeGenerator} Code generated in 13.740169 ms
[09:12:45,768] INFO  {CodeGenerator} Code generated in 13.850656 ms
[09:12:45,772] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:12:45,773] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 60 ms on localhost (1/1)
[09:12:45,773] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:12:45,774] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) finished in 0.061 s
[09:12:45,774] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:40, took 0.083519 s
[09:12:45,797] INFO  {CodeGenerator} Code generated in 13.268963 ms
[09:12:45,898] INFO  {CodeGenerator} Code generated in 13.529717 ms
[09:12:45,913] INFO  {CodeGenerator} Code generated in 9.5853 ms
[09:12:45,943] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:12:45,946] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:43)
[09:12:45,946] INFO  {DAGScheduler} Got job 2 (count at Main.scala:43) with 1 output partitions
[09:12:45,946] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:43)
[09:12:45,946] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:12:45,947] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:12:45,947] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:43), which has no missing parents
[09:12:45,954] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:12:45,955] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:12:45,956] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:37783 (size: 6.6 KB, free: 1128.9 MB)
[09:12:45,956] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:12:45,958] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:43)
[09:12:45,958] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:12:45,961] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:12:45,962] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:12:45,970] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:12:46,095] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:12:46,098] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 139 ms on localhost (1/1)
[09:12:46,098] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:12:46,099] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:43) finished in 0.140 s
[09:12:46,099] INFO  {DAGScheduler} looking for newly runnable stages
[09:12:46,100] INFO  {DAGScheduler} running: Set()
[09:12:46,100] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:12:46,100] INFO  {DAGScheduler} failed: Set()
[09:12:46,102] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:43), which has no missing parents
[09:12:46,107] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:12:46,109] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:12:46,110] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:37783 (size: 3.7 KB, free: 1128.9 MB)
[09:12:46,110] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:12:46,111] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:43)
[09:12:46,111] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:12:46,115] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:12:46,116] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:12:46,128] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:12:46,130] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[09:12:46,143] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:12:46,144] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 30 ms on localhost (1/1)
[09:12:46,144] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:12:46,145] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:43) finished in 0.032 s
[09:12:46,145] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:43, took 0.201997 s
[09:12:46,156] INFO  {CodeGenerator} Code generated in 7.804237 ms
[09:12:46,170] INFO  {SparkContext} Starting job: count at Main.scala:46
[09:12:46,171] INFO  {DAGScheduler} Got job 3 (count at Main.scala:46) with 1 output partitions
[09:12:46,171] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:46)
[09:12:46,171] INFO  {DAGScheduler} Parents of final stage: List()
[09:12:46,172] INFO  {DAGScheduler} Missing parents: List()
[09:12:46,172] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:46), which has no missing parents
[09:12:46,174] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:12:46,175] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:12:46,176] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:37783 (size: 2.0 KB, free: 1128.9 MB)
[09:12:46,177] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:12:46,177] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:46)
[09:12:46,177] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:12:46,179] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:12:46,179] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:12:46,183] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:12:46,220] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:12:46,221] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 43 ms on localhost (1/1)
[09:12:46,221] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:12:46,221] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:46) finished in 0.043 s
[09:12:46,222] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:46, took 0.051001 s
[09:12:46,225] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:12:46,231] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:12:46,233] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:12:46,235] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:12:46,235] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:12:46,235] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:12:46,235] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:12:46,235] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:12:46,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:12:46,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:12:46,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:12:46,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:12:46,239] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:12:46,369] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:12:46,373] INFO  {MemoryStore} MemoryStore cleared
[09:12:46,374] INFO  {BlockManager} BlockManager stopped
[09:12:46,375] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:12:46,377] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:12:46,379] INFO  {SparkContext} Successfully stopped SparkContext
[09:12:46,380] INFO  {ShutdownHookManager} Shutdown hook called
[09:12:46,380] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a4ba6cac-81fa-4858-87ad-7a1ee2207346
[09:21:28,326] INFO  {SparkContext} Running Spark version 2.0.1
[09:21:28,589] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:21:28,722] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:21:28,726] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:21:28,797] INFO  {SecurityManager} Changing view acls to: victor
[09:21:28,798] INFO  {SecurityManager} Changing modify acls to: victor
[09:21:28,799] INFO  {SecurityManager} Changing view acls groups to: 
[09:21:28,799] INFO  {SecurityManager} Changing modify acls groups to: 
[09:21:28,800] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:21:29,138] INFO  {Utils} Successfully started service 'sparkDriver' on port 37599.
[09:21:29,156] INFO  {SparkEnv} Registering MapOutputTracker
[09:21:29,171] INFO  {SparkEnv} Registering BlockManagerMaster
[09:21:29,183] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-abfba9a8-f487-4a86-a6ad-e6f7bfac4944
[09:21:29,197] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:21:29,247] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:21:29,316] INFO  {log} Logging initialized @1668ms
[09:21:29,417] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:21:29,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:21:29,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:21:29,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:21:29,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:21:29,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:21:29,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:21:29,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:21:29,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:21:29,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:21:29,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:21:29,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:21:29,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:21:29,437] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:21:29,437] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:21:29,443] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:21:29,443] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:21:29,444] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:21:29,444] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:21:29,451] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:21:29,451] INFO  {Server} Started @1804ms
[09:21:29,451] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:21:29,455] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:21:29,551] INFO  {Executor} Starting executor ID driver on host localhost
[09:21:29,576] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37145.
[09:21:29,577] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:37145
[09:21:29,579] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 37145)
[09:21:29,582] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:37145 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 37145)
[09:21:29,586] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 37145)
[09:21:29,716] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:21:30,157] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:21:30,214] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:21:30,216] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:37145 (size: 14.3 KB, free: 1128.9 MB)
[09:21:30,221] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:21:30,370] INFO  {FileInputFormat} Total input paths to process : 1
[09:21:30,388] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:21:30,403] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:21:30,404] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:21:30,405] INFO  {DAGScheduler} Parents of final stage: List()
[09:21:30,406] INFO  {DAGScheduler} Missing parents: List()
[09:21:30,416] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:21:30,481] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:21:30,485] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:21:30,486] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:37145 (size: 2.1 KB, free: 1128.9 MB)
[09:21:30,487] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:21:30,491] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:21:30,492] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:21:30,552] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:21:30,558] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:21:30,584] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:21:30,592] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:21:30,593] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:21:30,593] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:21:30,593] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:21:30,593] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:21:30,682] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:21:30,688] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 170 ms on localhost (1/1)
[09:21:30,689] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:21:30,692] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.189 s
[09:21:30,696] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.308075 s
[09:21:30,795] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:37145 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:21:32,098] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:21:32,098] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:21:32,099] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:21:32,099] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:21:32,101] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:21:32,110] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:21:32,810] INFO  {CodeGenerator} Code generated in 181.591536 ms
[09:21:32,839] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:21:32,840] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:21:32,840] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:21:32,840] INFO  {DAGScheduler} Parents of final stage: List()
[09:21:32,841] INFO  {DAGScheduler} Missing parents: List()
[09:21:32,841] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:21:32,858] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:21:32,860] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:21:32,874] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:37145 (size: 5.5 KB, free: 1128.9 MB)
[09:21:32,874] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:21:32,875] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:21:32,875] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:21:32,877] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:21:32,877] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:21:32,894] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:21:32,915] INFO  {CodeGenerator} Code generated in 14.918374 ms
[09:21:32,937] INFO  {CodeGenerator} Code generated in 13.812527 ms
[09:21:32,940] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:21:32,942] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 67 ms on localhost (1/1)
[09:21:32,942] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:21:32,943] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.068 s
[09:21:32,943] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.103861 s
[09:21:32,967] INFO  {CodeGenerator} Code generated in 14.428225 ms
[09:21:33,069] INFO  {CodeGenerator} Code generated in 11.278976 ms
[09:21:33,082] INFO  {CodeGenerator} Code generated in 9.099814 ms
[09:21:33,111] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:21:33,114] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:21:33,115] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:21:33,115] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:21:33,115] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:21:33,115] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:21:33,116] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:21:33,122] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:21:33,124] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:21:33,125] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:37145 (size: 6.6 KB, free: 1128.9 MB)
[09:21:33,126] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:21:33,128] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:21:33,128] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:21:33,131] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:21:33,131] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:21:33,141] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:21:33,261] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1801 bytes result sent to driver
[09:21:33,264] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 134 ms on localhost (1/1)
[09:21:33,264] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:21:33,265] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.136 s
[09:21:33,265] INFO  {DAGScheduler} looking for newly runnable stages
[09:21:33,265] INFO  {DAGScheduler} running: Set()
[09:21:33,266] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:21:33,266] INFO  {DAGScheduler} failed: Set()
[09:21:33,267] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:21:33,273] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:21:33,274] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:21:33,275] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:37145 (size: 3.7 KB, free: 1128.9 MB)
[09:21:33,276] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:21:33,276] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:21:33,276] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:21:33,280] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:21:33,280] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:21:33,293] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:21:33,295] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[09:21:33,306] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:21:33,308] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 29 ms on localhost (1/1)
[09:21:33,308] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:21:33,308] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.030 s
[09:21:33,309] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.197199 s
[09:21:33,319] INFO  {CodeGenerator} Code generated in 6.613664 ms
[09:21:33,326] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:21:33,327] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:21:33,327] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:21:33,327] INFO  {DAGScheduler} Parents of final stage: List()
[09:21:33,327] INFO  {DAGScheduler} Missing parents: List()
[09:21:33,327] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:21:33,329] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:21:33,331] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:21:33,332] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:37145 (size: 2.0 KB, free: 1128.9 MB)
[09:21:33,332] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:21:33,333] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:21:33,333] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:21:33,334] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:21:33,335] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:21:33,338] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:21:33,374] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:21:33,376] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 42 ms on localhost (1/1)
[09:21:33,376] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:21:33,376] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.043 s
[09:21:33,376] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.050442 s
[09:21:33,509] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:37145 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:21:33,511] INFO  {ContextCleaner} Cleaned accumulator 44
[09:21:33,511] INFO  {ContextCleaner} Cleaned accumulator 45
[09:21:33,512] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:37145 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 90
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 91
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 92
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 93
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 94
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 95
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 96
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 97
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 98
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 99
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 100
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 101
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 102
[09:21:33,516] INFO  {ContextCleaner} Cleaned shuffle 0
[09:21:33,517] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:37145 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:21:33,518] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:37145 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:21:33,586] INFO  {CodeGenerator} Code generated in 12.28617 ms
[09:21:33,603] INFO  {CodeGenerator} Code generated in 12.526978 ms
[09:21:33,617] INFO  {SparkContext} Starting job: show at Main.scala:48
[09:21:33,618] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:48)
[09:21:33,619] INFO  {DAGScheduler} Got job 4 (show at Main.scala:48) with 1 output partitions
[09:21:33,619] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:48)
[09:21:33,619] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:21:33,619] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:21:33,620] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:48), which has no missing parents
[09:21:33,623] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 14.0 KB, free 1128.7 MB)
[09:21:33,626] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.9 KB, free 1128.7 MB)
[09:21:33,627] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:37145 (size: 6.9 KB, free: 1128.9 MB)
[09:21:33,627] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:21:33,628] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:48)
[09:21:33,628] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:21:33,630] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:21:33,630] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:21:33,637] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:21:33,682] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:21:33,684] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 54 ms on localhost (1/1)
[09:21:33,684] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:21:33,684] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:48) finished in 0.056 s
[09:21:33,685] INFO  {DAGScheduler} looking for newly runnable stages
[09:21:33,685] INFO  {DAGScheduler} running: Set()
[09:21:33,685] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:21:33,685] INFO  {DAGScheduler} failed: Set()
[09:21:33,685] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:48), which has no missing parents
[09:21:33,688] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 7.7 KB, free 1128.7 MB)
[09:21:33,691] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1128.7 MB)
[09:21:33,692] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:37145 (size: 4.0 KB, free: 1128.9 MB)
[09:21:33,693] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:21:33,693] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:48)
[09:21:33,693] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:21:33,697] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:21:33,697] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:21:33,701] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:21:33,701] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:21:33,705] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1854 bytes result sent to driver
[09:21:33,706] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 11 ms on localhost (1/1)
[09:21:33,707] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:21:33,707] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:48) finished in 0.012 s
[09:21:33,707] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:48, took 0.089882 s
[09:21:33,722] INFO  {CodeGenerator} Code generated in 12.015744 ms
[09:21:33,727] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:21:33,732] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:21:33,734] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:21:33,734] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:21:33,738] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:21:33,738] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:21:33,738] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:21:33,740] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:21:33,748] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:21:33,754] INFO  {MemoryStore} MemoryStore cleared
[09:21:33,755] INFO  {BlockManager} BlockManager stopped
[09:21:33,756] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:21:33,759] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:21:33,761] INFO  {SparkContext} Successfully stopped SparkContext
[09:21:33,761] INFO  {ShutdownHookManager} Shutdown hook called
[09:21:33,762] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-e9d6bfe4-b523-4c1a-b92c-a8d6c245081a
[09:22:18,002] INFO  {SparkContext} Running Spark version 2.0.1
[09:22:18,226] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:22:18,329] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:22:18,330] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:22:18,417] INFO  {SecurityManager} Changing view acls to: victor
[09:22:18,418] INFO  {SecurityManager} Changing modify acls to: victor
[09:22:18,419] INFO  {SecurityManager} Changing view acls groups to: 
[09:22:18,422] INFO  {SecurityManager} Changing modify acls groups to: 
[09:22:18,423] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:22:18,754] INFO  {Utils} Successfully started service 'sparkDriver' on port 38635.
[09:22:18,771] INFO  {SparkEnv} Registering MapOutputTracker
[09:22:18,786] INFO  {SparkEnv} Registering BlockManagerMaster
[09:22:18,798] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-2faef6ba-2f2c-4318-a446-d723fba37948
[09:22:18,812] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:22:18,863] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:22:18,933] INFO  {log} Logging initialized @1543ms
[09:22:19,031] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:22:19,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:22:19,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:22:19,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:22:19,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:22:19,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:22:19,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:22:19,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:22:19,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:22:19,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:22:19,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:22:19,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:22:19,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:22:19,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:22:19,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:22:19,055] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:22:19,056] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:22:19,056] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:22:19,057] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:22:19,062] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:22:19,063] INFO  {Server} Started @1674ms
[09:22:19,063] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:22:19,065] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:22:19,140] INFO  {Executor} Starting executor ID driver on host localhost
[09:22:19,161] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34055.
[09:22:19,162] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:34055
[09:22:19,164] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 34055)
[09:22:19,167] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:34055 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 34055)
[09:22:19,170] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 34055)
[09:22:19,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:22:19,691] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:22:19,752] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:22:19,754] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:34055 (size: 14.3 KB, free: 1128.9 MB)
[09:22:19,761] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:22:19,894] INFO  {FileInputFormat} Total input paths to process : 1
[09:22:19,912] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:22:19,928] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:22:19,930] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:22:19,931] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:19,933] INFO  {DAGScheduler} Missing parents: List()
[09:22:19,944] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:22:20,015] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:22:20,018] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:22:20,019] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:34055 (size: 2.1 KB, free: 1128.9 MB)
[09:22:20,020] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:22:20,026] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:22:20,028] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:22:20,099] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:22:20,108] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:22:20,137] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:20,148] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:22:20,148] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:22:20,148] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:22:20,148] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:22:20,148] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:22:20,228] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:22:20,234] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 176 ms on localhost (1/1)
[09:22:20,235] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:22:20,239] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.197 s
[09:22:20,245] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.332971 s
[09:22:20,335] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:34055 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:22:21,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:22:21,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:22:21,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:22:21,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:22:21,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:22:21,654] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:22:22,376] INFO  {CodeGenerator} Code generated in 186.259555 ms
[09:22:22,410] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:22:22,412] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:22:22,412] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:22:22,412] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:22,412] INFO  {DAGScheduler} Missing parents: List()
[09:22:22,413] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:22:22,433] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:22:22,452] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:22:22,453] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:34055 (size: 5.5 KB, free: 1128.9 MB)
[09:22:22,454] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:22:22,454] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:22:22,454] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:22:22,457] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:22:22,458] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:22:22,473] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:22,494] INFO  {CodeGenerator} Code generated in 13.874675 ms
[09:22:22,516] INFO  {CodeGenerator} Code generated in 14.374296 ms
[09:22:22,519] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1466 bytes result sent to driver
[09:22:22,521] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 66 ms on localhost (1/1)
[09:22:22,521] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:22:22,522] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.067 s
[09:22:22,522] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.112307 s
[09:22:22,548] INFO  {CodeGenerator} Code generated in 15.174938 ms
[09:22:22,652] INFO  {CodeGenerator} Code generated in 12.276473 ms
[09:22:22,666] INFO  {CodeGenerator} Code generated in 9.675742 ms
[09:22:22,697] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:22:22,700] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:22:22,701] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:22:22,701] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:22:22,701] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:22:22,702] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:22:22,703] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:22:22,712] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:22:22,714] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:22:22,715] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:34055 (size: 6.6 KB, free: 1128.9 MB)
[09:22:22,716] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:22:22,717] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:22:22,718] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:22:22,721] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:22:22,721] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:22:22,728] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:22,867] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:22:22,870] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 152 ms on localhost (1/1)
[09:22:22,871] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:22:22,871] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.153 s
[09:22:22,872] INFO  {DAGScheduler} looking for newly runnable stages
[09:22:22,872] INFO  {DAGScheduler} running: Set()
[09:22:22,873] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:22:22,873] INFO  {DAGScheduler} failed: Set()
[09:22:22,874] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:22:22,879] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:22:22,881] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:22:22,882] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:34055 (size: 3.7 KB, free: 1128.9 MB)
[09:22:22,882] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:22:22,882] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:22:22,883] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:22:22,887] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:22:22,887] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:22:22,903] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:22:22,904] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 6 ms
[09:22:22,915] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:22:22,917] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 32 ms on localhost (1/1)
[09:22:22,917] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:22:22,918] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.032 s
[09:22:22,919] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.221699 s
[09:22:22,930] INFO  {CodeGenerator} Code generated in 7.122578 ms
[09:22:22,937] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:22:22,938] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:22:22,938] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:22:22,938] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:22,939] INFO  {DAGScheduler} Missing parents: List()
[09:22:22,939] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:22:22,942] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:22:22,944] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:22:22,944] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:34055 (size: 2.0 KB, free: 1128.9 MB)
[09:22:22,945] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:22:22,945] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:22:22,945] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:22:22,947] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:22:22,947] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:22:22,950] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:22,982] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:22:22,983] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 37 ms on localhost (1/1)
[09:22:22,983] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:22:22,983] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.037 s
[09:22:22,984] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.046384 s
[09:22:23,097] INFO  {ContextCleaner} Cleaned accumulator 44
[09:22:23,097] INFO  {ContextCleaner} Cleaned accumulator 45
[09:22:23,099] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:34055 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:22:23,099] INFO  {ContextCleaner} Cleaned accumulator 90
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 91
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 92
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 93
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 94
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 95
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 96
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 97
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 98
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 99
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 100
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 101
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 102
[09:22:23,104] INFO  {ContextCleaner} Cleaned shuffle 0
[09:22:23,105] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:34055 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:22:23,106] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:34055 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:22:23,108] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:34055 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:22:23,186] INFO  {CodeGenerator} Code generated in 16.992414 ms
[09:22:23,209] INFO  {CodeGenerator} Code generated in 14.782918 ms
[09:22:23,228] INFO  {SparkContext} Starting job: show at Main.scala:47
[09:22:23,230] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[09:22:23,230] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[09:22:23,230] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[09:22:23,230] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:22:23,230] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:22:23,231] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[09:22:23,234] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[09:22:23,236] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[09:22:23,237] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:34055 (size: 7.6 KB, free: 1128.9 MB)
[09:22:23,237] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:22:23,238] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[09:22:23,238] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:22:23,240] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:22:23,240] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:22:23,246] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:23,276] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:22:23,277] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 39 ms on localhost (1/1)
[09:22:23,277] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:22:23,278] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.040 s
[09:22:23,278] INFO  {DAGScheduler} looking for newly runnable stages
[09:22:23,278] INFO  {DAGScheduler} running: Set()
[09:22:23,278] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:22:23,278] INFO  {DAGScheduler} failed: Set()
[09:22:23,278] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[09:22:23,280] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[09:22:23,282] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[09:22:23,283] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:34055 (size: 4.6 KB, free: 1128.9 MB)
[09:22:23,283] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:22:23,283] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[09:22:23,283] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:22:23,285] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:22:23,285] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:22:23,289] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:22:23,289] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:22:23,293] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1858 bytes result sent to driver
[09:22:23,294] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 10 ms on localhost (1/1)
[09:22:23,294] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:22:23,294] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.010 s
[09:22:23,295] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.066115 s
[09:22:23,305] INFO  {CodeGenerator} Code generated in 8.396117 ms
[09:22:23,308] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:22:23,311] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:22:23,316] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:22:23,326] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:22:23,331] INFO  {MemoryStore} MemoryStore cleared
[09:22:23,331] INFO  {BlockManager} BlockManager stopped
[09:22:23,332] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:22:23,335] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:22:23,336] INFO  {SparkContext} Successfully stopped SparkContext
[09:22:23,337] INFO  {ShutdownHookManager} Shutdown hook called
[09:22:23,337] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-da71d3e8-a328-4259-bb06-4dab1c3fdda8
[09:22:35,139] INFO  {SparkContext} Running Spark version 2.0.1
[09:22:35,360] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:22:35,453] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:22:35,454] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:22:35,520] INFO  {SecurityManager} Changing view acls to: victor
[09:22:35,521] INFO  {SecurityManager} Changing modify acls to: victor
[09:22:35,522] INFO  {SecurityManager} Changing view acls groups to: 
[09:22:35,523] INFO  {SecurityManager} Changing modify acls groups to: 
[09:22:35,524] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:22:35,926] INFO  {Utils} Successfully started service 'sparkDriver' on port 36919.
[09:22:35,944] INFO  {SparkEnv} Registering MapOutputTracker
[09:22:35,959] INFO  {SparkEnv} Registering BlockManagerMaster
[09:22:35,971] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-9cd32d82-5941-46d7-ba18-9bbda1381796
[09:22:35,985] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:22:36,028] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:22:36,102] INFO  {log} Logging initialized @1540ms
[09:22:36,211] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:22:36,228] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[09:22:36,228] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[09:22:36,228] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[09:22:36,228] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[09:22:36,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[09:22:36,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[09:22:36,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[09:22:36,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[09:22:36,230] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[09:22:36,230] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[09:22:36,230] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[09:22:36,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[09:22:36,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[09:22:36,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[09:22:36,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[09:22:36,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[09:22:36,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[09:22:36,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[09:22:36,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[09:22:36,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[09:22:36,239] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[09:22:36,239] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[09:22:36,240] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[09:22:36,241] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[09:22:36,247] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[09:22:36,248] INFO  {Server} Started @1687ms
[09:22:36,248] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:22:36,251] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:22:36,344] INFO  {Executor} Starting executor ID driver on host localhost
[09:22:36,368] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44571.
[09:22:36,369] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:44571
[09:22:36,370] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 44571)
[09:22:36,373] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:44571 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 44571)
[09:22:36,376] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 44571)
[09:22:36,499] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[09:22:36,895] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:22:36,957] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:22:36,960] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:44571 (size: 14.3 KB, free: 1128.9 MB)
[09:22:36,966] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:22:37,096] INFO  {FileInputFormat} Total input paths to process : 1
[09:22:37,113] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:22:37,130] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:22:37,131] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:22:37,132] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:37,135] INFO  {DAGScheduler} Missing parents: List()
[09:22:37,146] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:22:37,215] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:22:37,218] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:22:37,219] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:44571 (size: 2.1 KB, free: 1128.9 MB)
[09:22:37,220] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:22:37,224] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:22:37,226] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:22:37,282] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:22:37,288] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:22:37,312] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:37,320] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:22:37,320] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:22:37,320] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:22:37,321] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:22:37,321] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:22:37,389] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[09:22:37,396] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 145 ms on localhost (1/1)
[09:22:37,397] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:22:37,402] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.165 s
[09:22:37,408] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.294925 s
[09:22:37,506] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:44571 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:22:38,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL,null,AVAILABLE}
[09:22:38,813] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@26d5a317{/SQL/json,null,AVAILABLE}
[09:22:38,813] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution,null,AVAILABLE}
[09:22:38,814] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@89caf47{/SQL/execution/json,null,AVAILABLE}
[09:22:38,815] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b24ea2a{/static/sql,null,AVAILABLE}
[09:22:38,824] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:22:39,504] INFO  {CodeGenerator} Code generated in 172.295374 ms
[09:22:39,531] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:22:39,532] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:22:39,533] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:22:39,533] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:39,533] INFO  {DAGScheduler} Missing parents: List()
[09:22:39,533] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:22:39,549] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:22:39,551] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:22:39,552] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:44571 (size: 5.5 KB, free: 1128.9 MB)
[09:22:39,552] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:22:39,553] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:22:39,553] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:22:39,555] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:22:39,555] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:22:39,568] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:39,593] INFO  {CodeGenerator} Code generated in 17.987036 ms
[09:22:39,624] INFO  {CodeGenerator} Code generated in 19.439276 ms
[09:22:39,627] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:22:39,629] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 76 ms on localhost (1/1)
[09:22:39,629] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:22:39,630] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.076 s
[09:22:39,630] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.098308 s
[09:22:39,656] INFO  {CodeGenerator} Code generated in 15.540176 ms
[09:22:39,705] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:44571 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:22:39,706] INFO  {ContextCleaner} Cleaned accumulator 44
[09:22:39,707] INFO  {ContextCleaner} Cleaned accumulator 45
[09:22:39,774] INFO  {CodeGenerator} Code generated in 11.341945 ms
[09:22:39,788] INFO  {CodeGenerator} Code generated in 8.814804 ms
[09:22:39,816] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:22:39,819] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:22:39,819] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:22:39,819] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:22:39,819] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:22:39,820] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:22:39,820] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:22:39,827] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:22:39,829] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:22:39,830] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:44571 (size: 6.6 KB, free: 1128.9 MB)
[09:22:39,831] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:22:39,832] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:22:39,832] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:22:39,836] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:22:39,836] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:22:39,847] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:39,983] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:22:39,986] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 153 ms on localhost (1/1)
[09:22:39,986] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:22:39,987] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.154 s
[09:22:39,988] INFO  {DAGScheduler} looking for newly runnable stages
[09:22:39,989] INFO  {DAGScheduler} running: Set()
[09:22:39,989] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:22:39,990] INFO  {DAGScheduler} failed: Set()
[09:22:39,991] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:22:39,996] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:22:39,998] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:22:39,998] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:44571 (size: 3.7 KB, free: 1128.9 MB)
[09:22:39,999] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:22:39,999] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:22:39,999] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:22:40,003] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:22:40,003] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:22:40,017] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:22:40,019] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[09:22:40,030] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:22:40,032] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 31 ms on localhost (1/1)
[09:22:40,032] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:22:40,033] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.032 s
[09:22:40,033] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.217160 s
[09:22:40,044] INFO  {CodeGenerator} Code generated in 6.95479 ms
[09:22:40,052] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:22:40,053] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:22:40,053] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:22:40,053] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:40,054] INFO  {DAGScheduler} Missing parents: List()
[09:22:40,054] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:22:40,057] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:22:40,059] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:22:40,059] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:44571 (size: 2.0 KB, free: 1128.9 MB)
[09:22:40,060] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:22:40,060] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:22:40,060] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:22:40,062] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:22:40,062] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:22:40,066] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:40,120] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:22:40,121] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 60 ms on localhost (1/1)
[09:22:40,121] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:22:40,122] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.061 s
[09:22:40,122] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.069742 s
[09:22:40,235] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:44571 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:22:40,236] INFO  {ContextCleaner} Cleaned accumulator 90
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 91
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 92
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 93
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 94
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 95
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 96
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 97
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 98
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 99
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 100
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 101
[09:22:40,238] INFO  {ContextCleaner} Cleaned accumulator 102
[09:22:40,241] INFO  {ContextCleaner} Cleaned shuffle 0
[09:22:40,243] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:44571 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:22:40,245] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:44571 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:22:40,273] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:22:40,277] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[09:22:40,278] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[09:22:40,278] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[09:22:40,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[09:22:40,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[09:22:40,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[09:22:40,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[09:22:40,282] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:22:40,292] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:22:40,296] INFO  {MemoryStore} MemoryStore cleared
[09:22:40,296] INFO  {BlockManager} BlockManager stopped
[09:22:40,298] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:22:40,299] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:22:40,301] INFO  {SparkContext} Successfully stopped SparkContext
[09:22:40,301] INFO  {ShutdownHookManager} Shutdown hook called
[09:22:40,302] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a332c959-9124-40d0-9cea-0e62d7d7b2a6
[09:23:10,792] INFO  {SparkContext} Running Spark version 2.0.1
[09:23:11,013] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:23:11,110] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:23:11,111] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:23:11,178] INFO  {SecurityManager} Changing view acls to: victor
[09:23:11,179] INFO  {SecurityManager} Changing modify acls to: victor
[09:23:11,180] INFO  {SecurityManager} Changing view acls groups to: 
[09:23:11,181] INFO  {SecurityManager} Changing modify acls groups to: 
[09:23:11,181] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:23:11,569] INFO  {Utils} Successfully started service 'sparkDriver' on port 42129.
[09:23:11,588] INFO  {SparkEnv} Registering MapOutputTracker
[09:23:11,603] INFO  {SparkEnv} Registering BlockManagerMaster
[09:23:11,616] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-274a810b-2b69-4418-8910-f02d9c2f34c5
[09:23:11,631] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:23:11,683] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:23:11,756] INFO  {log} Logging initialized @1580ms
[09:23:11,861] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:23:11,878] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:23:11,878] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:23:11,879] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:23:11,879] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:23:11,879] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:23:11,880] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:23:11,880] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:23:11,880] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:23:11,880] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:23:11,881] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:23:11,881] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:23:11,881] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:23:11,882] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:23:11,882] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:23:11,882] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:23:11,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:23:11,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:23:11,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:23:11,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:23:11,884] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:23:11,893] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:23:11,893] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:23:11,894] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:23:11,895] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:23:11,903] INFO  {ServerConnector} Started ServerConnector@43dbeaf4{HTTP/1.1}{0.0.0.0:4040}
[09:23:11,904] INFO  {Server} Started @1729ms
[09:23:11,904] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:23:11,907] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:23:12,005] INFO  {Executor} Starting executor ID driver on host localhost
[09:23:12,033] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33845.
[09:23:12,034] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:33845
[09:23:12,036] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 33845)
[09:23:12,039] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:33845 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 33845)
[09:23:12,042] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 33845)
[09:23:12,168] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:23:12,601] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:23:12,657] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:23:12,660] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:33845 (size: 14.3 KB, free: 1128.9 MB)
[09:23:12,665] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:23:12,812] INFO  {FileInputFormat} Total input paths to process : 1
[09:23:12,834] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:23:12,852] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:23:12,853] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:23:12,854] INFO  {DAGScheduler} Parents of final stage: List()
[09:23:12,856] INFO  {DAGScheduler} Missing parents: List()
[09:23:12,866] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:23:12,924] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:23:12,927] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:23:12,928] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:33845 (size: 2.1 KB, free: 1128.9 MB)
[09:23:12,928] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:23:12,931] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:23:12,933] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:23:12,980] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:23:12,989] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:23:13,013] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:23:13,022] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:23:13,022] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:23:13,022] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:23:13,022] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:23:13,022] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:23:13,088] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:23:13,095] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 138 ms on localhost (1/1)
[09:23:13,096] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:23:13,099] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.158 s
[09:23:13,104] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.269491 s
[09:23:13,204] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:33845 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:23:14,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:23:14,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:23:14,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:23:14,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:23:14,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:23:14,521] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:23:15,230] INFO  {CodeGenerator} Code generated in 183.650875 ms
[09:23:15,260] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:23:15,262] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:23:15,262] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:23:15,262] INFO  {DAGScheduler} Parents of final stage: List()
[09:23:15,262] INFO  {DAGScheduler} Missing parents: List()
[09:23:15,263] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:23:15,278] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:23:15,281] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:23:15,282] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:33845 (size: 5.5 KB, free: 1128.9 MB)
[09:23:15,283] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:23:15,283] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:23:15,283] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:23:15,286] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:23:15,287] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:23:15,318] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:23:15,339] INFO  {CodeGenerator} Code generated in 13.981869 ms
[09:23:15,360] INFO  {CodeGenerator} Code generated in 13.900065 ms
[09:23:15,363] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1452 bytes result sent to driver
[09:23:15,365] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 81 ms on localhost (1/1)
[09:23:15,365] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:23:15,366] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.082 s
[09:23:15,366] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.105503 s
[09:23:15,392] INFO  {CodeGenerator} Code generated in 15.021926 ms
[09:23:15,494] INFO  {CodeGenerator} Code generated in 11.226647 ms
[09:23:15,507] INFO  {CodeGenerator} Code generated in 9.41617 ms
[09:23:15,537] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:23:15,540] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:23:15,541] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:23:15,541] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:23:15,542] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:23:15,542] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:23:15,544] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:23:15,554] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:23:15,556] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:23:15,557] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:33845 (size: 6.6 KB, free: 1128.9 MB)
[09:23:15,557] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:23:15,560] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:23:15,560] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:23:15,563] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:23:15,563] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:23:15,572] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:23:15,726] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:23:15,729] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 168 ms on localhost (1/1)
[09:23:15,729] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:23:15,731] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.169 s
[09:23:15,732] INFO  {DAGScheduler} looking for newly runnable stages
[09:23:15,732] INFO  {DAGScheduler} running: Set()
[09:23:15,733] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:23:15,733] INFO  {DAGScheduler} failed: Set()
[09:23:15,734] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:23:15,740] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:23:15,742] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:23:15,743] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:33845 (size: 3.7 KB, free: 1128.9 MB)
[09:23:15,743] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:23:15,744] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:23:15,744] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:23:15,749] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:23:15,749] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:23:15,761] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:23:15,763] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[09:23:15,775] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:23:15,776] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 29 ms on localhost (1/1)
[09:23:15,776] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:23:15,777] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.030 s
[09:23:15,777] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.239750 s
[09:23:15,788] INFO  {CodeGenerator} Code generated in 6.936911 ms
[09:23:15,795] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:23:15,796] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:23:15,796] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:23:15,796] INFO  {DAGScheduler} Parents of final stage: List()
[09:23:15,796] INFO  {DAGScheduler} Missing parents: List()
[09:23:15,796] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:23:15,798] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:23:15,800] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:23:15,801] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:33845 (size: 2.0 KB, free: 1128.9 MB)
[09:23:15,801] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:23:15,801] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:23:15,801] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:23:15,803] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:23:15,803] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:23:15,809] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:23:15,851] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:23:15,853] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 51 ms on localhost (1/1)
[09:23:15,853] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:23:15,853] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.052 s
[09:23:15,854] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.058494 s
[09:23:15,959] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:33845 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:23:15,961] INFO  {ContextCleaner} Cleaned accumulator 44
[09:23:15,961] INFO  {ContextCleaner} Cleaned accumulator 45
[09:23:15,963] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:33845 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:23:15,963] INFO  {ContextCleaner} Cleaned accumulator 90
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 91
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 92
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 93
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 94
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 95
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 96
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 97
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 98
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 99
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 100
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 101
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 102
[09:23:15,968] INFO  {ContextCleaner} Cleaned shuffle 0
[09:23:15,969] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:33845 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:23:15,970] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:33845 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:23:16,058] INFO  {CodeGenerator} Code generated in 20.887189 ms
[09:23:16,081] INFO  {CodeGenerator} Code generated in 14.285161 ms
[09:23:16,094] INFO  {SparkContext} Starting job: show at Main.scala:47
[09:23:16,096] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[09:23:16,096] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[09:23:16,096] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[09:23:16,096] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:23:16,096] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:23:16,097] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[09:23:16,101] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[09:23:16,104] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[09:23:16,104] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:33845 (size: 7.6 KB, free: 1128.9 MB)
[09:23:16,105] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:23:16,105] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[09:23:16,105] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:23:16,107] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:23:16,107] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:23:16,112] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:23:16,145] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:23:16,146] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 40 ms on localhost (1/1)
[09:23:16,147] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:23:16,147] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.041 s
[09:23:16,147] INFO  {DAGScheduler} looking for newly runnable stages
[09:23:16,147] INFO  {DAGScheduler} running: Set()
[09:23:16,148] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:23:16,148] INFO  {DAGScheduler} failed: Set()
[09:23:16,148] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[09:23:16,150] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[09:23:16,153] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[09:23:16,154] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:33845 (size: 4.6 KB, free: 1128.9 MB)
[09:23:16,155] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:23:16,155] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[09:23:16,155] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:23:16,158] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:23:16,158] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:23:16,161] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:23:16,161] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:23:16,164] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1858 bytes result sent to driver
[09:23:16,166] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 9 ms on localhost (1/1)
[09:23:16,166] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:23:16,166] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.010 s
[09:23:16,167] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.072094 s
[09:23:16,177] INFO  {CodeGenerator} Code generated in 8.634441 ms
[09:23:16,181] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:23:16,184] INFO  {ServerConnector} Stopped ServerConnector@43dbeaf4{HTTP/1.1}{0.0.0.0:4040}
[09:23:16,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:23:16,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:23:16,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:23:16,189] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:23:16,189] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:23:16,190] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:23:16,198] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:23:16,203] INFO  {MemoryStore} MemoryStore cleared
[09:23:16,203] INFO  {BlockManager} BlockManager stopped
[09:23:16,204] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:23:16,206] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:23:16,208] INFO  {SparkContext} Successfully stopped SparkContext
[09:23:16,208] INFO  {ShutdownHookManager} Shutdown hook called
[09:23:16,209] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-bb67112f-e4c4-4034-b4eb-7bdd0ce02b40
[09:24:04,731] INFO  {SparkContext} Running Spark version 2.0.1
[09:24:04,944] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:24:05,050] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:24:05,051] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:24:05,111] INFO  {SecurityManager} Changing view acls to: victor
[09:24:05,111] INFO  {SecurityManager} Changing modify acls to: victor
[09:24:05,112] INFO  {SecurityManager} Changing view acls groups to: 
[09:24:05,113] INFO  {SecurityManager} Changing modify acls groups to: 
[09:24:05,113] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:24:05,476] INFO  {Utils} Successfully started service 'sparkDriver' on port 39915.
[09:24:05,494] INFO  {SparkEnv} Registering MapOutputTracker
[09:24:05,509] INFO  {SparkEnv} Registering BlockManagerMaster
[09:24:05,522] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-32d55a7e-2cf0-48bf-b322-20ad0e481b89
[09:24:05,538] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:24:05,588] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:24:05,659] INFO  {log} Logging initialized @1540ms
[09:24:05,768] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:24:05,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:24:05,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:24:05,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:24:05,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:24:05,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:24:05,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:24:05,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:24:05,788] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:24:05,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:24:05,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:24:05,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:24:05,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:24:05,801] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:24:05,802] INFO  {Server} Started @1683ms
[09:24:05,802] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:24:05,804] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:24:05,877] INFO  {Executor} Starting executor ID driver on host localhost
[09:24:05,897] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34171.
[09:24:05,898] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:34171
[09:24:05,900] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 34171)
[09:24:05,902] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:34171 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 34171)
[09:24:05,905] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 34171)
[09:24:06,030] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:24:06,448] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:24:06,509] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:24:06,512] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:34171 (size: 14.3 KB, free: 1128.9 MB)
[09:24:06,517] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:24:06,654] INFO  {FileInputFormat} Total input paths to process : 1
[09:24:06,673] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:24:06,693] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:24:06,693] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:24:06,694] INFO  {DAGScheduler} Parents of final stage: List()
[09:24:06,696] INFO  {DAGScheduler} Missing parents: List()
[09:24:06,707] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:24:06,770] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:24:06,773] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:24:06,774] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:34171 (size: 2.1 KB, free: 1128.9 MB)
[09:24:06,775] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:24:06,778] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:24:06,780] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:24:06,841] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:24:06,847] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:24:06,872] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:24:06,880] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:24:06,881] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:24:06,881] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:24:06,881] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:24:06,881] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:24:06,954] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:24:06,961] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 153 ms on localhost (1/1)
[09:24:06,962] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:24:06,966] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.174 s
[09:24:06,970] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.297371 s
[09:24:07,082] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:34171 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:24:08,455] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL,null,AVAILABLE}
[09:24:08,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@26d5a317{/SQL/json,null,AVAILABLE}
[09:24:08,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution,null,AVAILABLE}
[09:24:08,457] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@89caf47{/SQL/execution/json,null,AVAILABLE}
[09:24:08,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b24ea2a{/static/sql,null,AVAILABLE}
[09:24:08,468] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:24:09,221] INFO  {CodeGenerator} Code generated in 201.724266 ms
[09:24:09,250] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:24:09,252] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:24:09,252] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:24:09,252] INFO  {DAGScheduler} Parents of final stage: List()
[09:24:09,252] INFO  {DAGScheduler} Missing parents: List()
[09:24:09,253] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:24:09,273] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:24:09,275] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:24:09,275] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:34171 (size: 5.5 KB, free: 1128.9 MB)
[09:24:09,276] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:24:09,276] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:24:09,276] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:24:09,279] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:24:09,279] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:24:09,293] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:24:09,315] INFO  {CodeGenerator} Code generated in 15.39429 ms
[09:24:09,340] INFO  {CodeGenerator} Code generated in 15.858651 ms
[09:24:09,344] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:24:09,346] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 69 ms on localhost (1/1)
[09:24:09,346] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:24:09,346] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.069 s
[09:24:09,347] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.096340 s
[09:24:09,377] INFO  {CodeGenerator} Code generated in 17.332579 ms
[09:24:09,505] INFO  {CodeGenerator} Code generated in 12.274558 ms
[09:24:09,519] INFO  {CodeGenerator} Code generated in 9.649911 ms
[09:24:09,550] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:24:09,553] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:24:09,554] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:24:09,554] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:24:09,554] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:24:09,554] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:24:09,555] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:24:09,562] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:24:09,564] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:24:09,564] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:34171 (size: 6.6 KB, free: 1128.9 MB)
[09:24:09,565] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:24:09,566] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:24:09,567] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:24:09,569] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:24:09,569] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:24:09,578] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:24:09,687] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:24:09,690] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 122 ms on localhost (1/1)
[09:24:09,690] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:24:09,691] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.124 s
[09:24:09,692] INFO  {DAGScheduler} looking for newly runnable stages
[09:24:09,692] INFO  {DAGScheduler} running: Set()
[09:24:09,692] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:24:09,693] INFO  {DAGScheduler} failed: Set()
[09:24:09,695] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:24:09,702] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:24:09,704] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:24:09,704] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:34171 (size: 3.7 KB, free: 1128.9 MB)
[09:24:09,705] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:24:09,705] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:24:09,705] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:24:09,710] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:24:09,711] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:24:09,725] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:24:09,727] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[09:24:09,739] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1960 bytes result sent to driver
[09:24:09,741] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 33 ms on localhost (1/1)
[09:24:09,741] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:24:09,742] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.034 s
[09:24:09,743] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.191942 s
[09:24:09,753] INFO  {CodeGenerator} Code generated in 6.914037 ms
[09:24:09,759] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:24:09,760] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:24:09,760] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:24:09,760] INFO  {DAGScheduler} Parents of final stage: List()
[09:24:09,761] INFO  {DAGScheduler} Missing parents: List()
[09:24:09,761] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:24:09,763] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:24:09,764] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:24:09,765] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:34171 (size: 2.0 KB, free: 1128.9 MB)
[09:24:09,766] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:24:09,766] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:24:09,766] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:24:09,768] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:24:09,768] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:24:09,772] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:24:09,809] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:24:09,810] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 43 ms on localhost (1/1)
[09:24:09,810] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:24:09,811] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.045 s
[09:24:09,811] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.051351 s
[09:24:09,935] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:34171 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:24:09,939] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:34171 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:24:09,941] INFO  {ContextCleaner} Cleaned accumulator 44
[09:24:09,941] INFO  {ContextCleaner} Cleaned accumulator 45
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 90
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 91
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 92
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 93
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 94
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 95
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 96
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 97
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 98
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 99
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 100
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 101
[09:24:09,943] INFO  {ContextCleaner} Cleaned accumulator 102
[09:24:09,946] INFO  {ContextCleaner} Cleaned shuffle 0
[09:24:09,948] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:34171 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:24:09,950] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:34171 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:24:10,004] INFO  {CodeGenerator} Code generated in 15.560166 ms
[09:24:10,028] INFO  {CodeGenerator} Code generated in 14.450904 ms
[09:24:10,041] INFO  {SparkContext} Starting job: show at Main.scala:47
[09:24:10,042] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[09:24:10,043] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[09:24:10,043] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[09:24:10,043] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:24:10,043] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:24:10,044] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[09:24:10,047] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[09:24:10,049] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[09:24:10,049] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:34171 (size: 7.6 KB, free: 1128.9 MB)
[09:24:10,050] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:24:10,050] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[09:24:10,050] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:24:10,052] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:24:10,052] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:24:10,057] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:24:10,087] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:24:10,089] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 38 ms on localhost (1/1)
[09:24:10,089] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:24:10,089] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.038 s
[09:24:10,089] INFO  {DAGScheduler} looking for newly runnable stages
[09:24:10,090] INFO  {DAGScheduler} running: Set()
[09:24:10,090] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:24:10,090] INFO  {DAGScheduler} failed: Set()
[09:24:10,090] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[09:24:10,092] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[09:24:10,094] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[09:24:10,095] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:34171 (size: 4.6 KB, free: 1128.9 MB)
[09:24:10,095] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:24:10,095] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[09:24:10,095] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:24:10,097] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:24:10,098] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:24:10,100] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:24:10,100] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:24:10,104] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1858 bytes result sent to driver
[09:24:10,105] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 8 ms on localhost (1/1)
[09:24:10,105] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:24:10,105] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.009 s
[09:24:10,106] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.064344 s
[09:24:10,116] INFO  {CodeGenerator} Code generated in 8.364947 ms
[09:24:10,119] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:24:10,123] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:24:10,125] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:24:10,125] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:24:10,125] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:24:10,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:24:10,129] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:24:10,140] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:24:10,145] INFO  {MemoryStore} MemoryStore cleared
[09:24:10,146] INFO  {BlockManager} BlockManager stopped
[09:24:10,147] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:24:10,149] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:24:10,152] INFO  {SparkContext} Successfully stopped SparkContext
[09:24:10,152] INFO  {ShutdownHookManager} Shutdown hook called
[09:24:10,154] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-faae2d92-be7a-4dc4-aedb-bd50793e84e0
[09:49:59,385] INFO  {SparkContext} Running Spark version 2.0.1
[09:49:59,607] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:49:59,694] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:49:59,694] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:49:59,754] INFO  {SecurityManager} Changing view acls to: victor
[09:49:59,754] INFO  {SecurityManager} Changing modify acls to: victor
[09:49:59,755] INFO  {SecurityManager} Changing view acls groups to: 
[09:49:59,756] INFO  {SecurityManager} Changing modify acls groups to: 
[09:49:59,757] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:50:00,123] INFO  {Utils} Successfully started service 'sparkDriver' on port 43719.
[09:50:00,141] INFO  {SparkEnv} Registering MapOutputTracker
[09:50:00,155] INFO  {SparkEnv} Registering BlockManagerMaster
[09:50:00,168] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-981af496-622b-4a54-8446-5492750418e1
[09:50:00,182] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:50:00,242] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:50:00,310] INFO  {log} Logging initialized @1530ms
[09:50:00,409] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:50:00,425] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:50:00,425] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:50:00,425] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:50:00,425] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:50:00,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:50:00,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:50:00,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:50:00,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:50:00,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:50:00,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:50:00,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:50:00,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:50:00,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:50:00,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:50:00,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:50:00,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:50:00,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:50:00,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:50:00,443] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:50:00,443] INFO  {Server} Started @1663ms
[09:50:00,443] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:50:00,446] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:50:00,531] INFO  {Executor} Starting executor ID driver on host localhost
[09:50:00,555] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45379.
[09:50:00,556] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:45379
[09:50:00,558] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 45379)
[09:50:00,561] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:45379 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 45379)
[09:50:00,564] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 45379)
[09:50:00,690] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:50:01,128] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:50:01,186] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:50:01,188] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:45379 (size: 14.3 KB, free: 1128.9 MB)
[09:50:01,194] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:50:01,329] INFO  {FileInputFormat} Total input paths to process : 1
[09:50:01,349] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:50:01,366] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:50:01,367] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:50:01,368] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:01,370] INFO  {DAGScheduler} Missing parents: List()
[09:50:01,381] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:50:01,437] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:50:01,440] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:50:01,440] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:45379 (size: 2.1 KB, free: 1128.9 MB)
[09:50:01,441] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:50:01,445] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:50:01,446] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:50:01,494] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:50:01,501] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:50:01,525] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:01,533] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:50:01,534] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:50:01,534] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:50:01,534] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:50:01,534] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:50:01,606] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:50:01,614] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 146 ms on localhost (1/1)
[09:50:01,616] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:50:01,620] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.164 s
[09:50:01,626] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.276235 s
[09:50:01,711] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:45379 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:50:03,058] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:50:03,058] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:50:03,059] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:50:03,059] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:50:03,061] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:50:03,070] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:50:03,811] INFO  {CodeGenerator} Code generated in 185.424048 ms
[09:50:03,840] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:50:03,842] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:50:03,842] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:50:03,842] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:03,843] INFO  {DAGScheduler} Missing parents: List()
[09:50:03,843] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:50:03,860] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:50:03,875] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:50:03,876] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:45379 (size: 5.5 KB, free: 1128.9 MB)
[09:50:03,877] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:50:03,877] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:50:03,877] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:50:03,879] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:50:03,880] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:50:03,897] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:03,925] INFO  {CodeGenerator} Code generated in 19.548092 ms
[09:50:03,953] INFO  {CodeGenerator} Code generated in 18.73467 ms
[09:50:03,957] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:50:03,958] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 80 ms on localhost (1/1)
[09:50:03,958] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:50:03,959] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.082 s
[09:50:03,959] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.118458 s
[09:50:03,986] INFO  {CodeGenerator} Code generated in 14.493203 ms
[09:50:04,086] INFO  {CodeGenerator} Code generated in 11.595864 ms
[09:50:04,099] INFO  {CodeGenerator} Code generated in 9.035518 ms
[09:50:04,128] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:50:04,131] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:50:04,132] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:50:04,132] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:50:04,132] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:50:04,132] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:50:04,133] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:50:04,141] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:50:04,142] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:50:04,143] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:45379 (size: 6.6 KB, free: 1128.9 MB)
[09:50:04,144] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:50:04,146] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:50:04,146] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:50:04,148] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:50:04,148] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:50:04,160] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:04,295] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:50:04,297] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 151 ms on localhost (1/1)
[09:50:04,297] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:50:04,298] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.152 s
[09:50:04,299] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:04,299] INFO  {DAGScheduler} running: Set()
[09:50:04,299] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:50:04,300] INFO  {DAGScheduler} failed: Set()
[09:50:04,301] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:50:04,306] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:50:04,308] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:50:04,308] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:45379 (size: 3.7 KB, free: 1128.9 MB)
[09:50:04,309] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:50:04,309] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:50:04,309] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:50:04,313] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:50:04,314] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:50:04,328] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:04,329] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[09:50:04,341] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1960 bytes result sent to driver
[09:50:04,343] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 31 ms on localhost (1/1)
[09:50:04,343] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:50:04,343] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.031 s
[09:50:04,345] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.216611 s
[09:50:04,359] INFO  {CodeGenerator} Code generated in 8.920652 ms
[09:50:04,369] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:50:04,370] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:50:04,370] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:50:04,370] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:04,370] INFO  {DAGScheduler} Missing parents: List()
[09:50:04,371] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:50:04,374] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:50:04,376] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:50:04,376] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:45379 (size: 2.0 KB, free: 1128.9 MB)
[09:50:04,377] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:50:04,377] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:50:04,377] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:50:04,379] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:50:04,379] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:50:04,382] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:04,417] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:50:04,418] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 40 ms on localhost (1/1)
[09:50:04,418] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:50:04,419] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.042 s
[09:50:04,419] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.050343 s
[09:50:04,529] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:45379 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:50:04,531] INFO  {ContextCleaner} Cleaned accumulator 44
[09:50:04,531] INFO  {ContextCleaner} Cleaned accumulator 45
[09:50:04,532] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:45379 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 90
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 91
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 92
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 93
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 94
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 95
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 96
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 97
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 98
[09:50:04,534] INFO  {ContextCleaner} Cleaned accumulator 99
[09:50:04,534] INFO  {ContextCleaner} Cleaned accumulator 100
[09:50:04,534] INFO  {ContextCleaner} Cleaned accumulator 101
[09:50:04,534] INFO  {ContextCleaner} Cleaned accumulator 102
[09:50:04,537] INFO  {ContextCleaner} Cleaned shuffle 0
[09:50:04,538] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:45379 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:50:04,539] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:45379 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:50:04,604] INFO  {CodeGenerator} Code generated in 16.135308 ms
[09:50:04,627] INFO  {CodeGenerator} Code generated in 15.182145 ms
[09:50:04,641] INFO  {SparkContext} Starting job: show at Main.scala:47
[09:50:04,642] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[09:50:04,644] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[09:50:04,644] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[09:50:04,644] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:50:04,644] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:50:04,645] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[09:50:04,648] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[09:50:04,651] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[09:50:04,652] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:45379 (size: 7.6 KB, free: 1128.9 MB)
[09:50:04,652] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:50:04,652] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[09:50:04,653] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:50:04,655] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:50:04,655] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:50:04,661] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:04,706] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:50:04,707] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 54 ms on localhost (1/1)
[09:50:04,707] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:50:04,708] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.055 s
[09:50:04,708] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:04,708] INFO  {DAGScheduler} running: Set()
[09:50:04,708] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:50:04,708] INFO  {DAGScheduler} failed: Set()
[09:50:04,709] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[09:50:04,710] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[09:50:04,712] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[09:50:04,713] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:45379 (size: 4.6 KB, free: 1128.9 MB)
[09:50:04,713] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:50:04,714] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[09:50:04,714] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:50:04,716] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:50:04,716] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:50:04,720] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:04,720] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:50:04,724] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1858 bytes result sent to driver
[09:50:04,726] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 11 ms on localhost (1/1)
[09:50:04,726] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:50:04,726] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.012 s
[09:50:04,727] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.084960 s
[09:50:04,738] INFO  {CodeGenerator} Code generated in 9.0091 ms
[09:50:04,799] INFO  {SparkContext} Starting job: foreach at Main.scala:61
[09:50:04,801] INFO  {DAGScheduler} Registering RDD 23 (groupBy at Main.scala:51)
[09:50:04,801] INFO  {DAGScheduler} Got job 5 (foreach at Main.scala:61) with 1 output partitions
[09:50:04,801] INFO  {DAGScheduler} Final stage: ResultStage 8 (foreach at Main.scala:61)
[09:50:04,802] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 7)
[09:50:04,802] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 7)
[09:50:04,802] INFO  {DAGScheduler} Submitting ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51), which has no missing parents
[09:50:04,812] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 5.4 KB, free 1128.7 MB)
[09:50:04,814] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1128.7 MB)
[09:50:04,815] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.111:45379 (size: 2.9 KB, free: 1128.9 MB)
[09:50:04,816] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[09:50:04,816] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51)
[09:50:04,816] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[09:50:04,818] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5443 bytes)
[09:50:04,819] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[09:50:04,829] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:04,862] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1244 bytes result sent to driver
[09:50:04,863] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 47 ms on localhost (1/1)
[09:50:04,863] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[09:50:04,863] INFO  {DAGScheduler} ShuffleMapStage 7 (groupBy at Main.scala:51) finished in 0.047 s
[09:50:04,863] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:04,863] INFO  {DAGScheduler} running: Set()
[09:50:04,863] INFO  {DAGScheduler} waiting: Set(ResultStage 8)
[09:50:04,864] INFO  {DAGScheduler} failed: Set()
[09:50:04,864] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[25] at map at Main.scala:52), which has no missing parents
[09:50:04,870] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 6.4 KB, free 1128.7 MB)
[09:50:04,872] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1128.7 MB)
[09:50:04,873] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.111:45379 (size: 3.2 KB, free: 1128.9 MB)
[09:50:04,873] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[09:50:04,873] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[25] at map at Main.scala:52)
[09:50:04,874] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[09:50:04,876] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, ANY, 5183 bytes)
[09:50:04,876] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[09:50:04,880] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:04,880] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:50:04,988] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 1640 bytes result sent to driver
[09:50:04,989] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 115 ms on localhost (1/1)
[09:50:04,990] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[09:50:04,990] INFO  {DAGScheduler} ResultStage 8 (foreach at Main.scala:61) finished in 0.116 s
[09:50:04,991] INFO  {DAGScheduler} Job 5 finished: foreach at Main.scala:61, took 0.191154 s
[09:50:04,994] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:50:05,000] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:50:05,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:50:05,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:50:05,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:50:05,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:50:05,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:50:05,008] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:50:05,023] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:50:05,032] INFO  {MemoryStore} MemoryStore cleared
[09:50:05,032] INFO  {BlockManager} BlockManager stopped
[09:50:05,033] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:50:05,035] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:50:05,037] INFO  {SparkContext} Successfully stopped SparkContext
[09:50:05,038] INFO  {ShutdownHookManager} Shutdown hook called
[09:50:05,038] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-bc1a8eb4-45ad-4191-aae7-7c88aa3fa316
[09:50:38,547] INFO  {SparkContext} Running Spark version 2.0.1
[09:50:38,743] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:50:38,820] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:50:38,820] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:50:38,884] INFO  {SecurityManager} Changing view acls to: victor
[09:50:38,884] INFO  {SecurityManager} Changing modify acls to: victor
[09:50:38,885] INFO  {SecurityManager} Changing view acls groups to: 
[09:50:38,885] INFO  {SecurityManager} Changing modify acls groups to: 
[09:50:38,886] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:50:39,307] INFO  {Utils} Successfully started service 'sparkDriver' on port 36867.
[09:50:39,325] INFO  {SparkEnv} Registering MapOutputTracker
[09:50:39,342] INFO  {SparkEnv} Registering BlockManagerMaster
[09:50:39,359] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-6c17d498-94bc-45a7-871b-82d7a9bae8a1
[09:50:39,374] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:50:39,440] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:50:39,511] INFO  {log} Logging initialized @1522ms
[09:50:39,608] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:50:39,624] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:50:39,624] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:50:39,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:50:39,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:50:39,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:50:39,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:50:39,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:50:39,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:50:39,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:50:39,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:50:39,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:50:39,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:50:39,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:50:39,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:50:39,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:50:39,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:50:39,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:50:39,628] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:50:39,628] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:50:39,628] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:50:39,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:50:39,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:50:39,635] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:50:39,636] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:50:39,642] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:50:39,642] INFO  {Server} Started @1654ms
[09:50:39,642] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:50:39,644] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:50:39,723] INFO  {Executor} Starting executor ID driver on host localhost
[09:50:39,745] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45389.
[09:50:39,746] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:45389
[09:50:39,747] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 45389)
[09:50:39,751] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:45389 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 45389)
[09:50:39,754] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 45389)
[09:50:39,876] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:50:40,315] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:50:40,386] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:50:40,388] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:45389 (size: 14.3 KB, free: 1128.9 MB)
[09:50:40,393] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:50:40,520] INFO  {FileInputFormat} Total input paths to process : 1
[09:50:40,540] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:50:40,550] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:50:40,551] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:50:40,551] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:40,552] INFO  {DAGScheduler} Missing parents: List()
[09:50:40,559] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:50:40,610] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:50:40,613] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:50:40,614] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:45389 (size: 2.1 KB, free: 1128.9 MB)
[09:50:40,615] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:50:40,619] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:50:40,621] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:50:40,664] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:50:40,671] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:50:40,697] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:40,705] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:50:40,705] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:50:40,705] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:50:40,705] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:50:40,705] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:50:40,774] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:50:40,783] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 138 ms on localhost (1/1)
[09:50:40,784] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:50:40,787] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.155 s
[09:50:40,792] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.251882 s
[09:50:40,896] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:45389 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:50:42,224] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:50:42,224] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:50:42,225] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:50:42,225] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:50:42,226] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:50:42,236] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:50:42,939] INFO  {CodeGenerator} Code generated in 180.211045 ms
[09:50:42,981] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:50:42,982] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:50:42,983] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:50:42,983] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:42,983] INFO  {DAGScheduler} Missing parents: List()
[09:50:42,983] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:50:42,998] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:50:43,000] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:50:43,000] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:45389 (size: 5.5 KB, free: 1128.9 MB)
[09:50:43,001] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:50:43,001] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:50:43,001] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:50:43,003] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:50:43,004] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:50:43,016] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:43,037] INFO  {CodeGenerator} Code generated in 14.505346 ms
[09:50:43,058] INFO  {CodeGenerator} Code generated in 13.729221 ms
[09:50:43,062] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:50:43,063] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 61 ms on localhost (1/1)
[09:50:43,063] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:50:43,064] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.063 s
[09:50:43,064] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.082779 s
[09:50:43,087] INFO  {CodeGenerator} Code generated in 13.472337 ms
[09:50:43,191] INFO  {CodeGenerator} Code generated in 11.661845 ms
[09:50:43,204] INFO  {CodeGenerator} Code generated in 8.987698 ms
[09:50:43,234] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:50:43,236] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:50:43,237] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:50:43,237] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:50:43,237] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:50:43,237] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:50:43,239] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:50:43,246] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:50:43,248] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:50:43,249] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:45389 (size: 6.6 KB, free: 1128.9 MB)
[09:50:43,249] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:50:43,251] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:50:43,251] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:50:43,254] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:50:43,254] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:50:43,263] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:43,373] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:50:43,376] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 124 ms on localhost (1/1)
[09:50:43,376] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:50:43,377] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.125 s
[09:50:43,377] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:43,378] INFO  {DAGScheduler} running: Set()
[09:50:43,378] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:50:43,379] INFO  {DAGScheduler} failed: Set()
[09:50:43,380] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:50:43,386] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:50:43,388] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:50:43,388] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:45389 (size: 3.7 KB, free: 1128.9 MB)
[09:50:43,389] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:50:43,389] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:50:43,389] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:50:43,394] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:50:43,394] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:50:43,407] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:43,408] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[09:50:43,421] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:50:43,423] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 31 ms on localhost (1/1)
[09:50:43,423] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:50:43,424] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.031 s
[09:50:43,424] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.190042 s
[09:50:43,434] INFO  {CodeGenerator} Code generated in 7.113293 ms
[09:50:43,441] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:50:43,441] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:50:43,442] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:50:43,442] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:43,442] INFO  {DAGScheduler} Missing parents: List()
[09:50:43,442] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:50:43,444] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:50:43,446] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:50:43,446] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:45389 (size: 2.0 KB, free: 1128.9 MB)
[09:50:43,447] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:50:43,447] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:50:43,447] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:50:43,449] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:50:43,449] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:50:43,452] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:43,505] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:50:43,507] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 58 ms on localhost (1/1)
[09:50:43,507] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:50:43,507] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.060 s
[09:50:43,508] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.066827 s
[09:50:43,643] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:45389 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:50:43,645] INFO  {ContextCleaner} Cleaned accumulator 44
[09:50:43,645] INFO  {ContextCleaner} Cleaned accumulator 45
[09:50:43,646] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:45389 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:50:43,647] INFO  {ContextCleaner} Cleaned accumulator 90
[09:50:43,647] INFO  {ContextCleaner} Cleaned accumulator 91
[09:50:43,647] INFO  {ContextCleaner} Cleaned accumulator 92
[09:50:43,647] INFO  {ContextCleaner} Cleaned accumulator 93
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 94
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 95
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 96
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 97
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 98
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 99
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 100
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 101
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 102
[09:50:43,653] INFO  {ContextCleaner} Cleaned shuffle 0
[09:50:43,654] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:45389 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:50:43,656] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:45389 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:50:43,710] INFO  {CodeGenerator} Code generated in 16.072226 ms
[09:50:43,734] INFO  {CodeGenerator} Code generated in 14.706132 ms
[09:50:43,747] INFO  {SparkContext} Starting job: show at Main.scala:47
[09:50:43,748] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[09:50:43,748] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[09:50:43,748] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[09:50:43,748] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:50:43,749] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:50:43,749] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[09:50:43,752] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[09:50:43,754] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[09:50:43,755] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:45389 (size: 7.6 KB, free: 1128.9 MB)
[09:50:43,755] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:50:43,755] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[09:50:43,756] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:50:43,758] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:50:43,758] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:50:43,763] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:43,792] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:50:43,794] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 37 ms on localhost (1/1)
[09:50:43,794] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:50:43,794] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.038 s
[09:50:43,794] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:43,794] INFO  {DAGScheduler} running: Set()
[09:50:43,794] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:50:43,795] INFO  {DAGScheduler} failed: Set()
[09:50:43,795] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[09:50:43,797] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[09:50:43,798] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[09:50:43,799] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:45389 (size: 4.6 KB, free: 1128.9 MB)
[09:50:43,799] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:50:43,800] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[09:50:43,800] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:50:43,801] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:50:43,802] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:50:43,805] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:43,805] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:50:43,809] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1858 bytes result sent to driver
[09:50:43,810] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 10 ms on localhost (1/1)
[09:50:43,811] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:50:43,811] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.011 s
[09:50:43,811] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.064343 s
[09:50:43,821] INFO  {CodeGenerator} Code generated in 8.001598 ms
[09:50:43,872] INFO  {SparkContext} Starting job: foreach at Main.scala:61
[09:50:43,875] INFO  {DAGScheduler} Registering RDD 23 (groupBy at Main.scala:51)
[09:50:43,875] INFO  {DAGScheduler} Registering RDD 26 (sortBy at Main.scala:61)
[09:50:43,875] INFO  {DAGScheduler} Got job 5 (foreach at Main.scala:61) with 1 output partitions
[09:50:43,875] INFO  {DAGScheduler} Final stage: ResultStage 9 (foreach at Main.scala:61)
[09:50:43,875] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 8)
[09:50:43,876] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 8)
[09:50:43,876] INFO  {DAGScheduler} Submitting ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51), which has no missing parents
[09:50:43,883] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 5.4 KB, free 1128.7 MB)
[09:50:43,885] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1128.7 MB)
[09:50:43,886] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.111:45389 (size: 2.9 KB, free: 1128.9 MB)
[09:50:43,887] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[09:50:43,887] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51)
[09:50:43,887] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[09:50:43,889] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5443 bytes)
[09:50:43,890] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[09:50:43,895] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:43,943] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1244 bytes result sent to driver
[09:50:43,944] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 56 ms on localhost (1/1)
[09:50:43,945] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[09:50:43,945] INFO  {DAGScheduler} ShuffleMapStage 7 (groupBy at Main.scala:51) finished in 0.058 s
[09:50:43,945] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:43,945] INFO  {DAGScheduler} running: Set()
[09:50:43,945] INFO  {DAGScheduler} waiting: Set(ResultStage 9, ShuffleMapStage 8)
[09:50:43,945] INFO  {DAGScheduler} failed: Set()
[09:50:43,946] INFO  {DAGScheduler} Submitting ShuffleMapStage 8 (MapPartitionsRDD[26] at sortBy at Main.scala:61), which has no missing parents
[09:50:43,958] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 6.9 KB, free 1128.7 MB)
[09:50:43,960] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.5 KB, free 1128.7 MB)
[09:50:43,961] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.111:45389 (size: 3.5 KB, free: 1128.9 MB)
[09:50:43,962] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[09:50:43,962] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[26] at sortBy at Main.scala:61)
[09:50:43,962] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[09:50:43,965] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, ANY, 5172 bytes)
[09:50:43,966] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[09:50:43,973] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:43,973] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:50:44,081] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 1881 bytes result sent to driver
[09:50:44,083] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 120 ms on localhost (1/1)
[09:50:44,084] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[09:50:44,084] INFO  {DAGScheduler} ShuffleMapStage 8 (sortBy at Main.scala:61) finished in 0.121 s
[09:50:44,084] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:44,084] INFO  {DAGScheduler} running: Set()
[09:50:44,084] INFO  {DAGScheduler} waiting: Set(ResultStage 9)
[09:50:44,084] INFO  {DAGScheduler} failed: Set()
[09:50:44,085] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[28] at sortBy at Main.scala:61), which has no missing parents
[09:50:44,087] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:50:44,089] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 2003.0 B, free 1128.7 MB)
[09:50:44,090] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.111:45389 (size: 2003.0 B, free: 1128.9 MB)
[09:50:44,091] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[09:50:44,091] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[28] at sortBy at Main.scala:61)
[09:50:44,091] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[09:50:44,093] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, ANY, 5183 bytes)
[09:50:44,093] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[09:50:44,097] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:44,097] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[09:50:44,136] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 1553 bytes result sent to driver
[09:50:44,137] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 45 ms on localhost (1/1)
[09:50:44,137] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[09:50:44,138] INFO  {DAGScheduler} ResultStage 9 (foreach at Main.scala:61) finished in 0.046 s
[09:50:44,138] INFO  {DAGScheduler} Job 5 finished: foreach at Main.scala:61, took 0.266292 s
[09:50:44,142] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:50:44,148] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:50:44,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:50:44,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:50:44,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:50:44,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:50:44,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:50:44,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:50:44,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:50:44,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:50:44,157] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:50:44,171] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:50:44,180] INFO  {MemoryStore} MemoryStore cleared
[09:50:44,180] INFO  {BlockManager} BlockManager stopped
[09:50:44,182] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:50:44,186] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:50:44,191] INFO  {SparkContext} Successfully stopped SparkContext
[09:50:44,192] INFO  {ShutdownHookManager} Shutdown hook called
[09:50:44,193] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a883287c-ce27-4caa-85a8-4b305dc23f28
[11:47:35,750] INFO  {SparkContext} Running Spark version 2.0.1
[11:47:36,001] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[11:47:36,099] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[11:47:36,100] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[11:47:36,185] INFO  {SecurityManager} Changing view acls to: victor
[11:47:36,186] INFO  {SecurityManager} Changing modify acls to: victor
[11:47:36,187] INFO  {SecurityManager} Changing view acls groups to: 
[11:47:36,188] INFO  {SecurityManager} Changing modify acls groups to: 
[11:47:36,189] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[11:47:36,557] INFO  {Utils} Successfully started service 'sparkDriver' on port 43143.
[11:47:36,573] INFO  {SparkEnv} Registering MapOutputTracker
[11:47:36,588] INFO  {SparkEnv} Registering BlockManagerMaster
[11:47:36,601] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-7f81d7e6-d3b3-497b-bd80-91da2690efe0
[11:47:36,615] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[11:47:36,659] INFO  {SparkEnv} Registering OutputCommitCoordinator
[11:47:36,731] INFO  {log} Logging initialized @1698ms
[11:47:36,842] INFO  {Server} jetty-9.2.z-SNAPSHOT
[11:47:36,858] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[11:47:36,858] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[11:47:36,858] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[11:47:36,859] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[11:47:36,859] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[11:47:36,859] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[11:47:36,859] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[11:47:36,859] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[11:47:36,860] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[11:47:36,860] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[11:47:36,860] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[11:47:36,860] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[11:47:36,860] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[11:47:36,861] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[11:47:36,861] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[11:47:36,861] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[11:47:36,861] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[11:47:36,861] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[11:47:36,861] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[11:47:36,862] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[11:47:36,868] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[11:47:36,868] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[11:47:36,869] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[11:47:36,869] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[11:47:36,875] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[11:47:36,875] INFO  {Server} Started @1844ms
[11:47:36,875] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[11:47:36,878] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[11:47:36,949] INFO  {Executor} Starting executor ID driver on host localhost
[11:47:36,973] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36733.
[11:47:36,975] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:36733
[11:47:36,978] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 36733)
[11:47:36,981] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:36733 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 36733)
[11:47:36,984] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 36733)
[11:47:37,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[11:47:37,154] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[11:47:37,156] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[11:47:37,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[11:47:37,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[11:47:37,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[11:47:37,174] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[11:47:38,877] INFO  {SparkContext} Invoking stop() from shutdown hook
[11:47:38,882] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[11:47:38,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[11:47:38,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[11:47:38,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[11:47:38,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[11:47:38,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[11:47:38,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[11:47:38,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[11:47:38,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[11:47:38,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[11:47:38,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[11:47:38,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[11:47:38,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[11:47:38,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[11:47:38,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[11:47:38,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[11:47:38,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[11:47:38,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[11:47:38,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[11:47:38,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[11:47:38,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[11:47:38,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[11:47:38,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[11:47:38,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[11:47:38,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[11:47:38,888] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[11:47:38,897] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[11:47:38,900] INFO  {MemoryStore} MemoryStore cleared
[11:47:38,900] INFO  {BlockManager} BlockManager stopped
[11:47:38,905] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[11:47:38,909] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[11:47:38,910] INFO  {SparkContext} Successfully stopped SparkContext
[11:47:38,910] INFO  {ShutdownHookManager} Shutdown hook called
[11:47:38,911] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-ce795dca-b729-412e-a662-59e4db0e1b82
[11:48:09,378] INFO  {SparkContext} Running Spark version 2.0.1
[11:48:09,601] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[11:48:09,704] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[11:48:09,705] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[11:48:09,773] INFO  {SecurityManager} Changing view acls to: victor
[11:48:09,774] INFO  {SecurityManager} Changing modify acls to: victor
[11:48:09,775] INFO  {SecurityManager} Changing view acls groups to: 
[11:48:09,776] INFO  {SecurityManager} Changing modify acls groups to: 
[11:48:09,776] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[11:48:10,140] INFO  {Utils} Successfully started service 'sparkDriver' on port 46259.
[11:48:10,158] INFO  {SparkEnv} Registering MapOutputTracker
[11:48:10,172] INFO  {SparkEnv} Registering BlockManagerMaster
[11:48:10,184] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-d4997026-41d0-472c-97d3-a3dc4450e902
[11:48:10,198] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[11:48:10,242] INFO  {SparkEnv} Registering OutputCommitCoordinator
[11:48:10,320] INFO  {log} Logging initialized @1545ms
[11:48:10,429] INFO  {Server} jetty-9.2.z-SNAPSHOT
[11:48:10,446] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[11:48:10,446] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[11:48:10,446] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[11:48:10,447] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[11:48:10,447] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[11:48:10,447] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[11:48:10,447] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[11:48:10,448] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[11:48:10,448] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[11:48:10,448] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[11:48:10,449] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[11:48:10,449] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[11:48:10,449] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[11:48:10,449] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[11:48:10,449] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[11:48:10,450] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[11:48:10,450] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[11:48:10,450] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[11:48:10,451] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[11:48:10,451] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[11:48:10,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[11:48:10,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[11:48:10,459] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[11:48:10,460] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[11:48:10,466] INFO  {ServerConnector} Started ServerConnector@2ecfbf8e{HTTP/1.1}{0.0.0.0:4040}
[11:48:10,467] INFO  {Server} Started @1693ms
[11:48:10,467] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[11:48:10,472] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[11:48:10,566] INFO  {Executor} Starting executor ID driver on host localhost
[11:48:10,590] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45411.
[11:48:10,591] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:45411
[11:48:10,592] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 45411)
[11:48:10,596] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:45411 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 45411)
[11:48:10,598] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 45411)
[11:48:10,715] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[11:48:10,761] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[11:48:10,761] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[11:48:10,762] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[11:48:10,763] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[11:48:10,764] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[11:48:10,780] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[11:48:12,425] INFO  {SparkContext} Invoking stop() from shutdown hook
[11:48:12,429] INFO  {ServerConnector} Stopped ServerConnector@2ecfbf8e{HTTP/1.1}{0.0.0.0:4040}
[11:48:12,431] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[11:48:12,431] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[11:48:12,431] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[11:48:12,431] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[11:48:12,432] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[11:48:12,432] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[11:48:12,432] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[11:48:12,432] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[11:48:12,432] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[11:48:12,433] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[11:48:12,433] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[11:48:12,433] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[11:48:12,433] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[11:48:12,433] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[11:48:12,433] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[11:48:12,434] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[11:48:12,434] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[11:48:12,434] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[11:48:12,434] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[11:48:12,434] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[11:48:12,434] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[11:48:12,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[11:48:12,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[11:48:12,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[11:48:12,436] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[11:48:12,445] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[11:48:12,449] INFO  {MemoryStore} MemoryStore cleared
[11:48:12,449] INFO  {BlockManager} BlockManager stopped
[11:48:12,457] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[11:48:12,461] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[11:48:12,464] INFO  {SparkContext} Successfully stopped SparkContext
[11:48:12,464] INFO  {ShutdownHookManager} Shutdown hook called
[11:48:12,465] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-36303521-a1dc-4dc5-bd64-f9fa7402efe6
[11:48:33,283] INFO  {SparkContext} Running Spark version 2.0.1
[11:48:33,509] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[11:48:33,619] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[11:48:33,620] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[11:48:33,690] INFO  {SecurityManager} Changing view acls to: victor
[11:48:33,691] INFO  {SecurityManager} Changing modify acls to: victor
[11:48:33,691] INFO  {SecurityManager} Changing view acls groups to: 
[11:48:33,692] INFO  {SecurityManager} Changing modify acls groups to: 
[11:48:33,693] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[11:48:34,038] INFO  {Utils} Successfully started service 'sparkDriver' on port 41595.
[11:48:34,054] INFO  {SparkEnv} Registering MapOutputTracker
[11:48:34,069] INFO  {SparkEnv} Registering BlockManagerMaster
[11:48:34,080] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-bb2dae18-37e7-4cb0-be9d-83d5e1f62d7f
[11:48:34,094] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[11:48:34,137] INFO  {SparkEnv} Registering OutputCommitCoordinator
[11:48:34,210] INFO  {log} Logging initialized @1525ms
[11:48:34,312] INFO  {Server} jetty-9.2.z-SNAPSHOT
[11:48:34,333] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[11:48:34,333] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[11:48:34,334] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[11:48:34,334] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[11:48:34,334] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[11:48:34,334] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[11:48:34,334] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[11:48:34,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[11:48:34,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[11:48:34,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[11:48:34,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[11:48:34,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[11:48:34,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[11:48:34,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[11:48:34,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[11:48:34,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[11:48:34,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[11:48:34,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[11:48:34,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[11:48:34,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[11:48:34,343] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[11:48:34,343] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[11:48:34,344] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[11:48:34,344] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[11:48:34,352] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[11:48:34,352] INFO  {Server} Started @1668ms
[11:48:34,352] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[11:48:34,355] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[11:48:34,431] INFO  {Executor} Starting executor ID driver on host localhost
[11:48:34,452] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43953.
[11:48:34,453] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:43953
[11:48:34,455] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 43953)
[11:48:34,459] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:43953 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 43953)
[11:48:34,462] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 43953)
[11:48:34,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[11:48:35,048] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[11:48:35,101] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[11:48:35,104] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:43953 (size: 14.3 KB, free: 1128.9 MB)
[11:48:35,110] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[11:48:35,251] INFO  {FileInputFormat} Total input paths to process : 1
[11:48:35,268] INFO  {SparkContext} Starting job: top at Main.scala:23
[11:48:35,285] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[11:48:35,285] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[11:48:35,286] INFO  {DAGScheduler} Parents of final stage: List()
[11:48:35,288] INFO  {DAGScheduler} Missing parents: List()
[11:48:35,295] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[11:48:35,348] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[11:48:35,351] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[11:48:35,352] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:43953 (size: 2.1 KB, free: 1128.9 MB)
[11:48:35,353] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[11:48:35,357] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[11:48:35,358] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[11:48:35,405] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[11:48:35,411] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[11:48:35,434] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:48:35,444] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[11:48:35,444] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[11:48:35,444] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[11:48:35,444] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[11:48:35,444] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[11:48:35,509] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[11:48:35,516] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 132 ms on localhost (1/1)
[11:48:35,517] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[11:48:35,523] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.153 s
[11:48:35,530] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.261054 s
[11:48:35,633] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:43953 in memory (size: 2.1 KB, free: 1128.9 MB)
[11:48:36,935] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[11:48:36,935] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[11:48:36,936] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[11:48:36,937] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[11:48:36,938] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[11:48:36,947] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[11:48:37,642] INFO  {CodeGenerator} Code generated in 180.40683 ms
[11:48:37,669] INFO  {SparkContext} Starting job: show at Main.scala:37
[11:48:37,670] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[11:48:37,670] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[11:48:37,670] INFO  {DAGScheduler} Parents of final stage: List()
[11:48:37,670] INFO  {DAGScheduler} Missing parents: List()
[11:48:37,671] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[11:48:37,687] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[11:48:37,689] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[11:48:37,690] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:43953 (size: 5.5 KB, free: 1128.9 MB)
[11:48:37,690] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[11:48:37,690] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[11:48:37,691] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[11:48:37,693] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[11:48:37,693] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[11:48:37,705] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:48:37,727] INFO  {CodeGenerator} Code generated in 15.356468 ms
[11:48:37,749] INFO  {CodeGenerator} Code generated in 13.682152 ms
[11:48:37,752] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[11:48:37,754] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 62 ms on localhost (1/1)
[11:48:37,754] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[11:48:37,754] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.063 s
[11:48:37,754] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.085468 s
[11:48:37,779] INFO  {CodeGenerator} Code generated in 14.075718 ms
[11:48:37,839] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:43953 in memory (size: 5.5 KB, free: 1128.9 MB)
[11:48:37,841] INFO  {ContextCleaner} Cleaned accumulator 44
[11:48:37,841] INFO  {ContextCleaner} Cleaned accumulator 45
[11:48:37,901] INFO  {CodeGenerator} Code generated in 11.526599 ms
[11:48:37,915] INFO  {CodeGenerator} Code generated in 9.283326 ms
[11:48:37,944] INFO  {SparkContext} Starting job: count at Main.scala:40
[11:48:37,946] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[11:48:37,947] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[11:48:37,947] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[11:48:37,947] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[11:48:37,948] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[11:48:37,949] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[11:48:37,955] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[11:48:37,956] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[11:48:37,957] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:43953 (size: 6.6 KB, free: 1128.9 MB)
[11:48:37,958] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[11:48:37,959] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[11:48:37,960] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[11:48:37,963] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[11:48:37,963] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[11:48:37,974] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:48:38,086] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[11:48:38,089] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 129 ms on localhost (1/1)
[11:48:38,089] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[11:48:38,090] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.130 s
[11:48:38,091] INFO  {DAGScheduler} looking for newly runnable stages
[11:48:38,092] INFO  {DAGScheduler} running: Set()
[11:48:38,092] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[11:48:38,092] INFO  {DAGScheduler} failed: Set()
[11:48:38,094] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[11:48:38,099] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[11:48:38,101] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[11:48:38,102] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:43953 (size: 3.7 KB, free: 1128.9 MB)
[11:48:38,102] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[11:48:38,102] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[11:48:38,102] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[11:48:38,107] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[11:48:38,108] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[11:48:38,120] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[11:48:38,121] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 3 ms
[11:48:38,134] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[11:48:38,136] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 30 ms on localhost (1/1)
[11:48:38,136] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[11:48:38,137] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.031 s
[11:48:38,138] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.194246 s
[11:48:38,154] INFO  {CodeGenerator} Code generated in 10.212298 ms
[11:48:38,164] INFO  {SparkContext} Starting job: count at Main.scala:43
[11:48:38,165] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[11:48:38,165] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[11:48:38,165] INFO  {DAGScheduler} Parents of final stage: List()
[11:48:38,165] INFO  {DAGScheduler} Missing parents: List()
[11:48:38,165] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[11:48:38,168] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[11:48:38,169] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[11:48:38,170] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:43953 (size: 2.0 KB, free: 1128.9 MB)
[11:48:38,171] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[11:48:38,172] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[11:48:38,172] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[11:48:38,173] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[11:48:38,173] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[11:48:38,178] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:48:38,231] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[11:48:38,232] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 60 ms on localhost (1/1)
[11:48:38,233] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[11:48:38,233] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.061 s
[11:48:38,234] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.069891 s
[11:48:38,335] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:43953 in memory (size: 2.0 KB, free: 1128.9 MB)
[11:48:38,335] INFO  {ContextCleaner} Cleaned accumulator 90
[11:48:38,335] INFO  {ContextCleaner} Cleaned accumulator 91
[11:48:38,335] INFO  {ContextCleaner} Cleaned accumulator 92
[11:48:38,335] INFO  {ContextCleaner} Cleaned accumulator 93
[11:48:38,336] INFO  {ContextCleaner} Cleaned accumulator 94
[11:48:38,336] INFO  {ContextCleaner} Cleaned accumulator 95
[11:48:38,336] INFO  {ContextCleaner} Cleaned accumulator 96
[11:48:38,336] INFO  {ContextCleaner} Cleaned accumulator 97
[11:48:38,336] INFO  {ContextCleaner} Cleaned accumulator 98
[11:48:38,336] INFO  {ContextCleaner} Cleaned accumulator 99
[11:48:38,336] INFO  {ContextCleaner} Cleaned accumulator 100
[11:48:38,336] INFO  {ContextCleaner} Cleaned accumulator 101
[11:48:38,336] INFO  {ContextCleaner} Cleaned accumulator 102
[11:48:38,339] INFO  {ContextCleaner} Cleaned shuffle 0
[11:48:38,340] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:43953 in memory (size: 6.6 KB, free: 1128.9 MB)
[11:48:38,341] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:43953 in memory (size: 3.7 KB, free: 1128.9 MB)
[11:48:38,418] INFO  {CodeGenerator} Code generated in 17.00901 ms
[11:48:38,440] INFO  {CodeGenerator} Code generated in 13.619026 ms
[11:48:38,453] INFO  {SparkContext} Starting job: show at Main.scala:47
[11:48:38,454] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[11:48:38,454] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[11:48:38,454] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[11:48:38,454] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[11:48:38,455] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[11:48:38,456] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[11:48:38,460] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[11:48:38,462] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[11:48:38,463] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:43953 (size: 7.6 KB, free: 1128.9 MB)
[11:48:38,464] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[11:48:38,464] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[11:48:38,464] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[11:48:38,467] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[11:48:38,468] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[11:48:38,478] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:48:38,511] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[11:48:38,512] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 47 ms on localhost (1/1)
[11:48:38,512] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[11:48:38,512] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.047 s
[11:48:38,513] INFO  {DAGScheduler} looking for newly runnable stages
[11:48:38,513] INFO  {DAGScheduler} running: Set()
[11:48:38,513] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[11:48:38,513] INFO  {DAGScheduler} failed: Set()
[11:48:38,513] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[11:48:38,515] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[11:48:38,518] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[11:48:38,518] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:43953 (size: 4.6 KB, free: 1128.9 MB)
[11:48:38,519] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[11:48:38,520] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[11:48:38,521] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[11:48:38,524] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[11:48:38,524] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[11:48:38,530] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[11:48:38,530] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[11:48:38,533] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1858 bytes result sent to driver
[11:48:38,534] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 12 ms on localhost (1/1)
[11:48:38,535] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[11:48:38,535] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.013 s
[11:48:38,535] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.082022 s
[11:48:38,544] INFO  {CodeGenerator} Code generated in 7.769779 ms
[11:48:38,591] INFO  {SparkContext} Starting job: foreach at Main.scala:61
[11:48:38,593] INFO  {DAGScheduler} Registering RDD 23 (groupBy at Main.scala:51)
[11:48:38,593] INFO  {DAGScheduler} Registering RDD 26 (sortBy at Main.scala:61)
[11:48:38,593] INFO  {DAGScheduler} Got job 5 (foreach at Main.scala:61) with 1 output partitions
[11:48:38,593] INFO  {DAGScheduler} Final stage: ResultStage 9 (foreach at Main.scala:61)
[11:48:38,593] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 8)
[11:48:38,593] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 8)
[11:48:38,594] INFO  {DAGScheduler} Submitting ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51), which has no missing parents
[11:48:38,600] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 5.4 KB, free 1128.7 MB)
[11:48:38,602] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1128.7 MB)
[11:48:38,603] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:43953 (size: 2.9 KB, free: 1128.9 MB)
[11:48:38,604] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[11:48:38,604] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51)
[11:48:38,604] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[11:48:38,606] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5443 bytes)
[11:48:38,607] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[11:48:38,612] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:48:38,645] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1331 bytes result sent to driver
[11:48:38,646] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 42 ms on localhost (1/1)
[11:48:38,646] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[11:48:38,646] INFO  {DAGScheduler} ShuffleMapStage 7 (groupBy at Main.scala:51) finished in 0.042 s
[11:48:38,647] INFO  {DAGScheduler} looking for newly runnable stages
[11:48:38,647] INFO  {DAGScheduler} running: Set()
[11:48:38,647] INFO  {DAGScheduler} waiting: Set(ResultStage 9, ShuffleMapStage 8)
[11:48:38,647] INFO  {DAGScheduler} failed: Set()
[11:48:38,647] INFO  {DAGScheduler} Submitting ShuffleMapStage 8 (MapPartitionsRDD[26] at sortBy at Main.scala:61), which has no missing parents
[11:48:38,655] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 6.9 KB, free 1128.7 MB)
[11:48:38,657] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.5 KB, free 1128.7 MB)
[11:48:38,657] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:43953 (size: 3.5 KB, free: 1128.9 MB)
[11:48:38,658] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[11:48:38,658] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[26] at sortBy at Main.scala:61)
[11:48:38,658] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[11:48:38,661] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, ANY, 5172 bytes)
[11:48:38,661] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[11:48:38,666] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[11:48:38,666] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[11:48:38,783] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 1881 bytes result sent to driver
[11:48:38,784] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 125 ms on localhost (1/1)
[11:48:38,784] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[11:48:38,785] INFO  {DAGScheduler} ShuffleMapStage 8 (sortBy at Main.scala:61) finished in 0.127 s
[11:48:38,785] INFO  {DAGScheduler} looking for newly runnable stages
[11:48:38,785] INFO  {DAGScheduler} running: Set()
[11:48:38,785] INFO  {DAGScheduler} waiting: Set(ResultStage 9)
[11:48:38,785] INFO  {DAGScheduler} failed: Set()
[11:48:38,785] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[28] at sortBy at Main.scala:61), which has no missing parents
[11:48:38,787] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[11:48:38,790] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 2003.0 B, free 1128.7 MB)
[11:48:38,791] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:43953 (size: 2003.0 B, free: 1128.9 MB)
[11:48:38,792] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[11:48:38,792] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[28] at sortBy at Main.scala:61)
[11:48:38,792] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[11:48:38,794] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, ANY, 5183 bytes)
[11:48:38,794] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[11:48:38,797] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[11:48:38,798] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[11:48:38,824] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 1640 bytes result sent to driver
[11:48:38,825] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 33 ms on localhost (1/1)
[11:48:38,825] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[11:48:38,826] INFO  {DAGScheduler} ResultStage 9 (foreach at Main.scala:61) finished in 0.034 s
[11:48:38,827] INFO  {DAGScheduler} Job 5 finished: foreach at Main.scala:61, took 0.235513 s
[11:48:38,833] INFO  {SparkContext} Invoking stop() from shutdown hook
[11:48:38,839] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[11:48:38,842] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[11:48:38,842] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[11:48:38,842] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[11:48:38,842] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[11:48:38,842] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[11:48:38,842] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[11:48:38,842] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[11:48:38,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[11:48:38,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[11:48:38,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[11:48:38,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[11:48:38,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[11:48:38,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[11:48:38,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[11:48:38,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[11:48:38,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[11:48:38,844] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[11:48:38,844] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[11:48:38,844] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[11:48:38,844] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[11:48:38,844] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[11:48:38,844] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[11:48:38,844] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[11:48:38,844] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[11:48:38,846] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[11:48:38,860] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[11:48:38,868] INFO  {MemoryStore} MemoryStore cleared
[11:48:38,869] INFO  {BlockManager} BlockManager stopped
[11:48:38,872] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[11:48:38,877] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[11:48:38,878] INFO  {SparkContext} Successfully stopped SparkContext
[11:48:38,879] INFO  {ShutdownHookManager} Shutdown hook called
[11:48:38,880] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-25b990c4-8fc1-4e4d-ae83-dd9b5c9e5244
[11:49:02,291] INFO  {SparkContext} Running Spark version 2.0.1
[11:49:02,513] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[11:49:02,608] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[11:49:02,609] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[11:49:02,691] INFO  {SecurityManager} Changing view acls to: victor
[11:49:02,693] INFO  {SecurityManager} Changing modify acls to: victor
[11:49:02,694] INFO  {SecurityManager} Changing view acls groups to: 
[11:49:02,695] INFO  {SecurityManager} Changing modify acls groups to: 
[11:49:02,696] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[11:49:03,081] INFO  {Utils} Successfully started service 'sparkDriver' on port 41527.
[11:49:03,098] INFO  {SparkEnv} Registering MapOutputTracker
[11:49:03,112] INFO  {SparkEnv} Registering BlockManagerMaster
[11:49:03,124] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-88992b83-1b71-440f-9f0b-7700782dc1ac
[11:49:03,140] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[11:49:03,183] INFO  {SparkEnv} Registering OutputCommitCoordinator
[11:49:03,257] INFO  {log} Logging initialized @1570ms
[11:49:03,364] INFO  {Server} jetty-9.2.z-SNAPSHOT
[11:49:03,379] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[11:49:03,379] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[11:49:03,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[11:49:03,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[11:49:03,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[11:49:03,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[11:49:03,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[11:49:03,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[11:49:03,381] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[11:49:03,381] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[11:49:03,381] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[11:49:03,381] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[11:49:03,381] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[11:49:03,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[11:49:03,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[11:49:03,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[11:49:03,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[11:49:03,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[11:49:03,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[11:49:03,383] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[11:49:03,388] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[11:49:03,389] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[11:49:03,390] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[11:49:03,390] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[11:49:03,396] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[11:49:03,396] INFO  {Server} Started @1711ms
[11:49:03,396] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[11:49:03,398] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[11:49:03,486] INFO  {Executor} Starting executor ID driver on host localhost
[11:49:03,506] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36151.
[11:49:03,506] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:36151
[11:49:03,508] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 36151)
[11:49:03,510] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:36151 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 36151)
[11:49:03,513] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 36151)
[11:49:03,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[11:49:04,035] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[11:49:04,088] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[11:49:04,090] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:36151 (size: 14.3 KB, free: 1128.9 MB)
[11:49:04,096] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[11:49:04,221] INFO  {FileInputFormat} Total input paths to process : 1
[11:49:04,236] INFO  {SparkContext} Starting job: top at Main.scala:23
[11:49:04,250] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[11:49:04,251] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[11:49:04,252] INFO  {DAGScheduler} Parents of final stage: List()
[11:49:04,253] INFO  {DAGScheduler} Missing parents: List()
[11:49:04,263] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[11:49:04,325] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[11:49:04,328] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[11:49:04,328] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:36151 (size: 2.1 KB, free: 1128.9 MB)
[11:49:04,329] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[11:49:04,334] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[11:49:04,337] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[11:49:04,394] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[11:49:04,403] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[11:49:04,438] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:49:04,452] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[11:49:04,452] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[11:49:04,452] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[11:49:04,453] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[11:49:04,453] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[11:49:04,536] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[11:49:04,545] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 179 ms on localhost (1/1)
[11:49:04,547] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[11:49:04,551] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.202 s
[11:49:04,557] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.321198 s
[11:49:04,664] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:36151 in memory (size: 2.1 KB, free: 1128.9 MB)
[11:49:06,036] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[11:49:06,037] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[11:49:06,038] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[11:49:06,039] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[11:49:06,041] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[11:49:06,055] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[11:49:06,780] INFO  {CodeGenerator} Code generated in 178.371421 ms
[11:49:06,813] INFO  {SparkContext} Starting job: show at Main.scala:37
[11:49:06,815] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[11:49:06,815] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[11:49:06,815] INFO  {DAGScheduler} Parents of final stage: List()
[11:49:06,815] INFO  {DAGScheduler} Missing parents: List()
[11:49:06,816] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[11:49:06,834] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[11:49:06,836] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[11:49:06,837] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:36151 (size: 5.5 KB, free: 1128.9 MB)
[11:49:06,837] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[11:49:06,837] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[11:49:06,837] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[11:49:06,841] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[11:49:06,841] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[11:49:06,854] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:49:06,874] INFO  {CodeGenerator} Code generated in 12.92074 ms
[11:49:06,895] INFO  {CodeGenerator} Code generated in 13.460464 ms
[11:49:06,898] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[11:49:06,900] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 62 ms on localhost (1/1)
[11:49:06,900] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[11:49:06,900] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.062 s
[11:49:06,901] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.087121 s
[11:49:06,925] INFO  {CodeGenerator} Code generated in 14.898991 ms
[11:49:06,941] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:36151 in memory (size: 5.5 KB, free: 1128.9 MB)
[11:49:07,053] INFO  {CodeGenerator} Code generated in 12.401599 ms
[11:49:07,068] INFO  {CodeGenerator} Code generated in 10.670532 ms
[11:49:07,101] INFO  {SparkContext} Starting job: count at Main.scala:40
[11:49:07,104] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[11:49:07,104] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[11:49:07,105] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[11:49:07,105] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[11:49:07,105] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[11:49:07,106] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[11:49:07,113] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[11:49:07,115] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[11:49:07,115] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:36151 (size: 6.6 KB, free: 1128.9 MB)
[11:49:07,116] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[11:49:07,118] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[11:49:07,118] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[11:49:07,120] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[11:49:07,121] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[11:49:07,129] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:49:07,251] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[11:49:07,253] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 135 ms on localhost (1/1)
[11:49:07,254] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[11:49:07,255] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.136 s
[11:49:07,255] INFO  {DAGScheduler} looking for newly runnable stages
[11:49:07,255] INFO  {DAGScheduler} running: Set()
[11:49:07,256] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[11:49:07,256] INFO  {DAGScheduler} failed: Set()
[11:49:07,257] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[11:49:07,262] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[11:49:07,263] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[11:49:07,264] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:36151 (size: 3.7 KB, free: 1128.9 MB)
[11:49:07,265] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[11:49:07,265] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[11:49:07,265] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[11:49:07,269] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[11:49:07,269] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[11:49:07,287] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[11:49:07,288] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[11:49:07,300] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[11:49:07,302] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 35 ms on localhost (1/1)
[11:49:07,302] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[11:49:07,302] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.035 s
[11:49:07,303] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.201546 s
[11:49:07,314] INFO  {CodeGenerator} Code generated in 7.119702 ms
[11:49:07,322] INFO  {SparkContext} Starting job: count at Main.scala:43
[11:49:07,324] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[11:49:07,324] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[11:49:07,324] INFO  {DAGScheduler} Parents of final stage: List()
[11:49:07,324] INFO  {DAGScheduler} Missing parents: List()
[11:49:07,325] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[11:49:07,327] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[11:49:07,328] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[11:49:07,329] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:36151 (size: 2.0 KB, free: 1128.9 MB)
[11:49:07,329] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[11:49:07,329] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[11:49:07,329] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[11:49:07,331] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[11:49:07,331] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[11:49:07,334] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:49:07,369] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[11:49:07,370] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 40 ms on localhost (1/1)
[11:49:07,370] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[11:49:07,371] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.040 s
[11:49:07,371] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.048539 s
[11:49:07,472] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:36151 in memory (size: 2.0 KB, free: 1128.9 MB)
[11:49:07,474] INFO  {ContextCleaner} Cleaned accumulator 44
[11:49:07,475] INFO  {ContextCleaner} Cleaned accumulator 45
[11:49:07,475] INFO  {ContextCleaner} Cleaned accumulator 90
[11:49:07,475] INFO  {ContextCleaner} Cleaned accumulator 91
[11:49:07,475] INFO  {ContextCleaner} Cleaned accumulator 92
[11:49:07,475] INFO  {ContextCleaner} Cleaned accumulator 93
[11:49:07,475] INFO  {ContextCleaner} Cleaned accumulator 94
[11:49:07,475] INFO  {ContextCleaner} Cleaned accumulator 95
[11:49:07,475] INFO  {ContextCleaner} Cleaned accumulator 96
[11:49:07,475] INFO  {ContextCleaner} Cleaned accumulator 97
[11:49:07,475] INFO  {ContextCleaner} Cleaned accumulator 98
[11:49:07,475] INFO  {ContextCleaner} Cleaned accumulator 99
[11:49:07,476] INFO  {ContextCleaner} Cleaned accumulator 100
[11:49:07,476] INFO  {ContextCleaner} Cleaned accumulator 101
[11:49:07,476] INFO  {ContextCleaner} Cleaned accumulator 102
[11:49:07,479] INFO  {ContextCleaner} Cleaned shuffle 0
[11:49:07,480] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:36151 in memory (size: 6.6 KB, free: 1128.9 MB)
[11:49:07,481] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:36151 in memory (size: 3.7 KB, free: 1128.9 MB)
[11:49:07,577] INFO  {CodeGenerator} Code generated in 19.177246 ms
[11:49:07,605] INFO  {CodeGenerator} Code generated in 17.336987 ms
[11:49:07,624] INFO  {SparkContext} Starting job: show at Main.scala:47
[11:49:07,625] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[11:49:07,625] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[11:49:07,625] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[11:49:07,625] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[11:49:07,626] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[11:49:07,626] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[11:49:07,630] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[11:49:07,632] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[11:49:07,633] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:36151 (size: 7.6 KB, free: 1128.9 MB)
[11:49:07,634] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[11:49:07,634] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[11:49:07,634] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[11:49:07,636] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[11:49:07,636] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[11:49:07,643] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:49:07,681] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[11:49:07,682] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 47 ms on localhost (1/1)
[11:49:07,682] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[11:49:07,683] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.049 s
[11:49:07,683] INFO  {DAGScheduler} looking for newly runnable stages
[11:49:07,683] INFO  {DAGScheduler} running: Set()
[11:49:07,683] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[11:49:07,683] INFO  {DAGScheduler} failed: Set()
[11:49:07,684] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[11:49:07,686] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[11:49:07,688] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[11:49:07,688] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:36151 (size: 4.6 KB, free: 1128.9 MB)
[11:49:07,689] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[11:49:07,689] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[11:49:07,689] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[11:49:07,691] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[11:49:07,691] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[11:49:07,694] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[11:49:07,694] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[11:49:07,697] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1945 bytes result sent to driver
[11:49:07,698] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 8 ms on localhost (1/1)
[11:49:07,698] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[11:49:07,699] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.009 s
[11:49:07,699] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.075293 s
[11:49:07,709] INFO  {CodeGenerator} Code generated in 7.902071 ms
[11:49:07,757] INFO  {SparkContext} Starting job: foreach at Main.scala:61
[11:49:07,759] INFO  {DAGScheduler} Registering RDD 23 (groupBy at Main.scala:51)
[11:49:07,759] INFO  {DAGScheduler} Registering RDD 26 (sortBy at Main.scala:61)
[11:49:07,760] INFO  {DAGScheduler} Got job 5 (foreach at Main.scala:61) with 1 output partitions
[11:49:07,760] INFO  {DAGScheduler} Final stage: ResultStage 9 (foreach at Main.scala:61)
[11:49:07,760] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 8)
[11:49:07,760] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 8)
[11:49:07,761] INFO  {DAGScheduler} Submitting ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51), which has no missing parents
[11:49:07,771] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 5.4 KB, free 1128.7 MB)
[11:49:07,772] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1128.7 MB)
[11:49:07,773] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:36151 (size: 2.9 KB, free: 1128.9 MB)
[11:49:07,774] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[11:49:07,774] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51)
[11:49:07,774] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[11:49:07,776] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5443 bytes)
[11:49:07,777] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[11:49:07,781] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[11:49:07,814] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1244 bytes result sent to driver
[11:49:07,815] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 40 ms on localhost (1/1)
[11:49:07,815] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[11:49:07,816] INFO  {DAGScheduler} ShuffleMapStage 7 (groupBy at Main.scala:51) finished in 0.040 s
[11:49:07,816] INFO  {DAGScheduler} looking for newly runnable stages
[11:49:07,816] INFO  {DAGScheduler} running: Set()
[11:49:07,816] INFO  {DAGScheduler} waiting: Set(ResultStage 9, ShuffleMapStage 8)
[11:49:07,816] INFO  {DAGScheduler} failed: Set()
[11:49:07,816] INFO  {DAGScheduler} Submitting ShuffleMapStage 8 (MapPartitionsRDD[26] at sortBy at Main.scala:61), which has no missing parents
[11:49:07,828] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 6.9 KB, free 1128.7 MB)
[11:49:07,830] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.5 KB, free 1128.7 MB)
[11:49:07,830] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:36151 (size: 3.5 KB, free: 1128.9 MB)
[11:49:07,831] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[11:49:07,831] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[26] at sortBy at Main.scala:61)
[11:49:07,831] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[11:49:07,833] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, ANY, 5172 bytes)
[11:49:07,834] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[11:49:07,838] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[11:49:07,838] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[11:49:07,924] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 1881 bytes result sent to driver
[11:49:07,925] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 93 ms on localhost (1/1)
[11:49:07,925] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[11:49:07,925] INFO  {DAGScheduler} ShuffleMapStage 8 (sortBy at Main.scala:61) finished in 0.094 s
[11:49:07,926] INFO  {DAGScheduler} looking for newly runnable stages
[11:49:07,926] INFO  {DAGScheduler} running: Set()
[11:49:07,926] INFO  {DAGScheduler} waiting: Set(ResultStage 9)
[11:49:07,926] INFO  {DAGScheduler} failed: Set()
[11:49:07,926] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[28] at sortBy at Main.scala:61), which has no missing parents
[11:49:07,929] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[11:49:07,930] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 2003.0 B, free 1128.7 MB)
[11:49:07,931] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:36151 (size: 2003.0 B, free: 1128.9 MB)
[11:49:07,931] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[11:49:07,932] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[28] at sortBy at Main.scala:61)
[11:49:07,932] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[11:49:07,933] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, ANY, 5183 bytes)
[11:49:07,934] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[11:49:07,937] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[11:49:07,938] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[11:49:07,967] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 1640 bytes result sent to driver
[11:49:07,970] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 37 ms on localhost (1/1)
[11:49:07,970] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[11:49:07,972] INFO  {DAGScheduler} ResultStage 9 (foreach at Main.scala:61) finished in 0.038 s
[11:49:07,973] INFO  {DAGScheduler} Job 5 finished: foreach at Main.scala:61, took 0.215667 s
[11:49:07,978] INFO  {SparkContext} Invoking stop() from shutdown hook
[11:49:07,983] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[11:49:07,986] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[11:49:07,986] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[11:49:07,986] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[11:49:07,986] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[11:49:07,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[11:49:07,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[11:49:07,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[11:49:07,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[11:49:07,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[11:49:07,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[11:49:07,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[11:49:07,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[11:49:07,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[11:49:07,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[11:49:07,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[11:49:07,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[11:49:07,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[11:49:07,989] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[11:49:07,989] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[11:49:07,989] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[11:49:07,989] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[11:49:07,989] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[11:49:07,990] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[11:49:07,990] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[11:49:07,994] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[11:49:08,009] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[11:49:08,018] INFO  {MemoryStore} MemoryStore cleared
[11:49:08,018] INFO  {BlockManager} BlockManager stopped
[11:49:08,020] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[11:49:08,023] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[11:49:08,025] INFO  {SparkContext} Successfully stopped SparkContext
[11:49:08,026] INFO  {ShutdownHookManager} Shutdown hook called
[11:49:08,027] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-ed61c3b5-e10e-4b74-9839-a790172039ab
[11:49:13,583] INFO  {SparkContext} Running Spark version 2.0.1
[11:49:13,783] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[11:49:13,879] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[11:49:13,879] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[11:49:13,965] INFO  {SecurityManager} Changing view acls to: victor
[11:49:13,967] INFO  {SecurityManager} Changing modify acls to: victor
[11:49:13,968] INFO  {SecurityManager} Changing view acls groups to: 
[11:49:13,969] INFO  {SecurityManager} Changing modify acls groups to: 
[11:49:13,972] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[11:49:14,335] INFO  {Utils} Successfully started service 'sparkDriver' on port 43877.
[11:49:14,355] INFO  {SparkEnv} Registering MapOutputTracker
[11:49:14,369] INFO  {SparkEnv} Registering BlockManagerMaster
[11:49:14,381] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-ef1478fe-3483-408a-80b3-af4a2b43d55e
[11:49:14,395] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[11:49:14,465] INFO  {SparkEnv} Registering OutputCommitCoordinator
[11:49:14,542] INFO  {log} Logging initialized @1591ms
[11:49:14,647] INFO  {Server} jetty-9.2.z-SNAPSHOT
[11:49:14,662] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[11:49:14,662] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[11:49:14,663] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[11:49:14,663] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[11:49:14,663] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[11:49:14,663] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[11:49:14,663] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[11:49:14,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[11:49:14,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[11:49:14,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[11:49:14,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[11:49:14,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[11:49:14,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[11:49:14,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[11:49:14,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[11:49:14,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[11:49:14,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[11:49:14,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[11:49:14,666] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[11:49:14,666] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[11:49:14,672] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[11:49:14,672] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[11:49:14,673] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[11:49:14,673] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[11:49:14,679] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[11:49:14,679] INFO  {Server} Started @1730ms
[11:49:14,679] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[11:49:14,681] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[11:49:14,756] INFO  {Executor} Starting executor ID driver on host localhost
[11:49:14,778] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36147.
[11:49:14,779] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:36147
[11:49:14,781] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 36147)
[11:49:14,784] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:36147 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 36147)
[11:49:14,786] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 36147)
[11:49:14,911] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[11:49:14,957] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[11:49:14,958] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[11:49:14,959] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[11:49:14,959] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[11:49:14,961] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[11:49:14,976] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[11:49:16,632] INFO  {SparkContext} Invoking stop() from shutdown hook
[11:49:16,638] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[11:49:16,640] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[11:49:16,640] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[11:49:16,641] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[11:49:16,641] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[11:49:16,641] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[11:49:16,641] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[11:49:16,641] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[11:49:16,641] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[11:49:16,642] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[11:49:16,642] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[11:49:16,642] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[11:49:16,642] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[11:49:16,642] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[11:49:16,642] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[11:49:16,643] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[11:49:16,643] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[11:49:16,643] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[11:49:16,643] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[11:49:16,643] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[11:49:16,644] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[11:49:16,644] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[11:49:16,644] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[11:49:16,644] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[11:49:16,644] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[11:49:16,646] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[11:49:16,662] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[11:49:16,666] INFO  {MemoryStore} MemoryStore cleared
[11:49:16,666] INFO  {BlockManager} BlockManager stopped
[11:49:16,671] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[11:49:16,674] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[11:49:16,678] INFO  {SparkContext} Successfully stopped SparkContext
[11:49:16,679] INFO  {ShutdownHookManager} Shutdown hook called
[11:49:16,679] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f64c9083-e51e-41a9-bf46-6ce623287a6c
[11:50:41,375] INFO  {SparkContext} Running Spark version 2.0.1
[11:50:41,614] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[11:50:41,716] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[11:50:41,716] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[11:50:41,796] INFO  {SecurityManager} Changing view acls to: victor
[11:50:41,797] INFO  {SecurityManager} Changing modify acls to: victor
[11:50:41,798] INFO  {SecurityManager} Changing view acls groups to: 
[11:50:41,798] INFO  {SecurityManager} Changing modify acls groups to: 
[11:50:41,799] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[11:50:42,130] INFO  {Utils} Successfully started service 'sparkDriver' on port 37069.
[11:50:42,150] INFO  {SparkEnv} Registering MapOutputTracker
[11:50:42,166] INFO  {SparkEnv} Registering BlockManagerMaster
[11:50:42,179] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-ac2de5ec-d0da-4c56-9dae-49aa1c5966ca
[11:50:42,192] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[11:50:42,235] INFO  {SparkEnv} Registering OutputCommitCoordinator
[11:50:42,311] INFO  {log} Logging initialized @1542ms
[11:50:42,415] INFO  {Server} jetty-9.2.z-SNAPSHOT
[11:50:42,432] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[11:50:42,432] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[11:50:42,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[11:50:42,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[11:50:42,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[11:50:42,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[11:50:42,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[11:50:42,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[11:50:42,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[11:50:42,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[11:50:42,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[11:50:42,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[11:50:42,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[11:50:42,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[11:50:42,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[11:50:42,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[11:50:42,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[11:50:42,437] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[11:50:42,437] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[11:50:42,437] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[11:50:42,446] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[11:50:42,446] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[11:50:42,447] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[11:50:42,447] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[11:50:42,456] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[11:50:42,456] INFO  {Server} Started @1688ms
[11:50:42,456] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[11:50:42,459] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[11:50:42,565] INFO  {Executor} Starting executor ID driver on host localhost
[11:50:42,591] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44161.
[11:50:42,592] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:44161
[11:50:42,593] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 44161)
[11:50:42,597] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:44161 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 44161)
[11:50:42,601] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 44161)
[11:50:42,732] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[11:50:42,778] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[11:50:42,779] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[11:50:42,780] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[11:50:42,781] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[11:50:42,783] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[11:50:42,799] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[11:50:44,505] INFO  {SparkContext} Invoking stop() from shutdown hook
[11:50:44,510] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[11:50:44,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[11:50:44,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[11:50:44,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[11:50:44,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[11:50:44,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[11:50:44,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[11:50:44,513] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[11:50:44,513] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[11:50:44,513] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[11:50:44,513] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[11:50:44,513] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[11:50:44,513] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[11:50:44,513] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[11:50:44,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[11:50:44,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[11:50:44,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[11:50:44,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[11:50:44,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[11:50:44,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[11:50:44,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[11:50:44,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[11:50:44,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[11:50:44,515] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[11:50:44,515] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[11:50:44,516] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[11:50:44,529] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[11:50:44,536] INFO  {MemoryStore} MemoryStore cleared
[11:50:44,537] INFO  {BlockManager} BlockManager stopped
[11:50:44,545] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[11:50:44,550] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[11:50:44,554] INFO  {SparkContext} Successfully stopped SparkContext
[11:50:44,554] INFO  {ShutdownHookManager} Shutdown hook called
[11:50:44,556] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-c3621757-f7e0-4f23-9c83-bc5cddcfbe5f
[11:52:37,769] INFO  {SparkContext} Running Spark version 2.0.1
[11:52:38,014] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[11:52:38,127] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[11:52:38,128] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[11:52:38,228] INFO  {SecurityManager} Changing view acls to: victor
[11:52:38,229] INFO  {SecurityManager} Changing modify acls to: victor
[11:52:38,230] INFO  {SecurityManager} Changing view acls groups to: 
[11:52:38,231] INFO  {SecurityManager} Changing modify acls groups to: 
[11:52:38,231] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[11:52:38,591] INFO  {Utils} Successfully started service 'sparkDriver' on port 37619.
[11:52:38,611] INFO  {SparkEnv} Registering MapOutputTracker
[11:52:38,626] INFO  {SparkEnv} Registering BlockManagerMaster
[11:52:38,640] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-2d282e22-bb79-4161-a904-eebb43f399fd
[11:52:38,655] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[11:52:38,707] INFO  {SparkEnv} Registering OutputCommitCoordinator
[11:52:38,780] INFO  {log} Logging initialized @1674ms
[11:52:38,877] INFO  {Server} jetty-9.2.z-SNAPSHOT
[11:52:38,893] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[11:52:38,894] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[11:52:38,894] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[11:52:38,894] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[11:52:38,894] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[11:52:38,894] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[11:52:38,895] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[11:52:38,895] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[11:52:38,895] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[11:52:38,895] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[11:52:38,895] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[11:52:38,895] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[11:52:38,896] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[11:52:38,896] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[11:52:38,896] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[11:52:38,896] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[11:52:38,896] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[11:52:38,897] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[11:52:38,897] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[11:52:38,897] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[11:52:38,903] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[11:52:38,903] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[11:52:38,904] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[11:52:38,904] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[11:52:38,910] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[11:52:38,910] INFO  {Server} Started @1805ms
[11:52:38,911] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[11:52:38,913] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[11:52:38,990] INFO  {Executor} Starting executor ID driver on host localhost
[11:52:39,015] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39451.
[11:52:39,017] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:39451
[11:52:39,019] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 39451)
[11:52:39,022] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:39451 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 39451)
[11:52:39,025] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 39451)
[11:52:39,147] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[11:52:39,199] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[11:52:39,200] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[11:52:39,201] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[11:52:39,201] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[11:52:39,203] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[11:52:39,220] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[11:52:40,877] INFO  {SparkContext} Invoking stop() from shutdown hook
[11:52:40,881] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[11:52:40,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[11:52:40,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[11:52:40,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[11:52:40,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[11:52:40,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[11:52:40,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[11:52:40,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[11:52:40,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[11:52:40,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[11:52:40,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[11:52:40,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[11:52:40,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[11:52:40,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[11:52:40,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[11:52:40,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[11:52:40,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[11:52:40,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[11:52:40,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[11:52:40,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[11:52:40,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[11:52:40,885] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[11:52:40,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[11:52:40,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[11:52:40,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[11:52:40,887] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[11:52:40,911] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[11:52:40,916] INFO  {MemoryStore} MemoryStore cleared
[11:52:40,916] INFO  {BlockManager} BlockManager stopped
[11:52:40,921] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[11:52:40,924] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[11:52:40,926] INFO  {SparkContext} Successfully stopped SparkContext
[11:52:40,926] INFO  {ShutdownHookManager} Shutdown hook called
[11:52:40,927] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-31ccfbc4-5b13-4f16-a64f-ffc7756dc642
[12:00:15,518] INFO  {SparkContext} Running Spark version 2.0.1
[12:00:15,723] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:00:15,819] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:00:15,819] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:00:15,905] INFO  {SecurityManager} Changing view acls to: victor
[12:00:15,906] INFO  {SecurityManager} Changing modify acls to: victor
[12:00:15,907] INFO  {SecurityManager} Changing view acls groups to: 
[12:00:15,907] INFO  {SecurityManager} Changing modify acls groups to: 
[12:00:15,908] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:00:16,288] INFO  {Utils} Successfully started service 'sparkDriver' on port 46147.
[12:00:16,305] INFO  {SparkEnv} Registering MapOutputTracker
[12:00:16,319] INFO  {SparkEnv} Registering BlockManagerMaster
[12:00:16,330] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-7af2ceb6-321c-40bb-a78b-3d29d3a2b56e
[12:00:16,345] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:00:16,403] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:00:16,473] INFO  {log} Logging initialized @1589ms
[12:00:16,581] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:00:16,596] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:00:16,596] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:00:16,596] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:00:16,596] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:00:16,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:00:16,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:00:16,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:00:16,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:00:16,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:00:16,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:00:16,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:00:16,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:00:16,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:00:16,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:00:16,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:00:16,599] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:00:16,599] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:00:16,599] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:00:16,599] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:00:16,599] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:00:16,607] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:00:16,607] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:00:16,608] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:00:16,609] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:00:16,617] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:00:16,618] INFO  {Server} Started @1735ms
[12:00:16,618] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:00:16,621] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:00:16,725] INFO  {Executor} Starting executor ID driver on host localhost
[12:00:16,749] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42151.
[12:00:16,751] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:42151
[12:00:16,753] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 42151)
[12:00:16,756] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:42151 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 42151)
[12:00:16,759] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 42151)
[12:00:16,882] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:00:16,934] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:00:16,935] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:00:16,936] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:00:16,937] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:00:16,939] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:00:16,954] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:00:18,699] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:00:18,702] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:00:18,704] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:00:18,704] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:00:18,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:00:18,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:00:18,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:00:18,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:00:18,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:00:18,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:00:18,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:00:18,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:00:18,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:00:18,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:00:18,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:00:18,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:00:18,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:00:18,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:00:18,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:00:18,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:00:18,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:00:18,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:00:18,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:00:18,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:00:18,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:00:18,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:00:18,708] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:00:18,719] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:00:18,723] INFO  {MemoryStore} MemoryStore cleared
[12:00:18,723] INFO  {BlockManager} BlockManager stopped
[12:00:18,730] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:00:18,733] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:00:18,739] INFO  {SparkContext} Successfully stopped SparkContext
[12:00:18,740] INFO  {ShutdownHookManager} Shutdown hook called
[12:00:18,741] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-7340519e-7960-4308-bb02-dd654a3e22c5
[12:01:42,439] INFO  {SparkContext} Running Spark version 2.0.1
[12:01:42,657] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:01:42,752] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:01:42,753] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:01:42,832] INFO  {SecurityManager} Changing view acls to: victor
[12:01:42,832] INFO  {SecurityManager} Changing modify acls to: victor
[12:01:42,833] INFO  {SecurityManager} Changing view acls groups to: 
[12:01:42,833] INFO  {SecurityManager} Changing modify acls groups to: 
[12:01:42,834] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:01:43,210] INFO  {Utils} Successfully started service 'sparkDriver' on port 42397.
[12:01:43,227] INFO  {SparkEnv} Registering MapOutputTracker
[12:01:43,241] INFO  {SparkEnv} Registering BlockManagerMaster
[12:01:43,253] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-406b3d8f-fdc7-4d78-a462-75fe660bf724
[12:01:43,267] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:01:43,317] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:01:43,388] INFO  {log} Logging initialized @1577ms
[12:01:43,493] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:01:43,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:01:43,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:01:43,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:01:43,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:01:43,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:01:43,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:01:43,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:01:43,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:01:43,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:01:43,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:01:43,513] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:01:43,513] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:01:43,513] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:01:43,513] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:01:43,513] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:01:43,514] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:01:43,514] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:01:43,514] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:01:43,514] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:01:43,514] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:01:43,521] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:01:43,521] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:01:43,522] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:01:43,523] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:01:43,529] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:01:43,529] INFO  {Server} Started @1719ms
[12:01:43,529] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:01:43,532] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:01:43,611] INFO  {Executor} Starting executor ID driver on host localhost
[12:01:43,632] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45969.
[12:01:43,633] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:45969
[12:01:43,635] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 45969)
[12:01:43,638] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:45969 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 45969)
[12:01:43,641] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 45969)
[12:01:43,772] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:01:43,822] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:01:43,823] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:01:43,824] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:01:43,825] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:01:43,826] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:01:43,845] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:01:45,711] INFO  {FileSourceStrategy} Pruning directories with: 
[12:01:45,716] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:01:45,722] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:01:45,723] INFO  {FileSourceStrategy} Pushed Filters: 
[12:01:45,859] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:01:45,920] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:01:45,923] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:45969 (size: 14.6 KB, free: 1128.9 MB)
[12:01:45,930] INFO  {SparkContext} Created broadcast 0 from take at Main.scala:20
[12:01:45,935] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:01:46,430] INFO  {CodeGenerator} Code generated in 189.967857 ms
[12:01:46,493] INFO  {SparkContext} Starting job: take at Main.scala:20
[12:01:46,513] INFO  {DAGScheduler} Got job 0 (take at Main.scala:20) with 1 output partitions
[12:01:46,514] INFO  {DAGScheduler} Final stage: ResultStage 0 (take at Main.scala:20)
[12:01:46,515] INFO  {DAGScheduler} Parents of final stage: List()
[12:01:46,516] INFO  {DAGScheduler} Missing parents: List()
[12:01:46,521] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at take at Main.scala:20), which has no missing parents
[12:01:46,567] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 6.4 KB, free 1128.8 MB)
[12:01:46,570] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.5 KB, free 1128.7 MB)
[12:01:46,571] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:45969 (size: 3.5 KB, free: 1128.9 MB)
[12:01:46,572] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:01:46,575] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at take at Main.scala:20)
[12:01:46,576] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:01:46,624] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:01:46,630] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:01:46,667] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:01:46,687] INFO  {CodeGenerator} Code generated in 12.255424 ms
[12:01:46,715] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2124 bytes result sent to driver
[12:01:46,725] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 127 ms on localhost (1/1)
[12:01:46,727] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:01:46,730] INFO  {DAGScheduler} ResultStage 0 (take at Main.scala:20) finished in 0.144 s
[12:01:46,738] INFO  {DAGScheduler} Job 0 finished: take at Main.scala:20, took 0.244365 s
[12:01:46,768] INFO  {CodeGenerator} Code generated in 15.985071 ms
[12:01:46,794] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:01:46,799] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:01:46,801] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:01:46,801] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:01:46,801] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:01:46,801] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:01:46,802] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:01:46,802] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:01:46,802] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:01:46,802] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:01:46,802] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:01:46,802] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:01:46,802] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:01:46,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:01:46,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:01:46,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:01:46,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:01:46,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:01:46,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:01:46,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:01:46,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:01:46,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:01:46,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:01:46,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:01:46,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:01:46,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:01:46,806] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:01:46,816] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:01:46,819] INFO  {MemoryStore} MemoryStore cleared
[12:01:46,820] INFO  {BlockManager} BlockManager stopped
[12:01:46,827] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:01:46,845] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:01:46,847] INFO  {SparkContext} Successfully stopped SparkContext
[12:01:46,848] INFO  {ShutdownHookManager} Shutdown hook called
[12:01:46,849] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-83800f3a-9931-46ae-b60e-f31f80fc43a1
[12:14:32,359] INFO  {SparkContext} Running Spark version 2.0.1
[12:14:32,585] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:14:32,672] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:14:32,672] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:14:32,757] INFO  {SecurityManager} Changing view acls to: victor
[12:14:32,758] INFO  {SecurityManager} Changing modify acls to: victor
[12:14:32,758] INFO  {SecurityManager} Changing view acls groups to: 
[12:14:32,759] INFO  {SecurityManager} Changing modify acls groups to: 
[12:14:32,760] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:14:33,142] INFO  {Utils} Successfully started service 'sparkDriver' on port 40051.
[12:14:33,165] INFO  {SparkEnv} Registering MapOutputTracker
[12:14:33,180] INFO  {SparkEnv} Registering BlockManagerMaster
[12:14:33,192] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-5fe29af3-5f85-40e8-ab97-22c858ae63d3
[12:14:33,206] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:14:33,258] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:14:33,337] INFO  {log} Logging initialized @1579ms
[12:14:33,435] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:14:33,451] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:14:33,451] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:14:33,451] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:14:33,451] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:14:33,452] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:14:33,452] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:14:33,452] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:14:33,452] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:14:33,452] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:14:33,452] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:14:33,453] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:14:33,453] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:14:33,453] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:14:33,453] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:14:33,453] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:14:33,454] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:14:33,454] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:14:33,454] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:14:33,454] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:14:33,454] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:14:33,461] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:14:33,461] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:14:33,462] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:14:33,462] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:14:33,470] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:14:33,470] INFO  {Server} Started @1714ms
[12:14:33,470] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:14:33,473] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:14:33,547] INFO  {Executor} Starting executor ID driver on host localhost
[12:14:33,578] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43333.
[12:14:33,581] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:43333
[12:14:33,583] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 43333)
[12:14:33,586] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:43333 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 43333)
[12:14:33,589] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 43333)
[12:14:33,712] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:14:33,761] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:14:33,761] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:14:33,762] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:14:33,763] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:14:33,764] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:14:33,779] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:14:35,528] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:14:35,533] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:14:35,535] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:14:35,535] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:14:35,535] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:14:35,535] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:14:35,535] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:14:35,535] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:14:35,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:14:35,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:14:35,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:14:35,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:14:35,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:14:35,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:14:35,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:14:35,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:14:35,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:14:35,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:14:35,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:14:35,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:14:35,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:14:35,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:14:35,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:14:35,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:14:35,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:14:35,538] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:14:35,539] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:14:35,563] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:14:35,570] INFO  {MemoryStore} MemoryStore cleared
[12:14:35,570] INFO  {BlockManager} BlockManager stopped
[12:14:35,575] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:14:35,579] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:14:35,582] INFO  {SparkContext} Successfully stopped SparkContext
[12:14:35,583] INFO  {ShutdownHookManager} Shutdown hook called
[12:14:35,584] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-37f4e1b2-fe60-4dc7-91a4-a5b005df6ae0
[12:15:15,446] INFO  {SparkContext} Running Spark version 2.0.1
[12:15:15,669] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:15:15,770] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:15:15,770] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:15:15,848] INFO  {SecurityManager} Changing view acls to: victor
[12:15:15,848] INFO  {SecurityManager} Changing modify acls to: victor
[12:15:15,849] INFO  {SecurityManager} Changing view acls groups to: 
[12:15:15,849] INFO  {SecurityManager} Changing modify acls groups to: 
[12:15:15,850] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:15:16,198] INFO  {Utils} Successfully started service 'sparkDriver' on port 34355.
[12:15:16,215] INFO  {SparkEnv} Registering MapOutputTracker
[12:15:16,231] INFO  {SparkEnv} Registering BlockManagerMaster
[12:15:16,243] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-223c90e3-2e38-45fd-a408-a0a76354de67
[12:15:16,257] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:15:16,306] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:15:16,395] INFO  {log} Logging initialized @1591ms
[12:15:16,494] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:15:16,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:15:16,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:15:16,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:15:16,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:15:16,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:15:16,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:15:16,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:15:16,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:15:16,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:15:16,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:15:16,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:15:16,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:15:16,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:15:16,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:15:16,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:15:16,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:15:16,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:15:16,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:15:16,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:15:16,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:15:16,518] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:15:16,518] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:15:16,519] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:15:16,519] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:15:16,525] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:15:16,525] INFO  {Server} Started @1723ms
[12:15:16,525] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:15:16,527] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:15:16,598] INFO  {Executor} Starting executor ID driver on host localhost
[12:15:16,617] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40559.
[12:15:16,618] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:40559
[12:15:16,619] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 40559)
[12:15:16,622] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:40559 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 40559)
[12:15:16,625] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 40559)
[12:15:16,751] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:15:16,796] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:15:16,797] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:15:16,797] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:15:16,798] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:15:16,799] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:15:16,813] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:15:18,558] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:15:18,569] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:15:18,571] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:15:18,572] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:15:18,572] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:15:18,572] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:15:18,572] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:15:18,572] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:15:18,573] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:15:18,573] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:15:18,573] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:15:18,573] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:15:18,573] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:15:18,573] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:15:18,574] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:15:18,574] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:15:18,574] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:15:18,574] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:15:18,574] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:15:18,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:15:18,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:15:18,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:15:18,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:15:18,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:15:18,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:15:18,576] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:15:18,578] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:15:18,588] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:15:18,591] INFO  {MemoryStore} MemoryStore cleared
[12:15:18,592] INFO  {BlockManager} BlockManager stopped
[12:15:18,596] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:15:18,599] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:15:18,601] INFO  {SparkContext} Successfully stopped SparkContext
[12:15:18,602] INFO  {ShutdownHookManager} Shutdown hook called
[12:15:18,602] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-96b75705-b78c-4743-adc0-838a8639f1cb
[12:15:32,131] INFO  {SparkContext} Running Spark version 2.0.1
[12:15:32,365] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:15:32,462] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:15:32,463] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:15:32,545] INFO  {SecurityManager} Changing view acls to: victor
[12:15:32,546] INFO  {SecurityManager} Changing modify acls to: victor
[12:15:32,546] INFO  {SecurityManager} Changing view acls groups to: 
[12:15:32,547] INFO  {SecurityManager} Changing modify acls groups to: 
[12:15:32,548] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:15:32,895] INFO  {Utils} Successfully started service 'sparkDriver' on port 44165.
[12:15:32,912] INFO  {SparkEnv} Registering MapOutputTracker
[12:15:32,927] INFO  {SparkEnv} Registering BlockManagerMaster
[12:15:32,939] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-653c7680-29bd-4f17-a216-de6b45eeafe4
[12:15:32,953] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:15:33,013] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:15:33,088] INFO  {log} Logging initialized @1565ms
[12:15:33,191] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:15:33,207] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:15:33,207] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:15:33,207] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:15:33,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:15:33,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:15:33,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:15:33,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:15:33,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:15:33,209] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:15:33,209] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:15:33,209] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:15:33,209] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:15:33,209] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:15:33,210] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:15:33,210] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:15:33,210] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:15:33,210] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:15:33,210] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:15:33,210] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:15:33,211] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:15:33,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:15:33,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:15:33,220] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:15:33,221] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:15:33,229] INFO  {ServerConnector} Started ServerConnector@44a3581a{HTTP/1.1}{0.0.0.0:4040}
[12:15:33,229] INFO  {Server} Started @1707ms
[12:15:33,230] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:15:33,232] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:15:33,344] INFO  {Executor} Starting executor ID driver on host localhost
[12:15:33,367] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35265.
[12:15:33,368] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:35265
[12:15:33,369] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 35265)
[12:15:33,372] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:35265 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 35265)
[12:15:33,375] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 35265)
[12:15:33,496] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[12:15:33,549] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@759fad4{/SQL,null,AVAILABLE}
[12:15:33,550] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53499d85{/SQL/json,null,AVAILABLE}
[12:15:33,551] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/execution,null,AVAILABLE}
[12:15:33,551] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL/execution/json,null,AVAILABLE}
[12:15:33,553] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@24f360b2{/static/sql,null,AVAILABLE}
[12:15:33,569] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:15:35,275] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:15:35,280] INFO  {ServerConnector} Stopped ServerConnector@44a3581a{HTTP/1.1}{0.0.0.0:4040}
[12:15:35,282] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:15:35,282] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:15:35,282] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:15:35,282] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:15:35,282] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:15:35,282] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:15:35,283] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:15:35,283] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:15:35,283] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:15:35,283] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:15:35,283] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:15:35,283] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:15:35,283] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:15:35,283] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:15:35,283] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:15:35,284] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:15:35,284] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:15:35,284] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:15:35,284] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:15:35,284] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:15:35,284] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:15:35,284] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:15:35,285] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:15:35,285] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:15:35,287] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:15:35,296] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:15:35,300] INFO  {MemoryStore} MemoryStore cleared
[12:15:35,301] INFO  {BlockManager} BlockManager stopped
[12:15:35,306] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:15:35,309] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:15:35,310] INFO  {SparkContext} Successfully stopped SparkContext
[12:15:35,311] INFO  {ShutdownHookManager} Shutdown hook called
[12:15:35,311] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a372d39f-2153-494a-ae74-dffb5f305885
[12:15:50,040] INFO  {SparkContext} Running Spark version 2.0.1
[12:15:50,258] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:15:50,353] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:15:50,353] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:15:50,427] INFO  {SecurityManager} Changing view acls to: victor
[12:15:50,428] INFO  {SecurityManager} Changing modify acls to: victor
[12:15:50,429] INFO  {SecurityManager} Changing view acls groups to: 
[12:15:50,430] INFO  {SecurityManager} Changing modify acls groups to: 
[12:15:50,430] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:15:50,824] INFO  {Utils} Successfully started service 'sparkDriver' on port 35941.
[12:15:50,843] INFO  {SparkEnv} Registering MapOutputTracker
[12:15:50,857] INFO  {SparkEnv} Registering BlockManagerMaster
[12:15:50,869] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-512c8073-9b72-4845-911a-29c499684988
[12:15:50,883] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:15:50,932] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:15:51,003] INFO  {log} Logging initialized @1678ms
[12:15:51,108] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:15:51,128] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:15:51,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:15:51,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:15:51,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:15:51,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:15:51,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:15:51,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:15:51,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:15:51,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:15:51,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:15:51,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:15:51,131] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:15:51,131] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:15:51,131] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:15:51,131] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:15:51,131] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:15:51,131] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:15:51,132] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:15:51,132] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:15:51,132] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:15:51,140] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:15:51,140] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:15:51,141] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:15:51,141] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:15:51,147] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:15:51,147] INFO  {Server} Started @1824ms
[12:15:51,147] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:15:51,149] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:15:51,225] INFO  {Executor} Starting executor ID driver on host localhost
[12:15:51,246] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46603.
[12:15:51,246] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:46603
[12:15:51,248] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 46603)
[12:15:51,251] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:46603 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 46603)
[12:15:51,253] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 46603)
[12:15:51,372] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:15:51,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:15:51,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:15:51,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:15:51,430] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:15:51,432] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:15:51,447] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:15:53,207] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:15:53,211] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:15:53,212] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:15:53,213] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:15:53,213] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:15:53,213] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:15:53,213] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:15:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:15:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:15:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:15:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:15:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:15:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:15:53,215] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:15:53,215] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:15:53,215] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:15:53,215] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:15:53,215] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:15:53,216] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:15:53,216] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:15:53,216] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:15:53,216] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:15:53,216] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:15:53,216] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:15:53,217] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:15:53,217] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:15:53,218] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:15:53,238] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:15:53,242] INFO  {MemoryStore} MemoryStore cleared
[12:15:53,243] INFO  {BlockManager} BlockManager stopped
[12:15:53,249] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:15:53,252] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:15:53,254] INFO  {SparkContext} Successfully stopped SparkContext
[12:15:53,255] INFO  {ShutdownHookManager} Shutdown hook called
[12:15:53,256] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-190f7d13-5681-4335-b78a-251b782f80e3
[12:16:30,955] INFO  {SparkContext} Running Spark version 2.0.1
[12:16:31,165] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:16:31,252] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:16:31,252] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:16:31,330] INFO  {SecurityManager} Changing view acls to: victor
[12:16:31,331] INFO  {SecurityManager} Changing modify acls to: victor
[12:16:31,331] INFO  {SecurityManager} Changing view acls groups to: 
[12:16:31,332] INFO  {SecurityManager} Changing modify acls groups to: 
[12:16:31,332] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:16:31,712] INFO  {Utils} Successfully started service 'sparkDriver' on port 41603.
[12:16:31,730] INFO  {SparkEnv} Registering MapOutputTracker
[12:16:31,748] INFO  {SparkEnv} Registering BlockManagerMaster
[12:16:31,761] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-3148ad30-a00e-4cea-8032-781653c1bd2e
[12:16:31,775] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:16:31,831] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:16:31,909] INFO  {log} Logging initialized @1526ms
[12:16:32,016] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:16:32,032] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:16:32,032] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:16:32,033] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:16:32,033] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:16:32,033] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:16:32,034] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:16:32,034] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:16:32,034] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:16:32,034] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:16:32,035] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:16:32,035] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:16:32,035] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:16:32,036] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:16:32,036] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:16:32,036] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:16:32,036] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:16:32,037] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:16:32,037] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:16:32,037] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:16:32,037] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:16:32,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:16:32,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:16:32,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:16:32,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:16:32,058] INFO  {ServerConnector} Started ServerConnector@12da0d85{HTTP/1.1}{0.0.0.0:4040}
[12:16:32,059] INFO  {Server} Started @1676ms
[12:16:32,059] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:16:32,062] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:16:32,153] INFO  {Executor} Starting executor ID driver on host localhost
[12:16:32,184] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40947.
[12:16:32,184] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:40947
[12:16:32,186] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 40947)
[12:16:32,189] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:40947 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 40947)
[12:16:32,192] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 40947)
[12:16:32,311] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[12:16:32,356] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@759fad4{/SQL,null,AVAILABLE}
[12:16:32,357] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53499d85{/SQL/json,null,AVAILABLE}
[12:16:32,357] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/execution,null,AVAILABLE}
[12:16:32,358] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL/execution/json,null,AVAILABLE}
[12:16:32,361] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@24f360b2{/static/sql,null,AVAILABLE}
[12:16:32,376] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:16:34,120] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:16:34,124] INFO  {ServerConnector} Stopped ServerConnector@12da0d85{HTTP/1.1}{0.0.0.0:4040}
[12:16:34,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:16:34,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:16:34,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:16:34,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:16:34,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:16:34,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:16:34,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:16:34,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:16:34,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:16:34,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:16:34,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:16:34,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:16:34,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:16:34,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:16:34,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:16:34,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:16:34,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:16:34,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:16:34,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:16:34,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:16:34,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:16:34,129] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:16:34,129] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:16:34,129] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:16:34,131] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:16:34,144] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:16:34,149] INFO  {MemoryStore} MemoryStore cleared
[12:16:34,149] INFO  {BlockManager} BlockManager stopped
[12:16:34,157] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:16:34,162] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:16:34,171] INFO  {SparkContext} Successfully stopped SparkContext
[12:16:34,172] INFO  {ShutdownHookManager} Shutdown hook called
[12:16:34,174] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-d3997f72-fae1-4de9-a5dd-fa5379049c94
[12:16:48,454] INFO  {SparkContext} Running Spark version 2.0.1
[12:16:48,687] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:16:48,784] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:16:48,785] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:16:48,862] INFO  {SecurityManager} Changing view acls to: victor
[12:16:48,864] INFO  {SecurityManager} Changing modify acls to: victor
[12:16:48,865] INFO  {SecurityManager} Changing view acls groups to: 
[12:16:48,866] INFO  {SecurityManager} Changing modify acls groups to: 
[12:16:48,866] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:16:49,234] INFO  {Utils} Successfully started service 'sparkDriver' on port 39117.
[12:16:49,254] INFO  {SparkEnv} Registering MapOutputTracker
[12:16:49,273] INFO  {SparkEnv} Registering BlockManagerMaster
[12:16:49,286] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-bc2ff6ee-4130-40b5-9861-c39f9e6d48d6
[12:16:49,301] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:16:49,363] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:16:49,448] INFO  {log} Logging initialized @1593ms
[12:16:49,553] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:16:49,568] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:16:49,568] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:16:49,568] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:16:49,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:16:49,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:16:49,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:16:49,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:16:49,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:16:49,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:16:49,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:16:49,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:16:49,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:16:49,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:16:49,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:16:49,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:16:49,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:16:49,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:16:49,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:16:49,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:16:49,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:16:49,577] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:16:49,578] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:16:49,579] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:16:49,579] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:16:49,585] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:16:49,585] INFO  {Server} Started @1731ms
[12:16:49,585] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:16:49,587] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:16:49,664] INFO  {Executor} Starting executor ID driver on host localhost
[12:16:49,688] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37473.
[12:16:49,689] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:37473
[12:16:49,690] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 37473)
[12:16:49,693] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:37473 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 37473)
[12:16:49,696] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 37473)
[12:16:49,832] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:16:49,904] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:16:49,905] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:16:49,906] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:16:49,907] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:16:49,910] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:16:49,931] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:16:52,157] INFO  {FileSourceStrategy} Pruning directories with: 
[12:16:52,159] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:16:52,163] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:16:52,164] INFO  {FileSourceStrategy} Pushed Filters: 
[12:16:52,273] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:16:52,318] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:16:52,320] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:37473 (size: 14.6 KB, free: 1128.9 MB)
[12:16:52,326] INFO  {SparkContext} Created broadcast 0 from take at Main.scala:36
[12:16:52,330] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:16:52,827] INFO  {CodeGenerator} Code generated in 214.479588 ms
[12:16:52,916] INFO  {SparkContext} Starting job: take at Main.scala:36
[12:16:52,931] INFO  {DAGScheduler} Got job 0 (take at Main.scala:36) with 1 output partitions
[12:16:52,932] INFO  {DAGScheduler} Final stage: ResultStage 0 (take at Main.scala:36)
[12:16:52,932] INFO  {DAGScheduler} Parents of final stage: List()
[12:16:52,934] INFO  {DAGScheduler} Missing parents: List()
[12:16:52,939] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at take at Main.scala:36), which has no missing parents
[12:16:52,984] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[12:16:52,987] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[12:16:52,988] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:37473 (size: 6.6 KB, free: 1128.9 MB)
[12:16:52,988] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:16:52,991] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at take at Main.scala:36)
[12:16:52,993] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:16:53,031] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:16:53,037] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:16:53,087] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:16:53,104] INFO  {CodeGenerator} Code generated in 13.581584 ms
[12:16:53,140] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2532 bytes result sent to driver
[12:16:53,148] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 135 ms on localhost (1/1)
[12:16:53,149] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:16:53,153] INFO  {DAGScheduler} ResultStage 0 (take at Main.scala:36) finished in 0.149 s
[12:16:53,159] INFO  {DAGScheduler} Job 0 finished: take at Main.scala:36, took 0.242845 s
[12:16:53,197] INFO  {CodeGenerator} Code generated in 18.834039 ms
[12:16:53,208] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:16:53,212] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:16:53,213] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:16:53,213] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:16:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:16:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:16:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:16:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:16:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:16:53,214] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:16:53,215] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:16:53,215] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:16:53,215] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:16:53,215] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:16:53,215] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:16:53,216] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:16:53,216] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:16:53,216] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:16:53,216] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:16:53,216] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:16:53,217] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:16:53,217] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:16:53,217] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:16:53,217] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:16:53,218] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:16:53,218] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:16:53,220] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:16:53,231] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:16:53,234] INFO  {MemoryStore} MemoryStore cleared
[12:16:53,235] INFO  {BlockManager} BlockManager stopped
[12:16:53,239] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:16:53,241] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:16:53,242] INFO  {SparkContext} Successfully stopped SparkContext
[12:16:53,242] INFO  {ShutdownHookManager} Shutdown hook called
[12:16:53,243] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-5b7a4d20-838a-4145-bdc2-8edfa03f7173
[12:19:26,471] INFO  {SparkContext} Running Spark version 2.0.1
[12:19:26,706] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:19:26,800] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:19:26,801] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:19:26,880] INFO  {SecurityManager} Changing view acls to: victor
[12:19:26,881] INFO  {SecurityManager} Changing modify acls to: victor
[12:19:26,881] INFO  {SecurityManager} Changing view acls groups to: 
[12:19:26,882] INFO  {SecurityManager} Changing modify acls groups to: 
[12:19:26,883] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:19:27,270] INFO  {Utils} Successfully started service 'sparkDriver' on port 46287.
[12:19:27,286] INFO  {SparkEnv} Registering MapOutputTracker
[12:19:27,301] INFO  {SparkEnv} Registering BlockManagerMaster
[12:19:27,313] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-9833370c-408e-4610-a30f-825c329f9d4e
[12:19:27,327] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:19:27,382] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:19:27,459] INFO  {log} Logging initialized @1576ms
[12:19:27,558] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:19:27,573] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:19:27,574] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:19:27,574] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:19:27,574] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:19:27,574] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:19:27,574] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:19:27,575] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:19:27,575] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:19:27,575] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:19:27,575] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:19:27,575] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:19:27,576] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:19:27,576] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:19:27,576] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:19:27,576] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:19:27,576] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:19:27,576] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:19:27,577] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:19:27,577] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:19:27,577] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:19:27,583] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:19:27,583] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:19:27,584] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:19:27,584] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:19:27,590] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:19:27,590] INFO  {Server} Started @1708ms
[12:19:27,590] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:19:27,592] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:19:27,673] INFO  {Executor} Starting executor ID driver on host localhost
[12:19:27,698] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45743.
[12:19:27,699] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:45743
[12:19:27,702] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 45743)
[12:19:27,705] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:45743 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 45743)
[12:19:27,708] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 45743)
[12:19:27,832] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:19:27,880] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:19:27,881] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:19:27,881] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:19:27,882] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:19:27,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:19:27,897] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:19:29,760] INFO  {FileSourceStrategy} Pruning directories with: 
[12:19:29,761] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:19:29,765] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:19:29,766] INFO  {FileSourceStrategy} Pushed Filters: 
[12:19:29,869] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:19:29,913] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:19:29,915] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:45743 (size: 14.6 KB, free: 1128.9 MB)
[12:19:29,921] INFO  {SparkContext} Created broadcast 0 from take at Main.scala:36
[12:19:29,925] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:19:30,412] INFO  {CodeGenerator} Code generated in 209.497838 ms
[12:19:30,508] INFO  {SparkContext} Starting job: take at Main.scala:36
[12:19:30,524] INFO  {DAGScheduler} Got job 0 (take at Main.scala:36) with 1 output partitions
[12:19:30,524] INFO  {DAGScheduler} Final stage: ResultStage 0 (take at Main.scala:36)
[12:19:30,525] INFO  {DAGScheduler} Parents of final stage: List()
[12:19:30,526] INFO  {DAGScheduler} Missing parents: List()
[12:19:30,531] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at take at Main.scala:36), which has no missing parents
[12:19:30,574] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[12:19:30,577] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KB, free 1128.7 MB)
[12:19:30,577] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:45743 (size: 6.7 KB, free: 1128.9 MB)
[12:19:30,578] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:19:30,582] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at take at Main.scala:36)
[12:19:30,584] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:19:30,623] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:19:30,631] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:19:30,667] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:19:30,682] INFO  {CodeGenerator} Code generated in 11.150346 ms
[12:19:30,715] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2542 bytes result sent to driver
[12:19:30,721] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 117 ms on localhost (1/1)
[12:19:30,723] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:19:30,727] INFO  {DAGScheduler} ResultStage 0 (take at Main.scala:36) finished in 0.134 s
[12:19:30,733] INFO  {DAGScheduler} Job 0 finished: take at Main.scala:36, took 0.224932 s
[12:19:30,767] INFO  {CodeGenerator} Code generated in 20.810248 ms
[12:19:30,793] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:19:30,798] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:19:30,802] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:19:30,802] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:19:30,802] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:19:30,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:19:30,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:19:30,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:19:30,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:19:30,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:19:30,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:19:30,803] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:19:30,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:19:30,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:19:30,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:19:30,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:19:30,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:19:30,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:19:30,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:19:30,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:19:30,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:19:30,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:19:30,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:19:30,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:19:30,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:19:30,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:19:30,807] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:19:30,809] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:45743 in memory (size: 14.6 KB, free: 1128.9 MB)
[12:19:30,820] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:19:30,825] INFO  {MemoryStore} MemoryStore cleared
[12:19:30,825] INFO  {BlockManager} BlockManager stopped
[12:19:30,827] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:19:30,829] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:19:30,831] INFO  {SparkContext} Successfully stopped SparkContext
[12:19:30,832] INFO  {ShutdownHookManager} Shutdown hook called
[12:19:30,833] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-5741c3f3-421a-4082-a287-143ab7bc0f22
[12:20:35,639] INFO  {SparkContext} Running Spark version 2.0.1
[12:20:35,849] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:20:35,949] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:20:35,949] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:20:36,033] INFO  {SecurityManager} Changing view acls to: victor
[12:20:36,034] INFO  {SecurityManager} Changing modify acls to: victor
[12:20:36,035] INFO  {SecurityManager} Changing view acls groups to: 
[12:20:36,036] INFO  {SecurityManager} Changing modify acls groups to: 
[12:20:36,037] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:20:36,387] INFO  {Utils} Successfully started service 'sparkDriver' on port 34923.
[12:20:36,406] INFO  {SparkEnv} Registering MapOutputTracker
[12:20:36,422] INFO  {SparkEnv} Registering BlockManagerMaster
[12:20:36,438] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-49af93ec-7a6d-40fc-8b04-90569e5e8f2d
[12:20:36,463] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:20:36,546] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:20:36,626] INFO  {log} Logging initialized @1598ms
[12:20:36,737] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:20:36,756] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:20:36,756] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:20:36,756] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:20:36,756] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:20:36,756] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:20:36,757] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:20:36,757] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:20:36,757] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:20:36,757] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:20:36,757] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:20:36,758] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:20:36,758] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:20:36,758] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:20:36,758] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:20:36,758] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:20:36,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:20:36,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:20:36,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:20:36,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:20:36,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:20:36,765] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:20:36,765] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:20:36,766] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:20:36,766] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:20:36,772] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:20:36,773] INFO  {Server} Started @1745ms
[12:20:36,773] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:20:36,775] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:20:36,859] INFO  {Executor} Starting executor ID driver on host localhost
[12:20:36,891] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33017.
[12:20:36,892] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:33017
[12:20:36,895] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 33017)
[12:20:36,899] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:33017 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 33017)
[12:20:36,902] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 33017)
[12:20:37,062] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:20:37,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:20:37,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:20:37,123] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:20:37,124] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:20:37,125] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:20:37,143] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:20:39,178] INFO  {FileSourceStrategy} Pruning directories with: 
[12:20:39,180] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:20:39,184] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:20:39,185] INFO  {FileSourceStrategy} Pushed Filters: 
[12:20:39,289] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:20:39,333] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:20:39,335] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:33017 (size: 14.6 KB, free: 1128.9 MB)
[12:20:39,342] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:29
[12:20:39,346] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:20:39,835] INFO  {CodeGenerator} Code generated in 208.508697 ms
[12:20:39,927] INFO  {SparkContext} Starting job: show at Main.scala:29
[12:20:39,945] INFO  {DAGScheduler} Got job 0 (show at Main.scala:29) with 1 output partitions
[12:20:39,945] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:29)
[12:20:39,945] INFO  {DAGScheduler} Parents of final stage: List()
[12:20:39,946] INFO  {DAGScheduler} Missing parents: List()
[12:20:39,950] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:29), which has no missing parents
[12:20:39,996] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[12:20:39,999] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[12:20:40,000] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:33017 (size: 6.6 KB, free: 1128.9 MB)
[12:20:40,001] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:20:40,004] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:29)
[12:20:40,005] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:20:40,045] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:20:40,054] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:20:40,089] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:20:40,105] INFO  {CodeGenerator} Code generated in 11.135932 ms
[12:20:40,138] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2855 bytes result sent to driver
[12:20:40,147] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 123 ms on localhost (1/1)
[12:20:40,149] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:20:40,155] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:29) finished in 0.141 s
[12:20:40,162] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:29, took 0.234260 s
[12:20:40,209] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:33017 in memory (size: 6.6 KB, free: 1128.9 MB)
[12:20:40,214] INFO  {CodeGenerator} Code generated in 21.363086 ms
[12:20:40,232] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:20:40,237] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:20:40,238] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:20:40,238] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:20:40,239] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:20:40,239] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:20:40,239] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:20:40,239] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:20:40,239] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:20:40,239] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:20:40,240] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:20:40,240] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:20:40,240] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:20:40,240] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:20:40,241] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:20:40,241] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:20:40,241] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:20:40,241] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:20:40,241] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:20:40,242] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:20:40,242] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:20:40,242] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:20:40,242] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:20:40,242] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:20:40,242] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:20:40,243] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:20:40,244] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:20:40,254] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:20:40,258] INFO  {MemoryStore} MemoryStore cleared
[12:20:40,258] INFO  {BlockManager} BlockManager stopped
[12:20:40,260] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:20:40,262] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:20:40,263] INFO  {SparkContext} Successfully stopped SparkContext
[12:20:40,264] INFO  {ShutdownHookManager} Shutdown hook called
[12:20:40,265] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a287e3ed-bf43-49d6-85ce-7e0d840d2ad8
[12:21:29,949] INFO  {SparkContext} Running Spark version 2.0.1
[12:21:30,278] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:21:30,464] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:21:30,465] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:21:30,610] INFO  {SecurityManager} Changing view acls to: victor
[12:21:30,611] INFO  {SecurityManager} Changing modify acls to: victor
[12:21:30,612] INFO  {SecurityManager} Changing view acls groups to: 
[12:21:30,613] INFO  {SecurityManager} Changing modify acls groups to: 
[12:21:30,613] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:21:31,040] INFO  {Utils} Successfully started service 'sparkDriver' on port 45581.
[12:21:31,056] INFO  {SparkEnv} Registering MapOutputTracker
[12:21:31,073] INFO  {SparkEnv} Registering BlockManagerMaster
[12:21:31,085] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e93600e7-b307-45c4-8e1d-02ac351581b0
[12:21:31,101] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:21:31,163] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:21:31,260] INFO  {log} Logging initialized @2018ms
[12:21:31,448] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:21:31,476] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:21:31,476] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:21:31,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:21:31,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:21:31,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:21:31,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:21:31,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:21:31,478] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:21:31,478] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:21:31,478] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:21:31,479] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:21:31,479] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:21:31,479] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:21:31,479] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:21:31,480] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:21:31,480] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:21:31,480] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:21:31,481] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:21:31,481] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:21:31,481] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:21:31,499] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:21:31,501] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:21:31,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:21:31,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:21:31,531] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:21:31,532] INFO  {Server} Started @2293ms
[12:21:31,532] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:21:31,539] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:21:31,777] INFO  {Executor} Starting executor ID driver on host localhost
[12:21:31,823] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37851.
[12:21:31,825] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:37851
[12:21:31,827] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 37851)
[12:21:31,832] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:37851 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 37851)
[12:21:31,844] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 37851)
[12:21:32,060] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:21:32,128] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:21:32,128] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:21:32,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:21:32,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:21:32,131] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:21:32,157] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:21:34,607] INFO  {FileSourceStrategy} Pruning directories with: 
[12:21:34,609] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:21:34,619] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:21:34,619] INFO  {FileSourceStrategy} Pushed Filters: 
[12:21:34,797] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:21:34,876] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:21:34,881] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:37851 (size: 14.6 KB, free: 1128.9 MB)
[12:21:34,892] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:29
[12:21:34,900] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:21:35,485] INFO  {CodeGenerator} Code generated in 205.84295 ms
[12:21:35,579] INFO  {SparkContext} Starting job: show at Main.scala:29
[12:21:35,597] INFO  {DAGScheduler} Got job 0 (show at Main.scala:29) with 1 output partitions
[12:21:35,598] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:29)
[12:21:35,599] INFO  {DAGScheduler} Parents of final stage: List()
[12:21:35,600] INFO  {DAGScheduler} Missing parents: List()
[12:21:35,606] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:29), which has no missing parents
[12:21:35,651] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[12:21:35,654] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[12:21:35,655] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:37851 (size: 6.6 KB, free: 1128.9 MB)
[12:21:35,656] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:21:35,659] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:29)
[12:21:35,661] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:21:35,728] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:21:35,741] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:21:35,818] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:21:35,840] INFO  {CodeGenerator} Code generated in 17.129627 ms
[12:21:35,884] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2363 bytes result sent to driver
[12:21:35,892] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 203 ms on localhost (1/1)
[12:21:35,894] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:21:35,899] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:29) finished in 0.225 s
[12:21:35,903] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:29, took 0.323778 s
[12:21:35,939] INFO  {CodeGenerator} Code generated in 22.628736 ms
[12:21:35,952] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:21:35,956] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:21:35,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:21:35,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:21:35,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:21:35,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:21:35,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:21:35,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:21:35,960] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:21:35,960] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:21:35,960] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:21:35,960] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:21:35,960] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:21:35,961] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:21:35,961] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:21:35,961] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:21:35,961] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:21:35,961] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:21:35,962] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:21:35,962] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:21:35,962] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:21:35,962] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:21:35,962] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:21:35,963] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:21:35,963] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:21:35,963] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:21:35,965] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:21:35,975] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:21:35,979] INFO  {MemoryStore} MemoryStore cleared
[12:21:35,980] INFO  {BlockManager} BlockManager stopped
[12:21:35,988] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:21:35,991] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:21:35,993] INFO  {SparkContext} Successfully stopped SparkContext
[12:21:35,994] INFO  {ShutdownHookManager} Shutdown hook called
[12:21:35,995] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-994fec67-d368-434a-9e7a-85c2b63fe9dd
[12:24:00,426] INFO  {SparkContext} Running Spark version 2.0.1
[12:24:00,672] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:24:00,787] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:24:00,787] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:24:00,866] INFO  {SecurityManager} Changing view acls to: victor
[12:24:00,867] INFO  {SecurityManager} Changing modify acls to: victor
[12:24:00,869] INFO  {SecurityManager} Changing view acls groups to: 
[12:24:00,870] INFO  {SecurityManager} Changing modify acls groups to: 
[12:24:00,871] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:24:01,356] INFO  {Utils} Successfully started service 'sparkDriver' on port 41953.
[12:24:01,389] INFO  {SparkEnv} Registering MapOutputTracker
[12:24:01,415] INFO  {SparkEnv} Registering BlockManagerMaster
[12:24:01,433] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-1273eed6-8845-4bcf-8fbd-3d95d79fab05
[12:24:01,455] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:24:01,548] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:24:01,672] INFO  {log} Logging initialized @1891ms
[12:24:01,880] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:24:01,907] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:24:01,908] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:24:01,908] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:24:01,908] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:24:01,908] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:24:01,909] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:24:01,909] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:24:01,909] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:24:01,910] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:24:01,910] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:24:01,910] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:24:01,911] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:24:01,911] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:24:01,911] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:24:01,912] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:24:01,912] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:24:01,913] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:24:01,913] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:24:01,914] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:24:01,914] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:24:01,931] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:24:01,932] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:24:01,935] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:24:01,936] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:24:01,956] INFO  {ServerConnector} Started ServerConnector@2ecfbf8e{HTTP/1.1}{0.0.0.0:4040}
[12:24:01,957] INFO  {Server} Started @2178ms
[12:24:01,958] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:24:01,963] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:24:02,146] INFO  {Executor} Starting executor ID driver on host localhost
[12:24:02,174] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36433.
[12:24:02,175] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:36433
[12:24:02,177] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 36433)
[12:24:02,181] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:36433 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 36433)
[12:24:02,185] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 36433)
[12:24:02,345] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[12:24:02,404] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@759fad4{/SQL,null,AVAILABLE}
[12:24:02,404] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53499d85{/SQL/json,null,AVAILABLE}
[12:24:02,405] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/execution,null,AVAILABLE}
[12:24:02,406] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL/execution/json,null,AVAILABLE}
[12:24:02,407] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@24f360b2{/static/sql,null,AVAILABLE}
[12:24:02,422] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:24:05,253] INFO  {FileSourceStrategy} Pruning directories with: 
[12:24:05,254] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:24:05,259] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:24:05,259] INFO  {FileSourceStrategy} Pushed Filters: 
[12:24:05,365] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:24:05,409] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:24:05,411] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:36433 (size: 14.6 KB, free: 1128.9 MB)
[12:24:05,418] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:29
[12:24:05,422] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:24:06,117] INFO  {CodeGenerator} Code generated in 375.612864 ms
[12:24:06,301] INFO  {SparkContext} Starting job: show at Main.scala:29
[12:24:06,332] INFO  {DAGScheduler} Got job 0 (show at Main.scala:29) with 1 output partitions
[12:24:06,333] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:29)
[12:24:06,335] INFO  {DAGScheduler} Parents of final stage: List()
[12:24:06,341] INFO  {DAGScheduler} Missing parents: List()
[12:24:06,348] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:29), which has no missing parents
[12:24:06,400] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[12:24:06,421] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[12:24:06,422] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:36433 (size: 6.6 KB, free: 1128.9 MB)
[12:24:06,422] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:24:06,425] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:29)
[12:24:06,427] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:24:06,466] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:24:06,473] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:24:06,508] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:24:06,522] INFO  {CodeGenerator} Code generated in 10.007117 ms
[12:24:06,557] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[12:24:06,568] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 119 ms on localhost (1/1)
[12:24:06,570] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:24:06,580] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:29) finished in 0.141 s
[12:24:06,588] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:29, took 0.286651 s
[12:24:06,658] INFO  {CodeGenerator} Code generated in 26.133953 ms
[12:24:06,683] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:24:06,688] INFO  {ServerConnector} Stopped ServerConnector@2ecfbf8e{HTTP/1.1}{0.0.0.0:4040}
[12:24:06,690] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:24:06,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:24:06,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:24:06,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:24:06,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:24:06,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:24:06,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:24:06,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:24:06,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:24:06,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:24:06,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:24:06,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:24:06,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:24:06,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:24:06,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:24:06,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:24:06,693] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:24:06,693] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:24:06,693] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:24:06,693] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:24:06,693] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:24:06,693] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:24:06,693] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:24:06,694] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:24:06,695] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:24:06,704] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:24:06,708] INFO  {MemoryStore} MemoryStore cleared
[12:24:06,708] INFO  {BlockManager} BlockManager stopped
[12:24:06,715] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:24:06,718] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:24:06,720] INFO  {SparkContext} Successfully stopped SparkContext
[12:24:06,720] INFO  {ShutdownHookManager} Shutdown hook called
[12:24:06,722] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-b572a366-eb8f-485a-850b-73eabf210d82
[12:33:23,685] INFO  {SparkContext} Running Spark version 2.0.1
[12:33:23,885] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:33:23,972] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:33:23,973] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:33:24,042] INFO  {SecurityManager} Changing view acls to: victor
[12:33:24,042] INFO  {SecurityManager} Changing modify acls to: victor
[12:33:24,043] INFO  {SecurityManager} Changing view acls groups to: 
[12:33:24,043] INFO  {SecurityManager} Changing modify acls groups to: 
[12:33:24,044] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:33:24,405] INFO  {Utils} Successfully started service 'sparkDriver' on port 42669.
[12:33:24,425] INFO  {SparkEnv} Registering MapOutputTracker
[12:33:24,441] INFO  {SparkEnv} Registering BlockManagerMaster
[12:33:24,452] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-3ea0425c-e031-4466-8821-1612ca617816
[12:33:24,466] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:33:24,522] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:33:24,591] INFO  {log} Logging initialized @1476ms
[12:33:24,696] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:33:24,712] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:33:24,712] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:33:24,712] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:33:24,713] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:33:24,713] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:33:24,713] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:33:24,713] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:33:24,713] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:33:24,714] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:33:24,714] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:33:24,714] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:33:24,714] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:33:24,714] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:33:24,715] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:33:24,715] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:33:24,715] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:33:24,715] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:33:24,715] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:33:24,716] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:33:24,716] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:33:24,722] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:33:24,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:33:24,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:33:24,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:33:24,730] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:33:24,730] INFO  {Server} Started @1617ms
[12:33:24,731] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:33:24,733] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:33:24,813] INFO  {Executor} Starting executor ID driver on host localhost
[12:33:24,835] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38807.
[12:33:24,836] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:38807
[12:33:24,838] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 38807)
[12:33:24,841] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:38807 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 38807)
[12:33:24,845] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 38807)
[12:33:24,982] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:33:25,031] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:33:25,032] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:33:25,033] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:33:25,034] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:33:25,035] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:33:25,051] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:33:26,928] INFO  {FileSourceStrategy} Pruning directories with: 
[12:33:26,930] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:33:26,935] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:33:26,935] INFO  {FileSourceStrategy} Pushed Filters: 
[12:33:27,042] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:33:27,086] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:33:27,088] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:38807 (size: 14.6 KB, free: 1128.9 MB)
[12:33:27,094] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:30
[12:33:27,098] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:33:27,598] INFO  {CodeGenerator} Code generated in 208.761002 ms
[12:33:27,689] INFO  {SparkContext} Starting job: show at Main.scala:30
[12:33:27,709] INFO  {DAGScheduler} Got job 0 (show at Main.scala:30) with 1 output partitions
[12:33:27,710] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:30)
[12:33:27,710] INFO  {DAGScheduler} Parents of final stage: List()
[12:33:27,712] INFO  {DAGScheduler} Missing parents: List()
[12:33:27,715] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:30), which has no missing parents
[12:33:27,758] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[12:33:27,760] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[12:33:27,761] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:38807 (size: 6.6 KB, free: 1128.9 MB)
[12:33:27,762] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:33:27,765] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:30)
[12:33:27,766] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:33:27,811] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:33:27,817] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:33:27,855] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:33:27,874] INFO  {CodeGenerator} Code generated in 14.998954 ms
[12:33:27,909] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[12:33:27,916] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 128 ms on localhost (1/1)
[12:33:27,917] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:33:27,921] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:30) finished in 0.146 s
[12:33:27,928] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:30, took 0.239290 s
[12:33:27,978] INFO  {CodeGenerator} Code generated in 35.496095 ms
[12:33:27,981] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:38807 in memory (size: 6.6 KB, free: 1128.9 MB)
[12:33:28,010] INFO  {FileSourceStrategy} Pruning directories with: 
[12:33:28,010] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:33:28,011] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:33:28,011] INFO  {FileSourceStrategy} Pushed Filters: 
[12:33:28,018] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[12:33:28,029] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[12:33:28,029] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:38807 (size: 14.6 KB, free: 1128.9 MB)
[12:33:28,031] INFO  {SparkContext} Created broadcast 2 from take at Main.scala:35
[12:33:28,031] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:33:28,052] INFO  {SparkContext} Starting job: take at Main.scala:35
[12:33:28,053] INFO  {DAGScheduler} Got job 1 (take at Main.scala:35) with 1 output partitions
[12:33:28,053] INFO  {DAGScheduler} Final stage: ResultStage 1 (take at Main.scala:35)
[12:33:28,053] INFO  {DAGScheduler} Parents of final stage: List()
[12:33:28,053] INFO  {DAGScheduler} Missing parents: List()
[12:33:28,054] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at take at Main.scala:35), which has no missing parents
[12:33:28,058] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 13.5 KB, free 1128.6 MB)
[12:33:28,060] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.6 MB)
[12:33:28,061] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:38807 (size: 6.6 KB, free: 1128.9 MB)
[12:33:28,062] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[12:33:28,062] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at take at Main.scala:35)
[12:33:28,062] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[12:33:28,065] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:33:28,065] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[12:33:28,073] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:33:28,079] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2459 bytes result sent to driver
[12:33:28,081] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 18 ms on localhost (1/1)
[12:33:28,082] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[12:33:28,082] INFO  {DAGScheduler} ResultStage 1 (take at Main.scala:35) finished in 0.019 s
[12:33:28,082] INFO  {DAGScheduler} Job 1 finished: take at Main.scala:35, took 0.030098 s
[12:33:28,098] INFO  {CodeGenerator} Code generated in 13.821026 ms
[12:33:28,104] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:33:28,108] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:33:28,110] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:33:28,110] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:33:28,111] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:33:28,111] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:33:28,111] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:33:28,111] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:33:28,111] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:33:28,112] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:33:28,112] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:33:28,112] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:33:28,112] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:33:28,112] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:33:28,112] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:33:28,113] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:33:28,113] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:33:28,113] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:33:28,113] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:33:28,113] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:33:28,113] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:33:28,113] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:33:28,114] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:33:28,114] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:33:28,114] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:33:28,114] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:33:28,115] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:33:28,126] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:33:28,131] INFO  {MemoryStore} MemoryStore cleared
[12:33:28,132] INFO  {BlockManager} BlockManager stopped
[12:33:28,133] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:33:28,137] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:33:28,139] INFO  {SparkContext} Successfully stopped SparkContext
[12:33:28,140] INFO  {ShutdownHookManager} Shutdown hook called
[12:33:28,140] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-d5f9d49c-77a6-40db-bea4-0f7bfdce2b6a
[12:39:13,031] INFO  {SparkContext} Running Spark version 2.0.1
[12:39:13,260] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:39:13,354] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:39:13,355] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:39:13,419] INFO  {SecurityManager} Changing view acls to: victor
[12:39:13,419] INFO  {SecurityManager} Changing modify acls to: victor
[12:39:13,420] INFO  {SecurityManager} Changing view acls groups to: 
[12:39:13,420] INFO  {SecurityManager} Changing modify acls groups to: 
[12:39:13,421] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:39:13,786] INFO  {Utils} Successfully started service 'sparkDriver' on port 39681.
[12:39:13,803] INFO  {SparkEnv} Registering MapOutputTracker
[12:39:13,818] INFO  {SparkEnv} Registering BlockManagerMaster
[12:39:13,830] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-d2da7206-992d-453d-9a97-13f3cd31fc0e
[12:39:13,843] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:39:13,894] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:39:13,963] INFO  {log} Logging initialized @1601ms
[12:39:14,063] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:39:14,080] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:39:14,080] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:39:14,080] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:39:14,080] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:39:14,081] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:39:14,081] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:39:14,081] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:39:14,081] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:39:14,081] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:39:14,081] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:39:14,082] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:39:14,082] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:39:14,082] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:39:14,082] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:39:14,082] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:39:14,083] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:39:14,083] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:39:14,083] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:39:14,083] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:39:14,083] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:39:14,089] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:39:14,089] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:39:14,090] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:39:14,090] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:39:14,096] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:39:14,097] INFO  {Server} Started @1736ms
[12:39:14,097] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:39:14,099] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:39:14,176] INFO  {Executor} Starting executor ID driver on host localhost
[12:39:14,198] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36803.
[12:39:14,199] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:36803
[12:39:14,201] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 36803)
[12:39:14,204] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:36803 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 36803)
[12:39:14,207] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 36803)
[12:39:14,326] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:39:14,368] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:39:14,369] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:39:14,370] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:39:14,370] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:39:14,372] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:39:14,387] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:39:16,228] INFO  {FileSourceStrategy} Pruning directories with: 
[12:39:16,229] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:39:16,234] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:39:16,234] INFO  {FileSourceStrategy} Pushed Filters: 
[12:39:16,342] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:39:16,385] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:39:16,387] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:36803 (size: 14.6 KB, free: 1128.9 MB)
[12:39:16,393] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:32
[12:39:16,397] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:39:16,875] INFO  {CodeGenerator} Code generated in 211.293565 ms
[12:39:16,963] INFO  {SparkContext} Starting job: show at Main.scala:32
[12:39:16,977] INFO  {DAGScheduler} Got job 0 (show at Main.scala:32) with 1 output partitions
[12:39:16,978] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:32)
[12:39:16,979] INFO  {DAGScheduler} Parents of final stage: List()
[12:39:16,980] INFO  {DAGScheduler} Missing parents: List()
[12:39:16,984] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32), which has no missing parents
[12:39:17,024] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[12:39:17,026] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[12:39:17,027] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:36803 (size: 6.6 KB, free: 1128.9 MB)
[12:39:17,027] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:39:17,030] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32)
[12:39:17,032] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:39:17,071] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:39:17,078] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:39:17,117] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:39:17,131] INFO  {CodeGenerator} Code generated in 10.820641 ms
[12:39:17,166] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[12:39:17,172] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 121 ms on localhost (1/1)
[12:39:17,174] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:39:17,177] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:32) finished in 0.136 s
[12:39:17,182] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:32, took 0.218705 s
[12:39:17,214] INFO  {CodeGenerator} Code generated in 18.895765 ms
[12:39:17,252] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:36803 in memory (size: 6.6 KB, free: 1128.9 MB)
[12:39:17,263] INFO  {FileSourceStrategy} Pruning directories with: 
[12:39:17,263] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:39:17,263] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:39:17,264] INFO  {FileSourceStrategy} Pushed Filters: 
[12:39:17,271] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[12:39:17,281] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[12:39:17,282] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:36803 (size: 14.6 KB, free: 1128.9 MB)
[12:39:17,283] INFO  {SparkContext} Created broadcast 2 from take at Main.scala:35
[12:39:17,283] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:39:17,303] INFO  {SparkContext} Starting job: take at Main.scala:35
[12:39:17,304] INFO  {DAGScheduler} Got job 1 (take at Main.scala:35) with 1 output partitions
[12:39:17,304] INFO  {DAGScheduler} Final stage: ResultStage 1 (take at Main.scala:35)
[12:39:17,304] INFO  {DAGScheduler} Parents of final stage: List()
[12:39:17,304] INFO  {DAGScheduler} Missing parents: List()
[12:39:17,305] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at take at Main.scala:35), which has no missing parents
[12:39:17,310] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 13.5 KB, free 1128.6 MB)
[12:39:17,312] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.6 MB)
[12:39:17,312] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:36803 (size: 6.6 KB, free: 1128.9 MB)
[12:39:17,313] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[12:39:17,313] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at take at Main.scala:35)
[12:39:17,313] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[12:39:17,315] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:39:17,316] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[12:39:17,326] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:39:17,330] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2459 bytes result sent to driver
[12:39:17,332] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 18 ms on localhost (1/1)
[12:39:17,332] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[12:39:17,333] INFO  {DAGScheduler} ResultStage 1 (take at Main.scala:35) finished in 0.019 s
[12:39:17,333] INFO  {DAGScheduler} Job 1 finished: take at Main.scala:35, took 0.030500 s
[12:39:17,348] INFO  {CodeGenerator} Code generated in 13.201994 ms
[12:39:17,354] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:39:17,358] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:39:17,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:39:17,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:39:17,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:39:17,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:39:17,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:39:17,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:39:17,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:39:17,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:39:17,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:39:17,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:39:17,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:39:17,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:39:17,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:39:17,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:39:17,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:39:17,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:39:17,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:39:17,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:39:17,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:39:17,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:39:17,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:39:17,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:39:17,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:39:17,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:39:17,364] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:39:17,373] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:39:17,378] INFO  {MemoryStore} MemoryStore cleared
[12:39:17,378] INFO  {BlockManager} BlockManager stopped
[12:39:17,379] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:39:17,382] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:39:17,383] INFO  {SparkContext} Successfully stopped SparkContext
[12:39:17,384] INFO  {ShutdownHookManager} Shutdown hook called
[12:39:17,385] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a084e1b9-bf66-4599-92df-284196ce3f10
[12:43:14,334] INFO  {SparkContext} Running Spark version 2.0.1
[12:43:14,542] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:43:14,628] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:43:14,628] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:43:14,694] INFO  {SecurityManager} Changing view acls to: victor
[12:43:14,695] INFO  {SecurityManager} Changing modify acls to: victor
[12:43:14,696] INFO  {SecurityManager} Changing view acls groups to: 
[12:43:14,697] INFO  {SecurityManager} Changing modify acls groups to: 
[12:43:14,698] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:43:15,066] INFO  {Utils} Successfully started service 'sparkDriver' on port 46777.
[12:43:15,083] INFO  {SparkEnv} Registering MapOutputTracker
[12:43:15,097] INFO  {SparkEnv} Registering BlockManagerMaster
[12:43:15,109] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-5c43721c-99af-4e17-a363-adeba452d9cc
[12:43:15,123] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:43:15,183] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:43:15,256] INFO  {log} Logging initialized @1473ms
[12:43:15,362] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:43:15,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[12:43:15,383] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[12:43:15,383] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[12:43:15,383] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[12:43:15,384] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[12:43:15,384] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[12:43:15,384] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[12:43:15,385] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[12:43:15,385] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[12:43:15,385] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[12:43:15,386] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[12:43:15,386] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[12:43:15,386] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[12:43:15,386] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[12:43:15,387] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[12:43:15,387] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[12:43:15,387] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[12:43:15,388] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[12:43:15,388] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[12:43:15,388] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[12:43:15,396] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[12:43:15,397] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[12:43:15,398] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[12:43:15,398] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[12:43:15,406] INFO  {ServerConnector} Started ServerConnector@6e6c2a80{HTTP/1.1}{0.0.0.0:4040}
[12:43:15,407] INFO  {Server} Started @1625ms
[12:43:15,407] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:43:15,409] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:43:15,502] INFO  {Executor} Starting executor ID driver on host localhost
[12:43:15,524] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43219.
[12:43:15,524] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:43219
[12:43:15,526] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 43219)
[12:43:15,529] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:43219 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 43219)
[12:43:15,534] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 43219)
[12:43:15,661] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b6579e8{/metrics/json,null,AVAILABLE}
[12:43:15,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53499d85{/SQL,null,AVAILABLE}
[12:43:15,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@782a4fff{/SQL/json,null,AVAILABLE}
[12:43:15,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL/execution,null,AVAILABLE}
[12:43:15,727] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1133ec6e{/SQL/execution/json,null,AVAILABLE}
[12:43:15,729] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/static/sql,null,AVAILABLE}
[12:43:15,748] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:43:17,677] INFO  {FileSourceStrategy} Pruning directories with: 
[12:43:17,679] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:43:17,683] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:43:17,684] INFO  {FileSourceStrategy} Pushed Filters: 
[12:43:17,783] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:43:17,827] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:43:17,829] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:43219 (size: 14.6 KB, free: 1128.9 MB)
[12:43:17,834] INFO  {SparkContext} Created broadcast 0 from persist at Main.scala:34
[12:43:17,837] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:43:18,314] INFO  {CodeGenerator} Code generated in 206.982159 ms
[12:43:18,478] INFO  {SparkContext} Starting job: show at Main.scala:35
[12:43:18,493] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[12:43:18,493] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[12:43:18,494] INFO  {DAGScheduler} Parents of final stage: List()
[12:43:18,498] INFO  {DAGScheduler} Missing parents: List()
[12:43:18,502] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35), which has no missing parents
[12:43:18,561] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 16.9 KB, free 1128.7 MB)
[12:43:18,563] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[12:43:18,564] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:43219 (size: 8.2 KB, free: 1128.9 MB)
[12:43:18,565] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:43:18,569] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35)
[12:43:18,571] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:43:18,614] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:43:18,621] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:43:18,665] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:43:18,680] INFO  {CodeGenerator} Code generated in 11.449874 ms
[12:43:18,988] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 2.7 MB, free 1126.0 MB)
[12:43:18,989] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 80.216.145.125:43219 (size: 2.7 MB, free: 1126.2 MB)
[12:43:19,047] INFO  {CodeGenerator} Code generated in 8.25239 ms
[12:43:19,074] INFO  {CodeGenerator} Code generated in 20.939069 ms
[12:43:19,100] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[12:43:19,106] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4564 bytes result sent to driver
[12:43:19,116] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 519 ms on localhost (1/1)
[12:43:19,117] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:43:19,121] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.538 s
[12:43:19,126] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.647076 s
[12:43:19,162] INFO  {CodeGenerator} Code generated in 18.057295 ms
[12:43:19,179] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:43:19,184] INFO  {ServerConnector} Stopped ServerConnector@6e6c2a80{HTTP/1.1}{0.0.0.0:4040}
[12:43:19,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[12:43:19,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[12:43:19,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[12:43:19,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[12:43:19,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[12:43:19,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[12:43:19,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[12:43:19,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[12:43:19,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[12:43:19,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[12:43:19,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[12:43:19,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[12:43:19,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[12:43:19,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[12:43:19,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[12:43:19,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[12:43:19,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[12:43:19,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[12:43:19,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[12:43:19,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[12:43:19,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[12:43:19,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[12:43:19,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[12:43:19,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[12:43:19,189] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:43:19,198] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:43:19,201] INFO  {MemoryStore} MemoryStore cleared
[12:43:19,201] INFO  {BlockManager} BlockManager stopped
[12:43:19,206] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:43:19,209] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:43:19,210] INFO  {SparkContext} Successfully stopped SparkContext
[12:43:19,211] INFO  {ShutdownHookManager} Shutdown hook called
[12:43:19,212] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-0e296f3b-1f95-4b43-846b-bc23f859c40f
[12:43:38,571] INFO  {SparkContext} Running Spark version 2.0.1
[12:43:38,803] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:43:38,916] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:43:38,916] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:43:38,988] INFO  {SecurityManager} Changing view acls to: victor
[12:43:38,989] INFO  {SecurityManager} Changing modify acls to: victor
[12:43:38,990] INFO  {SecurityManager} Changing view acls groups to: 
[12:43:38,990] INFO  {SecurityManager} Changing modify acls groups to: 
[12:43:38,991] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:43:39,351] INFO  {Utils} Successfully started service 'sparkDriver' on port 35149.
[12:43:39,367] INFO  {SparkEnv} Registering MapOutputTracker
[12:43:39,382] INFO  {SparkEnv} Registering BlockManagerMaster
[12:43:39,395] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-a8797403-da1d-4b35-a913-eebd098b5ca0
[12:43:39,409] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:43:39,468] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:43:39,545] INFO  {log} Logging initialized @1594ms
[12:43:39,652] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:43:39,668] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:43:39,668] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:43:39,669] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:43:39,669] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:43:39,669] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:43:39,669] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:43:39,669] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:43:39,670] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:43:39,670] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:43:39,670] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:43:39,670] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:43:39,670] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:43:39,671] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:43:39,671] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:43:39,671] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:43:39,671] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:43:39,671] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:43:39,672] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:43:39,672] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:43:39,672] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:43:39,678] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:43:39,678] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:43:39,679] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:43:39,679] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:43:39,685] INFO  {ServerConnector} Started ServerConnector@6163c071{HTTP/1.1}{0.0.0.0:4040}
[12:43:39,686] INFO  {Server} Started @1736ms
[12:43:39,686] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:43:39,688] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:43:39,770] INFO  {Executor} Starting executor ID driver on host localhost
[12:43:39,793] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44679.
[12:43:39,794] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:44679
[12:43:39,797] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 44679)
[12:43:39,800] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:44679 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 44679)
[12:43:39,803] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 44679)
[12:43:39,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[12:43:39,973] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@759fad4{/SQL,null,AVAILABLE}
[12:43:39,974] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53499d85{/SQL/json,null,AVAILABLE}
[12:43:39,975] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/execution,null,AVAILABLE}
[12:43:39,976] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL/execution/json,null,AVAILABLE}
[12:43:39,978] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@24f360b2{/static/sql,null,AVAILABLE}
[12:43:39,995] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:43:41,973] INFO  {FileSourceStrategy} Pruning directories with: 
[12:43:41,976] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:43:41,981] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:43:41,982] INFO  {FileSourceStrategy} Pushed Filters: 
[12:43:42,104] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:43:42,149] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:43:42,150] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:44679 (size: 14.6 KB, free: 1128.9 MB)
[12:43:42,157] INFO  {SparkContext} Created broadcast 0 from persist at Main.scala:34
[12:43:42,160] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:43:42,635] INFO  {CodeGenerator} Code generated in 211.121174 ms
[12:43:42,779] INFO  {SparkContext} Starting job: show at Main.scala:35
[12:43:42,793] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[12:43:42,794] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[12:43:42,794] INFO  {DAGScheduler} Parents of final stage: List()
[12:43:42,797] INFO  {DAGScheduler} Missing parents: List()
[12:43:42,801] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35), which has no missing parents
[12:43:42,856] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 16.9 KB, free 1128.7 MB)
[12:43:42,858] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[12:43:42,859] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:44679 (size: 8.2 KB, free: 1128.9 MB)
[12:43:42,860] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:43:42,864] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35)
[12:43:42,866] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:43:42,906] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:43:42,912] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:43:42,955] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:43:42,968] INFO  {CodeGenerator} Code generated in 9.946493 ms
[12:43:43,306] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 2.7 MB, free 1126.0 MB)
[12:43:43,307] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 80.216.145.125:44679 (size: 2.7 MB, free: 1126.2 MB)
[12:43:43,317] INFO  {CodeGenerator} Code generated in 4.308656 ms
[12:43:43,344] INFO  {CodeGenerator} Code generated in 20.941647 ms
[12:43:43,360] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[12:43:43,367] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4564 bytes result sent to driver
[12:43:43,375] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 486 ms on localhost (1/1)
[12:43:43,376] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:43:43,380] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.503 s
[12:43:43,385] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.606224 s
[12:43:43,421] INFO  {CodeGenerator} Code generated in 21.476559 ms
[12:43:43,436] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:43:43,441] INFO  {ServerConnector} Stopped ServerConnector@6163c071{HTTP/1.1}{0.0.0.0:4040}
[12:43:43,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:43:43,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:43:43,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:43:43,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:43:43,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:43:43,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:43:43,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:43:43,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:43:43,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:43:43,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:43:43,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:43:43,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:43:43,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:43:43,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:43:43,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:43:43,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:43:43,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:43:43,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:43:43,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:43:43,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:43:43,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:43:43,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:43:43,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:43:43,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:43:43,447] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:43:43,456] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:43:43,460] INFO  {MemoryStore} MemoryStore cleared
[12:43:43,460] INFO  {BlockManager} BlockManager stopped
[12:43:43,466] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:43:43,468] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:43:43,470] INFO  {SparkContext} Successfully stopped SparkContext
[12:43:43,470] INFO  {ShutdownHookManager} Shutdown hook called
[12:43:43,471] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-225668cf-7075-42b2-a228-d65b6dea4707
[12:43:54,113] INFO  {SparkContext} Running Spark version 2.0.1
[12:43:54,340] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:43:54,440] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:43:54,441] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:43:54,516] INFO  {SecurityManager} Changing view acls to: victor
[12:43:54,517] INFO  {SecurityManager} Changing modify acls to: victor
[12:43:54,518] INFO  {SecurityManager} Changing view acls groups to: 
[12:43:54,519] INFO  {SecurityManager} Changing modify acls groups to: 
[12:43:54,520] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:43:54,855] INFO  {Utils} Successfully started service 'sparkDriver' on port 41437.
[12:43:54,875] INFO  {SparkEnv} Registering MapOutputTracker
[12:43:54,894] INFO  {SparkEnv} Registering BlockManagerMaster
[12:43:54,911] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-145eea93-d31a-4e41-9afa-3ae6308d9507
[12:43:54,925] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:43:54,986] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:43:55,062] INFO  {log} Logging initialized @1555ms
[12:43:55,170] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:43:55,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:43:55,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:43:55,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:43:55,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:43:55,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:43:55,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:43:55,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:43:55,188] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:43:55,188] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:43:55,188] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:43:55,189] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:43:55,189] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:43:55,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:43:55,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:43:55,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:43:55,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:43:55,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:43:55,191] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:43:55,191] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:43:55,191] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:43:55,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:43:55,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:43:55,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:43:55,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:43:55,205] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:43:55,205] INFO  {Server} Started @1699ms
[12:43:55,205] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:43:55,208] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:43:55,290] INFO  {Executor} Starting executor ID driver on host localhost
[12:43:55,313] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45007.
[12:43:55,314] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:45007
[12:43:55,316] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 45007)
[12:43:55,319] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:45007 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 45007)
[12:43:55,322] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 45007)
[12:43:55,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:43:55,492] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:43:55,493] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:43:55,493] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:43:55,494] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:43:55,495] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:43:55,512] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:43:57,393] INFO  {FileSourceStrategy} Pruning directories with: 
[12:43:57,395] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:43:57,399] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:43:57,400] INFO  {FileSourceStrategy} Pushed Filters: 
[12:43:57,507] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:43:57,551] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:43:57,554] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:45007 (size: 14.6 KB, free: 1128.9 MB)
[12:43:57,559] INFO  {SparkContext} Created broadcast 0 from persist at Main.scala:34
[12:43:57,563] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:43:58,033] INFO  {CodeGenerator} Code generated in 209.697331 ms
[12:43:58,202] INFO  {SparkContext} Starting job: show at Main.scala:35
[12:43:58,217] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[12:43:58,218] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[12:43:58,218] INFO  {DAGScheduler} Parents of final stage: List()
[12:43:58,221] INFO  {DAGScheduler} Missing parents: List()
[12:43:58,225] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35), which has no missing parents
[12:43:58,288] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 16.9 KB, free 1128.7 MB)
[12:43:58,291] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[12:43:58,291] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:45007 (size: 8.2 KB, free: 1128.9 MB)
[12:43:58,292] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:43:58,295] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35)
[12:43:58,297] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:43:58,338] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:43:58,346] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:43:58,394] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:43:58,409] INFO  {CodeGenerator} Code generated in 11.333871 ms
[12:43:58,731] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 2.7 MB, free 1126.0 MB)
[12:43:58,732] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 80.216.145.125:45007 (size: 2.7 MB, free: 1126.2 MB)
[12:43:58,742] INFO  {CodeGenerator} Code generated in 4.661654 ms
[12:43:58,769] INFO  {CodeGenerator} Code generated in 21.388978 ms
[12:43:58,787] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[12:43:58,795] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4564 bytes result sent to driver
[12:43:58,804] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 486 ms on localhost (1/1)
[12:43:58,806] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:43:58,809] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.502 s
[12:43:58,816] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.613413 s
[12:43:58,853] INFO  {CodeGenerator} Code generated in 18.726667 ms
[12:43:58,869] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:43:58,877] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:43:58,879] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:43:58,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:43:58,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:43:58,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:43:58,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:43:58,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:43:58,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:43:58,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:43:58,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:43:58,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:43:58,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:43:58,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:43:58,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:43:58,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:43:58,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:43:58,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:43:58,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:43:58,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:43:58,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:43:58,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:43:58,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:43:58,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:43:58,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:43:58,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:43:58,884] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:43:58,892] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:43:58,896] INFO  {MemoryStore} MemoryStore cleared
[12:43:58,896] INFO  {BlockManager} BlockManager stopped
[12:43:58,900] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:43:58,902] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:43:58,904] INFO  {SparkContext} Successfully stopped SparkContext
[12:43:58,904] INFO  {ShutdownHookManager} Shutdown hook called
[12:43:58,905] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-c32d3713-37ef-4570-854e-9512fa729072
[12:44:10,105] INFO  {SparkContext} Running Spark version 2.0.1
[12:44:10,339] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:44:10,442] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:44:10,443] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:44:10,525] INFO  {SecurityManager} Changing view acls to: victor
[12:44:10,526] INFO  {SecurityManager} Changing modify acls to: victor
[12:44:10,527] INFO  {SecurityManager} Changing view acls groups to: 
[12:44:10,528] INFO  {SecurityManager} Changing modify acls groups to: 
[12:44:10,529] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:44:10,870] INFO  {Utils} Successfully started service 'sparkDriver' on port 38447.
[12:44:10,886] INFO  {SparkEnv} Registering MapOutputTracker
[12:44:10,901] INFO  {SparkEnv} Registering BlockManagerMaster
[12:44:10,914] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-14b0d6c1-3162-4bbc-a545-b6bd17633474
[12:44:10,929] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:44:10,984] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:44:11,060] INFO  {log} Logging initialized @1534ms
[12:44:11,169] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:44:11,189] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:44:11,189] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:44:11,189] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:44:11,189] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:44:11,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:44:11,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:44:11,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:44:11,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:44:11,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:44:11,191] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:44:11,191] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:44:11,191] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:44:11,191] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:44:11,191] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:44:11,192] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:44:11,192] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:44:11,192] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:44:11,192] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:44:11,192] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:44:11,192] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:44:11,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:44:11,199] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:44:11,199] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:44:11,200] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:44:11,206] INFO  {ServerConnector} Started ServerConnector@4183705{HTTP/1.1}{0.0.0.0:4040}
[12:44:11,207] INFO  {Server} Started @1682ms
[12:44:11,207] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:44:11,209] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:44:11,289] INFO  {Executor} Starting executor ID driver on host localhost
[12:44:11,314] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33365.
[12:44:11,315] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:33365
[12:44:11,317] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 33365)
[12:44:11,320] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:33365 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 33365)
[12:44:11,323] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 33365)
[12:44:11,446] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[12:44:11,493] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@759fad4{/SQL,null,AVAILABLE}
[12:44:11,494] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53499d85{/SQL/json,null,AVAILABLE}
[12:44:11,495] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/execution,null,AVAILABLE}
[12:44:11,495] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL/execution/json,null,AVAILABLE}
[12:44:11,497] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@24f360b2{/static/sql,null,AVAILABLE}
[12:44:11,512] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:44:13,411] INFO  {FileSourceStrategy} Pruning directories with: 
[12:44:13,413] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:44:13,417] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:44:13,418] INFO  {FileSourceStrategy} Pushed Filters: 
[12:44:13,524] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:44:13,571] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:44:13,573] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:33365 (size: 14.6 KB, free: 1128.9 MB)
[12:44:13,578] INFO  {SparkContext} Created broadcast 0 from persist at Main.scala:34
[12:44:13,582] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:44:14,064] INFO  {CodeGenerator} Code generated in 219.303868 ms
[12:44:14,221] INFO  {SparkContext} Starting job: show at Main.scala:35
[12:44:14,240] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[12:44:14,241] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[12:44:14,242] INFO  {DAGScheduler} Parents of final stage: List()
[12:44:14,246] INFO  {DAGScheduler} Missing parents: List()
[12:44:14,251] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35), which has no missing parents
[12:44:14,317] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 16.9 KB, free 1128.7 MB)
[12:44:14,320] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[12:44:14,321] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:33365 (size: 8.2 KB, free: 1128.9 MB)
[12:44:14,322] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:44:14,325] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35)
[12:44:14,327] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:44:14,362] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:44:14,368] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:44:14,413] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:44:14,444] INFO  {CodeGenerator} Code generated in 27.843545 ms
[12:44:14,739] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 2.7 MB, free 1126.0 MB)
[12:44:14,740] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 80.216.145.125:33365 (size: 2.7 MB, free: 1126.2 MB)
[12:44:14,752] INFO  {CodeGenerator} Code generated in 4.498986 ms
[12:44:14,779] INFO  {CodeGenerator} Code generated in 20.855861 ms
[12:44:14,796] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[12:44:14,803] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4564 bytes result sent to driver
[12:44:14,812] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 466 ms on localhost (1/1)
[12:44:14,814] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:44:14,818] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.481 s
[12:44:14,824] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.603153 s
[12:44:14,862] INFO  {CodeGenerator} Code generated in 22.58894 ms
[12:44:14,879] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:44:14,884] INFO  {ServerConnector} Stopped ServerConnector@4183705{HTTP/1.1}{0.0.0.0:4040}
[12:44:14,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:44:14,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:44:14,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:44:14,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:44:14,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:44:14,886] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:44:14,887] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:44:14,887] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:44:14,887] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:44:14,887] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:44:14,887] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:44:14,887] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:44:14,887] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:44:14,887] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:44:14,887] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:44:14,887] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:44:14,888] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:44:14,888] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:44:14,888] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:44:14,888] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:44:14,888] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:44:14,888] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:44:14,888] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:44:14,888] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:44:14,890] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:44:14,897] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:44:14,901] INFO  {MemoryStore} MemoryStore cleared
[12:44:14,901] INFO  {BlockManager} BlockManager stopped
[12:44:14,905] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:44:14,908] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:44:14,912] INFO  {SparkContext} Successfully stopped SparkContext
[12:44:14,913] INFO  {ShutdownHookManager} Shutdown hook called
[12:44:14,913] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-6cda2ae8-2ea1-45be-86d2-8de080e41106
[12:45:14,999] INFO  {SparkContext} Running Spark version 2.0.1
[12:45:15,209] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:45:15,304] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:45:15,305] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:45:15,381] INFO  {SecurityManager} Changing view acls to: victor
[12:45:15,382] INFO  {SecurityManager} Changing modify acls to: victor
[12:45:15,383] INFO  {SecurityManager} Changing view acls groups to: 
[12:45:15,383] INFO  {SecurityManager} Changing modify acls groups to: 
[12:45:15,384] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:45:15,753] INFO  {Utils} Successfully started service 'sparkDriver' on port 33797.
[12:45:15,771] INFO  {SparkEnv} Registering MapOutputTracker
[12:45:15,785] INFO  {SparkEnv} Registering BlockManagerMaster
[12:45:15,797] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-aee15f1a-a831-4c47-91ed-874d94ebc3e4
[12:45:15,811] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:45:15,867] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:45:15,936] INFO  {log} Logging initialized @1513ms
[12:45:16,034] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:45:16,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:45:16,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:45:16,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:45:16,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:45:16,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:45:16,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:45:16,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:45:16,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:45:16,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:45:16,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:45:16,052] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:45:16,052] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:45:16,052] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:45:16,052] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:45:16,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:45:16,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:45:16,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:45:16,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:45:16,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:45:16,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:45:16,059] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:45:16,060] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:45:16,060] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:45:16,061] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:45:16,067] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:45:16,067] INFO  {Server} Started @1646ms
[12:45:16,067] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:45:16,069] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:45:16,148] INFO  {Executor} Starting executor ID driver on host localhost
[12:45:16,171] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46395.
[12:45:16,171] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:46395
[12:45:16,173] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 46395)
[12:45:16,177] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:46395 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 46395)
[12:45:16,180] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 46395)
[12:45:16,305] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:45:16,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:45:16,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:45:16,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:45:16,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:45:16,353] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:45:16,368] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:45:18,213] INFO  {FileSourceStrategy} Pruning directories with: 
[12:45:18,215] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:45:18,219] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:45:18,220] INFO  {FileSourceStrategy} Pushed Filters: 
[12:45:18,320] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:45:18,364] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:45:18,365] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:46395 (size: 14.6 KB, free: 1128.9 MB)
[12:45:18,372] INFO  {SparkContext} Created broadcast 0 from persist at Main.scala:34
[12:45:18,376] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:45:18,831] INFO  {CodeGenerator} Code generated in 206.433774 ms
[12:45:18,978] INFO  {SparkContext} Starting job: show at Main.scala:35
[12:45:18,993] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[12:45:18,993] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[12:45:18,993] INFO  {DAGScheduler} Parents of final stage: List()
[12:45:18,997] INFO  {DAGScheduler} Missing parents: List()
[12:45:19,000] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35), which has no missing parents
[12:45:19,060] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 16.9 KB, free 1128.7 MB)
[12:45:19,063] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[12:45:19,063] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:46395 (size: 8.2 KB, free: 1128.9 MB)
[12:45:19,064] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:45:19,067] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35)
[12:45:19,069] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:45:19,105] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:45:19,112] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:45:19,158] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:45:19,171] INFO  {CodeGenerator} Code generated in 9.966414 ms
[12:45:19,486] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 2.7 MB, free 1126.0 MB)
[12:45:19,487] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 80.216.145.125:46395 (size: 2.7 MB, free: 1126.2 MB)
[12:45:19,498] INFO  {CodeGenerator} Code generated in 4.564655 ms
[12:45:19,525] INFO  {CodeGenerator} Code generated in 20.739821 ms
[12:45:19,540] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[12:45:19,547] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4564 bytes result sent to driver
[12:45:19,557] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 468 ms on localhost (1/1)
[12:45:19,558] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:45:19,562] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.483 s
[12:45:19,567] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.588004 s
[12:45:19,596] INFO  {CodeGenerator} Code generated in 15.683044 ms
[12:45:19,626] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:45:19,630] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:45:19,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:45:19,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:45:19,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:45:19,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:45:19,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:45:19,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:45:19,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:45:19,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:45:19,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:45:19,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:45:19,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:45:19,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:45:19,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:45:19,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:45:19,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:45:19,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:45:19,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:45:19,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:45:19,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:45:19,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:45:19,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:45:19,634] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:45:19,634] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:45:19,634] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:45:19,636] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:45:19,646] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:45:19,650] INFO  {MemoryStore} MemoryStore cleared
[12:45:19,650] INFO  {BlockManager} BlockManager stopped
[12:45:19,654] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:45:19,657] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:45:19,660] INFO  {SparkContext} Successfully stopped SparkContext
[12:45:19,660] INFO  {ShutdownHookManager} Shutdown hook called
[12:45:19,661] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-dbc60547-f913-4920-ba0d-f69beaeda509
[12:49:52,480] INFO  {SparkContext} Running Spark version 2.0.1
[12:49:52,719] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:49:52,815] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:49:52,815] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:49:52,912] INFO  {SecurityManager} Changing view acls to: victor
[12:49:52,913] INFO  {SecurityManager} Changing modify acls to: victor
[12:49:52,914] INFO  {SecurityManager} Changing view acls groups to: 
[12:49:52,914] INFO  {SecurityManager} Changing modify acls groups to: 
[12:49:52,915] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:49:53,290] INFO  {Utils} Successfully started service 'sparkDriver' on port 40197.
[12:49:53,308] INFO  {SparkEnv} Registering MapOutputTracker
[12:49:53,326] INFO  {SparkEnv} Registering BlockManagerMaster
[12:49:53,339] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e30ffcf9-06b2-4f1d-b7a2-4dc59178f1b2
[12:49:53,353] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:49:53,407] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:49:53,482] INFO  {log} Logging initialized @1630ms
[12:49:53,589] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:49:53,605] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:49:53,605] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:49:53,606] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:49:53,606] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:49:53,606] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:49:53,607] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:49:53,607] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:49:53,607] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:49:53,607] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:49:53,608] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:49:53,608] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:49:53,608] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:49:53,609] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:49:53,609] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:49:53,609] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:49:53,609] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:49:53,610] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:49:53,610] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:49:53,610] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:49:53,610] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:49:53,619] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:49:53,620] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:49:53,621] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:49:53,621] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:49:53,631] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:49:53,631] INFO  {Server} Started @1781ms
[12:49:53,632] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:49:53,634] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:49:53,718] INFO  {Executor} Starting executor ID driver on host localhost
[12:49:53,740] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43475.
[12:49:53,741] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:43475
[12:49:53,742] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 43475)
[12:49:53,745] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:43475 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 43475)
[12:49:53,749] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 43475)
[12:49:53,890] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f4d427e{/metrics/json,null,AVAILABLE}
[12:49:53,932] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@114a85c2{/SQL,null,AVAILABLE}
[12:49:53,933] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@cf65451{/SQL/json,null,AVAILABLE}
[12:49:53,934] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64da2a7{/SQL/execution,null,AVAILABLE}
[12:49:53,935] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@d78795{/SQL/execution/json,null,AVAILABLE}
[12:49:53,937] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@72b16078{/static/sql,null,AVAILABLE}
[12:49:53,952] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:49:55,841] INFO  {FileSourceStrategy} Pruning directories with: 
[12:49:55,843] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:49:55,847] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:49:55,848] INFO  {FileSourceStrategy} Pushed Filters: 
[12:49:55,951] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:49:55,995] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:49:55,997] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:43475 (size: 14.6 KB, free: 1128.9 MB)
[12:49:56,003] INFO  {SparkContext} Created broadcast 0 from persist at Main.scala:34
[12:49:56,007] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:49:56,479] INFO  {CodeGenerator} Code generated in 213.708301 ms
[12:49:56,623] INFO  {SparkContext} Starting job: show at Main.scala:35
[12:49:56,640] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[12:49:56,640] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[12:49:56,640] INFO  {DAGScheduler} Parents of final stage: List()
[12:49:56,644] INFO  {DAGScheduler} Missing parents: List()
[12:49:56,648] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35), which has no missing parents
[12:49:56,715] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 16.9 KB, free 1128.7 MB)
[12:49:56,718] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[12:49:56,719] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:43475 (size: 8.2 KB, free: 1128.9 MB)
[12:49:56,720] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:49:56,724] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:35)
[12:49:56,726] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:49:56,770] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[12:49:56,777] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:49:56,819] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[12:49:56,836] INFO  {CodeGenerator} Code generated in 13.17341 ms
[12:49:57,184] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 2.7 MB, free 1126.0 MB)
[12:49:57,184] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 80.216.145.125:43475 (size: 2.7 MB, free: 1126.2 MB)
[12:49:57,197] INFO  {CodeGenerator} Code generated in 4.828175 ms
[12:49:57,226] INFO  {CodeGenerator} Code generated in 21.870044 ms
[12:49:57,244] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[12:49:57,251] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4564 bytes result sent to driver
[12:49:57,261] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 512 ms on localhost (1/1)
[12:49:57,263] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:49:57,267] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.532 s
[12:49:57,274] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.650378 s
[12:49:57,317] INFO  {CodeGenerator} Code generated in 23.756944 ms
[12:49:57,345] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:49:57,356] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:49:57,358] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:49:57,359] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:49:57,359] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:49:57,359] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:49:57,359] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:49:57,359] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:49:57,359] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:49:57,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:49:57,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:49:57,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:49:57,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:49:57,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:49:57,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:49:57,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:49:57,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:49:57,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:49:57,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:49:57,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:49:57,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:49:57,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:49:57,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:49:57,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:49:57,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:49:57,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:49:57,364] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:49:57,373] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:49:57,377] INFO  {MemoryStore} MemoryStore cleared
[12:49:57,378] INFO  {BlockManager} BlockManager stopped
[12:49:57,383] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:49:57,385] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:49:57,386] INFO  {SparkContext} Successfully stopped SparkContext
[12:49:57,387] INFO  {ShutdownHookManager} Shutdown hook called
[12:49:57,388] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-5df0a83f-6e43-42de-83e0-417c3c58b5a7
[12:50:30,677] INFO  {SparkContext} Running Spark version 2.0.1
[12:50:30,912] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:50:31,012] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[12:50:31,015] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:50:31,091] INFO  {SecurityManager} Changing view acls to: victor
[12:50:31,091] INFO  {SecurityManager} Changing modify acls to: victor
[12:50:31,092] INFO  {SecurityManager} Changing view acls groups to: 
[12:50:31,093] INFO  {SecurityManager} Changing modify acls groups to: 
[12:50:31,093] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:50:31,499] INFO  {Utils} Successfully started service 'sparkDriver' on port 33391.
[12:50:31,515] INFO  {SparkEnv} Registering MapOutputTracker
[12:50:31,530] INFO  {SparkEnv} Registering BlockManagerMaster
[12:50:31,542] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-7cf06851-82a8-426f-baa4-8c62831d4c1d
[12:50:31,557] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:50:31,622] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:50:31,697] INFO  {log} Logging initialized @1615ms
[12:50:31,824] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:50:31,844] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[12:50:31,845] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[12:50:31,845] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[12:50:31,845] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[12:50:31,846] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[12:50:31,846] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[12:50:31,846] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[12:50:31,846] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[12:50:31,847] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[12:50:31,847] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[12:50:31,847] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[12:50:31,848] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[12:50:31,848] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[12:50:31,848] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[12:50:31,848] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[12:50:31,849] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[12:50:31,849] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[12:50:31,849] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[12:50:31,849] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[12:50:31,850] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[12:50:31,859] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[12:50:31,860] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[12:50:31,862] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[12:50:31,863] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[12:50:31,871] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:50:31,871] INFO  {Server} Started @1791ms
[12:50:31,871] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:50:31,874] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[12:50:31,976] INFO  {Executor} Starting executor ID driver on host localhost
[12:50:31,997] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38435.
[12:50:31,997] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:38435
[12:50:31,999] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 38435)
[12:50:32,001] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:38435 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 38435)
[12:50:32,003] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 38435)
[12:50:32,128] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[12:50:32,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[12:50:32,192] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[12:50:32,194] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[12:50:32,195] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[12:50:32,199] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[12:50:32,215] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:50:34,118] INFO  {FileSourceStrategy} Pruning directories with: 
[12:50:34,120] INFO  {FileSourceStrategy} Post-Scan Filters: 
[12:50:34,124] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[12:50:34,125] INFO  {FileSourceStrategy} Pushed Filters: 
[12:50:34,230] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[12:50:34,277] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:50:34,279] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:38435 (size: 14.6 KB, free: 1128.9 MB)
[12:50:34,285] INFO  {SparkContext} Created broadcast 0 from persist at Main.scala:34
[12:50:34,288] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[12:50:34,775] INFO  {CodeGenerator} Code generated in 229.211629 ms
[12:50:34,883] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:50:34,887] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[12:50:34,889] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[12:50:34,889] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[12:50:34,889] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[12:50:34,889] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[12:50:34,889] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[12:50:34,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[12:50:34,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[12:50:34,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[12:50:34,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[12:50:34,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[12:50:34,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[12:50:34,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[12:50:34,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[12:50:34,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[12:50:34,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[12:50:34,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[12:50:34,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[12:50:34,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[12:50:34,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[12:50:34,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[12:50:34,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[12:50:34,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[12:50:34,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[12:50:34,892] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[12:50:34,893] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[12:50:34,901] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:50:34,905] INFO  {MemoryStore} MemoryStore cleared
[12:50:34,905] INFO  {BlockManager} BlockManager stopped
[12:50:34,912] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:50:34,915] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:50:34,931] INFO  {SparkContext} Successfully stopped SparkContext
[12:50:34,931] INFO  {ShutdownHookManager} Shutdown hook called
[12:50:34,932] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-9108d50b-ba66-43d3-8ffe-9ea5be3fbeb4
[13:35:49,684] INFO  {SparkContext} Running Spark version 2.0.1
[13:35:49,898] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:35:50,000] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[13:35:50,001] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:35:50,083] INFO  {SecurityManager} Changing view acls to: victor
[13:35:50,083] INFO  {SecurityManager} Changing modify acls to: victor
[13:35:50,084] INFO  {SecurityManager} Changing view acls groups to: 
[13:35:50,085] INFO  {SecurityManager} Changing modify acls groups to: 
[13:35:50,085] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:35:50,455] INFO  {Utils} Successfully started service 'sparkDriver' on port 39981.
[13:35:50,475] INFO  {SparkEnv} Registering MapOutputTracker
[13:35:50,490] INFO  {SparkEnv} Registering BlockManagerMaster
[13:35:50,503] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-1e7bf3fc-1b50-4804-a0bb-91bbd0b41280
[13:35:50,519] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:35:50,582] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:35:50,658] INFO  {log} Logging initialized @1590ms
[13:35:50,760] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:35:50,777] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[13:35:50,778] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[13:35:50,778] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[13:35:50,778] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[13:35:50,779] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[13:35:50,779] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[13:35:50,779] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[13:35:50,779] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[13:35:50,780] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[13:35:50,780] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[13:35:50,780] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[13:35:50,781] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[13:35:50,781] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[13:35:50,781] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[13:35:50,781] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[13:35:50,782] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[13:35:50,782] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[13:35:50,782] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[13:35:50,782] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[13:35:50,783] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[13:35:50,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[13:35:50,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[13:35:50,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[13:35:50,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[13:35:50,805] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[13:35:50,805] INFO  {Server} Started @1739ms
[13:35:50,805] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:35:50,808] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[13:35:50,917] INFO  {Executor} Starting executor ID driver on host localhost
[13:35:50,939] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43195.
[13:35:50,940] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:43195
[13:35:50,942] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 43195)
[13:35:50,945] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:43195 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 43195)
[13:35:50,951] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 43195)
[13:35:51,090] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[13:35:51,143] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[13:35:51,144] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[13:35:51,145] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[13:35:51,146] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[13:35:51,148] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[13:35:51,170] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:35:53,100] INFO  {FileSourceStrategy} Pruning directories with: 
[13:35:53,102] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:35:53,106] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:35:53,106] INFO  {FileSourceStrategy} Pushed Filters: 
[13:35:53,216] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[13:35:53,260] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:35:53,262] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:43195 (size: 14.6 KB, free: 1128.9 MB)
[13:35:53,268] INFO  {SparkContext} Created broadcast 0 from persist at Main.scala:35
[13:35:53,271] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:35:53,752] INFO  {CodeGenerator} Code generated in 211.928157 ms
[13:35:53,906] INFO  {SparkContext} Starting job: show at Main.scala:36
[13:35:53,922] INFO  {DAGScheduler} Got job 0 (show at Main.scala:36) with 1 output partitions
[13:35:53,922] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:36)
[13:35:53,923] INFO  {DAGScheduler} Parents of final stage: List()
[13:35:53,926] INFO  {DAGScheduler} Missing parents: List()
[13:35:53,930] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:36), which has no missing parents
[13:35:53,993] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 16.9 KB, free 1128.7 MB)
[13:35:53,995] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[13:35:53,996] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:43195 (size: 8.2 KB, free: 1128.9 MB)
[13:35:53,997] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:35:54,000] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:36)
[13:35:54,002] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:35:54,040] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[13:35:54,046] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:35:54,087] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:35:54,100] INFO  {CodeGenerator} Code generated in 10.16778 ms
[13:35:54,451] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 2.7 MB, free 1126.0 MB)
[13:35:54,451] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 80.216.145.125:43195 (size: 2.7 MB, free: 1126.2 MB)
[13:35:54,463] INFO  {CodeGenerator} Code generated in 5.472401 ms
[13:35:54,494] INFO  {CodeGenerator} Code generated in 24.586437 ms
[13:35:54,519] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[13:35:54,526] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4564 bytes result sent to driver
[13:35:54,535] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 513 ms on localhost (1/1)
[13:35:54,537] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:35:54,541] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:36) finished in 0.530 s
[13:35:54,549] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:36, took 0.642098 s
[13:35:54,588] INFO  {CodeGenerator} Code generated in 21.60483 ms
[13:35:54,643] INFO  {SparkContext} Starting job: foreach at Main.scala:39
[13:35:54,644] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:39) with 1 output partitions
[13:35:54,644] INFO  {DAGScheduler} Final stage: ResultStage 1 (foreach at Main.scala:39)
[13:35:54,644] INFO  {DAGScheduler} Parents of final stage: List()
[13:35:54,646] INFO  {DAGScheduler} Missing parents: List()
[13:35:54,647] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[7] at foreach at Main.scala:39), which has no missing parents
[13:35:54,657] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 18.9 KB, free 1126.0 MB)
[13:35:54,658] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.2 KB, free 1126.0 MB)
[13:35:54,659] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:43195 (size: 9.2 KB, free: 1126.2 MB)
[13:35:54,659] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[13:35:54,660] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at foreach at Main.scala:39)
[13:35:54,660] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:35:54,666] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5989 bytes)
[13:35:54,666] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:35:54,678] INFO  {BlockManager} Found block rdd_2_0 locally
[13:35:54,695] INFO  {CodeGenerator} Code generated in 15.936432 ms
[13:35:54,711] INFO  {CodeGenerator} Code generated in 13.006175 ms
[13:35:54,818] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1743 bytes result sent to driver
[13:35:54,820] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 157 ms on localhost (1/1)
[13:35:54,820] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:35:54,821] INFO  {DAGScheduler} ResultStage 1 (foreach at Main.scala:39) finished in 0.158 s
[13:35:54,822] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:39, took 0.178699 s
[13:35:54,827] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:35:54,833] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[13:35:54,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[13:35:54,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[13:35:54,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[13:35:54,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[13:35:54,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[13:35:54,837] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[13:35:54,837] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[13:35:54,837] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[13:35:54,837] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[13:35:54,837] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[13:35:54,837] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[13:35:54,838] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[13:35:54,838] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[13:35:54,838] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[13:35:54,838] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[13:35:54,838] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[13:35:54,838] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[13:35:54,838] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[13:35:54,838] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[13:35:54,839] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[13:35:54,839] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[13:35:54,839] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[13:35:54,839] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[13:35:54,839] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[13:35:54,841] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[13:35:54,857] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:35:54,863] INFO  {MemoryStore} MemoryStore cleared
[13:35:54,864] INFO  {BlockManager} BlockManager stopped
[13:35:54,869] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:35:54,986] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:35:55,004] INFO  {SparkContext} Successfully stopped SparkContext
[13:35:55,006] INFO  {ShutdownHookManager} Shutdown hook called
[13:35:55,008] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-cbbe808b-fe74-4bc5-b352-b63d5fa273b6
[13:40:20,274] INFO  {SparkContext} Running Spark version 2.0.1
[13:40:20,528] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:40:20,644] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[13:40:20,645] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:40:20,731] INFO  {SecurityManager} Changing view acls to: victor
[13:40:20,732] INFO  {SecurityManager} Changing modify acls to: victor
[13:40:20,732] INFO  {SecurityManager} Changing view acls groups to: 
[13:40:20,733] INFO  {SecurityManager} Changing modify acls groups to: 
[13:40:20,733] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:40:21,114] INFO  {Utils} Successfully started service 'sparkDriver' on port 32771.
[13:40:21,136] INFO  {SparkEnv} Registering MapOutputTracker
[13:40:21,156] INFO  {SparkEnv} Registering BlockManagerMaster
[13:40:21,169] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-7b7da7cc-c50f-4030-bc09-407bbc54dda5
[13:40:21,183] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:40:21,229] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:40:21,305] INFO  {log} Logging initialized @1674ms
[13:40:21,412] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:40:21,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[13:40:21,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[13:40:21,430] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[13:40:21,430] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[13:40:21,430] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[13:40:21,430] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[13:40:21,431] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[13:40:21,431] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[13:40:21,431] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[13:40:21,431] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[13:40:21,432] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[13:40:21,432] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[13:40:21,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[13:40:21,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[13:40:21,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[13:40:21,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[13:40:21,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[13:40:21,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[13:40:21,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[13:40:21,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[13:40:21,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[13:40:21,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[13:40:21,442] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[13:40:21,442] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[13:40:21,449] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[13:40:21,449] INFO  {Server} Started @1819ms
[13:40:21,450] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:40:21,453] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[13:40:21,559] INFO  {Executor} Starting executor ID driver on host localhost
[13:40:21,591] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41347.
[13:40:21,592] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:41347
[13:40:21,594] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 41347)
[13:40:21,597] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:41347 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 41347)
[13:40:21,601] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 41347)
[13:40:21,732] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[13:40:21,776] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[13:40:21,777] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[13:40:21,778] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[13:40:21,778] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[13:40:21,780] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[13:40:21,794] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:40:23,851] INFO  {FileSourceStrategy} Pruning directories with: 
[13:40:23,852] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:40:23,857] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:40:23,858] INFO  {FileSourceStrategy} Pushed Filters: 
[13:40:23,973] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[13:40:24,018] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:40:24,020] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:41347 (size: 14.6 KB, free: 1128.9 MB)
[13:40:24,026] INFO  {SparkContext} Created broadcast 0 from persist at Main.scala:35
[13:40:24,029] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:40:24,529] INFO  {CodeGenerator} Code generated in 215.360716 ms
[13:40:24,710] INFO  {SparkContext} Starting job: show at Main.scala:36
[13:40:24,724] INFO  {DAGScheduler} Got job 0 (show at Main.scala:36) with 1 output partitions
[13:40:24,724] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:36)
[13:40:24,725] INFO  {DAGScheduler} Parents of final stage: List()
[13:40:24,728] INFO  {DAGScheduler} Missing parents: List()
[13:40:24,732] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:36), which has no missing parents
[13:40:24,788] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 16.9 KB, free 1128.7 MB)
[13:40:24,790] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[13:40:24,791] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:41347 (size: 8.2 KB, free: 1128.9 MB)
[13:40:24,792] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:40:24,795] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at Main.scala:36)
[13:40:24,797] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:40:24,834] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[13:40:24,842] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:40:24,888] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:40:24,904] INFO  {CodeGenerator} Code generated in 12.618031 ms
[13:40:25,251] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 2.7 MB, free 1126.0 MB)
[13:40:25,252] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 80.216.145.125:41347 (size: 2.7 MB, free: 1126.2 MB)
[13:40:25,262] INFO  {CodeGenerator} Code generated in 4.34901 ms
[13:40:25,289] INFO  {CodeGenerator} Code generated in 20.999728 ms
[13:40:25,306] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[13:40:25,313] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4564 bytes result sent to driver
[13:40:25,323] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 507 ms on localhost (1/1)
[13:40:25,325] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:40:25,330] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:36) finished in 0.523 s
[13:40:25,337] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:36, took 0.627005 s
[13:40:25,375] INFO  {CodeGenerator} Code generated in 24.073952 ms
[13:40:25,437] INFO  {SparkContext} Starting job: foreach at Main.scala:39
[13:40:25,438] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:39) with 1 output partitions
[13:40:25,438] INFO  {DAGScheduler} Final stage: ResultStage 1 (foreach at Main.scala:39)
[13:40:25,438] INFO  {DAGScheduler} Parents of final stage: List()
[13:40:25,441] INFO  {DAGScheduler} Missing parents: List()
[13:40:25,442] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[7] at foreach at Main.scala:39), which has no missing parents
[13:40:25,457] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 18.9 KB, free 1126.0 MB)
[13:40:25,459] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.2 KB, free 1126.0 MB)
[13:40:25,459] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:41347 (size: 9.2 KB, free: 1126.2 MB)
[13:40:25,460] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[13:40:25,460] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at foreach at Main.scala:39)
[13:40:25,460] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:40:25,466] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5989 bytes)
[13:40:25,466] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:40:25,484] INFO  {BlockManager} Found block rdd_2_0 locally
[13:40:25,510] INFO  {CodeGenerator} Code generated in 25.092244 ms
[13:40:25,535] INFO  {CodeGenerator} Code generated in 20.386159 ms
[13:40:25,672] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1656 bytes result sent to driver
[13:40:25,675] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 211 ms on localhost (1/1)
[13:40:25,675] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:40:25,675] INFO  {DAGScheduler} ResultStage 1 (foreach at Main.scala:39) finished in 0.212 s
[13:40:25,676] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:39, took 0.239119 s
[13:40:25,809] INFO  {CodeGenerator} Code generated in 53.929757 ms
[13:40:25,828] INFO  {SparkContext} Starting job: show at Main.scala:48
[13:40:25,830] INFO  {DAGScheduler} Got job 2 (show at Main.scala:48) with 1 output partitions
[13:40:25,830] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:48)
[13:40:25,830] INFO  {DAGScheduler} Parents of final stage: List()
[13:40:25,831] INFO  {DAGScheduler} Missing parents: List()
[13:40:25,831] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[10] at show at Main.scala:48), which has no missing parents
[13:40:25,836] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 26.4 KB, free 1126.0 MB)
[13:40:25,839] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1126.0 MB)
[13:40:25,840] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:41347 (size: 10.1 KB, free: 1126.2 MB)
[13:40:25,841] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[13:40:25,841] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at show at Main.scala:48)
[13:40:25,841] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:40:25,844] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[13:40:25,844] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:40:25,855] INFO  {BlockManager} Found block rdd_2_0 locally
[13:40:26,019] INFO  {ContextCleaner} Cleaned accumulator 3
[13:40:26,034] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:41347 in memory (size: 8.2 KB, free: 1126.2 MB)
[13:40:26,037] INFO  {ContextCleaner} Cleaned accumulator 48
[13:40:26,037] INFO  {ContextCleaner} Cleaned accumulator 49
[13:40:26,038] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:41347 in memory (size: 9.2 KB, free: 1126.2 MB)
[13:40:26,078] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[13:40:26,079] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4002 bytes result sent to driver
[13:40:26,084] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 242 ms on localhost (1/1)
[13:40:26,084] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:40:26,086] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:48) finished in 0.243 s
[13:40:26,087] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:48, took 0.258092 s
[13:40:26,128] INFO  {CodeGenerator} Code generated in 31.82703 ms
[13:40:26,152] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:40:26,158] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[13:40:26,160] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[13:40:26,160] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[13:40:26,160] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[13:40:26,160] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[13:40:26,160] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[13:40:26,160] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[13:40:26,161] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[13:40:26,161] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[13:40:26,161] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[13:40:26,161] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[13:40:26,161] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[13:40:26,161] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[13:40:26,161] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[13:40:26,162] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[13:40:26,162] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[13:40:26,162] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[13:40:26,162] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[13:40:26,162] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[13:40:26,162] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[13:40:26,163] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[13:40:26,163] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[13:40:26,163] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[13:40:26,163] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[13:40:26,163] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[13:40:26,165] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[13:40:26,175] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:40:26,180] INFO  {MemoryStore} MemoryStore cleared
[13:40:26,180] INFO  {BlockManager} BlockManager stopped
[13:40:26,182] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:40:26,185] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:40:26,188] INFO  {SparkContext} Successfully stopped SparkContext
[13:40:26,188] INFO  {ShutdownHookManager} Shutdown hook called
[13:40:26,189] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-139aa50c-14a1-4197-8cfb-214b03e3098c
[13:42:15,166] INFO  {SparkContext} Running Spark version 2.0.1
[13:42:15,381] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:42:15,505] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[13:42:15,506] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:42:15,576] INFO  {SecurityManager} Changing view acls to: victor
[13:42:15,577] INFO  {SecurityManager} Changing modify acls to: victor
[13:42:15,577] INFO  {SecurityManager} Changing view acls groups to: 
[13:42:15,578] INFO  {SecurityManager} Changing modify acls groups to: 
[13:42:15,579] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:42:15,988] INFO  {Utils} Successfully started service 'sparkDriver' on port 35151.
[13:42:16,009] INFO  {SparkEnv} Registering MapOutputTracker
[13:42:16,024] INFO  {SparkEnv} Registering BlockManagerMaster
[13:42:16,036] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-ed05d72d-29fd-4421-933c-d99dc9e2fe2d
[13:42:16,053] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:42:16,106] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:42:16,184] INFO  {log} Logging initialized @1831ms
[13:42:16,286] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:42:16,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[13:42:16,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[13:42:16,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[13:42:16,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[13:42:16,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[13:42:16,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[13:42:16,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[13:42:16,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[13:42:16,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[13:42:16,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[13:42:16,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[13:42:16,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[13:42:16,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[13:42:16,304] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[13:42:16,304] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[13:42:16,304] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[13:42:16,304] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[13:42:16,304] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[13:42:16,304] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[13:42:16,305] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[13:42:16,311] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[13:42:16,311] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[13:42:16,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[13:42:16,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[13:42:16,318] INFO  {ServerConnector} Started ServerConnector@5f20a567{HTTP/1.1}{0.0.0.0:4040}
[13:42:16,319] INFO  {Server} Started @1967ms
[13:42:16,319] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:42:16,321] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[13:42:16,395] INFO  {Executor} Starting executor ID driver on host localhost
[13:42:16,414] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41069.
[13:42:16,415] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:41069
[13:42:16,416] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 41069)
[13:42:16,419] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:41069 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 41069)
[13:42:16,422] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 41069)
[13:42:16,542] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[13:42:16,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@759fad4{/SQL,null,AVAILABLE}
[13:42:16,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53499d85{/SQL/json,null,AVAILABLE}
[13:42:16,600] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/execution,null,AVAILABLE}
[13:42:16,601] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL/execution/json,null,AVAILABLE}
[13:42:16,603] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@24f360b2{/static/sql,null,AVAILABLE}
[13:42:16,624] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:42:18,834] INFO  {FileSourceStrategy} Pruning directories with: 
[13:42:18,836] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:42:18,841] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:42:18,841] INFO  {FileSourceStrategy} Pushed Filters: 
[13:42:18,949] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[13:42:18,999] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:42:19,001] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:41069 (size: 14.6 KB, free: 1128.9 MB)
[13:42:19,008] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:36
[13:42:19,012] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:42:19,514] INFO  {CodeGenerator} Code generated in 211.231556 ms
[13:42:19,626] INFO  {SparkContext} Starting job: show at Main.scala:36
[13:42:19,642] INFO  {DAGScheduler} Got job 0 (show at Main.scala:36) with 1 output partitions
[13:42:19,642] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:36)
[13:42:19,642] INFO  {DAGScheduler} Parents of final stage: List()
[13:42:19,643] INFO  {DAGScheduler} Missing parents: List()
[13:42:19,648] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:36), which has no missing parents
[13:42:19,692] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[13:42:19,694] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KB, free 1128.7 MB)
[13:42:19,695] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:41069 (size: 6.7 KB, free: 1128.9 MB)
[13:42:19,696] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:42:19,699] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:36)
[13:42:19,701] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:42:19,742] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[13:42:19,750] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:42:19,791] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:42:19,806] INFO  {CodeGenerator} Code generated in 11.331211 ms
[13:42:19,839] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[13:42:19,846] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 128 ms on localhost (1/1)
[13:42:19,847] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:42:19,851] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:36) finished in 0.142 s
[13:42:19,856] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:36, took 0.229492 s
[13:42:19,892] INFO  {CodeGenerator} Code generated in 21.799441 ms
[13:42:19,928] INFO  {FileSourceStrategy} Pruning directories with: 
[13:42:19,928] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:42:19,928] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:42:19,928] INFO  {FileSourceStrategy} Pushed Filters: 
[13:42:19,935] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[13:42:19,947] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[13:42:19,947] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:41069 (size: 14.6 KB, free: 1128.9 MB)
[13:42:19,949] INFO  {SparkContext} Created broadcast 2 from foreach at Main.scala:39
[13:42:19,949] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:42:19,971] INFO  {FileSourceStrategy} Pruning directories with: 
[13:42:19,971] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:42:19,972] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:42:19,972] INFO  {FileSourceStrategy} Pushed Filters: 
[13:42:19,979] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[13:42:20,005] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[13:42:20,011] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:41069 (size: 14.6 KB, free: 1128.9 MB)
[13:42:20,013] INFO  {SparkContext} Created broadcast 3 from foreach at Main.scala:39
[13:42:20,013] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:42:20,020] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:41069 in memory (size: 14.6 KB, free: 1128.9 MB)
[13:42:20,025] INFO  {ContextCleaner} Cleaned accumulator 0
[13:42:20,025] INFO  {ContextCleaner} Cleaned accumulator 1
[13:42:20,026] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:41069 in memory (size: 6.7 KB, free: 1128.9 MB)
[13:42:20,045] INFO  {CodeGenerator} Code generated in 23.243867 ms
[13:42:20,062] INFO  {SparkContext} Starting job: foreach at Main.scala:39
[13:42:20,063] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:39) with 1 output partitions
[13:42:20,063] INFO  {DAGScheduler} Final stage: ResultStage 1 (foreach at Main.scala:39)
[13:42:20,063] INFO  {DAGScheduler} Parents of final stage: List()
[13:42:20,063] INFO  {DAGScheduler} Missing parents: List()
[13:42:20,064] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[7] at foreach at Main.scala:39), which has no missing parents
[13:42:20,088] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 17.0 KB, free 1128.6 MB)
[13:42:20,091] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.6 MB)
[13:42:20,091] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:41069 (size: 8.4 KB, free: 1128.9 MB)
[13:42:20,092] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[13:42:20,093] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at foreach at Main.scala:39)
[13:42:20,093] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:42:20,096] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5989 bytes)
[13:42:20,096] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:42:20,125] INFO  {CodeGenerator} Code generated in 16.492416 ms
[13:42:20,127] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:42:20,428] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1222 bytes result sent to driver
[13:42:20,430] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 336 ms on localhost (1/1)
[13:42:20,430] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:42:20,431] INFO  {DAGScheduler} ResultStage 1 (foreach at Main.scala:39) finished in 0.337 s
[13:42:20,432] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:39, took 0.369232 s
[13:42:20,438] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:42:20,442] INFO  {ServerConnector} Stopped ServerConnector@5f20a567{HTTP/1.1}{0.0.0.0:4040}
[13:42:20,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[13:42:20,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[13:42:20,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[13:42:20,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[13:42:20,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[13:42:20,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[13:42:20,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[13:42:20,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[13:42:20,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[13:42:20,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[13:42:20,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[13:42:20,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[13:42:20,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[13:42:20,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[13:42:20,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[13:42:20,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[13:42:20,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[13:42:20,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[13:42:20,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[13:42:20,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[13:42:20,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[13:42:20,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[13:42:20,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[13:42:20,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[13:42:20,448] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[13:42:20,457] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:42:20,461] INFO  {MemoryStore} MemoryStore cleared
[13:42:20,461] INFO  {BlockManager} BlockManager stopped
[13:42:20,463] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:42:20,465] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:42:20,468] INFO  {SparkContext} Successfully stopped SparkContext
[13:42:20,469] INFO  {ShutdownHookManager} Shutdown hook called
[13:42:20,470] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-17bbcedf-c5ab-46ac-b6f9-2cc61418ac59
[13:42:34,515] INFO  {SparkContext} Running Spark version 2.0.1
[13:42:34,769] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:42:34,881] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[13:42:34,882] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:42:34,956] INFO  {SecurityManager} Changing view acls to: victor
[13:42:34,957] INFO  {SecurityManager} Changing modify acls to: victor
[13:42:34,958] INFO  {SecurityManager} Changing view acls groups to: 
[13:42:34,959] INFO  {SecurityManager} Changing modify acls groups to: 
[13:42:34,959] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:42:35,382] INFO  {Utils} Successfully started service 'sparkDriver' on port 44105.
[13:42:35,399] INFO  {SparkEnv} Registering MapOutputTracker
[13:42:35,414] INFO  {SparkEnv} Registering BlockManagerMaster
[13:42:35,427] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-ef8d8df8-0adf-45cb-9797-cb94966a7687
[13:42:35,446] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:42:35,499] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:42:35,579] INFO  {log} Logging initialized @1701ms
[13:42:35,684] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:42:35,702] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[13:42:35,702] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[13:42:35,702] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[13:42:35,703] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[13:42:35,703] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[13:42:35,703] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[13:42:35,704] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[13:42:35,704] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[13:42:35,704] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[13:42:35,704] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[13:42:35,705] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[13:42:35,705] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[13:42:35,705] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[13:42:35,706] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[13:42:35,706] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[13:42:35,706] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[13:42:35,706] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[13:42:35,707] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[13:42:35,707] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[13:42:35,707] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[13:42:35,715] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[13:42:35,716] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[13:42:35,717] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[13:42:35,717] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[13:42:35,726] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[13:42:35,727] INFO  {Server} Started @1850ms
[13:42:35,727] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:42:35,730] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[13:42:35,847] INFO  {Executor} Starting executor ID driver on host localhost
[13:42:35,876] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42831.
[13:42:35,877] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:42831
[13:42:35,879] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 42831)
[13:42:35,882] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:42831 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 42831)
[13:42:35,884] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 42831)
[13:42:36,006] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@63cd604c{/metrics/json,null,AVAILABLE}
[13:42:36,056] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ea1bcdc{/SQL,null,AVAILABLE}
[13:42:36,057] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL/json,null,AVAILABLE}
[13:42:36,058] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59fc684e{/SQL/execution,null,AVAILABLE}
[13:42:36,059] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution/json,null,AVAILABLE}
[13:42:36,061] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/static/sql,null,AVAILABLE}
[13:42:36,077] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:42:38,105] INFO  {FileSourceStrategy} Pruning directories with: 
[13:42:38,107] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:42:38,111] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:42:38,112] INFO  {FileSourceStrategy} Pushed Filters: 
[13:42:38,228] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[13:42:38,275] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:42:38,277] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:42831 (size: 14.6 KB, free: 1128.9 MB)
[13:42:38,284] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:36
[13:42:38,290] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:42:38,842] INFO  {CodeGenerator} Code generated in 249.777904 ms
[13:42:38,939] INFO  {SparkContext} Starting job: show at Main.scala:36
[13:42:38,955] INFO  {DAGScheduler} Got job 0 (show at Main.scala:36) with 1 output partitions
[13:42:38,955] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:36)
[13:42:38,955] INFO  {DAGScheduler} Parents of final stage: List()
[13:42:38,956] INFO  {DAGScheduler} Missing parents: List()
[13:42:38,961] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:36), which has no missing parents
[13:42:39,003] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[13:42:39,006] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[13:42:39,007] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:42831 (size: 6.6 KB, free: 1128.9 MB)
[13:42:39,007] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:42:39,010] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:36)
[13:42:39,012] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:42:39,059] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[13:42:39,066] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:42:39,103] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:42:39,117] INFO  {CodeGenerator} Code generated in 10.619574 ms
[13:42:39,150] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[13:42:39,158] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 124 ms on localhost (1/1)
[13:42:39,159] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:42:39,162] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:36) finished in 0.142 s
[13:42:39,167] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:36, took 0.227287 s
[13:42:39,198] INFO  {CodeGenerator} Code generated in 17.948942 ms
[13:42:39,235] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:42831 in memory (size: 6.6 KB, free: 1128.9 MB)
[13:42:39,251] INFO  {FileSourceStrategy} Pruning directories with: 
[13:42:39,252] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:42:39,252] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:42:39,252] INFO  {FileSourceStrategy} Pushed Filters: 
[13:42:39,259] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[13:42:39,271] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[13:42:39,272] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:42831 (size: 14.6 KB, free: 1128.9 MB)
[13:42:39,273] INFO  {SparkContext} Created broadcast 2 from foreach at Main.scala:39
[13:42:39,273] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:42:39,288] INFO  {FileSourceStrategy} Pruning directories with: 
[13:42:39,288] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:42:39,289] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:42:39,289] INFO  {FileSourceStrategy} Pushed Filters: 
[13:42:39,294] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[13:42:39,303] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[13:42:39,303] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:42831 (size: 14.6 KB, free: 1128.9 MB)
[13:42:39,304] INFO  {SparkContext} Created broadcast 3 from foreach at Main.scala:39
[13:42:39,304] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:42:39,329] INFO  {CodeGenerator} Code generated in 17.586068 ms
[13:42:39,347] INFO  {SparkContext} Starting job: foreach at Main.scala:39
[13:42:39,348] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:39) with 1 output partitions
[13:42:39,348] INFO  {DAGScheduler} Final stage: ResultStage 1 (foreach at Main.scala:39)
[13:42:39,348] INFO  {DAGScheduler} Parents of final stage: List()
[13:42:39,348] INFO  {DAGScheduler} Missing parents: List()
[13:42:39,349] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[7] at foreach at Main.scala:39), which has no missing parents
[13:42:39,372] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 17.0 KB, free 1128.5 MB)
[13:42:39,374] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.4 MB)
[13:42:39,375] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:42831 (size: 8.4 KB, free: 1128.8 MB)
[13:42:39,375] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[13:42:39,375] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at foreach at Main.scala:39)
[13:42:39,376] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:42:39,378] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5989 bytes)
[13:42:39,378] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:42:39,417] INFO  {CodeGenerator} Code generated in 21.133896 ms
[13:42:39,420] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:42:39,729] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1309 bytes result sent to driver
[13:42:39,732] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 356 ms on localhost (1/1)
[13:42:39,733] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:42:39,733] INFO  {DAGScheduler} ResultStage 1 (foreach at Main.scala:39) finished in 0.357 s
[13:42:39,734] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:39, took 0.386603 s
[13:42:39,765] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:42:39,769] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[13:42:39,770] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[13:42:39,771] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[13:42:39,771] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[13:42:39,771] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[13:42:39,771] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[13:42:39,771] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[13:42:39,771] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[13:42:39,771] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[13:42:39,772] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[13:42:39,772] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[13:42:39,772] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[13:42:39,772] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[13:42:39,772] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[13:42:39,772] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[13:42:39,772] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[13:42:39,772] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[13:42:39,773] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[13:42:39,773] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[13:42:39,773] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[13:42:39,773] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[13:42:39,773] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[13:42:39,773] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[13:42:39,773] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[13:42:39,773] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[13:42:39,775] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[13:42:39,785] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:42:39,790] INFO  {MemoryStore} MemoryStore cleared
[13:42:39,790] INFO  {BlockManager} BlockManager stopped
[13:42:39,791] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:42:39,794] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:42:39,797] INFO  {SparkContext} Successfully stopped SparkContext
[13:42:39,798] INFO  {ShutdownHookManager} Shutdown hook called
[13:42:39,800] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f3ad7ed5-d2ee-4fd9-b0c3-6e66c19612b0
[13:45:41,243] INFO  {SparkContext} Running Spark version 2.0.1
[13:45:41,460] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:45:41,565] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[13:45:41,566] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:45:41,649] INFO  {SecurityManager} Changing view acls to: victor
[13:45:41,649] INFO  {SecurityManager} Changing modify acls to: victor
[13:45:41,650] INFO  {SecurityManager} Changing view acls groups to: 
[13:45:41,650] INFO  {SecurityManager} Changing modify acls groups to: 
[13:45:41,651] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:45:42,073] INFO  {Utils} Successfully started service 'sparkDriver' on port 34225.
[13:45:42,100] INFO  {SparkEnv} Registering MapOutputTracker
[13:45:42,118] INFO  {SparkEnv} Registering BlockManagerMaster
[13:45:42,133] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-6dd58b80-ce2f-4246-982a-59d6e2f5e7ee
[13:45:42,149] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:45:42,199] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:45:42,274] INFO  {log} Logging initialized @1670ms
[13:45:42,387] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:45:42,404] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[13:45:42,405] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[13:45:42,405] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[13:45:42,405] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[13:45:42,405] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[13:45:42,405] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[13:45:42,406] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[13:45:42,406] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[13:45:42,406] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[13:45:42,406] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[13:45:42,406] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[13:45:42,406] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[13:45:42,407] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[13:45:42,407] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[13:45:42,407] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[13:45:42,407] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[13:45:42,407] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[13:45:42,408] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[13:45:42,408] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[13:45:42,408] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[13:45:42,417] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[13:45:42,417] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[13:45:42,419] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[13:45:42,419] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[13:45:42,425] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:45:42,426] INFO  {Server} Started @1822ms
[13:45:42,426] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:45:42,429] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[13:45:42,516] INFO  {Executor} Starting executor ID driver on host localhost
[13:45:42,545] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42529.
[13:45:42,546] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:42529
[13:45:42,548] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 42529)
[13:45:42,551] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:42529 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 42529)
[13:45:42,555] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 42529)
[13:45:42,683] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[13:45:42,729] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL,null,AVAILABLE}
[13:45:42,730] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/json,null,AVAILABLE}
[13:45:42,731] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution,null,AVAILABLE}
[13:45:42,732] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/execution/json,null,AVAILABLE}
[13:45:42,733] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54107f42{/static/sql,null,AVAILABLE}
[13:45:42,748] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:45:44,810] INFO  {FileSourceStrategy} Pruning directories with: 
[13:45:44,812] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:45:44,818] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:45:44,818] INFO  {FileSourceStrategy} Pushed Filters: 
[13:45:44,924] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[13:45:44,977] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:45:44,979] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:42529 (size: 14.6 KB, free: 1128.9 MB)
[13:45:44,987] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:36
[13:45:44,991] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:45:45,508] INFO  {CodeGenerator} Code generated in 223.455347 ms
[13:45:45,600] INFO  {SparkContext} Starting job: show at Main.scala:36
[13:45:45,617] INFO  {DAGScheduler} Got job 0 (show at Main.scala:36) with 1 output partitions
[13:45:45,618] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:36)
[13:45:45,618] INFO  {DAGScheduler} Parents of final stage: List()
[13:45:45,620] INFO  {DAGScheduler} Missing parents: List()
[13:45:45,624] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:36), which has no missing parents
[13:45:45,664] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[13:45:45,667] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[13:45:45,667] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:42529 (size: 6.6 KB, free: 1128.9 MB)
[13:45:45,668] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:45:45,671] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:36)
[13:45:45,672] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:45:45,715] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[13:45:45,724] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:45:45,760] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:45:45,775] INFO  {CodeGenerator} Code generated in 11.168258 ms
[13:45:45,813] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[13:45:45,822] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 130 ms on localhost (1/1)
[13:45:45,824] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:45:45,829] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:36) finished in 0.148 s
[13:45:45,837] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:36, took 0.235890 s
[13:45:45,870] INFO  {CodeGenerator} Code generated in 19.69023 ms
[13:45:45,918] INFO  {FileSourceStrategy} Pruning directories with: 
[13:45:45,918] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:45:45,918] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:45:45,919] INFO  {FileSourceStrategy} Pushed Filters: 
[13:45:45,926] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[13:45:45,937] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[13:45:45,938] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:42529 (size: 14.6 KB, free: 1128.9 MB)
[13:45:45,940] INFO  {SparkContext} Created broadcast 2 from persist at Main.scala:44
[13:45:45,940] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:45:45,995] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:42529 in memory (size: 14.6 KB, free: 1128.9 MB)
[13:45:46,008] INFO  {ContextCleaner} Cleaned accumulator 0
[13:45:46,008] INFO  {ContextCleaner} Cleaned accumulator 1
[13:45:46,009] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:42529 in memory (size: 6.6 KB, free: 1128.9 MB)
[13:45:46,027] INFO  {CodeGenerator} Code generated in 70.281718 ms
[13:45:46,093] INFO  {SparkContext} Starting job: show at Main.scala:46
[13:45:46,095] INFO  {DAGScheduler} Got job 1 (show at Main.scala:46) with 1 output partitions
[13:45:46,096] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:46)
[13:45:46,096] INFO  {DAGScheduler} Parents of final stage: List()
[13:45:46,100] INFO  {DAGScheduler} Missing parents: List()
[13:45:46,101] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[7] at show at Main.scala:46), which has no missing parents
[13:45:46,120] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 24.8 KB, free 1128.7 MB)
[13:45:46,121] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.9 KB, free 1128.7 MB)
[13:45:46,122] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:42529 (size: 9.9 KB, free: 1128.9 MB)
[13:45:46,123] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[13:45:46,123] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at show at Main.scala:46)
[13:45:46,123] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:45:46,125] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[13:45:46,125] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:45:46,146] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:45:46,618] INFO  {MemoryStore} Block rdd_5_0 stored as values in memory (estimated size 4.0 MB, free 1124.7 MB)
[13:45:46,619] INFO  {BlockManagerInfo} Added rdd_5_0 in memory on 80.216.145.125:42529 (size: 4.0 MB, free: 1124.9 MB)
[13:45:46,637] INFO  {CodeGenerator} Code generated in 8.581938 ms
[13:45:46,676] INFO  {CodeGenerator} Code generated in 26.408098 ms
[13:45:46,693] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_5_0]
[13:45:46,700] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 5786 bytes result sent to driver
[13:45:46,703] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 580 ms on localhost (1/1)
[13:45:46,703] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:45:46,704] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:46) finished in 0.581 s
[13:45:46,705] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:46, took 0.611492 s
[13:45:46,827] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:42529 in memory (size: 9.9 KB, free: 1124.9 MB)
[13:45:46,857] INFO  {CodeGenerator} Code generated in 21.695893 ms
[13:45:46,872] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:45:46,878] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:45:46,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[13:45:46,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[13:45:46,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[13:45:46,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[13:45:46,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[13:45:46,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[13:45:46,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[13:45:46,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[13:45:46,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[13:45:46,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[13:45:46,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[13:45:46,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[13:45:46,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[13:45:46,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[13:45:46,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[13:45:46,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[13:45:46,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[13:45:46,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[13:45:46,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[13:45:46,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[13:45:46,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[13:45:46,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[13:45:46,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[13:45:46,884] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[13:45:46,886] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[13:45:46,900] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:45:46,908] INFO  {MemoryStore} MemoryStore cleared
[13:45:46,911] INFO  {BlockManager} BlockManager stopped
[13:45:46,914] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:45:46,919] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:45:46,931] INFO  {SparkContext} Successfully stopped SparkContext
[13:45:46,933] INFO  {ShutdownHookManager} Shutdown hook called
[13:45:46,935] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-3a79c6ea-8c77-4dc4-988c-bf2de5e79991
[14:08:33,150] INFO  {SparkContext} Running Spark version 2.0.1
[14:08:33,361] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:08:33,462] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[14:08:33,462] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:08:33,537] INFO  {SecurityManager} Changing view acls to: victor
[14:08:33,538] INFO  {SecurityManager} Changing modify acls to: victor
[14:08:33,539] INFO  {SecurityManager} Changing view acls groups to: 
[14:08:33,540] INFO  {SecurityManager} Changing modify acls groups to: 
[14:08:33,541] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:08:33,929] INFO  {Utils} Successfully started service 'sparkDriver' on port 38485.
[14:08:33,950] INFO  {SparkEnv} Registering MapOutputTracker
[14:08:33,966] INFO  {SparkEnv} Registering BlockManagerMaster
[14:08:33,978] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-d8477f48-2b7c-4507-a815-d62d32cdad09
[14:08:33,991] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:08:34,062] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:08:34,131] INFO  {log} Logging initialized @1568ms
[14:08:34,236] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:08:34,252] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[14:08:34,253] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[14:08:34,253] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[14:08:34,253] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[14:08:34,253] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[14:08:34,253] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[14:08:34,253] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[14:08:34,254] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[14:08:34,254] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[14:08:34,254] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[14:08:34,254] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[14:08:34,254] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[14:08:34,255] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[14:08:34,255] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[14:08:34,255] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[14:08:34,255] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[14:08:34,255] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[14:08:34,255] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[14:08:34,256] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[14:08:34,256] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[14:08:34,262] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[14:08:34,262] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[14:08:34,263] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[14:08:34,263] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[14:08:34,269] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:08:34,270] INFO  {Server} Started @1708ms
[14:08:34,270] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:08:34,272] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[14:08:34,351] INFO  {Executor} Starting executor ID driver on host localhost
[14:08:34,372] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33183.
[14:08:34,373] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:33183
[14:08:34,375] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 33183)
[14:08:34,378] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:33183 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 33183)
[14:08:34,381] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 33183)
[14:08:34,498] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[14:08:34,554] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[14:08:34,555] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[14:08:34,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[14:08:34,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[14:08:34,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[14:08:34,572] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[14:08:36,480] INFO  {FileSourceStrategy} Pruning directories with: 
[14:08:36,481] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:08:36,485] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:08:36,486] INFO  {FileSourceStrategy} Pushed Filters: 
[14:08:36,587] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[14:08:36,631] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:08:36,633] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:33183 (size: 14.6 KB, free: 1128.9 MB)
[14:08:36,639] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:36
[14:08:36,644] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:08:37,140] INFO  {CodeGenerator} Code generated in 224.911187 ms
[14:08:37,231] INFO  {SparkContext} Starting job: show at Main.scala:36
[14:08:37,247] INFO  {DAGScheduler} Got job 0 (show at Main.scala:36) with 1 output partitions
[14:08:37,248] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:36)
[14:08:37,248] INFO  {DAGScheduler} Parents of final stage: List()
[14:08:37,249] INFO  {DAGScheduler} Missing parents: List()
[14:08:37,254] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:36), which has no missing parents
[14:08:37,307] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[14:08:37,310] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[14:08:37,310] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:33183 (size: 6.6 KB, free: 1128.9 MB)
[14:08:37,311] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:08:37,314] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:36)
[14:08:37,315] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:08:37,362] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:08:37,369] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:08:37,404] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:08:37,417] INFO  {CodeGenerator} Code generated in 10.256389 ms
[14:08:37,451] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[14:08:37,457] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 120 ms on localhost (1/1)
[14:08:37,458] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:08:37,462] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:36) finished in 0.138 s
[14:08:37,469] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:36, took 0.237638 s
[14:08:37,500] INFO  {CodeGenerator} Code generated in 18.574988 ms
[14:08:37,536] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:33183 in memory (size: 6.6 KB, free: 1128.9 MB)
[14:08:37,570] INFO  {FileSourceStrategy} Pruning directories with: 
[14:08:37,570] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:08:37,571] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:08:37,571] INFO  {FileSourceStrategy} Pushed Filters: 
[14:08:37,577] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:08:37,586] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:08:37,587] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:33183 (size: 14.6 KB, free: 1128.9 MB)
[14:08:37,588] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:47
[14:08:37,588] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:08:37,642] INFO  {CodeGenerator} Code generated in 38.359201 ms
[14:08:37,660] INFO  {SparkContext} Starting job: show at Main.scala:47
[14:08:37,662] INFO  {DAGScheduler} Got job 1 (show at Main.scala:47) with 1 output partitions
[14:08:37,662] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:47)
[14:08:37,662] INFO  {DAGScheduler} Parents of final stage: List()
[14:08:37,662] INFO  {DAGScheduler} Missing parents: List()
[14:08:37,663] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:47), which has no missing parents
[14:08:37,667] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[14:08:37,669] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[14:08:37,670] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:33183 (size: 8.2 KB, free: 1128.9 MB)
[14:08:37,670] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[14:08:37,671] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:47)
[14:08:37,671] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[14:08:37,673] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:08:37,673] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[14:08:37,685] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:08:37,700] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[14:08:37,702] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on localhost (1/1)
[14:08:37,702] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[14:08:37,703] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:47) finished in 0.032 s
[14:08:37,704] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:47, took 0.043743 s
[14:08:37,726] INFO  {CodeGenerator} Code generated in 15.073891 ms
[14:08:37,845] INFO  {FileSourceStrategy} Pruning directories with: 
[14:08:37,846] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:08:37,846] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:08:37,846] INFO  {FileSourceStrategy} Pushed Filters: 
[14:08:37,851] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[14:08:37,860] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[14:08:37,860] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:33183 (size: 14.6 KB, free: 1128.8 MB)
[14:08:37,861] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:54
[14:08:37,861] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:08:37,914] INFO  {CodeGenerator} Code generated in 38.457178 ms
[14:08:37,923] INFO  {SparkContext} Starting job: show at Main.scala:54
[14:08:37,924] INFO  {DAGScheduler} Got job 2 (show at Main.scala:54) with 1 output partitions
[14:08:37,924] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:54)
[14:08:37,924] INFO  {DAGScheduler} Parents of final stage: List()
[14:08:37,924] INFO  {DAGScheduler} Missing parents: List()
[14:08:37,925] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:54), which has no missing parents
[14:08:37,929] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[14:08:37,931] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[14:08:37,932] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:33183 (size: 9.6 KB, free: 1128.8 MB)
[14:08:37,933] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[14:08:37,933] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:54)
[14:08:37,934] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[14:08:37,937] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:08:37,938] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[14:08:37,953] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:08:37,970] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[14:08:37,972] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 37 ms on localhost (1/1)
[14:08:37,972] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[14:08:37,972] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:54) finished in 0.038 s
[14:08:37,972] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:54, took 0.049121 s
[14:08:37,991] INFO  {CodeGenerator} Code generated in 15.979603 ms
[14:08:38,001] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:08:38,007] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:08:38,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[14:08:38,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[14:08:38,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[14:08:38,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[14:08:38,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[14:08:38,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[14:08:38,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[14:08:38,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[14:08:38,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[14:08:38,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[14:08:38,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[14:08:38,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[14:08:38,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[14:08:38,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[14:08:38,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[14:08:38,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[14:08:38,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[14:08:38,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[14:08:38,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[14:08:38,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[14:08:38,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[14:08:38,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[14:08:38,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[14:08:38,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[14:08:38,016] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[14:08:38,028] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:08:38,035] INFO  {MemoryStore} MemoryStore cleared
[14:08:38,036] INFO  {BlockManager} BlockManager stopped
[14:08:38,037] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:08:38,040] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:08:38,043] INFO  {SparkContext} Successfully stopped SparkContext
[14:08:38,043] INFO  {ShutdownHookManager} Shutdown hook called
[14:08:38,044] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-fe786ca9-b8b8-446f-9dba-be6ef756e1d6
[14:24:06,174] INFO  {SparkContext} Running Spark version 2.0.1
[14:24:06,384] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:24:06,492] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[14:24:06,493] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:24:06,563] INFO  {SecurityManager} Changing view acls to: victor
[14:24:06,564] INFO  {SecurityManager} Changing modify acls to: victor
[14:24:06,565] INFO  {SecurityManager} Changing view acls groups to: 
[14:24:06,565] INFO  {SecurityManager} Changing modify acls groups to: 
[14:24:06,566] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:24:06,945] INFO  {Utils} Successfully started service 'sparkDriver' on port 42499.
[14:24:06,961] INFO  {SparkEnv} Registering MapOutputTracker
[14:24:06,975] INFO  {SparkEnv} Registering BlockManagerMaster
[14:24:06,987] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-f60b2985-bec3-4799-b624-7c2d29d4f062
[14:24:07,002] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:24:07,050] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:24:07,122] INFO  {log} Logging initialized @1549ms
[14:24:07,224] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:24:07,240] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:24:07,240] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:24:07,240] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:24:07,240] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:24:07,241] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:24:07,241] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:24:07,241] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:24:07,241] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:24:07,241] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:24:07,242] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:24:07,242] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:24:07,242] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:24:07,242] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:24:07,242] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:24:07,243] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:24:07,243] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:24:07,243] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:24:07,243] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:24:07,243] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:24:07,244] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:24:07,250] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:24:07,250] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:24:07,251] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:24:07,251] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:24:07,257] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:24:07,258] INFO  {Server} Started @1686ms
[14:24:07,258] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:24:07,260] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[14:24:07,343] INFO  {Executor} Starting executor ID driver on host localhost
[14:24:07,366] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39485.
[14:24:07,367] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:39485
[14:24:07,369] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 39485)
[14:24:07,372] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:39485 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 39485)
[14:24:07,374] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 39485)
[14:24:07,497] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:24:07,552] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[14:24:07,553] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[14:24:07,554] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[14:24:07,555] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[14:24:07,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[14:24:07,569] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[14:24:09,414] INFO  {FileSourceStrategy} Pruning directories with: 
[14:24:09,417] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:24:09,422] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:24:09,422] INFO  {FileSourceStrategy} Pushed Filters: 
[14:24:09,530] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[14:24:09,575] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:24:09,577] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:39485 (size: 14.6 KB, free: 1128.9 MB)
[14:24:09,585] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:32
[14:24:09,589] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:24:10,086] INFO  {CodeGenerator} Code generated in 216.127318 ms
[14:24:10,180] INFO  {SparkContext} Starting job: show at Main.scala:32
[14:24:10,196] INFO  {DAGScheduler} Got job 0 (show at Main.scala:32) with 1 output partitions
[14:24:10,197] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:32)
[14:24:10,197] INFO  {DAGScheduler} Parents of final stage: List()
[14:24:10,198] INFO  {DAGScheduler} Missing parents: List()
[14:24:10,202] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32), which has no missing parents
[14:24:10,246] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[14:24:10,248] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[14:24:10,249] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:39485 (size: 6.6 KB, free: 1128.9 MB)
[14:24:10,249] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:24:10,252] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32)
[14:24:10,254] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:24:10,296] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:24:10,303] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:24:10,340] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:24:10,354] INFO  {CodeGenerator} Code generated in 10.600542 ms
[14:24:10,387] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[14:24:10,395] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 121 ms on localhost (1/1)
[14:24:10,397] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:24:10,403] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:32) finished in 0.139 s
[14:24:10,409] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:32, took 0.229414 s
[14:24:10,443] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:39485 in memory (size: 6.6 KB, free: 1128.9 MB)
[14:24:10,460] INFO  {CodeGenerator} Code generated in 21.609752 ms
[14:24:10,522] INFO  {FileSourceStrategy} Pruning directories with: 
[14:24:10,523] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:24:10,523] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:24:10,524] INFO  {FileSourceStrategy} Pushed Filters: 
[14:24:10,533] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:24:10,545] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:24:10,546] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:39485 (size: 14.6 KB, free: 1128.9 MB)
[14:24:10,548] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[14:24:10,548] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:24:10,596] INFO  {CodeGenerator} Code generated in 32.537551 ms
[14:24:10,608] INFO  {SparkContext} Starting job: show at Main.scala:43
[14:24:10,609] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[14:24:10,609] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[14:24:10,609] INFO  {DAGScheduler} Parents of final stage: List()
[14:24:10,610] INFO  {DAGScheduler} Missing parents: List()
[14:24:10,610] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[14:24:10,613] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[14:24:10,615] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[14:24:10,615] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:39485 (size: 8.2 KB, free: 1128.9 MB)
[14:24:10,616] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[14:24:10,616] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[14:24:10,616] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[14:24:10,619] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:24:10,619] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[14:24:10,631] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:24:10,649] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3492 bytes result sent to driver
[14:24:10,651] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on localhost (1/1)
[14:24:10,651] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[14:24:10,652] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.035 s
[14:24:10,652] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.043919 s
[14:24:10,683] INFO  {CodeGenerator} Code generated in 22.510168 ms
[14:24:10,776] INFO  {FileSourceStrategy} Pruning directories with: 
[14:24:10,777] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:24:10,778] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:24:10,778] INFO  {FileSourceStrategy} Pushed Filters: 
[14:24:10,782] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[14:24:10,791] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[14:24:10,791] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:39485 (size: 14.6 KB, free: 1128.8 MB)
[14:24:10,792] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:51
[14:24:10,793] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:24:10,846] INFO  {CodeGenerator} Code generated in 37.518351 ms
[14:24:10,856] INFO  {SparkContext} Starting job: show at Main.scala:51
[14:24:10,857] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[14:24:10,857] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[14:24:10,857] INFO  {DAGScheduler} Parents of final stage: List()
[14:24:10,857] INFO  {DAGScheduler} Missing parents: List()
[14:24:10,858] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51), which has no missing parents
[14:24:10,862] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[14:24:10,864] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[14:24:10,864] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:39485 (size: 9.6 KB, free: 1128.8 MB)
[14:24:10,865] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[14:24:10,865] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51)
[14:24:10,865] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[14:24:10,867] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:24:10,867] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[14:24:10,876] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:24:10,885] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[14:24:10,886] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 21 ms on localhost (1/1)
[14:24:10,886] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[14:24:10,886] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.021 s
[14:24:10,887] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.030857 s
[14:24:10,907] INFO  {CodeGenerator} Code generated in 18.063785 ms
[14:24:10,967] INFO  {FileSourceStrategy} Pruning directories with: 
[14:24:10,967] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:24:10,968] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:24:10,968] INFO  {FileSourceStrategy} Pushed Filters: 
[14:24:10,975] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[14:24:10,987] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.3 MB)
[14:24:10,988] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:39485 (size: 14.6 KB, free: 1128.8 MB)
[14:24:10,989] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:61
[14:24:10,989] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:24:11,063] INFO  {CodeGenerator} Code generated in 46.051636 ms
[14:24:11,072] INFO  {SparkContext} Starting job: show at Main.scala:61
[14:24:11,073] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[14:24:11,073] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[14:24:11,073] INFO  {DAGScheduler} Parents of final stage: List()
[14:24:11,073] INFO  {DAGScheduler} Missing parents: List()
[14:24:11,074] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61), which has no missing parents
[14:24:11,077] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[14:24:11,079] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[14:24:11,079] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:39485 (size: 10.9 KB, free: 1128.8 MB)
[14:24:11,080] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[14:24:11,080] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61)
[14:24:11,080] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[14:24:11,082] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:24:11,082] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[14:24:11,090] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:24:11,099] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[14:24:11,100] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 19 ms on localhost (1/1)
[14:24:11,101] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[14:24:11,101] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.020 s
[14:24:11,101] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.029073 s
[14:24:11,117] INFO  {CodeGenerator} Code generated in 13.319993 ms
[14:24:11,125] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:24:11,130] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:24:11,132] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:24:11,132] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:24:11,132] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:24:11,133] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:24:11,133] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:24:11,133] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:24:11,133] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:24:11,133] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:24:11,133] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:24:11,133] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:24:11,134] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:24:11,134] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:24:11,134] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:24:11,134] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:24:11,134] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:24:11,134] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:24:11,135] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:24:11,135] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:24:11,135] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:24:11,135] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:24:11,135] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:24:11,136] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:24:11,136] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:24:11,136] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:24:11,138] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[14:24:11,146] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:24:11,152] INFO  {MemoryStore} MemoryStore cleared
[14:24:11,153] INFO  {BlockManager} BlockManager stopped
[14:24:11,155] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:24:11,158] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:24:11,159] INFO  {SparkContext} Successfully stopped SparkContext
[14:24:11,160] INFO  {ShutdownHookManager} Shutdown hook called
[14:24:11,161] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-3230f680-e3e6-405b-903b-e84b81eb37d7
[14:30:15,790] INFO  {SparkContext} Running Spark version 2.0.1
[14:30:15,990] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:30:16,088] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[14:30:16,089] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:30:16,152] INFO  {SecurityManager} Changing view acls to: victor
[14:30:16,152] INFO  {SecurityManager} Changing modify acls to: victor
[14:30:16,153] INFO  {SecurityManager} Changing view acls groups to: 
[14:30:16,154] INFO  {SecurityManager} Changing modify acls groups to: 
[14:30:16,156] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:30:16,536] INFO  {Utils} Successfully started service 'sparkDriver' on port 40557.
[14:30:16,552] INFO  {SparkEnv} Registering MapOutputTracker
[14:30:16,569] INFO  {SparkEnv} Registering BlockManagerMaster
[14:30:16,582] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-270a2d49-4643-4e0d-817f-0a8513c0ce5f
[14:30:16,597] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:30:16,646] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:30:16,716] INFO  {log} Logging initialized @1519ms
[14:30:16,816] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:30:16,833] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[14:30:16,833] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[14:30:16,834] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[14:30:16,834] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[14:30:16,834] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[14:30:16,834] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[14:30:16,834] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[14:30:16,834] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[14:30:16,835] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[14:30:16,835] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[14:30:16,835] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[14:30:16,835] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[14:30:16,836] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[14:30:16,836] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[14:30:16,836] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[14:30:16,836] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[14:30:16,836] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[14:30:16,837] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[14:30:16,837] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[14:30:16,837] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[14:30:16,845] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[14:30:16,845] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[14:30:16,846] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[14:30:16,846] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[14:30:16,852] INFO  {ServerConnector} Started ServerConnector@34172b75{HTTP/1.1}{0.0.0.0:4040}
[14:30:16,852] INFO  {Server} Started @1656ms
[14:30:16,852] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:30:16,854] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[14:30:16,930] INFO  {Executor} Starting executor ID driver on host localhost
[14:30:16,951] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45331.
[14:30:16,952] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:45331
[14:30:16,954] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 45331)
[14:30:16,957] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:45331 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 45331)
[14:30:16,960] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 45331)
[14:30:17,078] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[14:30:17,126] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[14:30:17,126] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[14:30:17,127] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[14:30:17,127] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[14:30:17,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[14:30:17,146] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[14:30:19,026] INFO  {FileSourceStrategy} Pruning directories with: 
[14:30:19,028] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:30:19,033] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:30:19,034] INFO  {FileSourceStrategy} Pushed Filters: 
[14:30:19,148] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[14:30:19,196] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:30:19,198] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:45331 (size: 14.6 KB, free: 1128.9 MB)
[14:30:19,204] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:32
[14:30:19,209] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:30:19,732] INFO  {CodeGenerator} Code generated in 226.932701 ms
[14:30:19,820] INFO  {SparkContext} Starting job: show at Main.scala:32
[14:30:19,837] INFO  {DAGScheduler} Got job 0 (show at Main.scala:32) with 1 output partitions
[14:30:19,838] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:32)
[14:30:19,839] INFO  {DAGScheduler} Parents of final stage: List()
[14:30:19,840] INFO  {DAGScheduler} Missing parents: List()
[14:30:19,844] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32), which has no missing parents
[14:30:19,885] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[14:30:19,887] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[14:30:19,888] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:45331 (size: 6.6 KB, free: 1128.9 MB)
[14:30:19,889] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:30:19,891] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32)
[14:30:19,893] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:30:19,930] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:30:19,937] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:30:19,978] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:30:19,996] INFO  {CodeGenerator} Code generated in 15.069043 ms
[14:30:20,031] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2808 bytes result sent to driver
[14:30:20,039] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 128 ms on localhost (1/1)
[14:30:20,040] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:30:20,047] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:32) finished in 0.146 s
[14:30:20,055] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:32, took 0.234952 s
[14:30:20,095] INFO  {CodeGenerator} Code generated in 25.188118 ms
[14:30:20,148] INFO  {FileSourceStrategy} Pruning directories with: 
[14:30:20,148] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:30:20,149] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:30:20,149] INFO  {FileSourceStrategy} Pushed Filters: 
[14:30:20,158] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:30:20,184] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:30:20,184] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:45331 (size: 14.6 KB, free: 1128.9 MB)
[14:30:20,186] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[14:30:20,186] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:30:20,205] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:45331 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:30:20,208] INFO  {ContextCleaner} Cleaned accumulator 0
[14:30:20,209] INFO  {ContextCleaner} Cleaned accumulator 1
[14:30:20,210] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:45331 in memory (size: 6.6 KB, free: 1128.9 MB)
[14:30:20,258] INFO  {CodeGenerator} Code generated in 46.253409 ms
[14:30:20,275] INFO  {SparkContext} Starting job: show at Main.scala:43
[14:30:20,276] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[14:30:20,276] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[14:30:20,276] INFO  {DAGScheduler} Parents of final stage: List()
[14:30:20,277] INFO  {DAGScheduler} Missing parents: List()
[14:30:20,277] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[14:30:20,280] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.7 MB)
[14:30:20,282] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1128.7 MB)
[14:30:20,283] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:45331 (size: 8.1 KB, free: 1128.9 MB)
[14:30:20,283] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[14:30:20,284] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[14:30:20,284] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[14:30:20,286] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:30:20,286] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[14:30:20,299] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:30:20,315] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[14:30:20,319] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on localhost (1/1)
[14:30:20,320] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[14:30:20,320] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.036 s
[14:30:20,320] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.044754 s
[14:30:20,346] INFO  {CodeGenerator} Code generated in 17.062346 ms
[14:30:20,425] INFO  {FileSourceStrategy} Pruning directories with: 
[14:30:20,425] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:30:20,426] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:30:20,426] INFO  {FileSourceStrategy} Pushed Filters: 
[14:30:20,431] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:30:20,439] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:30:20,440] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:45331 (size: 14.6 KB, free: 1128.9 MB)
[14:30:20,441] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:51
[14:30:20,441] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:30:20,497] INFO  {CodeGenerator} Code generated in 40.142483 ms
[14:30:20,507] INFO  {SparkContext} Starting job: show at Main.scala:51
[14:30:20,508] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[14:30:20,508] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[14:30:20,508] INFO  {DAGScheduler} Parents of final stage: List()
[14:30:20,508] INFO  {DAGScheduler} Missing parents: List()
[14:30:20,509] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51), which has no missing parents
[14:30:20,513] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.6 MB)
[14:30:20,514] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.5 MB)
[14:30:20,515] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:45331 (size: 9.6 KB, free: 1128.9 MB)
[14:30:20,515] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[14:30:20,515] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51)
[14:30:20,515] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[14:30:20,517] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:30:20,518] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[14:30:20,526] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:30:20,535] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[14:30:20,537] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 21 ms on localhost (1/1)
[14:30:20,537] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[14:30:20,538] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.021 s
[14:30:20,538] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.031073 s
[14:30:20,554] INFO  {CodeGenerator} Code generated in 13.617658 ms
[14:30:20,604] INFO  {FileSourceStrategy} Pruning directories with: 
[14:30:20,605] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:30:20,606] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:30:20,606] INFO  {FileSourceStrategy} Pushed Filters: 
[14:30:20,610] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[14:30:20,620] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[14:30:20,621] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:45331 (size: 14.6 KB, free: 1128.8 MB)
[14:30:20,622] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:61
[14:30:20,622] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:30:20,688] INFO  {CodeGenerator} Code generated in 44.523846 ms
[14:30:20,698] INFO  {SparkContext} Starting job: show at Main.scala:61
[14:30:20,698] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[14:30:20,698] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[14:30:20,698] INFO  {DAGScheduler} Parents of final stage: List()
[14:30:20,699] INFO  {DAGScheduler} Missing parents: List()
[14:30:20,699] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61), which has no missing parents
[14:30:20,701] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.4 MB)
[14:30:20,703] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.4 MB)
[14:30:20,703] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:45331 (size: 10.9 KB, free: 1128.8 MB)
[14:30:20,704] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[14:30:20,704] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61)
[14:30:20,704] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[14:30:20,706] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:30:20,706] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[14:30:20,714] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:30:20,722] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[14:30:20,723] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 19 ms on localhost (1/1)
[14:30:20,723] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[14:30:20,724] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.019 s
[14:30:20,724] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.026120 s
[14:30:20,739] INFO  {CodeGenerator} Code generated in 12.737085 ms
[14:30:20,783] INFO  {FileSourceStrategy} Pruning directories with: 
[14:30:20,783] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:30:20,784] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:30:20,784] INFO  {FileSourceStrategy} Pushed Filters: 
[14:30:20,788] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.2 MB)
[14:30:20,795] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.2 MB)
[14:30:20,796] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:45331 (size: 14.6 KB, free: 1128.8 MB)
[14:30:20,797] INFO  {SparkContext} Created broadcast 8 from show at Main.scala:72
[14:30:20,797] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:30:20,871] INFO  {CodeGenerator} Code generated in 55.003728 ms
[14:30:20,880] INFO  {SparkContext} Starting job: show at Main.scala:72
[14:30:20,881] INFO  {DAGScheduler} Got job 4 (show at Main.scala:72) with 1 output partitions
[14:30:20,881] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:72)
[14:30:20,881] INFO  {DAGScheduler} Parents of final stage: List()
[14:30:20,881] INFO  {DAGScheduler} Missing parents: List()
[14:30:20,882] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:72), which has no missing parents
[14:30:20,884] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 42.9 KB, free 1128.2 MB)
[14:30:20,886] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.6 KB, free 1128.2 MB)
[14:30:20,887] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:45331 (size: 12.6 KB, free: 1128.8 MB)
[14:30:20,887] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[14:30:20,888] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:72)
[14:30:20,888] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[14:30:20,889] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:30:20,890] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[14:30:20,897] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:30:20,903] ERROR {Executor} Exception in task 0.0 in stage 4.0 (TID 4)
org.apache.spark.SparkException: Failed to execute user defined function(anonfun$1: (vector) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.ml.linalg.DenseVector cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:118)
	at se.kth.spark.lab1.task2.Main$$anonfun$1.apply(Main.scala:64)
	... 16 more
[14:30:21,020] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:45331 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:30:21,020] INFO  {ContextCleaner} Cleaned accumulator 46
[14:30:21,020] INFO  {ContextCleaner} Cleaned accumulator 47
[14:30:21,021] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:45331 in memory (size: 8.1 KB, free: 1128.8 MB)
[14:30:21,024] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:45331 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:30:21,024] INFO  {ContextCleaner} Cleaned accumulator 92
[14:30:21,024] INFO  {ContextCleaner} Cleaned accumulator 93
[14:30:21,025] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:45331 in memory (size: 9.6 KB, free: 1128.8 MB)
[14:30:21,026] WARN  {TaskSetManager} Lost task 0.0 in stage 4.0 (TID 4, localhost): org.apache.spark.SparkException: Failed to execute user defined function(anonfun$1: (vector) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.ml.linalg.DenseVector cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:118)
	at se.kth.spark.lab1.task2.Main$$anonfun$1.apply(Main.scala:64)
	... 16 more

[14:30:21,026] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:45331 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:30:21,027] INFO  {ContextCleaner} Cleaned accumulator 138
[14:30:21,027] INFO  {ContextCleaner} Cleaned accumulator 139
[14:30:21,028] ERROR {TaskSetManager} Task 0 in stage 4.0 failed 1 times; aborting job
[14:30:21,028] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:45331 in memory (size: 10.9 KB, free: 1128.9 MB)
[14:30:21,031] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[14:30:21,034] INFO  {TaskSchedulerImpl} Cancelling stage 4
[14:30:21,035] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:72) failed in 0.147 s
[14:30:21,036] INFO  {DAGScheduler} Job 4 failed: show at Main.scala:72, took 0.156280 s
[14:30:21,043] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:30:21,047] INFO  {ServerConnector} Stopped ServerConnector@34172b75{HTTP/1.1}{0.0.0.0:4040}
[14:30:21,050] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[14:30:21,050] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[14:30:21,050] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[14:30:21,050] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[14:30:21,050] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[14:30:21,050] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[14:30:21,051] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[14:30:21,051] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[14:30:21,051] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[14:30:21,051] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[14:30:21,051] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[14:30:21,051] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[14:30:21,051] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[14:30:21,052] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[14:30:21,052] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[14:30:21,052] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[14:30:21,052] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[14:30:21,052] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[14:30:21,052] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[14:30:21,052] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[14:30:21,053] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[14:30:21,053] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[14:30:21,053] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[14:30:21,053] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[14:30:21,055] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[14:30:21,064] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:30:21,070] INFO  {MemoryStore} MemoryStore cleared
[14:30:21,070] INFO  {BlockManager} BlockManager stopped
[14:30:21,072] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:30:21,075] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:30:21,084] INFO  {SparkContext} Successfully stopped SparkContext
[14:30:21,084] INFO  {ShutdownHookManager} Shutdown hook called
[14:30:21,085] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-50e79f0e-f32f-4e68-9848-4ff77eea99dd
[14:31:23,263] INFO  {SparkContext} Running Spark version 2.0.1
[14:31:23,479] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:31:23,574] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[14:31:23,575] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:31:23,642] INFO  {SecurityManager} Changing view acls to: victor
[14:31:23,642] INFO  {SecurityManager} Changing modify acls to: victor
[14:31:23,643] INFO  {SecurityManager} Changing view acls groups to: 
[14:31:23,644] INFO  {SecurityManager} Changing modify acls groups to: 
[14:31:23,644] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:31:24,010] INFO  {Utils} Successfully started service 'sparkDriver' on port 33571.
[14:31:24,027] INFO  {SparkEnv} Registering MapOutputTracker
[14:31:24,048] INFO  {SparkEnv} Registering BlockManagerMaster
[14:31:24,060] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-aad3d9e0-67a4-4a80-846b-ce4efcb7d1ed
[14:31:24,074] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:31:24,139] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:31:24,210] INFO  {log} Logging initialized @1511ms
[14:31:24,311] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:31:24,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[14:31:24,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[14:31:24,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[14:31:24,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[14:31:24,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[14:31:24,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[14:31:24,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[14:31:24,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[14:31:24,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[14:31:24,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[14:31:24,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[14:31:24,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[14:31:24,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[14:31:24,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[14:31:24,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[14:31:24,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[14:31:24,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[14:31:24,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[14:31:24,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[14:31:24,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[14:31:24,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[14:31:24,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[14:31:24,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[14:31:24,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[14:31:24,344] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:31:24,344] INFO  {Server} Started @1647ms
[14:31:24,344] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:31:24,346] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[14:31:24,424] INFO  {Executor} Starting executor ID driver on host localhost
[14:31:24,446] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41543.
[14:31:24,447] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:41543
[14:31:24,449] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 41543)
[14:31:24,452] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:41543 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 41543)
[14:31:24,455] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 41543)
[14:31:24,579] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[14:31:24,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[14:31:24,635] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[14:31:24,636] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[14:31:24,636] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[14:31:24,638] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[14:31:24,653] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[14:31:26,530] INFO  {FileSourceStrategy} Pruning directories with: 
[14:31:26,531] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:31:26,535] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:31:26,536] INFO  {FileSourceStrategy} Pushed Filters: 
[14:31:26,643] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[14:31:26,688] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:31:26,690] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:41543 (size: 14.6 KB, free: 1128.9 MB)
[14:31:26,695] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:32
[14:31:26,699] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:31:27,185] INFO  {CodeGenerator} Code generated in 215.736251 ms
[14:31:27,277] INFO  {SparkContext} Starting job: show at Main.scala:32
[14:31:27,295] INFO  {DAGScheduler} Got job 0 (show at Main.scala:32) with 1 output partitions
[14:31:27,296] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:32)
[14:31:27,296] INFO  {DAGScheduler} Parents of final stage: List()
[14:31:27,297] INFO  {DAGScheduler} Missing parents: List()
[14:31:27,302] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32), which has no missing parents
[14:31:27,344] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[14:31:27,346] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KB, free 1128.7 MB)
[14:31:27,347] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:41543 (size: 6.7 KB, free: 1128.9 MB)
[14:31:27,347] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:31:27,350] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32)
[14:31:27,351] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:31:27,391] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:31:27,397] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:31:27,441] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:31:27,459] INFO  {CodeGenerator} Code generated in 14.389082 ms
[14:31:27,489] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[14:31:27,495] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 123 ms on localhost (1/1)
[14:31:27,496] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:31:27,499] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:32) finished in 0.140 s
[14:31:27,505] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:32, took 0.227270 s
[14:31:27,544] INFO  {CodeGenerator} Code generated in 25.780045 ms
[14:31:27,583] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:41543 in memory (size: 6.7 KB, free: 1128.9 MB)
[14:31:27,622] INFO  {FileSourceStrategy} Pruning directories with: 
[14:31:27,623] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:31:27,623] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:31:27,623] INFO  {FileSourceStrategy} Pushed Filters: 
[14:31:27,630] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:31:27,641] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:31:27,642] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:41543 (size: 14.6 KB, free: 1128.9 MB)
[14:31:27,644] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[14:31:27,644] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:31:27,714] INFO  {CodeGenerator} Code generated in 42.988083 ms
[14:31:27,730] INFO  {SparkContext} Starting job: show at Main.scala:43
[14:31:27,731] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[14:31:27,731] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[14:31:27,731] INFO  {DAGScheduler} Parents of final stage: List()
[14:31:27,732] INFO  {DAGScheduler} Missing parents: List()
[14:31:27,732] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[14:31:27,736] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[14:31:27,739] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[14:31:27,739] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:41543 (size: 8.2 KB, free: 1128.9 MB)
[14:31:27,740] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[14:31:27,740] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[14:31:27,740] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[14:31:27,743] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:31:27,744] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[14:31:27,758] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:31:27,775] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[14:31:27,778] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on localhost (1/1)
[14:31:27,778] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[14:31:27,778] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.037 s
[14:31:27,779] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.048632 s
[14:31:27,805] INFO  {CodeGenerator} Code generated in 16.512781 ms
[14:31:27,882] INFO  {FileSourceStrategy} Pruning directories with: 
[14:31:27,882] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:31:27,883] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:31:27,883] INFO  {FileSourceStrategy} Pushed Filters: 
[14:31:27,888] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[14:31:27,896] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[14:31:27,897] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:41543 (size: 14.6 KB, free: 1128.8 MB)
[14:31:27,898] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:51
[14:31:27,898] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:31:27,950] INFO  {CodeGenerator} Code generated in 38.211673 ms
[14:31:27,958] INFO  {SparkContext} Starting job: show at Main.scala:51
[14:31:27,959] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[14:31:27,959] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[14:31:27,959] INFO  {DAGScheduler} Parents of final stage: List()
[14:31:27,960] INFO  {DAGScheduler} Missing parents: List()
[14:31:27,960] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51), which has no missing parents
[14:31:27,963] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[14:31:27,964] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[14:31:27,965] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:41543 (size: 9.6 KB, free: 1128.8 MB)
[14:31:27,966] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[14:31:27,966] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51)
[14:31:27,966] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[14:31:27,968] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:31:27,968] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[14:31:27,977] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:31:27,987] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[14:31:27,989] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 22 ms on localhost (1/1)
[14:31:27,989] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[14:31:27,989] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.023 s
[14:31:27,989] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.030676 s
[14:31:28,007] INFO  {CodeGenerator} Code generated in 15.137274 ms
[14:31:28,053] INFO  {FileSourceStrategy} Pruning directories with: 
[14:31:28,054] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:31:28,055] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:31:28,055] INFO  {FileSourceStrategy} Pushed Filters: 
[14:31:28,060] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[14:31:28,071] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.3 MB)
[14:31:28,071] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:41543 (size: 14.6 KB, free: 1128.8 MB)
[14:31:28,072] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:61
[14:31:28,072] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:31:28,143] INFO  {CodeGenerator} Code generated in 50.439586 ms
[14:31:28,154] INFO  {SparkContext} Starting job: show at Main.scala:61
[14:31:28,155] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[14:31:28,155] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[14:31:28,155] INFO  {DAGScheduler} Parents of final stage: List()
[14:31:28,155] INFO  {DAGScheduler} Missing parents: List()
[14:31:28,155] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61), which has no missing parents
[14:31:28,158] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[14:31:28,159] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[14:31:28,160] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:41543 (size: 10.9 KB, free: 1128.8 MB)
[14:31:28,160] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[14:31:28,161] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61)
[14:31:28,161] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[14:31:28,163] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:31:28,164] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[14:31:28,176] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:31:28,185] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[14:31:28,186] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 24 ms on localhost (1/1)
[14:31:28,186] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[14:31:28,186] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.024 s
[14:31:28,187] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.032765 s
[14:31:28,202] INFO  {CodeGenerator} Code generated in 13.241719 ms
[14:31:28,243] INFO  {FileSourceStrategy} Pruning directories with: 
[14:31:28,243] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:31:28,244] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:31:28,244] INFO  {FileSourceStrategy} Pushed Filters: 
[14:31:28,247] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.1 MB)
[14:31:28,255] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.1 MB)
[14:31:28,256] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:41543 (size: 14.6 KB, free: 1128.8 MB)
[14:31:28,257] INFO  {SparkContext} Created broadcast 8 from show at Main.scala:72
[14:31:28,257] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:31:28,321] INFO  {CodeGenerator} Code generated in 45.135062 ms
[14:31:28,330] INFO  {SparkContext} Starting job: show at Main.scala:72
[14:31:28,331] INFO  {DAGScheduler} Got job 4 (show at Main.scala:72) with 1 output partitions
[14:31:28,331] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:72)
[14:31:28,331] INFO  {DAGScheduler} Parents of final stage: List()
[14:31:28,331] INFO  {DAGScheduler} Missing parents: List()
[14:31:28,331] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:72), which has no missing parents
[14:31:28,334] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 42.9 KB, free 1128.0 MB)
[14:31:28,336] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.6 KB, free 1128.0 MB)
[14:31:28,337] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:41543 (size: 12.6 KB, free: 1128.8 MB)
[14:31:28,337] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[14:31:28,338] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:72)
[14:31:28,338] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[14:31:28,340] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:31:28,341] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[14:31:28,350] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:31:28,357] ERROR {Executor} Exception in task 0.0 in stage 4.0 (TID 4)
org.apache.spark.SparkException: Failed to execute user defined function(anonfun$1: (vector) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.ml.linalg.DenseVector cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:118)
	at se.kth.spark.lab1.task2.Main$$anonfun$1.apply(Main.scala:64)
	... 16 more
[14:31:28,485] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:41543 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:31:28,487] WARN  {TaskSetManager} Lost task 0.0 in stage 4.0 (TID 4, localhost): org.apache.spark.SparkException: Failed to execute user defined function(anonfun$1: (vector) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.ml.linalg.DenseVector cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:118)
	at se.kth.spark.lab1.task2.Main$$anonfun$1.apply(Main.scala:64)
	... 16 more

[14:31:28,488] INFO  {ContextCleaner} Cleaned accumulator 0
[14:31:28,488] INFO  {ContextCleaner} Cleaned accumulator 1
[14:31:28,489] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:41543 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:31:28,490] ERROR {TaskSetManager} Task 0 in stage 4.0 failed 1 times; aborting job
[14:31:28,490] INFO  {ContextCleaner} Cleaned accumulator 46
[14:31:28,490] INFO  {ContextCleaner} Cleaned accumulator 47
[14:31:28,491] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:41543 in memory (size: 8.2 KB, free: 1128.8 MB)
[14:31:28,491] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[14:31:28,492] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:41543 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:31:28,493] INFO  {ContextCleaner} Cleaned accumulator 92
[14:31:28,493] INFO  {ContextCleaner} Cleaned accumulator 93
[14:31:28,494] INFO  {TaskSchedulerImpl} Cancelling stage 4
[14:31:28,494] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:41543 in memory (size: 9.6 KB, free: 1128.8 MB)
[14:31:28,495] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:72) failed in 0.156 s
[14:31:28,496] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:41543 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:31:28,496] INFO  {ContextCleaner} Cleaned accumulator 138
[14:31:28,497] INFO  {ContextCleaner} Cleaned accumulator 139
[14:31:28,497] INFO  {DAGScheduler} Job 4 failed: show at Main.scala:72, took 0.167027 s
[14:31:28,499] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:41543 in memory (size: 10.9 KB, free: 1128.9 MB)
[14:31:28,504] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:31:28,509] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:31:28,511] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[14:31:28,511] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[14:31:28,511] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[14:31:28,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[14:31:28,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[14:31:28,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[14:31:28,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[14:31:28,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[14:31:28,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[14:31:28,513] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[14:31:28,513] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[14:31:28,513] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[14:31:28,513] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[14:31:28,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[14:31:28,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[14:31:28,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[14:31:28,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[14:31:28,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[14:31:28,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[14:31:28,514] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[14:31:28,515] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[14:31:28,515] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[14:31:28,515] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[14:31:28,515] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[14:31:28,517] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[14:31:28,526] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:31:28,531] INFO  {MemoryStore} MemoryStore cleared
[14:31:28,532] INFO  {BlockManager} BlockManager stopped
[14:31:28,534] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:31:28,536] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:31:28,543] INFO  {SparkContext} Successfully stopped SparkContext
[14:31:28,543] INFO  {ShutdownHookManager} Shutdown hook called
[14:31:28,544] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-dc9e2850-a65b-455d-bdc8-f3cd2afca9fe
[14:31:56,924] INFO  {SparkContext} Running Spark version 2.0.1
[14:31:57,134] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:31:57,223] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[14:31:57,224] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:31:57,290] INFO  {SecurityManager} Changing view acls to: victor
[14:31:57,291] INFO  {SecurityManager} Changing modify acls to: victor
[14:31:57,292] INFO  {SecurityManager} Changing view acls groups to: 
[14:31:57,293] INFO  {SecurityManager} Changing modify acls groups to: 
[14:31:57,294] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:31:57,653] INFO  {Utils} Successfully started service 'sparkDriver' on port 39673.
[14:31:57,672] INFO  {SparkEnv} Registering MapOutputTracker
[14:31:57,696] INFO  {SparkEnv} Registering BlockManagerMaster
[14:31:57,711] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-2df6bca2-bb68-4ecd-beba-791293824d8e
[14:31:57,729] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:31:57,802] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:31:57,875] INFO  {log} Logging initialized @1545ms
[14:31:57,978] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:31:57,997] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:31:57,997] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:31:57,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:31:57,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:31:57,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:31:57,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:31:57,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:31:57,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:31:57,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:31:57,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:31:57,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:31:57,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:31:58,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:31:58,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:31:58,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:31:58,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:31:58,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:31:58,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:31:58,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:31:58,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:31:58,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:31:58,011] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:31:58,012] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:31:58,012] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:31:58,021] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:31:58,021] INFO  {Server} Started @1691ms
[14:31:58,021] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:31:58,024] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[14:31:58,122] INFO  {Executor} Starting executor ID driver on host localhost
[14:31:58,148] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34403.
[14:31:58,149] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:34403
[14:31:58,151] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 34403)
[14:31:58,156] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:34403 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 34403)
[14:31:58,158] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 34403)
[14:31:58,283] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:31:58,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[14:31:58,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[14:31:58,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[14:31:58,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[14:31:58,332] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[14:31:58,348] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[14:32:00,195] INFO  {FileSourceStrategy} Pruning directories with: 
[14:32:00,196] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:32:00,201] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:32:00,201] INFO  {FileSourceStrategy} Pushed Filters: 
[14:32:00,304] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[14:32:00,349] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:32:00,351] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:34403 (size: 14.6 KB, free: 1128.9 MB)
[14:32:00,360] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:32
[14:32:00,365] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:32:00,913] INFO  {CodeGenerator} Code generated in 232.867384 ms
[14:32:01,004] INFO  {SparkContext} Starting job: show at Main.scala:32
[14:32:01,018] INFO  {DAGScheduler} Got job 0 (show at Main.scala:32) with 1 output partitions
[14:32:01,019] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:32)
[14:32:01,019] INFO  {DAGScheduler} Parents of final stage: List()
[14:32:01,020] INFO  {DAGScheduler} Missing parents: List()
[14:32:01,025] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32), which has no missing parents
[14:32:01,068] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[14:32:01,070] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[14:32:01,071] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:34403 (size: 6.6 KB, free: 1128.9 MB)
[14:32:01,072] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:32:01,075] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32)
[14:32:01,077] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:32:01,120] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:32:01,126] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:32:01,169] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:32:01,183] INFO  {CodeGenerator} Code generated in 10.305563 ms
[14:32:01,227] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2794 bytes result sent to driver
[14:32:01,234] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 138 ms on localhost (1/1)
[14:32:01,235] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:32:01,239] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:32) finished in 0.154 s
[14:32:01,245] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:32, took 0.241084 s
[14:32:01,280] INFO  {CodeGenerator} Code generated in 18.807961 ms
[14:32:01,338] INFO  {FileSourceStrategy} Pruning directories with: 
[14:32:01,338] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:32:01,339] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:32:01,339] INFO  {FileSourceStrategy} Pushed Filters: 
[14:32:01,346] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:32:01,356] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:32:01,357] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:34403 (size: 14.6 KB, free: 1128.9 MB)
[14:32:01,358] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[14:32:01,359] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:32:01,422] INFO  {CodeGenerator} Code generated in 39.681176 ms
[14:32:01,436] INFO  {SparkContext} Starting job: show at Main.scala:43
[14:32:01,437] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[14:32:01,437] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[14:32:01,437] INFO  {DAGScheduler} Parents of final stage: List()
[14:32:01,437] INFO  {DAGScheduler} Missing parents: List()
[14:32:01,438] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[14:32:01,443] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[14:32:01,445] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[14:32:01,445] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:34403 (size: 8.2 KB, free: 1128.9 MB)
[14:32:01,446] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[14:32:01,446] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[14:32:01,446] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[14:32:01,448] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:32:01,449] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[14:32:01,459] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:32:01,477] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3492 bytes result sent to driver
[14:32:01,479] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on localhost (1/1)
[14:32:01,479] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[14:32:01,480] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.032 s
[14:32:01,480] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.043732 s
[14:32:01,511] INFO  {CodeGenerator} Code generated in 20.896235 ms
[14:32:01,620] INFO  {FileSourceStrategy} Pruning directories with: 
[14:32:01,620] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:32:01,622] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:32:01,622] INFO  {FileSourceStrategy} Pushed Filters: 
[14:32:01,630] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[14:32:01,643] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[14:32:01,643] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:34403 (size: 14.6 KB, free: 1128.8 MB)
[14:32:01,644] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:51
[14:32:01,645] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:32:01,712] INFO  {CodeGenerator} Code generated in 47.586609 ms
[14:32:01,723] INFO  {SparkContext} Starting job: show at Main.scala:51
[14:32:01,724] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[14:32:01,725] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[14:32:01,725] INFO  {DAGScheduler} Parents of final stage: List()
[14:32:01,725] INFO  {DAGScheduler} Missing parents: List()
[14:32:01,726] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51), which has no missing parents
[14:32:01,733] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[14:32:01,735] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[14:32:01,736] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:34403 (size: 9.6 KB, free: 1128.8 MB)
[14:32:01,736] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[14:32:01,736] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51)
[14:32:01,737] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[14:32:01,739] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:32:01,739] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[14:32:01,749] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:32:01,759] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[14:32:01,760] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 23 ms on localhost (1/1)
[14:32:01,760] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[14:32:01,761] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.023 s
[14:32:01,761] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.037362 s
[14:32:01,780] INFO  {CodeGenerator} Code generated in 15.697787 ms
[14:32:01,818] INFO  {FileSourceStrategy} Pruning directories with: 
[14:32:01,819] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:32:01,819] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:32:01,819] INFO  {FileSourceStrategy} Pushed Filters: 
[14:32:01,824] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[14:32:01,833] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.2 MB)
[14:32:01,834] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:34403 (size: 14.6 KB, free: 1128.8 MB)
[14:32:01,835] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:61
[14:32:01,835] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:32:01,900] INFO  {CodeGenerator} Code generated in 46.742554 ms
[14:32:01,912] INFO  {SparkContext} Starting job: show at Main.scala:61
[14:32:01,913] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[14:32:01,913] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[14:32:01,913] INFO  {DAGScheduler} Parents of final stage: List()
[14:32:01,913] INFO  {DAGScheduler} Missing parents: List()
[14:32:01,914] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61), which has no missing parents
[14:32:01,916] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[14:32:01,918] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[14:32:01,918] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:34403 (size: 10.9 KB, free: 1128.8 MB)
[14:32:01,919] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[14:32:01,919] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61)
[14:32:01,919] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[14:32:01,921] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:32:01,921] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[14:32:01,937] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:32:01,949] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[14:32:01,952] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 32 ms on localhost (1/1)
[14:32:01,952] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[14:32:01,952] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.032 s
[14:32:01,953] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.040251 s
[14:32:01,969] INFO  {CodeGenerator} Code generated in 14.426967 ms
[14:32:02,020] INFO  {FileSourceStrategy} Pruning directories with: 
[14:32:02,021] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:32:02,021] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:32:02,021] INFO  {FileSourceStrategy} Pushed Filters: 
[14:32:02,026] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.1 MB)
[14:32:02,036] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.1 MB)
[14:32:02,036] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:34403 (size: 14.6 KB, free: 1128.8 MB)
[14:32:02,037] INFO  {SparkContext} Created broadcast 8 from show at Main.scala:72
[14:32:02,038] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:32:02,115] INFO  {CodeGenerator} Code generated in 52.371318 ms
[14:32:02,123] INFO  {SparkContext} Starting job: show at Main.scala:72
[14:32:02,124] INFO  {DAGScheduler} Got job 4 (show at Main.scala:72) with 1 output partitions
[14:32:02,125] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:72)
[14:32:02,125] INFO  {DAGScheduler} Parents of final stage: List()
[14:32:02,125] INFO  {DAGScheduler} Missing parents: List()
[14:32:02,125] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:72), which has no missing parents
[14:32:02,127] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 42.9 KB, free 1128.0 MB)
[14:32:02,129] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.6 KB, free 1128.0 MB)
[14:32:02,130] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:34403 (size: 12.6 KB, free: 1128.8 MB)
[14:32:02,130] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[14:32:02,130] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:72)
[14:32:02,131] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[14:32:02,132] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:32:02,133] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[14:32:02,144] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:32:02,151] ERROR {Executor} Exception in task 0.0 in stage 4.0 (TID 4)
org.apache.spark.SparkException: Failed to execute user defined function(anonfun$1: (vector) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.ml.linalg.DenseVector cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:118)
	at se.kth.spark.lab1.task2.Main$$anonfun$1.apply(Main.scala:64)
	... 16 more
[14:32:02,174] WARN  {TaskSetManager} Lost task 0.0 in stage 4.0 (TID 4, localhost): org.apache.spark.SparkException: Failed to execute user defined function(anonfun$1: (vector) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.ml.linalg.DenseVector cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:118)
	at se.kth.spark.lab1.task2.Main$$anonfun$1.apply(Main.scala:64)
	... 16 more

[14:32:02,176] ERROR {TaskSetManager} Task 0 in stage 4.0 failed 1 times; aborting job
[14:32:02,177] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[14:32:02,181] INFO  {TaskSchedulerImpl} Cancelling stage 4
[14:32:02,183] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:72) failed in 0.051 s
[14:32:02,283] INFO  {DAGScheduler} Job 4 failed: show at Main.scala:72, took 0.159676 s
[14:32:02,293] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:32:02,303] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:32:02,305] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:32:02,305] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:32:02,305] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:32:02,306] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:32:02,306] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:32:02,306] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:32:02,306] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:32:02,306] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:32:02,306] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:32:02,306] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:32:02,306] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:32:02,306] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:32:02,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:32:02,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:32:02,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:32:02,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:32:02,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:32:02,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:32:02,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:32:02,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:32:02,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:32:02,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:32:02,308] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:32:02,308] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:32:02,310] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:34403 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:32:02,311] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[14:32:02,329] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:32:02,337] INFO  {MemoryStore} MemoryStore cleared
[14:32:02,338] INFO  {BlockManager} BlockManager stopped
[14:32:02,339] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:32:02,342] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:32:02,348] INFO  {SparkContext} Successfully stopped SparkContext
[14:32:02,349] INFO  {ShutdownHookManager} Shutdown hook called
[14:32:02,352] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-88aa4bf6-ff3e-491f-9625-2a8fe246763b
[14:36:03,196] INFO  {SparkContext} Running Spark version 2.0.1
[14:36:03,408] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:36:03,525] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[14:36:03,526] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:36:03,615] INFO  {SecurityManager} Changing view acls to: victor
[14:36:03,616] INFO  {SecurityManager} Changing modify acls to: victor
[14:36:03,616] INFO  {SecurityManager} Changing view acls groups to: 
[14:36:03,617] INFO  {SecurityManager} Changing modify acls groups to: 
[14:36:03,618] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:36:03,982] INFO  {Utils} Successfully started service 'sparkDriver' on port 34373.
[14:36:03,999] INFO  {SparkEnv} Registering MapOutputTracker
[14:36:04,013] INFO  {SparkEnv} Registering BlockManagerMaster
[14:36:04,025] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-a924efd7-7e63-44ae-82ed-706007b1b1dc
[14:36:04,039] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:36:04,091] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:36:04,165] INFO  {log} Logging initialized @1603ms
[14:36:04,270] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:36:04,286] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[14:36:04,286] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[14:36:04,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[14:36:04,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[14:36:04,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[14:36:04,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[14:36:04,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[14:36:04,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[14:36:04,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[14:36:04,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[14:36:04,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[14:36:04,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[14:36:04,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[14:36:04,290] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[14:36:04,290] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[14:36:04,290] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[14:36:04,290] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[14:36:04,291] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[14:36:04,291] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[14:36:04,291] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[14:36:04,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[14:36:04,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[14:36:04,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[14:36:04,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[14:36:04,310] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:36:04,310] INFO  {Server} Started @1750ms
[14:36:04,310] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:36:04,313] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[14:36:04,402] INFO  {Executor} Starting executor ID driver on host localhost
[14:36:04,423] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37921.
[14:36:04,423] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:37921
[14:36:04,425] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 37921)
[14:36:04,428] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:37921 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 37921)
[14:36:04,430] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 37921)
[14:36:04,553] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[14:36:04,603] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[14:36:04,604] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[14:36:04,604] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[14:36:04,605] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[14:36:04,607] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[14:36:04,622] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[14:36:06,575] INFO  {FileSourceStrategy} Pruning directories with: 
[14:36:06,576] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:36:06,581] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:36:06,581] INFO  {FileSourceStrategy} Pushed Filters: 
[14:36:06,685] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[14:36:06,732] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:36:06,738] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:37921 (size: 14.6 KB, free: 1128.9 MB)
[14:36:06,744] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:32
[14:36:06,748] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:36:07,237] INFO  {CodeGenerator} Code generated in 220.941969 ms
[14:36:07,329] INFO  {SparkContext} Starting job: show at Main.scala:32
[14:36:07,346] INFO  {DAGScheduler} Got job 0 (show at Main.scala:32) with 1 output partitions
[14:36:07,346] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:32)
[14:36:07,347] INFO  {DAGScheduler} Parents of final stage: List()
[14:36:07,348] INFO  {DAGScheduler} Missing parents: List()
[14:36:07,353] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32), which has no missing parents
[14:36:07,400] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[14:36:07,403] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[14:36:07,404] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:37921 (size: 6.6 KB, free: 1128.9 MB)
[14:36:07,405] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:36:07,408] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:32)
[14:36:07,409] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:36:07,449] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:36:07,458] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:36:07,492] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:36:07,506] INFO  {CodeGenerator} Code generated in 10.425818 ms
[14:36:07,536] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[14:36:07,555] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 126 ms on localhost (1/1)
[14:36:07,556] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:36:07,560] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:32) finished in 0.142 s
[14:36:07,567] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:32, took 0.236941 s
[14:36:07,601] INFO  {CodeGenerator} Code generated in 19.771754 ms
[14:36:07,648] INFO  {FileSourceStrategy} Pruning directories with: 
[14:36:07,648] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:36:07,648] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:36:07,648] INFO  {FileSourceStrategy} Pushed Filters: 
[14:36:07,655] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:36:07,665] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:36:07,665] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:37921 (size: 14.6 KB, free: 1128.9 MB)
[14:36:07,667] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[14:36:07,667] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:36:07,716] INFO  {CodeGenerator} Code generated in 32.893633 ms
[14:36:07,727] INFO  {SparkContext} Starting job: show at Main.scala:43
[14:36:07,729] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[14:36:07,729] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[14:36:07,729] INFO  {DAGScheduler} Parents of final stage: List()
[14:36:07,729] INFO  {DAGScheduler} Missing parents: List()
[14:36:07,730] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[14:36:07,735] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[14:36:07,740] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[14:36:07,741] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:37921 (size: 8.2 KB, free: 1128.9 MB)
[14:36:07,742] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[14:36:07,743] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[14:36:07,743] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[14:36:07,746] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:36:07,746] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[14:36:07,756] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:36:07,771] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[14:36:07,773] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 29 ms on localhost (1/1)
[14:36:07,774] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[14:36:07,774] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.030 s
[14:36:07,774] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.046438 s
[14:36:07,804] INFO  {CodeGenerator} Code generated in 20.430163 ms
[14:36:07,940] INFO  {FileSourceStrategy} Pruning directories with: 
[14:36:07,941] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:36:07,941] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:36:07,941] INFO  {FileSourceStrategy} Pushed Filters: 
[14:36:07,947] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[14:36:07,955] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[14:36:07,956] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:37921 (size: 14.6 KB, free: 1128.8 MB)
[14:36:07,957] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:51
[14:36:07,957] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:36:08,015] INFO  {CodeGenerator} Code generated in 42.489601 ms
[14:36:08,024] INFO  {SparkContext} Starting job: show at Main.scala:51
[14:36:08,025] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[14:36:08,025] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[14:36:08,025] INFO  {DAGScheduler} Parents of final stage: List()
[14:36:08,026] INFO  {DAGScheduler} Missing parents: List()
[14:36:08,026] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51), which has no missing parents
[14:36:08,031] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[14:36:08,034] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[14:36:08,034] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:37921 (size: 9.6 KB, free: 1128.8 MB)
[14:36:08,035] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[14:36:08,035] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51)
[14:36:08,035] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[14:36:08,037] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:36:08,037] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[14:36:08,046] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:36:08,055] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[14:36:08,056] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 20 ms on localhost (1/1)
[14:36:08,056] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[14:36:08,057] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.021 s
[14:36:08,057] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.032721 s
[14:36:08,078] INFO  {CodeGenerator} Code generated in 18.257437 ms
[14:36:08,124] INFO  {FileSourceStrategy} Pruning directories with: 
[14:36:08,124] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:36:08,125] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:36:08,126] INFO  {FileSourceStrategy} Pushed Filters: 
[14:36:08,134] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[14:36:08,148] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.2 MB)
[14:36:08,149] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:37921 (size: 14.6 KB, free: 1128.8 MB)
[14:36:08,149] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:61
[14:36:08,150] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:36:08,242] INFO  {CodeGenerator} Code generated in 68.783901 ms
[14:36:08,257] INFO  {SparkContext} Starting job: show at Main.scala:61
[14:36:08,258] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[14:36:08,258] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[14:36:08,258] INFO  {DAGScheduler} Parents of final stage: List()
[14:36:08,258] INFO  {DAGScheduler} Missing parents: List()
[14:36:08,259] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61), which has no missing parents
[14:36:08,263] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[14:36:08,265] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[14:36:08,266] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:37921 (size: 10.9 KB, free: 1128.8 MB)
[14:36:08,266] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[14:36:08,266] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61)
[14:36:08,267] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[14:36:08,269] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:36:08,269] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[14:36:08,280] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:36:08,294] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[14:36:08,295] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 28 ms on localhost (1/1)
[14:36:08,295] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[14:36:08,296] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.029 s
[14:36:08,296] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.039307 s
[14:36:08,315] INFO  {CodeGenerator} Code generated in 16.604526 ms
[14:36:08,367] INFO  {FileSourceStrategy} Pruning directories with: 
[14:36:08,367] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:36:08,368] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:36:08,368] INFO  {FileSourceStrategy} Pushed Filters: 
[14:36:08,373] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.1 MB)
[14:36:08,382] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.1 MB)
[14:36:08,382] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:37921 (size: 14.6 KB, free: 1128.8 MB)
[14:36:08,383] INFO  {SparkContext} Created broadcast 8 from show at Main.scala:72
[14:36:08,383] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:36:08,468] INFO  {CodeGenerator} Code generated in 57.60154 ms
[14:36:08,477] INFO  {SparkContext} Starting job: show at Main.scala:72
[14:36:08,478] INFO  {DAGScheduler} Got job 4 (show at Main.scala:72) with 1 output partitions
[14:36:08,478] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:72)
[14:36:08,478] INFO  {DAGScheduler} Parents of final stage: List()
[14:36:08,479] INFO  {DAGScheduler} Missing parents: List()
[14:36:08,479] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:72), which has no missing parents
[14:36:08,482] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 48.6 KB, free 1128.0 MB)
[14:36:08,484] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1128.0 MB)
[14:36:08,485] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:37921 (size: 13.0 KB, free: 1128.8 MB)
[14:36:08,487] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[14:36:08,488] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:72)
[14:36:08,488] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[14:36:08,490] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:36:08,490] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[14:36:08,498] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:36:08,507] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 3496 bytes result sent to driver
[14:36:08,508] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 19 ms on localhost (1/1)
[14:36:08,508] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[14:36:08,508] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:72) finished in 0.020 s
[14:36:08,509] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:72, took 0.031524 s
[14:36:08,530] INFO  {CodeGenerator} Code generated in 19.444915 ms
[14:36:08,537] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:36:08,543] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:36:08,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[14:36:08,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[14:36:08,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[14:36:08,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[14:36:08,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[14:36:08,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[14:36:08,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[14:36:08,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[14:36:08,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[14:36:08,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[14:36:08,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[14:36:08,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[14:36:08,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[14:36:08,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[14:36:08,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[14:36:08,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[14:36:08,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[14:36:08,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[14:36:08,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[14:36:08,549] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[14:36:08,549] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[14:36:08,549] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[14:36:08,549] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[14:36:08,549] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[14:36:08,551] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[14:36:08,564] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:36:08,570] INFO  {MemoryStore} MemoryStore cleared
[14:36:08,571] INFO  {BlockManager} BlockManager stopped
[14:36:08,579] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:36:08,685] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:36:08,688] INFO  {SparkContext} Successfully stopped SparkContext
[14:36:08,688] INFO  {ShutdownHookManager} Shutdown hook called
[14:36:08,689] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-faaa713d-c4de-47a2-ac52-8be3e5c68a14
[14:43:19,499] INFO  {SparkContext} Running Spark version 2.0.1
[14:43:19,712] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:43:19,813] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[14:43:19,814] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:43:19,885] INFO  {SecurityManager} Changing view acls to: victor
[14:43:19,886] INFO  {SecurityManager} Changing modify acls to: victor
[14:43:19,887] INFO  {SecurityManager} Changing view acls groups to: 
[14:43:19,888] INFO  {SecurityManager} Changing modify acls groups to: 
[14:43:19,889] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:43:20,282] INFO  {Utils} Successfully started service 'sparkDriver' on port 46057.
[14:43:20,301] INFO  {SparkEnv} Registering MapOutputTracker
[14:43:20,318] INFO  {SparkEnv} Registering BlockManagerMaster
[14:43:20,331] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-79d39ced-4e3b-4c39-a25b-fa414a734351
[14:43:20,346] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:43:20,404] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:43:20,479] INFO  {log} Logging initialized @1595ms
[14:43:20,592] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:43:20,613] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[14:43:20,614] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[14:43:20,614] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[14:43:20,615] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[14:43:20,615] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[14:43:20,615] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[14:43:20,615] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[14:43:20,616] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[14:43:20,616] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[14:43:20,616] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[14:43:20,616] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[14:43:20,617] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[14:43:20,617] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[14:43:20,617] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[14:43:20,617] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[14:43:20,618] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[14:43:20,618] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[14:43:20,618] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[14:43:20,618] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[14:43:20,618] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[14:43:20,624] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[14:43:20,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[14:43:20,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[14:43:20,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[14:43:20,632] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:43:20,632] INFO  {Server} Started @1749ms
[14:43:20,632] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:43:20,634] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[14:43:20,707] INFO  {Executor} Starting executor ID driver on host localhost
[14:43:20,728] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44639.
[14:43:20,729] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:44639
[14:43:20,730] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 44639)
[14:43:20,734] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:44639 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 44639)
[14:43:20,737] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 44639)
[14:43:20,865] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[14:43:20,925] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[14:43:20,925] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[14:43:20,926] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[14:43:20,927] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[14:43:20,928] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[14:43:20,945] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[14:43:22,903] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:22,904] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:22,908] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:22,909] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:23,017] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[14:43:23,063] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:43:23,064] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:44639 (size: 14.6 KB, free: 1128.9 MB)
[14:43:23,070] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[14:43:23,074] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:23,552] INFO  {CodeGenerator} Code generated in 207.169774 ms
[14:43:23,639] INFO  {SparkContext} Starting job: show at Main.scala:34
[14:43:23,654] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[14:43:23,655] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[14:43:23,655] INFO  {DAGScheduler} Parents of final stage: List()
[14:43:23,656] INFO  {DAGScheduler} Missing parents: List()
[14:43:23,660] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[14:43:23,701] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[14:43:23,703] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[14:43:23,703] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:44639 (size: 6.6 KB, free: 1128.9 MB)
[14:43:23,704] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:43:23,707] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[14:43:23,708] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:43:23,752] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:43:23,759] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:43:23,801] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:23,819] INFO  {CodeGenerator} Code generated in 14.48394 ms
[14:43:23,851] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[14:43:23,858] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 130 ms on localhost (1/1)
[14:43:23,859] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:43:23,864] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.147 s
[14:43:23,870] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.231353 s
[14:43:23,910] INFO  {CodeGenerator} Code generated in 25.838208 ms
[14:43:23,966] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:23,966] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:23,967] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:23,967] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:23,974] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:43:23,999] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:43:24,000] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:44639 (size: 14.6 KB, free: 1128.9 MB)
[14:43:24,002] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:45
[14:43:24,003] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:24,020] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:44639 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:43:24,030] INFO  {ContextCleaner} Cleaned accumulator 0
[14:43:24,030] INFO  {ContextCleaner} Cleaned accumulator 1
[14:43:24,032] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:44639 in memory (size: 6.6 KB, free: 1128.9 MB)
[14:43:24,076] INFO  {CodeGenerator} Code generated in 40.32097 ms
[14:43:24,089] INFO  {SparkContext} Starting job: show at Main.scala:45
[14:43:24,090] INFO  {DAGScheduler} Got job 1 (show at Main.scala:45) with 1 output partitions
[14:43:24,090] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:45)
[14:43:24,090] INFO  {DAGScheduler} Parents of final stage: List()
[14:43:24,090] INFO  {DAGScheduler} Missing parents: List()
[14:43:24,092] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:45), which has no missing parents
[14:43:24,097] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.7 MB)
[14:43:24,100] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[14:43:24,101] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:44639 (size: 8.2 KB, free: 1128.9 MB)
[14:43:24,102] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[14:43:24,103] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:45)
[14:43:24,103] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[14:43:24,108] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:43:24,108] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[14:43:24,118] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:24,136] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[14:43:24,138] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on localhost (1/1)
[14:43:24,138] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[14:43:24,138] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:45) finished in 0.034 s
[14:43:24,139] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:45, took 0.049591 s
[14:43:24,164] INFO  {CodeGenerator} Code generated in 17.396067 ms
[14:43:24,261] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:24,262] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:24,262] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:24,263] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:24,270] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:43:24,279] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:43:24,280] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:44639 (size: 14.6 KB, free: 1128.9 MB)
[14:43:24,281] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:53
[14:43:24,282] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:24,359] INFO  {CodeGenerator} Code generated in 57.622667 ms
[14:43:24,371] INFO  {SparkContext} Starting job: show at Main.scala:53
[14:43:24,373] INFO  {DAGScheduler} Got job 2 (show at Main.scala:53) with 1 output partitions
[14:43:24,373] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:53)
[14:43:24,373] INFO  {DAGScheduler} Parents of final stage: List()
[14:43:24,373] INFO  {DAGScheduler} Missing parents: List()
[14:43:24,373] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53), which has no missing parents
[14:43:24,377] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.6 MB)
[14:43:24,379] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.5 MB)
[14:43:24,380] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:44639 (size: 9.6 KB, free: 1128.9 MB)
[14:43:24,381] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[14:43:24,381] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53)
[14:43:24,381] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[14:43:24,384] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:43:24,384] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[14:43:24,393] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:24,404] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[14:43:24,405] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 23 ms on localhost (1/1)
[14:43:24,406] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[14:43:24,406] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:53) finished in 0.024 s
[14:43:24,406] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:53, took 0.034419 s
[14:43:24,430] INFO  {CodeGenerator} Code generated in 20.630385 ms
[14:43:24,472] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:24,472] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:24,472] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:24,473] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:24,477] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[14:43:24,485] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[14:43:24,486] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:44639 (size: 14.6 KB, free: 1128.8 MB)
[14:43:24,487] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:63
[14:43:24,487] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:24,548] INFO  {CodeGenerator} Code generated in 44.306781 ms
[14:43:24,559] INFO  {SparkContext} Starting job: show at Main.scala:63
[14:43:24,560] INFO  {DAGScheduler} Got job 3 (show at Main.scala:63) with 1 output partitions
[14:43:24,560] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:63)
[14:43:24,560] INFO  {DAGScheduler} Parents of final stage: List()
[14:43:24,560] INFO  {DAGScheduler} Missing parents: List()
[14:43:24,561] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63), which has no missing parents
[14:43:24,563] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.4 MB)
[14:43:24,564] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.4 MB)
[14:43:24,565] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:44639 (size: 10.9 KB, free: 1128.8 MB)
[14:43:24,565] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[14:43:24,566] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63)
[14:43:24,566] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[14:43:24,567] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:43:24,568] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[14:43:24,577] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:24,584] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[14:43:24,586] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on localhost (1/1)
[14:43:24,586] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[14:43:24,586] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:63) finished in 0.020 s
[14:43:24,586] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:63, took 0.027088 s
[14:43:24,606] INFO  {CodeGenerator} Code generated in 16.792634 ms
[14:43:24,773] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:44639 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:43:24,774] INFO  {ContextCleaner} Cleaned accumulator 46
[14:43:24,774] INFO  {ContextCleaner} Cleaned accumulator 47
[14:43:24,775] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:44639 in memory (size: 8.2 KB, free: 1128.9 MB)
[14:43:24,776] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:44639 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:43:24,776] INFO  {ContextCleaner} Cleaned accumulator 92
[14:43:24,776] INFO  {ContextCleaner} Cleaned accumulator 93
[14:43:24,777] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:44639 in memory (size: 9.6 KB, free: 1128.9 MB)
[14:43:24,778] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:44639 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:43:24,778] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:24,778] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:24,778] INFO  {ContextCleaner} Cleaned accumulator 138
[14:43:24,779] INFO  {ContextCleaner} Cleaned accumulator 139
[14:43:24,779] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:24,779] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:24,779] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:44639 in memory (size: 10.9 KB, free: 1128.9 MB)
[14:43:24,784] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[14:43:24,793] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:43:24,794] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:44639 (size: 14.6 KB, free: 1128.9 MB)
[14:43:24,795] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:65
[14:43:24,795] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:24,841] INFO  {CodeGenerator} Code generated in 14.111076 ms
[14:43:24,874] INFO  {CodeGenerator} Code generated in 24.639772 ms
[14:43:24,908] INFO  {SparkContext} Starting job: collect at Main.scala:65
[14:43:24,911] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:65)
[14:43:24,912] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:65) with 1 output partitions
[14:43:24,912] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:65)
[14:43:24,913] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[14:43:24,913] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[14:43:24,914] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:65), which has no missing parents
[14:43:24,921] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[14:43:24,924] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[14:43:24,924] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:44639 (size: 8.3 KB, free: 1128.9 MB)
[14:43:24,925] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[14:43:24,927] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:65)
[14:43:24,927] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[14:43:24,930] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[14:43:24,930] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[14:43:24,953] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:25,247] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[14:43:25,250] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 323 ms on localhost (1/1)
[14:43:25,250] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[14:43:25,251] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:65) finished in 0.324 s
[14:43:25,252] INFO  {DAGScheduler} looking for newly runnable stages
[14:43:25,253] INFO  {DAGScheduler} running: Set()
[14:43:25,253] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[14:43:25,253] INFO  {DAGScheduler} failed: Set()
[14:43:25,254] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:65), which has no missing parents
[14:43:25,259] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[14:43:25,261] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[14:43:25,261] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:44639 (size: 3.9 KB, free: 1128.9 MB)
[14:43:25,262] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[14:43:25,262] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:65)
[14:43:25,262] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[14:43:25,267] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[14:43:25,268] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[14:43:25,281] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[14:43:25,282] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[14:43:25,294] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[14:43:25,295] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 30 ms on localhost (1/1)
[14:43:25,295] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[14:43:25,296] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:65) finished in 0.031 s
[14:43:25,296] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:65, took 0.388613 s
[14:43:25,310] INFO  {CodeGenerator} Code generated in 9.287789 ms
[14:43:25,369] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:25,369] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:25,370] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:25,370] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:25,373] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:43:25,383] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:43:25,383] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:44639 (size: 14.6 KB, free: 1128.9 MB)
[14:43:25,384] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:79
[14:43:25,384] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:25,478] INFO  {CodeGenerator} Code generated in 67.555517 ms
[14:43:25,490] INFO  {SparkContext} Starting job: show at Main.scala:79
[14:43:25,491] INFO  {DAGScheduler} Got job 5 (show at Main.scala:79) with 1 output partitions
[14:43:25,491] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:79)
[14:43:25,491] INFO  {DAGScheduler} Parents of final stage: List()
[14:43:25,491] INFO  {DAGScheduler} Missing parents: List()
[14:43:25,492] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:79), which has no missing parents
[14:43:25,494] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 48.6 KB, free 1128.5 MB)
[14:43:25,495] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1128.5 MB)
[14:43:25,496] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:44639 (size: 13.0 KB, free: 1128.8 MB)
[14:43:25,497] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[14:43:25,497] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:79)
[14:43:25,497] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[14:43:25,499] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:43:25,499] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[14:43:25,508] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:25,514] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3496 bytes result sent to driver
[14:43:25,516] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 18 ms on localhost (1/1)
[14:43:25,516] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[14:43:25,516] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:79) finished in 0.019 s
[14:43:25,517] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:79, took 0.026243 s
[14:43:25,541] INFO  {CodeGenerator} Code generated in 19.967044 ms
[14:43:25,547] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:43:25,551] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:43:25,554] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[14:43:25,554] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[14:43:25,554] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[14:43:25,555] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[14:43:25,555] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[14:43:25,555] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[14:43:25,555] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[14:43:25,555] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[14:43:25,555] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[14:43:25,556] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[14:43:25,556] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[14:43:25,556] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[14:43:25,556] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[14:43:25,556] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[14:43:25,556] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[14:43:25,556] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[14:43:25,556] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[14:43:25,557] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[14:43:25,557] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[14:43:25,557] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[14:43:25,557] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[14:43:25,557] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[14:43:25,557] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[14:43:25,557] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[14:43:25,559] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[14:43:25,572] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:43:25,577] INFO  {MemoryStore} MemoryStore cleared
[14:43:25,577] INFO  {BlockManager} BlockManager stopped
[14:43:25,579] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:43:25,581] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:43:25,583] INFO  {SparkContext} Successfully stopped SparkContext
[14:43:25,583] INFO  {ShutdownHookManager} Shutdown hook called
[14:43:25,584] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f0525f46-478a-4a43-bb8f-45321c5d8708
[14:43:46,686] INFO  {SparkContext} Running Spark version 2.0.1
[14:43:46,907] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:43:47,001] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[14:43:47,002] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:43:47,072] INFO  {SecurityManager} Changing view acls to: victor
[14:43:47,073] INFO  {SecurityManager} Changing modify acls to: victor
[14:43:47,076] INFO  {SecurityManager} Changing view acls groups to: 
[14:43:47,078] INFO  {SecurityManager} Changing modify acls groups to: 
[14:43:47,079] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:43:47,467] INFO  {Utils} Successfully started service 'sparkDriver' on port 37803.
[14:43:47,486] INFO  {SparkEnv} Registering MapOutputTracker
[14:43:47,501] INFO  {SparkEnv} Registering BlockManagerMaster
[14:43:47,514] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-c1647ce6-3fee-4b76-828d-91c51cf3f756
[14:43:47,530] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:43:47,587] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:43:47,660] INFO  {log} Logging initialized @1536ms
[14:43:47,775] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:43:47,792] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[14:43:47,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[14:43:47,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[14:43:47,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[14:43:47,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[14:43:47,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[14:43:47,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[14:43:47,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[14:43:47,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[14:43:47,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[14:43:47,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[14:43:47,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[14:43:47,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[14:43:47,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[14:43:47,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[14:43:47,796] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[14:43:47,796] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[14:43:47,796] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[14:43:47,796] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[14:43:47,796] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[14:43:47,802] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[14:43:47,803] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[14:43:47,803] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[14:43:47,804] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[14:43:47,810] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:43:47,810] INFO  {Server} Started @1687ms
[14:43:47,810] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:43:47,812] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[14:43:47,891] INFO  {Executor} Starting executor ID driver on host localhost
[14:43:47,913] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39687.
[14:43:47,914] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:39687
[14:43:47,915] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 39687)
[14:43:47,918] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:39687 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 39687)
[14:43:47,921] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 39687)
[14:43:48,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[14:43:48,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[14:43:48,109] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[14:43:48,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[14:43:48,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[14:43:48,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[14:43:48,128] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[14:43:50,144] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:50,146] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:50,151] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:50,151] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:50,258] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[14:43:50,303] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:43:50,305] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:39687 (size: 14.6 KB, free: 1128.9 MB)
[14:43:50,312] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[14:43:50,316] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:50,820] INFO  {CodeGenerator} Code generated in 216.026265 ms
[14:43:50,907] INFO  {SparkContext} Starting job: show at Main.scala:34
[14:43:50,922] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[14:43:50,922] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[14:43:50,923] INFO  {DAGScheduler} Parents of final stage: List()
[14:43:50,924] INFO  {DAGScheduler} Missing parents: List()
[14:43:50,927] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[14:43:50,973] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[14:43:50,978] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KB, free 1128.7 MB)
[14:43:50,978] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:39687 (size: 6.7 KB, free: 1128.9 MB)
[14:43:50,979] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:43:50,982] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[14:43:50,984] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:43:51,030] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:43:51,037] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:43:51,077] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:51,091] INFO  {CodeGenerator} Code generated in 11.465248 ms
[14:43:51,122] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[14:43:51,128] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 124 ms on localhost (1/1)
[14:43:51,129] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:43:51,132] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.140 s
[14:43:51,149] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.241304 s
[14:43:51,169] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:39687 in memory (size: 6.7 KB, free: 1128.9 MB)
[14:43:51,186] INFO  {CodeGenerator} Code generated in 18.64522 ms
[14:43:51,238] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:51,238] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:51,239] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:51,239] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:51,246] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:43:51,257] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:43:51,257] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:39687 (size: 14.6 KB, free: 1128.9 MB)
[14:43:51,259] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:45
[14:43:51,259] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:51,314] INFO  {CodeGenerator} Code generated in 38.323847 ms
[14:43:51,326] INFO  {SparkContext} Starting job: show at Main.scala:45
[14:43:51,327] INFO  {DAGScheduler} Got job 1 (show at Main.scala:45) with 1 output partitions
[14:43:51,327] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:45)
[14:43:51,327] INFO  {DAGScheduler} Parents of final stage: List()
[14:43:51,328] INFO  {DAGScheduler} Missing parents: List()
[14:43:51,328] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:45), which has no missing parents
[14:43:51,333] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[14:43:51,335] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[14:43:51,336] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:39687 (size: 8.2 KB, free: 1128.9 MB)
[14:43:51,337] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[14:43:51,337] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:45)
[14:43:51,337] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[14:43:51,340] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:43:51,341] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[14:43:51,353] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:51,374] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[14:43:51,376] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 38 ms on localhost (1/1)
[14:43:51,376] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[14:43:51,377] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:45) finished in 0.038 s
[14:43:51,377] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:45, took 0.050871 s
[14:43:51,411] INFO  {CodeGenerator} Code generated in 25.123901 ms
[14:43:51,497] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:51,497] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:51,498] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:51,498] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:51,503] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[14:43:51,511] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[14:43:51,512] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:39687 (size: 14.6 KB, free: 1128.8 MB)
[14:43:51,513] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:53
[14:43:51,513] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:51,569] INFO  {CodeGenerator} Code generated in 41.440303 ms
[14:43:51,579] INFO  {SparkContext} Starting job: show at Main.scala:53
[14:43:51,580] INFO  {DAGScheduler} Got job 2 (show at Main.scala:53) with 1 output partitions
[14:43:51,580] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:53)
[14:43:51,580] INFO  {DAGScheduler} Parents of final stage: List()
[14:43:51,580] INFO  {DAGScheduler} Missing parents: List()
[14:43:51,581] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53), which has no missing parents
[14:43:51,585] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[14:43:51,586] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[14:43:51,588] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:39687 (size: 9.6 KB, free: 1128.8 MB)
[14:43:51,589] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[14:43:51,589] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53)
[14:43:51,589] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[14:43:51,591] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:43:51,591] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[14:43:51,600] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:51,609] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[14:43:51,610] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 20 ms on localhost (1/1)
[14:43:51,610] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[14:43:51,611] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:53) finished in 0.021 s
[14:43:51,611] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:53, took 0.031968 s
[14:43:51,635] INFO  {CodeGenerator} Code generated in 19.709165 ms
[14:43:51,680] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:51,680] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:51,681] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:51,681] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:51,685] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[14:43:51,695] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.3 MB)
[14:43:51,696] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:39687 (size: 14.6 KB, free: 1128.8 MB)
[14:43:51,696] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:63
[14:43:51,697] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:51,763] INFO  {CodeGenerator} Code generated in 47.467369 ms
[14:43:51,774] INFO  {SparkContext} Starting job: show at Main.scala:63
[14:43:51,775] INFO  {DAGScheduler} Got job 3 (show at Main.scala:63) with 1 output partitions
[14:43:51,775] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:63)
[14:43:51,775] INFO  {DAGScheduler} Parents of final stage: List()
[14:43:51,775] INFO  {DAGScheduler} Missing parents: List()
[14:43:51,776] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63), which has no missing parents
[14:43:51,779] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[14:43:51,782] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[14:43:51,782] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:39687 (size: 10.9 KB, free: 1128.8 MB)
[14:43:51,783] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[14:43:51,784] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63)
[14:43:51,784] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[14:43:51,785] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:43:51,786] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[14:43:51,794] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:51,803] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[14:43:51,805] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 21 ms on localhost (1/1)
[14:43:51,805] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[14:43:51,805] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:63) finished in 0.021 s
[14:43:51,806] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:63, took 0.031504 s
[14:43:51,824] INFO  {CodeGenerator} Code generated in 15.2139 ms
[14:43:51,993] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:39687 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:43:51,994] INFO  {ContextCleaner} Cleaned accumulator 0
[14:43:51,995] INFO  {ContextCleaner} Cleaned accumulator 1
[14:43:51,996] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:39687 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:43:51,996] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:51,996] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:51,996] INFO  {ContextCleaner} Cleaned accumulator 46
[14:43:51,996] INFO  {ContextCleaner} Cleaned accumulator 47
[14:43:51,996] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:51,997] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:51,997] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:39687 in memory (size: 8.2 KB, free: 1128.9 MB)
[14:43:51,999] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:39687 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:43:51,999] INFO  {ContextCleaner} Cleaned accumulator 92
[14:43:51,999] INFO  {ContextCleaner} Cleaned accumulator 93
[14:43:52,001] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:39687 in memory (size: 9.6 KB, free: 1128.9 MB)
[14:43:52,002] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:39687 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:43:52,002] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.7 MB)
[14:43:52,002] INFO  {ContextCleaner} Cleaned accumulator 138
[14:43:52,003] INFO  {ContextCleaner} Cleaned accumulator 139
[14:43:52,004] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:39687 in memory (size: 10.9 KB, free: 1128.9 MB)
[14:43:52,013] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:43:52,013] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:39687 (size: 14.6 KB, free: 1128.9 MB)
[14:43:52,014] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:65
[14:43:52,014] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:52,073] INFO  {CodeGenerator} Code generated in 20.440292 ms
[14:43:52,111] INFO  {CodeGenerator} Code generated in 30.24386 ms
[14:43:52,161] INFO  {SparkContext} Starting job: collect at Main.scala:65
[14:43:52,164] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:65)
[14:43:52,165] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:65) with 1 output partitions
[14:43:52,165] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:65)
[14:43:52,165] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[14:43:52,166] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[14:43:52,167] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:65), which has no missing parents
[14:43:52,172] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[14:43:52,175] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[14:43:52,175] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:39687 (size: 8.3 KB, free: 1128.9 MB)
[14:43:52,176] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[14:43:52,178] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:65)
[14:43:52,178] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[14:43:52,181] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[14:43:52,181] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[14:43:52,197] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:52,536] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[14:43:52,538] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 360 ms on localhost (1/1)
[14:43:52,538] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[14:43:52,539] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:65) finished in 0.360 s
[14:43:52,539] INFO  {DAGScheduler} looking for newly runnable stages
[14:43:52,539] INFO  {DAGScheduler} running: Set()
[14:43:52,540] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[14:43:52,541] INFO  {DAGScheduler} failed: Set()
[14:43:52,542] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:65), which has no missing parents
[14:43:52,546] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[14:43:52,547] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[14:43:52,548] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:39687 (size: 3.9 KB, free: 1128.9 MB)
[14:43:52,548] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[14:43:52,549] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:65)
[14:43:52,549] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[14:43:52,553] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[14:43:52,553] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[14:43:52,564] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[14:43:52,565] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[14:43:52,583] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1955 bytes result sent to driver
[14:43:52,584] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 33 ms on localhost (1/1)
[14:43:52,584] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[14:43:52,585] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:65) finished in 0.033 s
[14:43:52,585] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:65, took 0.423808 s
[14:43:52,600] INFO  {CodeGenerator} Code generated in 11.260068 ms
[14:43:52,662] INFO  {FileSourceStrategy} Pruning directories with: 
[14:43:52,662] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:43:52,663] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:43:52,663] INFO  {FileSourceStrategy} Pushed Filters: 
[14:43:52,667] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:43:52,678] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:43:52,679] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:39687 (size: 14.6 KB, free: 1128.9 MB)
[14:43:52,680] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:78
[14:43:52,680] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:43:52,748] INFO  {CodeGenerator} Code generated in 49.852237 ms
[14:43:52,757] INFO  {SparkContext} Starting job: show at Main.scala:78
[14:43:52,758] INFO  {DAGScheduler} Got job 5 (show at Main.scala:78) with 1 output partitions
[14:43:52,758] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:78)
[14:43:52,758] INFO  {DAGScheduler} Parents of final stage: List()
[14:43:52,758] INFO  {DAGScheduler} Missing parents: List()
[14:43:52,759] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:78), which has no missing parents
[14:43:52,761] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 48.6 KB, free 1128.5 MB)
[14:43:52,763] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1128.5 MB)
[14:43:52,764] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:39687 (size: 13.0 KB, free: 1128.8 MB)
[14:43:52,764] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[14:43:52,764] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:78)
[14:43:52,765] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[14:43:52,766] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:43:52,766] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[14:43:52,775] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:43:52,782] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3496 bytes result sent to driver
[14:43:52,783] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 18 ms on localhost (1/1)
[14:43:52,783] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[14:43:52,783] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:78) finished in 0.018 s
[14:43:52,784] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:78, took 0.026582 s
[14:43:52,800] INFO  {CodeGenerator} Code generated in 13.629285 ms
[14:43:52,805] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:43:52,810] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:43:52,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[14:43:52,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[14:43:52,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[14:43:52,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[14:43:52,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[14:43:52,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[14:43:52,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[14:43:52,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[14:43:52,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[14:43:52,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[14:43:52,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[14:43:52,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[14:43:52,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[14:43:52,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[14:43:52,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[14:43:52,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[14:43:52,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[14:43:52,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[14:43:52,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[14:43:52,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[14:43:52,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[14:43:52,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[14:43:52,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[14:43:52,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[14:43:52,818] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[14:43:52,832] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:43:52,840] INFO  {MemoryStore} MemoryStore cleared
[14:43:52,841] INFO  {BlockManager} BlockManager stopped
[14:43:52,843] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:43:52,846] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:43:52,848] INFO  {SparkContext} Successfully stopped SparkContext
[14:43:52,849] INFO  {ShutdownHookManager} Shutdown hook called
[14:43:52,849] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f62ee075-a65d-4500-9b32-6f88d119fada
[14:46:23,948] INFO  {SparkContext} Running Spark version 2.0.1
[14:46:24,168] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:46:24,262] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[14:46:24,263] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:46:24,348] INFO  {SecurityManager} Changing view acls to: victor
[14:46:24,349] INFO  {SecurityManager} Changing modify acls to: victor
[14:46:24,350] INFO  {SecurityManager} Changing view acls groups to: 
[14:46:24,351] INFO  {SecurityManager} Changing modify acls groups to: 
[14:46:24,352] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:46:24,768] INFO  {Utils} Successfully started service 'sparkDriver' on port 40801.
[14:46:24,785] INFO  {SparkEnv} Registering MapOutputTracker
[14:46:24,801] INFO  {SparkEnv} Registering BlockManagerMaster
[14:46:24,813] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-16ba495c-60f6-4efc-814b-7ec5a9984827
[14:46:24,828] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:46:24,900] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:46:24,975] INFO  {log} Logging initialized @1661ms
[14:46:25,088] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:46:25,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[14:46:25,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[14:46:25,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[14:46:25,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[14:46:25,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[14:46:25,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[14:46:25,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[14:46:25,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[14:46:25,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[14:46:25,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[14:46:25,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[14:46:25,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[14:46:25,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[14:46:25,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[14:46:25,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[14:46:25,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[14:46:25,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[14:46:25,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[14:46:25,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[14:46:25,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[14:46:25,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[14:46:25,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[14:46:25,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[14:46:25,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[14:46:25,121] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:46:25,121] INFO  {Server} Started @1808ms
[14:46:25,121] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:46:25,123] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[14:46:25,220] INFO  {Executor} Starting executor ID driver on host localhost
[14:46:25,243] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36197.
[14:46:25,244] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:36197
[14:46:25,247] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 36197)
[14:46:25,251] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:36197 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 36197)
[14:46:25,253] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 36197)
[14:46:25,383] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[14:46:25,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[14:46:25,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[14:46:25,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[14:46:25,442] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[14:46:25,443] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[14:46:25,457] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[14:46:27,496] INFO  {FileSourceStrategy} Pruning directories with: 
[14:46:27,498] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:46:27,503] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:46:27,504] INFO  {FileSourceStrategy} Pushed Filters: 
[14:46:27,618] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[14:46:27,666] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:46:27,668] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:36197 (size: 14.6 KB, free: 1128.9 MB)
[14:46:27,674] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[14:46:27,679] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:46:28,226] INFO  {CodeGenerator} Code generated in 241.797434 ms
[14:46:28,325] INFO  {SparkContext} Starting job: show at Main.scala:34
[14:46:28,342] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[14:46:28,342] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[14:46:28,343] INFO  {DAGScheduler} Parents of final stage: List()
[14:46:28,344] INFO  {DAGScheduler} Missing parents: List()
[14:46:28,348] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[14:46:28,394] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[14:46:28,397] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[14:46:28,397] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:36197 (size: 6.6 KB, free: 1128.9 MB)
[14:46:28,398] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:46:28,402] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[14:46:28,404] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:46:28,443] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:46:28,450] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:46:28,486] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:46:28,504] INFO  {CodeGenerator} Code generated in 13.77057 ms
[14:46:28,553] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2794 bytes result sent to driver
[14:46:28,560] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 138 ms on localhost (1/1)
[14:46:28,561] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:46:28,564] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.152 s
[14:46:28,569] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.243309 s
[14:46:28,609] INFO  {CodeGenerator} Code generated in 21.125801 ms
[14:46:28,664] INFO  {FileSourceStrategy} Pruning directories with: 
[14:46:28,664] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:46:28,665] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:46:28,665] INFO  {FileSourceStrategy} Pushed Filters: 
[14:46:28,671] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:46:28,682] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:46:28,683] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:36197 (size: 14.6 KB, free: 1128.9 MB)
[14:46:28,684] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:45
[14:46:28,684] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:46:28,736] INFO  {CodeGenerator} Code generated in 34.491353 ms
[14:46:28,748] INFO  {SparkContext} Starting job: show at Main.scala:45
[14:46:28,749] INFO  {DAGScheduler} Got job 1 (show at Main.scala:45) with 1 output partitions
[14:46:28,749] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:45)
[14:46:28,749] INFO  {DAGScheduler} Parents of final stage: List()
[14:46:28,750] INFO  {DAGScheduler} Missing parents: List()
[14:46:28,750] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:45), which has no missing parents
[14:46:28,755] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[14:46:28,758] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1128.6 MB)
[14:46:28,759] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:36197 (size: 8.1 KB, free: 1128.9 MB)
[14:46:28,760] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[14:46:28,760] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:45)
[14:46:28,760] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[14:46:28,763] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:46:28,763] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[14:46:28,776] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:46:28,792] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[14:46:28,795] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (1/1)
[14:46:28,795] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[14:46:28,795] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:45) finished in 0.034 s
[14:46:28,796] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:45, took 0.047082 s
[14:46:28,820] INFO  {CodeGenerator} Code generated in 17.202727 ms
[14:46:28,919] INFO  {FileSourceStrategy} Pruning directories with: 
[14:46:28,919] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:46:28,920] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:46:28,920] INFO  {FileSourceStrategy} Pushed Filters: 
[14:46:28,926] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[14:46:28,934] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[14:46:28,935] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:36197 (size: 14.6 KB, free: 1128.8 MB)
[14:46:28,936] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:53
[14:46:28,936] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:46:29,003] INFO  {CodeGenerator} Code generated in 48.718001 ms
[14:46:29,017] INFO  {SparkContext} Starting job: show at Main.scala:53
[14:46:29,018] INFO  {DAGScheduler} Got job 2 (show at Main.scala:53) with 1 output partitions
[14:46:29,018] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:53)
[14:46:29,019] INFO  {DAGScheduler} Parents of final stage: List()
[14:46:29,019] INFO  {DAGScheduler} Missing parents: List()
[14:46:29,019] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53), which has no missing parents
[14:46:29,023] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[14:46:29,027] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[14:46:29,027] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:36197 (size: 9.6 KB, free: 1128.8 MB)
[14:46:29,028] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[14:46:29,028] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53)
[14:46:29,028] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[14:46:29,031] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:46:29,031] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[14:46:29,048] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:46:29,056] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[14:46:29,059] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (1/1)
[14:46:29,059] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[14:46:29,060] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:53) finished in 0.030 s
[14:46:29,060] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:53, took 0.042420 s
[14:46:29,086] INFO  {CodeGenerator} Code generated in 22.995501 ms
[14:46:29,147] INFO  {FileSourceStrategy} Pruning directories with: 
[14:46:29,147] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:46:29,148] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:46:29,148] INFO  {FileSourceStrategy} Pushed Filters: 
[14:46:29,153] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[14:46:29,161] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.2 MB)
[14:46:29,162] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:36197 (size: 14.6 KB, free: 1128.8 MB)
[14:46:29,162] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:63
[14:46:29,163] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:46:29,244] INFO  {CodeGenerator} Code generated in 56.27836 ms
[14:46:29,253] INFO  {SparkContext} Starting job: show at Main.scala:63
[14:46:29,254] INFO  {DAGScheduler} Got job 3 (show at Main.scala:63) with 1 output partitions
[14:46:29,254] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:63)
[14:46:29,254] INFO  {DAGScheduler} Parents of final stage: List()
[14:46:29,254] INFO  {DAGScheduler} Missing parents: List()
[14:46:29,255] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63), which has no missing parents
[14:46:29,257] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[14:46:29,260] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[14:46:29,260] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:36197 (size: 10.9 KB, free: 1128.8 MB)
[14:46:29,261] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[14:46:29,261] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63)
[14:46:29,261] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[14:46:29,263] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:46:29,263] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[14:46:29,278] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:46:29,286] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[14:46:29,287] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on localhost (1/1)
[14:46:29,287] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[14:46:29,288] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:63) finished in 0.027 s
[14:46:29,288] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:63, took 0.034510 s
[14:46:29,308] INFO  {CodeGenerator} Code generated in 16.138752 ms
[14:46:29,373] INFO  {FileSourceStrategy} Pruning directories with: 
[14:46:29,373] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:46:29,374] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:46:29,374] INFO  {FileSourceStrategy} Pushed Filters: 
[14:46:29,378] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.1 MB)
[14:46:29,387] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.1 MB)
[14:46:29,387] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:36197 (size: 14.6 KB, free: 1128.8 MB)
[14:46:29,388] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:67
[14:46:29,388] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:46:29,529] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:36197 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:46:29,532] INFO  {ContextCleaner} Cleaned accumulator 0
[14:46:29,532] INFO  {ContextCleaner} Cleaned accumulator 1
[14:46:29,533] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:36197 in memory (size: 6.6 KB, free: 1128.8 MB)
[14:46:29,535] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:36197 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:46:29,535] INFO  {ContextCleaner} Cleaned accumulator 46
[14:46:29,535] INFO  {CodeGenerator} Code generated in 15.877706 ms
[14:46:29,535] INFO  {ContextCleaner} Cleaned accumulator 47
[14:46:29,536] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:36197 in memory (size: 8.1 KB, free: 1128.8 MB)
[14:46:29,538] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:36197 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:46:29,538] INFO  {ContextCleaner} Cleaned accumulator 92
[14:46:29,538] INFO  {ContextCleaner} Cleaned accumulator 93
[14:46:29,539] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:36197 in memory (size: 9.6 KB, free: 1128.9 MB)
[14:46:29,541] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:36197 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:46:29,541] INFO  {ContextCleaner} Cleaned accumulator 138
[14:46:29,542] INFO  {ContextCleaner} Cleaned accumulator 139
[14:46:29,547] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:36197 in memory (size: 10.9 KB, free: 1128.9 MB)
[14:46:29,548] INFO  {ContextCleaner} Cleaned accumulator 184
[14:46:29,568] INFO  {CodeGenerator} Code generated in 26.554763 ms
[14:46:29,614] INFO  {SparkContext} Starting job: collect at Main.scala:67
[14:46:29,618] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:67)
[14:46:29,619] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[14:46:29,619] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[14:46:29,620] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[14:46:29,620] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[14:46:29,621] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:67), which has no missing parents
[14:46:29,629] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[14:46:29,631] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[14:46:29,632] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:36197 (size: 8.3 KB, free: 1128.9 MB)
[14:46:29,632] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[14:46:29,634] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:67)
[14:46:29,635] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[14:46:29,637] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[14:46:29,638] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[14:46:29,658] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:46:29,955] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[14:46:29,958] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 323 ms on localhost (1/1)
[14:46:29,958] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[14:46:29,959] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.324 s
[14:46:29,960] INFO  {DAGScheduler} looking for newly runnable stages
[14:46:29,960] INFO  {DAGScheduler} running: Set()
[14:46:29,961] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[14:46:29,961] INFO  {DAGScheduler} failed: Set()
[14:46:29,963] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[14:46:29,969] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[14:46:29,971] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[14:46:29,971] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:36197 (size: 3.9 KB, free: 1128.9 MB)
[14:46:29,972] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[14:46:29,972] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:67)
[14:46:29,973] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[14:46:29,979] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[14:46:29,979] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[14:46:29,997] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[14:46:29,999] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 6 ms
[14:46:30,016] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[14:46:30,017] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 41 ms on localhost (1/1)
[14:46:30,017] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[14:46:30,017] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.041 s
[14:46:30,018] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.403425 s
[14:46:30,029] INFO  {CodeGenerator} Code generated in 8.450209 ms
[14:46:30,090] INFO  {FileSourceStrategy} Pruning directories with: 
[14:46:30,091] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:46:30,092] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:46:30,092] INFO  {FileSourceStrategy} Pushed Filters: 
[14:46:30,098] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:46:30,112] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:46:30,112] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:36197 (size: 14.6 KB, free: 1128.9 MB)
[14:46:30,113] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:77
[14:46:30,114] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:46:30,218] INFO  {CodeGenerator} Code generated in 79.609468 ms
[14:46:30,235] INFO  {SparkContext} Starting job: show at Main.scala:77
[14:46:30,236] INFO  {DAGScheduler} Got job 5 (show at Main.scala:77) with 1 output partitions
[14:46:30,236] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:77)
[14:46:30,236] INFO  {DAGScheduler} Parents of final stage: List()
[14:46:30,236] INFO  {DAGScheduler} Missing parents: List()
[14:46:30,237] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:77), which has no missing parents
[14:46:30,240] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 48.6 KB, free 1128.5 MB)
[14:46:30,242] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1128.5 MB)
[14:46:30,242] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:36197 (size: 13.0 KB, free: 1128.8 MB)
[14:46:30,243] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[14:46:30,243] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:77)
[14:46:30,243] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[14:46:30,245] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:46:30,246] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[14:46:30,254] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:46:30,260] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3583 bytes result sent to driver
[14:46:30,263] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 19 ms on localhost (1/1)
[14:46:30,264] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[14:46:30,264] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:77) finished in 0.020 s
[14:46:30,265] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:77, took 0.029677 s
[14:46:30,287] INFO  {CodeGenerator} Code generated in 18.466823 ms
[14:46:30,293] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:46:30,299] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:46:30,301] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[14:46:30,302] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[14:46:30,302] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[14:46:30,302] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[14:46:30,302] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[14:46:30,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[14:46:30,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[14:46:30,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[14:46:30,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[14:46:30,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[14:46:30,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[14:46:30,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[14:46:30,304] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[14:46:30,304] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[14:46:30,304] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[14:46:30,304] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[14:46:30,304] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[14:46:30,304] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[14:46:30,304] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[14:46:30,305] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[14:46:30,305] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[14:46:30,305] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[14:46:30,305] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[14:46:30,305] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[14:46:30,307] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[14:46:30,321] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:46:30,326] INFO  {MemoryStore} MemoryStore cleared
[14:46:30,327] INFO  {BlockManager} BlockManager stopped
[14:46:30,328] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:46:30,331] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:46:30,332] INFO  {SparkContext} Successfully stopped SparkContext
[14:46:30,333] INFO  {ShutdownHookManager} Shutdown hook called
[14:46:30,334] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-b9f6e0c8-4775-4c37-986f-343ab7009e7d
[14:48:01,545] INFO  {SparkContext} Running Spark version 2.0.1
[14:48:01,792] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:48:01,904] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[14:48:01,905] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:48:01,984] INFO  {SecurityManager} Changing view acls to: victor
[14:48:01,985] INFO  {SecurityManager} Changing modify acls to: victor
[14:48:01,986] INFO  {SecurityManager} Changing view acls groups to: 
[14:48:01,987] INFO  {SecurityManager} Changing modify acls groups to: 
[14:48:01,987] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:48:02,323] INFO  {Utils} Successfully started service 'sparkDriver' on port 45803.
[14:48:02,339] INFO  {SparkEnv} Registering MapOutputTracker
[14:48:02,355] INFO  {SparkEnv} Registering BlockManagerMaster
[14:48:02,367] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-8b2c2ff1-7aec-464d-b009-380b822e614b
[14:48:02,381] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:48:02,434] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:48:02,513] INFO  {log} Logging initialized @1615ms
[14:48:02,615] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:48:02,631] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[14:48:02,631] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[14:48:02,631] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[14:48:02,631] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[14:48:02,632] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[14:48:02,632] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[14:48:02,632] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[14:48:02,632] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[14:48:02,632] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[14:48:02,633] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[14:48:02,633] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[14:48:02,633] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[14:48:02,633] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[14:48:02,633] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[14:48:02,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[14:48:02,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[14:48:02,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[14:48:02,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[14:48:02,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[14:48:02,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[14:48:02,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[14:48:02,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[14:48:02,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[14:48:02,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[14:48:02,648] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:48:02,648] INFO  {Server} Started @1751ms
[14:48:02,648] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:48:02,650] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[14:48:02,732] INFO  {Executor} Starting executor ID driver on host localhost
[14:48:02,755] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38167.
[14:48:02,756] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:38167
[14:48:02,758] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 38167)
[14:48:02,761] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:38167 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 38167)
[14:48:02,764] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 38167)
[14:48:02,887] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[14:48:02,941] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[14:48:02,941] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[14:48:02,942] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[14:48:02,942] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[14:48:02,944] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[14:48:02,957] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[14:48:04,940] INFO  {FileSourceStrategy} Pruning directories with: 
[14:48:04,941] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:48:04,946] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:48:04,947] INFO  {FileSourceStrategy} Pushed Filters: 
[14:48:05,071] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[14:48:05,123] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:48:05,125] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:38167 (size: 14.6 KB, free: 1128.9 MB)
[14:48:05,131] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[14:48:05,135] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:48:05,635] INFO  {CodeGenerator} Code generated in 228.040359 ms
[14:48:05,727] INFO  {SparkContext} Starting job: show at Main.scala:34
[14:48:05,741] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[14:48:05,741] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[14:48:05,741] INFO  {DAGScheduler} Parents of final stage: List()
[14:48:05,742] INFO  {DAGScheduler} Missing parents: List()
[14:48:05,746] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[14:48:05,790] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[14:48:05,792] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[14:48:05,793] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:38167 (size: 6.6 KB, free: 1128.9 MB)
[14:48:05,794] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:48:05,797] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[14:48:05,798] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:48:05,843] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:48:05,851] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:48:05,887] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:48:05,903] INFO  {CodeGenerator} Code generated in 12.565898 ms
[14:48:05,935] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[14:48:05,943] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 124 ms on localhost (1/1)
[14:48:05,961] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:48:05,967] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.160 s
[14:48:05,971] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.244529 s
[14:48:06,006] INFO  {CodeGenerator} Code generated in 21.203454 ms
[14:48:06,058] INFO  {FileSourceStrategy} Pruning directories with: 
[14:48:06,058] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:48:06,059] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:48:06,059] INFO  {FileSourceStrategy} Pushed Filters: 
[14:48:06,066] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:48:06,079] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:48:06,079] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:38167 (size: 14.6 KB, free: 1128.9 MB)
[14:48:06,081] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:45
[14:48:06,081] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:48:06,135] INFO  {CodeGenerator} Code generated in 33.795844 ms
[14:48:06,148] INFO  {SparkContext} Starting job: show at Main.scala:45
[14:48:06,149] INFO  {DAGScheduler} Got job 1 (show at Main.scala:45) with 1 output partitions
[14:48:06,149] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:45)
[14:48:06,149] INFO  {DAGScheduler} Parents of final stage: List()
[14:48:06,149] INFO  {DAGScheduler} Missing parents: List()
[14:48:06,150] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:45), which has no missing parents
[14:48:06,153] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[14:48:06,157] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[14:48:06,158] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:38167 (size: 8.2 KB, free: 1128.9 MB)
[14:48:06,158] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[14:48:06,158] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:45)
[14:48:06,159] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[14:48:06,161] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:48:06,162] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[14:48:06,174] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:48:06,190] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[14:48:06,192] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (1/1)
[14:48:06,192] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[14:48:06,192] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:45) finished in 0.033 s
[14:48:06,193] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:45, took 0.044423 s
[14:48:06,224] INFO  {CodeGenerator} Code generated in 21.022212 ms
[14:48:06,325] INFO  {FileSourceStrategy} Pruning directories with: 
[14:48:06,325] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:48:06,326] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:48:06,326] INFO  {FileSourceStrategy} Pushed Filters: 
[14:48:06,331] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[14:48:06,339] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[14:48:06,340] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:38167 (size: 14.6 KB, free: 1128.8 MB)
[14:48:06,341] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:53
[14:48:06,341] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:48:06,397] INFO  {CodeGenerator} Code generated in 41.097643 ms
[14:48:06,409] INFO  {SparkContext} Starting job: show at Main.scala:53
[14:48:06,411] INFO  {DAGScheduler} Got job 2 (show at Main.scala:53) with 1 output partitions
[14:48:06,411] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:53)
[14:48:06,411] INFO  {DAGScheduler} Parents of final stage: List()
[14:48:06,411] INFO  {DAGScheduler} Missing parents: List()
[14:48:06,411] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53), which has no missing parents
[14:48:06,415] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[14:48:06,416] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[14:48:06,417] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:38167 (size: 9.6 KB, free: 1128.8 MB)
[14:48:06,418] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[14:48:06,418] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53)
[14:48:06,418] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[14:48:06,420] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:48:06,420] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[14:48:06,434] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:48:06,448] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3566 bytes result sent to driver
[14:48:06,450] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 32 ms on localhost (1/1)
[14:48:06,450] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[14:48:06,450] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:53) finished in 0.032 s
[14:48:06,451] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:53, took 0.040917 s
[14:48:06,470] INFO  {CodeGenerator} Code generated in 17.40675 ms
[14:48:06,523] INFO  {FileSourceStrategy} Pruning directories with: 
[14:48:06,523] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:48:06,524] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:48:06,524] INFO  {FileSourceStrategy} Pushed Filters: 
[14:48:06,531] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[14:48:06,545] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.2 MB)
[14:48:06,546] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:38167 (size: 14.6 KB, free: 1128.8 MB)
[14:48:06,547] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:63
[14:48:06,547] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:48:06,642] INFO  {CodeGenerator} Code generated in 68.887485 ms
[14:48:06,655] INFO  {SparkContext} Starting job: show at Main.scala:63
[14:48:06,656] INFO  {DAGScheduler} Got job 3 (show at Main.scala:63) with 1 output partitions
[14:48:06,656] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:63)
[14:48:06,657] INFO  {DAGScheduler} Parents of final stage: List()
[14:48:06,657] INFO  {DAGScheduler} Missing parents: List()
[14:48:06,657] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63), which has no missing parents
[14:48:06,660] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[14:48:06,661] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[14:48:06,662] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:38167 (size: 10.9 KB, free: 1128.8 MB)
[14:48:06,663] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[14:48:06,663] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63)
[14:48:06,663] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[14:48:06,665] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:48:06,665] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[14:48:06,677] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:48:06,690] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[14:48:06,692] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 29 ms on localhost (1/1)
[14:48:06,692] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[14:48:06,693] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:63) finished in 0.029 s
[14:48:06,693] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:63, took 0.037262 s
[14:48:06,715] INFO  {CodeGenerator} Code generated in 19.458592 ms
[14:48:06,788] INFO  {FileSourceStrategy} Pruning directories with: 
[14:48:06,788] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:48:06,788] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:48:06,788] INFO  {FileSourceStrategy} Pushed Filters: 
[14:48:06,792] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.1 MB)
[14:48:06,800] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.1 MB)
[14:48:06,800] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:38167 (size: 14.6 KB, free: 1128.8 MB)
[14:48:06,801] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:67
[14:48:06,802] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:48:06,943] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:38167 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:48:06,950] INFO  {ContextCleaner} Cleaned accumulator 0
[14:48:06,950] INFO  {ContextCleaner} Cleaned accumulator 1
[14:48:06,952] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:38167 in memory (size: 6.6 KB, free: 1128.8 MB)
[14:48:06,952] INFO  {CodeGenerator} Code generated in 18.941719 ms
[14:48:06,954] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:38167 in memory (size: 14.6 KB, free: 1128.8 MB)
[14:48:06,956] INFO  {ContextCleaner} Cleaned accumulator 46
[14:48:06,956] INFO  {ContextCleaner} Cleaned accumulator 47
[14:48:06,957] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:38167 in memory (size: 8.2 KB, free: 1128.8 MB)
[14:48:06,958] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:38167 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:48:06,959] INFO  {ContextCleaner} Cleaned accumulator 92
[14:48:06,959] INFO  {ContextCleaner} Cleaned accumulator 93
[14:48:06,959] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:38167 in memory (size: 9.6 KB, free: 1128.9 MB)
[14:48:06,961] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:38167 in memory (size: 14.6 KB, free: 1128.9 MB)
[14:48:06,961] INFO  {ContextCleaner} Cleaned accumulator 138
[14:48:06,961] INFO  {ContextCleaner} Cleaned accumulator 139
[14:48:06,962] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:38167 in memory (size: 10.9 KB, free: 1128.9 MB)
[14:48:06,963] INFO  {ContextCleaner} Cleaned accumulator 184
[14:48:06,978] INFO  {CodeGenerator} Code generated in 18.964811 ms
[14:48:07,009] INFO  {SparkContext} Starting job: collect at Main.scala:67
[14:48:07,013] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:67)
[14:48:07,014] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[14:48:07,014] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[14:48:07,014] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[14:48:07,014] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[14:48:07,016] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:67), which has no missing parents
[14:48:07,022] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[14:48:07,023] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[14:48:07,024] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:38167 (size: 8.3 KB, free: 1128.9 MB)
[14:48:07,024] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[14:48:07,026] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:67)
[14:48:07,026] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[14:48:07,029] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[14:48:07,029] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[14:48:07,045] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:48:07,327] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[14:48:07,329] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 301 ms on localhost (1/1)
[14:48:07,329] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[14:48:07,329] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.302 s
[14:48:07,330] INFO  {DAGScheduler} looking for newly runnable stages
[14:48:07,330] INFO  {DAGScheduler} running: Set()
[14:48:07,330] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[14:48:07,331] INFO  {DAGScheduler} failed: Set()
[14:48:07,332] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[14:48:07,337] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[14:48:07,339] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[14:48:07,340] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:38167 (size: 3.9 KB, free: 1128.9 MB)
[14:48:07,340] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[14:48:07,340] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:67)
[14:48:07,341] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[14:48:07,345] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[14:48:07,345] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[14:48:07,357] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[14:48:07,359] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[14:48:07,372] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[14:48:07,374] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 30 ms on localhost (1/1)
[14:48:07,374] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[14:48:07,374] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.031 s
[14:48:07,374] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.364710 s
[14:48:07,386] INFO  {CodeGenerator} Code generated in 7.66378 ms
[14:48:07,429] INFO  {FileSourceStrategy} Pruning directories with: 
[14:48:07,429] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:48:07,430] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:48:07,430] INFO  {FileSourceStrategy} Pushed Filters: 
[14:48:07,434] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[14:48:07,442] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[14:48:07,443] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:38167 (size: 14.6 KB, free: 1128.9 MB)
[14:48:07,444] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:77
[14:48:07,444] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:48:07,508] INFO  {CodeGenerator} Code generated in 46.209124 ms
[14:48:07,517] INFO  {SparkContext} Starting job: show at Main.scala:77
[14:48:07,518] INFO  {DAGScheduler} Got job 5 (show at Main.scala:77) with 1 output partitions
[14:48:07,518] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:77)
[14:48:07,518] INFO  {DAGScheduler} Parents of final stage: List()
[14:48:07,518] INFO  {DAGScheduler} Missing parents: List()
[14:48:07,518] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:77), which has no missing parents
[14:48:07,522] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 48.6 KB, free 1128.5 MB)
[14:48:07,524] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1128.5 MB)
[14:48:07,524] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:38167 (size: 13.0 KB, free: 1128.8 MB)
[14:48:07,525] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[14:48:07,525] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:77)
[14:48:07,525] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[14:48:07,527] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:48:07,527] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[14:48:07,534] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:48:07,543] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3496 bytes result sent to driver
[14:48:07,545] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 19 ms on localhost (1/1)
[14:48:07,545] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[14:48:07,546] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:77) finished in 0.021 s
[14:48:07,547] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:77, took 0.030405 s
[14:48:07,570] INFO  {CodeGenerator} Code generated in 19.559254 ms
[14:48:07,625] INFO  {FileSourceStrategy} Pruning directories with: 
[14:48:07,625] INFO  {FileSourceStrategy} Post-Scan Filters: 
[14:48:07,626] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[14:48:07,626] INFO  {FileSourceStrategy} Pushed Filters: 
[14:48:07,628] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[14:48:07,636] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[14:48:07,636] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 80.216.145.125:38167 (size: 14.6 KB, free: 1128.8 MB)
[14:48:07,637] INFO  {SparkContext} Created broadcast 13 from show at Main.scala:85
[14:48:07,637] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[14:48:07,706] INFO  {CodeGenerator} Code generated in 50.359874 ms
[14:48:07,715] INFO  {SparkContext} Starting job: show at Main.scala:85
[14:48:07,716] INFO  {DAGScheduler} Got job 6 (show at Main.scala:85) with 1 output partitions
[14:48:07,716] INFO  {DAGScheduler} Final stage: ResultStage 7 (show at Main.scala:85)
[14:48:07,716] INFO  {DAGScheduler} Parents of final stage: List()
[14:48:07,716] INFO  {DAGScheduler} Missing parents: List()
[14:48:07,716] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[23] at show at Main.scala:85), which has no missing parents
[14:48:07,719] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 57.2 KB, free 1128.3 MB)
[14:48:07,722] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.3 MB)
[14:48:07,723] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 80.216.145.125:38167 (size: 14.6 KB, free: 1128.8 MB)
[14:48:07,723] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[14:48:07,723] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at show at Main.scala:85)
[14:48:07,724] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[14:48:07,726] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[14:48:07,726] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[14:48:07,738] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[14:48:07,745] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 3559 bytes result sent to driver
[14:48:07,746] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 22 ms on localhost (1/1)
[14:48:07,746] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[14:48:07,747] INFO  {DAGScheduler} ResultStage 7 (show at Main.scala:85) finished in 0.023 s
[14:48:07,747] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:85, took 0.032163 s
[14:48:07,765] INFO  {CodeGenerator} Code generated in 15.047395 ms
[14:48:07,771] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:48:07,776] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[14:48:07,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[14:48:07,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[14:48:07,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[14:48:07,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[14:48:07,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[14:48:07,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[14:48:07,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[14:48:07,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[14:48:07,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[14:48:07,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[14:48:07,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[14:48:07,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[14:48:07,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[14:48:07,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[14:48:07,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[14:48:07,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[14:48:07,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[14:48:07,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[14:48:07,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[14:48:07,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[14:48:07,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[14:48:07,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[14:48:07,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[14:48:07,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[14:48:07,785] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[14:48:07,797] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:48:07,806] INFO  {MemoryStore} MemoryStore cleared
[14:48:07,807] INFO  {BlockManager} BlockManager stopped
[14:48:07,809] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:48:07,815] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:48:07,823] INFO  {SparkContext} Successfully stopped SparkContext
[14:48:07,823] INFO  {ShutdownHookManager} Shutdown hook called
[14:48:07,824] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-effcaa65-a56b-482f-b64a-d8de0b1ba691
[15:03:22,429] INFO  {SparkContext} Running Spark version 2.0.1
[15:03:22,654] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:03:22,768] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:03:22,771] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:03:22,841] INFO  {SecurityManager} Changing view acls to: victor
[15:03:22,841] INFO  {SecurityManager} Changing modify acls to: victor
[15:03:22,842] INFO  {SecurityManager} Changing view acls groups to: 
[15:03:22,843] INFO  {SecurityManager} Changing modify acls groups to: 
[15:03:22,844] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:03:23,206] INFO  {Utils} Successfully started service 'sparkDriver' on port 46061.
[15:03:23,223] INFO  {SparkEnv} Registering MapOutputTracker
[15:03:23,239] INFO  {SparkEnv} Registering BlockManagerMaster
[15:03:23,252] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-4dd15851-4dc3-4beb-b9ac-eba07308a098
[15:03:23,266] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:03:23,326] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:03:23,404] INFO  {log} Logging initialized @1593ms
[15:03:23,520] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:03:23,538] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:03:23,538] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:03:23,538] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:03:23,538] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:03:23,539] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:03:23,539] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:03:23,539] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:03:23,539] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:03:23,539] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:03:23,540] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:03:23,540] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:03:23,540] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:03:23,540] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:03:23,540] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:03:23,540] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:03:23,541] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:03:23,541] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:03:23,541] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:03:23,541] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:03:23,541] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:03:23,548] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:03:23,548] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:03:23,549] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:03:23,549] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:03:23,555] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:03:23,555] INFO  {Server} Started @1746ms
[15:03:23,555] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:03:23,558] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:03:23,643] INFO  {Executor} Starting executor ID driver on host localhost
[15:03:23,674] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46021.
[15:03:23,675] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:46021
[15:03:23,677] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 46021)
[15:03:23,680] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:46021 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 46021)
[15:03:23,683] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 46021)
[15:03:23,803] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:03:23,853] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[15:03:23,854] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[15:03:23,855] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[15:03:23,856] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[15:03:23,857] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[15:03:23,872] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:03:25,944] INFO  {FileSourceStrategy} Pruning directories with: 
[15:03:25,946] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:03:25,950] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:03:25,951] INFO  {FileSourceStrategy} Pushed Filters: 
[15:03:26,056] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:03:26,106] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:03:26,108] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:46021 (size: 14.6 KB, free: 1128.9 MB)
[15:03:26,113] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[15:03:26,117] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:03:26,620] INFO  {CodeGenerator} Code generated in 222.340438 ms
[15:03:26,709] INFO  {SparkContext} Starting job: show at Main.scala:34
[15:03:26,725] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[15:03:26,726] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[15:03:26,726] INFO  {DAGScheduler} Parents of final stage: List()
[15:03:26,727] INFO  {DAGScheduler} Missing parents: List()
[15:03:26,731] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[15:03:26,777] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:03:26,780] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[15:03:26,780] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:46021 (size: 6.6 KB, free: 1128.9 MB)
[15:03:26,781] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:03:26,784] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[15:03:26,786] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:03:26,829] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:03:26,836] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:03:26,872] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:03:26,891] INFO  {CodeGenerator} Code generated in 15.488978 ms
[15:03:26,940] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2794 bytes result sent to driver
[15:03:26,946] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 140 ms on localhost (1/1)
[15:03:26,947] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:03:26,950] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.155 s
[15:03:26,954] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.245053 s
[15:03:26,988] INFO  {CodeGenerator} Code generated in 20.369391 ms
[15:03:27,042] INFO  {FileSourceStrategy} Pruning directories with: 
[15:03:27,043] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:03:27,043] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:03:27,043] INFO  {FileSourceStrategy} Pushed Filters: 
[15:03:27,051] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:03:27,062] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:03:27,062] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:46021 (size: 14.6 KB, free: 1128.9 MB)
[15:03:27,064] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[15:03:27,064] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:03:27,115] INFO  {CodeGenerator} Code generated in 35.467733 ms
[15:03:27,128] INFO  {SparkContext} Starting job: show at Main.scala:43
[15:03:27,129] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[15:03:27,129] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[15:03:27,129] INFO  {DAGScheduler} Parents of final stage: List()
[15:03:27,129] INFO  {DAGScheduler} Missing parents: List()
[15:03:27,129] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[15:03:27,134] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[15:03:27,137] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[15:03:27,138] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:46021 (size: 8.2 KB, free: 1128.9 MB)
[15:03:27,140] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:03:27,140] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[15:03:27,140] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:03:27,143] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:03:27,143] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:03:27,155] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:03:27,170] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:03:27,172] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on localhost (1/1)
[15:03:27,172] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:03:27,172] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.031 s
[15:03:27,173] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.044712 s
[15:03:27,196] INFO  {CodeGenerator} Code generated in 15.850952 ms
[15:03:27,292] INFO  {FileSourceStrategy} Pruning directories with: 
[15:03:27,292] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:03:27,293] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:03:27,293] INFO  {FileSourceStrategy} Pushed Filters: 
[15:03:27,298] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[15:03:27,308] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:03:27,308] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:46021 (size: 14.6 KB, free: 1128.8 MB)
[15:03:27,310] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:51
[15:03:27,310] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:03:27,379] INFO  {CodeGenerator} Code generated in 45.163727 ms
[15:03:27,389] INFO  {SparkContext} Starting job: show at Main.scala:51
[15:03:27,390] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[15:03:27,390] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[15:03:27,390] INFO  {DAGScheduler} Parents of final stage: List()
[15:03:27,390] INFO  {DAGScheduler} Missing parents: List()
[15:03:27,391] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51), which has no missing parents
[15:03:27,395] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[15:03:27,397] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[15:03:27,398] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:46021 (size: 9.6 KB, free: 1128.8 MB)
[15:03:27,398] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:03:27,399] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:51)
[15:03:27,399] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:03:27,401] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:03:27,401] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:03:27,412] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:03:27,422] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:03:27,423] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 24 ms on localhost (1/1)
[15:03:27,423] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:03:27,423] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.024 s
[15:03:27,424] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.035011 s
[15:03:27,446] INFO  {CodeGenerator} Code generated in 19.724114 ms
[15:03:27,493] INFO  {FileSourceStrategy} Pruning directories with: 
[15:03:27,493] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:03:27,494] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:03:27,494] INFO  {FileSourceStrategy} Pushed Filters: 
[15:03:27,500] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[15:03:27,509] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.2 MB)
[15:03:27,510] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:46021 (size: 14.6 KB, free: 1128.8 MB)
[15:03:27,511] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:61
[15:03:27,511] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:03:27,589] INFO  {CodeGenerator} Code generated in 54.442807 ms
[15:03:27,597] INFO  {SparkContext} Starting job: show at Main.scala:61
[15:03:27,598] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[15:03:27,599] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[15:03:27,599] INFO  {DAGScheduler} Parents of final stage: List()
[15:03:27,599] INFO  {DAGScheduler} Missing parents: List()
[15:03:27,599] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61), which has no missing parents
[15:03:27,602] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[15:03:27,604] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[15:03:27,605] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:46021 (size: 10.9 KB, free: 1128.8 MB)
[15:03:27,605] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:03:27,605] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:61)
[15:03:27,606] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:03:27,607] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:03:27,608] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:03:27,616] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:03:27,624] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:03:27,628] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 21 ms on localhost (1/1)
[15:03:27,628] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:03:27,628] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.022 s
[15:03:27,628] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.030797 s
[15:03:27,644] INFO  {CodeGenerator} Code generated in 13.603939 ms
[15:03:27,712] INFO  {FileSourceStrategy} Pruning directories with: 
[15:03:27,712] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:03:27,713] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:03:27,713] INFO  {FileSourceStrategy} Pushed Filters: 
[15:03:27,717] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.1 MB)
[15:03:27,725] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.1 MB)
[15:03:27,726] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:46021 (size: 14.6 KB, free: 1128.8 MB)
[15:03:27,728] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:65
[15:03:27,728] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:03:27,896] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:46021 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:03:27,898] INFO  {CodeGenerator} Code generated in 23.053902 ms
[15:03:27,909] INFO  {ContextCleaner} Cleaned accumulator 0
[15:03:27,909] INFO  {ContextCleaner} Cleaned accumulator 1
[15:03:27,911] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:46021 in memory (size: 6.6 KB, free: 1128.8 MB)
[15:03:27,913] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:46021 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:03:27,914] INFO  {ContextCleaner} Cleaned accumulator 46
[15:03:27,914] INFO  {ContextCleaner} Cleaned accumulator 47
[15:03:27,917] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:46021 in memory (size: 8.2 KB, free: 1128.8 MB)
[15:03:27,921] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:46021 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:03:27,921] INFO  {ContextCleaner} Cleaned accumulator 92
[15:03:27,921] INFO  {ContextCleaner} Cleaned accumulator 93
[15:03:27,922] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:46021 in memory (size: 9.6 KB, free: 1128.9 MB)
[15:03:27,924] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:46021 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:03:27,925] INFO  {ContextCleaner} Cleaned accumulator 138
[15:03:27,925] INFO  {ContextCleaner} Cleaned accumulator 139
[15:03:27,926] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:46021 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:03:27,926] INFO  {ContextCleaner} Cleaned accumulator 184
[15:03:27,945] INFO  {CodeGenerator} Code generated in 35.767549 ms
[15:03:27,991] INFO  {SparkContext} Starting job: collect at Main.scala:65
[15:03:27,994] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:65)
[15:03:27,995] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:65) with 1 output partitions
[15:03:27,996] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:65)
[15:03:27,996] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[15:03:27,996] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[15:03:27,997] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:65), which has no missing parents
[15:03:28,004] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[15:03:28,006] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[15:03:28,007] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:46021 (size: 8.3 KB, free: 1128.9 MB)
[15:03:28,008] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:03:28,010] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:65)
[15:03:28,010] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:03:28,015] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[15:03:28,016] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:03:28,035] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:03:28,329] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[15:03:28,332] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 321 ms on localhost (1/1)
[15:03:28,332] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:03:28,333] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:65) finished in 0.322 s
[15:03:28,333] INFO  {DAGScheduler} looking for newly runnable stages
[15:03:28,334] INFO  {DAGScheduler} running: Set()
[15:03:28,334] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[15:03:28,335] INFO  {DAGScheduler} failed: Set()
[15:03:28,336] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:65), which has no missing parents
[15:03:28,342] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[15:03:28,343] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[15:03:28,344] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:46021 (size: 3.9 KB, free: 1128.9 MB)
[15:03:28,344] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[15:03:28,345] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:65)
[15:03:28,345] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:03:28,349] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[15:03:28,350] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:03:28,365] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[15:03:28,366] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[15:03:28,379] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[15:03:28,380] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 33 ms on localhost (1/1)
[15:03:28,381] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:03:28,381] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:65) finished in 0.034 s
[15:03:28,381] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:65, took 0.390248 s
[15:03:28,392] INFO  {CodeGenerator} Code generated in 7.053912 ms
[15:03:28,453] INFO  {FileSourceStrategy} Pruning directories with: 
[15:03:28,453] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:03:28,454] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:03:28,454] INFO  {FileSourceStrategy} Pushed Filters: 
[15:03:28,457] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:03:28,468] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:03:28,468] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:46021 (size: 14.6 KB, free: 1128.9 MB)
[15:03:28,469] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:75
[15:03:28,469] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:03:28,548] INFO  {CodeGenerator} Code generated in 59.349797 ms
[15:03:28,557] INFO  {SparkContext} Starting job: show at Main.scala:75
[15:03:28,559] INFO  {DAGScheduler} Got job 5 (show at Main.scala:75) with 1 output partitions
[15:03:28,559] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:75)
[15:03:28,559] INFO  {DAGScheduler} Parents of final stage: List()
[15:03:28,560] INFO  {DAGScheduler} Missing parents: List()
[15:03:28,560] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:75), which has no missing parents
[15:03:28,563] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 48.6 KB, free 1128.5 MB)
[15:03:28,564] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1128.5 MB)
[15:03:28,565] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:46021 (size: 13.0 KB, free: 1128.8 MB)
[15:03:28,566] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[15:03:28,566] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:75)
[15:03:28,566] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[15:03:28,567] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:03:28,568] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[15:03:28,575] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:03:28,580] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3496 bytes result sent to driver
[15:03:28,581] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 14 ms on localhost (1/1)
[15:03:28,581] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[15:03:28,581] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:75) finished in 0.015 s
[15:03:28,582] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:75, took 0.024105 s
[15:03:28,599] INFO  {CodeGenerator} Code generated in 15.042165 ms
[15:03:28,640] INFO  {FileSourceStrategy} Pruning directories with: 
[15:03:28,640] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:03:28,640] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:03:28,640] INFO  {FileSourceStrategy} Pushed Filters: 
[15:03:28,643] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[15:03:28,651] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:03:28,651] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 80.216.145.125:46021 (size: 14.6 KB, free: 1128.8 MB)
[15:03:28,652] INFO  {SparkContext} Created broadcast 13 from show at Main.scala:83
[15:03:28,652] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:03:28,736] INFO  {CodeGenerator} Code generated in 63.961855 ms
[15:03:28,749] INFO  {SparkContext} Starting job: show at Main.scala:83
[15:03:28,750] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[15:03:28,750] INFO  {DAGScheduler} Final stage: ResultStage 7 (show at Main.scala:83)
[15:03:28,750] INFO  {DAGScheduler} Parents of final stage: List()
[15:03:28,750] INFO  {DAGScheduler} Missing parents: List()
[15:03:28,750] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[23] at show at Main.scala:83), which has no missing parents
[15:03:28,754] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 57.2 KB, free 1128.3 MB)
[15:03:28,759] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.3 MB)
[15:03:28,759] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 80.216.145.125:46021 (size: 14.6 KB, free: 1128.8 MB)
[15:03:28,760] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[15:03:28,760] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at show at Main.scala:83)
[15:03:28,760] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[15:03:28,762] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:03:28,762] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[15:03:28,770] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:03:28,778] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 3559 bytes result sent to driver
[15:03:28,780] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 19 ms on localhost (1/1)
[15:03:28,780] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[15:03:28,780] INFO  {DAGScheduler} ResultStage 7 (show at Main.scala:83) finished in 0.019 s
[15:03:28,781] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.031814 s
[15:03:28,798] INFO  {CodeGenerator} Code generated in 14.65645 ms
[15:03:28,803] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:03:28,807] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:03:28,812] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:03:28,812] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:03:28,812] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:03:28,812] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:03:28,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:03:28,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:03:28,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:03:28,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:03:28,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:03:28,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:03:28,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:03:28,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:03:28,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:03:28,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:03:28,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:03:28,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:03:28,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:03:28,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:03:28,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:03:28,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:03:28,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:03:28,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:03:28,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:03:28,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:03:28,818] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:03:28,837] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:03:28,850] INFO  {MemoryStore} MemoryStore cleared
[15:03:28,850] INFO  {BlockManager} BlockManager stopped
[15:03:28,853] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:03:28,856] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:03:28,877] INFO  {SparkContext} Successfully stopped SparkContext
[15:03:28,880] INFO  {ShutdownHookManager} Shutdown hook called
[15:03:28,881] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-dc3622bc-0cb2-49d1-8d12-3d46fa6f7e11
[15:11:13,394] INFO  {SparkContext} Running Spark version 2.0.1
[15:11:13,636] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:11:13,739] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:11:13,741] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:11:13,819] INFO  {SecurityManager} Changing view acls to: victor
[15:11:13,820] INFO  {SecurityManager} Changing modify acls to: victor
[15:11:13,821] INFO  {SecurityManager} Changing view acls groups to: 
[15:11:13,821] INFO  {SecurityManager} Changing modify acls groups to: 
[15:11:13,822] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:11:14,189] INFO  {Utils} Successfully started service 'sparkDriver' on port 42631.
[15:11:14,206] INFO  {SparkEnv} Registering MapOutputTracker
[15:11:14,224] INFO  {SparkEnv} Registering BlockManagerMaster
[15:11:14,236] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-85ae0386-9c7d-4730-92f1-055b84e20ddd
[15:11:14,250] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:11:14,294] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:11:14,369] INFO  {log} Logging initialized @1617ms
[15:11:14,476] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:11:14,491] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:11:14,492] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:11:14,492] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:11:14,492] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:11:14,492] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:11:14,492] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:11:14,492] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:11:14,493] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:11:14,493] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:11:14,493] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:11:14,493] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:11:14,493] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:11:14,494] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:11:14,494] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:11:14,494] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:11:14,494] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:11:14,494] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:11:14,494] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:11:14,495] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:11:14,495] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:11:14,501] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:11:14,501] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:11:14,502] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:11:14,502] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:11:14,509] INFO  {ServerConnector} Started ServerConnector@289714c1{HTTP/1.1}{0.0.0.0:4040}
[15:11:14,509] INFO  {Server} Started @1759ms
[15:11:14,510] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:11:14,512] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:11:14,603] INFO  {Executor} Starting executor ID driver on host localhost
[15:11:14,625] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33333.
[15:11:14,625] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:33333
[15:11:14,627] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 33333)
[15:11:14,629] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:33333 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 33333)
[15:11:14,632] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 33333)
[15:11:14,754] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b6579e8{/metrics/json,null,AVAILABLE}
[15:11:14,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53499d85{/SQL,null,AVAILABLE}
[15:11:14,806] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@782a4fff{/SQL/json,null,AVAILABLE}
[15:11:14,806] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL/execution,null,AVAILABLE}
[15:11:14,807] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1133ec6e{/SQL/execution/json,null,AVAILABLE}
[15:11:14,808] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/static/sql,null,AVAILABLE}
[15:11:14,822] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:11:16,669] INFO  {FileSourceStrategy} Pruning directories with: 
[15:11:16,671] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:11:16,676] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:11:16,676] INFO  {FileSourceStrategy} Pushed Filters: 
[15:11:16,797] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:11:16,844] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:11:16,846] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:33333 (size: 14.6 KB, free: 1128.9 MB)
[15:11:16,853] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[15:11:16,858] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:11:17,366] INFO  {CodeGenerator} Code generated in 212.154223 ms
[15:11:17,457] INFO  {SparkContext} Starting job: show at Main.scala:34
[15:11:17,473] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[15:11:17,473] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[15:11:17,474] INFO  {DAGScheduler} Parents of final stage: List()
[15:11:17,475] INFO  {DAGScheduler} Missing parents: List()
[15:11:17,479] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[15:11:17,526] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:11:17,528] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[15:11:17,529] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:33333 (size: 6.6 KB, free: 1128.9 MB)
[15:11:17,529] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:11:17,533] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[15:11:17,534] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:11:17,572] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:11:17,578] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:11:17,622] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:11:17,640] INFO  {CodeGenerator} Code generated in 14.624957 ms
[15:11:17,672] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[15:11:17,681] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 126 ms on localhost (1/1)
[15:11:17,682] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:11:17,688] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.144 s
[15:11:17,695] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.238449 s
[15:11:17,726] INFO  {CodeGenerator} Code generated in 18.539662 ms
[15:11:17,789] INFO  {FileSourceStrategy} Pruning directories with: 
[15:11:17,790] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:11:17,790] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:11:17,790] INFO  {FileSourceStrategy} Pushed Filters: 
[15:11:17,798] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:11:17,809] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:11:17,810] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:33333 (size: 14.6 KB, free: 1128.9 MB)
[15:11:17,812] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[15:11:17,812] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:11:17,886] INFO  {CodeGenerator} Code generated in 49.615616 ms
[15:11:17,912] INFO  {SparkContext} Starting job: show at Main.scala:43
[15:11:17,914] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[15:11:17,914] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[15:11:17,914] INFO  {DAGScheduler} Parents of final stage: List()
[15:11:17,914] INFO  {DAGScheduler} Missing parents: List()
[15:11:17,914] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[15:11:17,918] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[15:11:17,921] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[15:11:17,921] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:33333 (size: 8.2 KB, free: 1128.9 MB)
[15:11:17,923] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:11:17,923] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[15:11:17,923] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:33333 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:11:17,923] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:11:17,925] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:11:17,926] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:11:17,928] INFO  {ContextCleaner} Cleaned accumulator 0
[15:11:17,929] INFO  {ContextCleaner} Cleaned accumulator 1
[15:11:17,930] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:33333 in memory (size: 6.6 KB, free: 1128.9 MB)
[15:11:17,937] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:11:17,955] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:11:17,957] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (1/1)
[15:11:17,957] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:11:17,958] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.033 s
[15:11:17,958] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.045237 s
[15:11:17,988] INFO  {CodeGenerator} Code generated in 20.634064 ms
[15:11:18,075] INFO  {FileSourceStrategy} Pruning directories with: 
[15:11:18,076] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:11:18,076] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:11:18,077] INFO  {FileSourceStrategy} Pushed Filters: 
[15:11:18,083] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:11:18,097] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:11:18,097] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:33333 (size: 14.6 KB, free: 1128.9 MB)
[15:11:18,098] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:52
[15:11:18,098] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:11:18,155] INFO  {CodeGenerator} Code generated in 40.299178 ms
[15:11:18,164] INFO  {SparkContext} Starting job: show at Main.scala:52
[15:11:18,165] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[15:11:18,166] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[15:11:18,166] INFO  {DAGScheduler} Parents of final stage: List()
[15:11:18,166] INFO  {DAGScheduler} Missing parents: List()
[15:11:18,166] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52), which has no missing parents
[15:11:18,172] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.6 MB)
[15:11:18,173] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.5 MB)
[15:11:18,174] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:33333 (size: 9.6 KB, free: 1128.9 MB)
[15:11:18,175] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:11:18,175] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52)
[15:11:18,175] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:11:18,177] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:11:18,178] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:11:18,187] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:11:18,197] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:11:18,198] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 22 ms on localhost (1/1)
[15:11:18,198] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:11:18,199] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.023 s
[15:11:18,199] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.034771 s
[15:11:18,222] INFO  {CodeGenerator} Code generated in 18.87817 ms
[15:11:18,269] INFO  {FileSourceStrategy} Pruning directories with: 
[15:11:18,269] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:11:18,270] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:11:18,271] INFO  {FileSourceStrategy} Pushed Filters: 
[15:11:18,280] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[15:11:18,293] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:11:18,294] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:33333 (size: 14.6 KB, free: 1128.8 MB)
[15:11:18,296] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:62
[15:11:18,296] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:11:18,371] INFO  {CodeGenerator} Code generated in 50.438028 ms
[15:11:18,381] INFO  {SparkContext} Starting job: show at Main.scala:62
[15:11:18,381] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[15:11:18,382] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[15:11:18,382] INFO  {DAGScheduler} Parents of final stage: List()
[15:11:18,382] INFO  {DAGScheduler} Missing parents: List()
[15:11:18,382] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62), which has no missing parents
[15:11:18,385] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.4 MB)
[15:11:18,386] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.4 MB)
[15:11:18,387] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:33333 (size: 10.9 KB, free: 1128.8 MB)
[15:11:18,388] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:11:18,388] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62)
[15:11:18,388] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:11:18,390] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:11:18,390] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:11:18,399] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:11:18,408] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:11:18,409] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 21 ms on localhost (1/1)
[15:11:18,409] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:11:18,410] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.022 s
[15:11:18,410] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.029226 s
[15:11:18,427] INFO  {CodeGenerator} Code generated in 14.568245 ms
[15:11:18,590] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:33333 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:11:18,591] INFO  {ContextCleaner} Cleaned accumulator 46
[15:11:18,591] INFO  {ContextCleaner} Cleaned accumulator 47
[15:11:18,592] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:33333 in memory (size: 8.2 KB, free: 1128.9 MB)
[15:11:18,593] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:33333 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:11:18,593] INFO  {ContextCleaner} Cleaned accumulator 92
[15:11:18,593] INFO  {ContextCleaner} Cleaned accumulator 93
[15:11:18,594] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:33333 in memory (size: 9.6 KB, free: 1128.9 MB)
[15:11:18,595] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:33333 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:11:18,595] INFO  {ContextCleaner} Cleaned accumulator 138
[15:11:18,595] INFO  {ContextCleaner} Cleaned accumulator 139
[15:11:18,596] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:33333 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:11:18,599] INFO  {FileSourceStrategy} Pruning directories with: 
[15:11:18,599] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:11:18,600] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:11:18,600] INFO  {FileSourceStrategy} Pushed Filters: 
[15:11:18,605] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:11:18,618] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:11:18,618] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:33333 (size: 14.6 KB, free: 1128.9 MB)
[15:11:18,620] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:66
[15:11:18,620] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:11:18,671] INFO  {CodeGenerator} Code generated in 14.585869 ms
[15:11:18,700] INFO  {CodeGenerator} Code generated in 21.021251 ms
[15:11:18,737] INFO  {SparkContext} Starting job: collect at Main.scala:66
[15:11:18,746] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:66)
[15:11:18,747] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:66) with 1 output partitions
[15:11:18,747] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:66)
[15:11:18,747] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[15:11:18,747] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[15:11:18,749] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66), which has no missing parents
[15:11:18,756] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[15:11:18,760] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[15:11:18,761] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:33333 (size: 8.3 KB, free: 1128.9 MB)
[15:11:18,762] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:11:18,764] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66)
[15:11:18,764] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:11:18,767] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[15:11:18,767] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:11:18,789] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:11:19,078] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[15:11:19,082] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 316 ms on localhost (1/1)
[15:11:19,082] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:11:19,083] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:66) finished in 0.319 s
[15:11:19,083] INFO  {DAGScheduler} looking for newly runnable stages
[15:11:19,084] INFO  {DAGScheduler} running: Set()
[15:11:19,084] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[15:11:19,084] INFO  {DAGScheduler} failed: Set()
[15:11:19,086] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66), which has no missing parents
[15:11:19,091] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[15:11:19,092] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[15:11:19,093] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:33333 (size: 3.9 KB, free: 1128.9 MB)
[15:11:19,093] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[15:11:19,093] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66)
[15:11:19,093] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:11:19,098] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[15:11:19,098] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:11:19,113] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[15:11:19,115] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[15:11:19,127] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[15:11:19,129] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 32 ms on localhost (1/1)
[15:11:19,129] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:11:19,129] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:66) finished in 0.033 s
[15:11:19,130] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:66, took 0.392755 s
[15:11:19,143] INFO  {CodeGenerator} Code generated in 8.478734 ms
[15:11:19,197] INFO  {FileSourceStrategy} Pruning directories with: 
[15:11:19,198] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:11:19,198] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:11:19,198] INFO  {FileSourceStrategy} Pushed Filters: 
[15:11:19,201] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:11:19,208] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:11:19,209] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:33333 (size: 14.6 KB, free: 1128.9 MB)
[15:11:19,210] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:86
[15:11:19,210] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:11:19,296] INFO  {CodeGenerator} Code generated in 66.201495 ms
[15:11:19,305] INFO  {SparkContext} Starting job: show at Main.scala:86
[15:11:19,306] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[15:11:19,306] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:86)
[15:11:19,306] INFO  {DAGScheduler} Parents of final stage: List()
[15:11:19,306] INFO  {DAGScheduler} Missing parents: List()
[15:11:19,306] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[15:11:19,309] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 57.2 KB, free 1128.5 MB)
[15:11:19,310] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[15:11:19,311] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:33333 (size: 14.6 KB, free: 1128.8 MB)
[15:11:19,312] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[15:11:19,313] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86)
[15:11:19,313] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[15:11:19,316] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:11:19,317] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[15:11:19,325] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:11:19,334] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3559 bytes result sent to driver
[15:11:19,335] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 21 ms on localhost (1/1)
[15:11:19,335] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[15:11:19,335] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:86) finished in 0.022 s
[15:11:19,335] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.030213 s
[15:11:19,352] INFO  {CodeGenerator} Code generated in 14.034725 ms
[15:11:19,357] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:11:19,362] INFO  {ServerConnector} Stopped ServerConnector@289714c1{HTTP/1.1}{0.0.0.0:4040}
[15:11:19,365] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:11:19,365] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:11:19,365] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:11:19,365] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:11:19,365] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:11:19,365] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:11:19,366] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:11:19,366] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:11:19,366] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:11:19,366] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:11:19,366] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:11:19,366] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:11:19,366] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:11:19,366] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:11:19,367] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:11:19,367] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:11:19,367] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:11:19,367] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:11:19,367] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:11:19,367] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:11:19,367] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:11:19,367] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:11:19,368] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:11:19,368] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:11:19,370] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:11:19,383] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:11:19,389] INFO  {MemoryStore} MemoryStore cleared
[15:11:19,389] INFO  {BlockManager} BlockManager stopped
[15:11:19,391] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:11:19,393] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:11:19,404] INFO  {SparkContext} Successfully stopped SparkContext
[15:11:19,405] INFO  {ShutdownHookManager} Shutdown hook called
[15:11:19,406] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-85542d7c-17eb-494b-a8a0-b4ac52a16f99
[15:20:51,311] INFO  {SparkContext} Running Spark version 2.0.1
[15:20:51,525] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:20:51,622] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:20:51,623] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:20:51,692] INFO  {SecurityManager} Changing view acls to: victor
[15:20:51,693] INFO  {SecurityManager} Changing modify acls to: victor
[15:20:51,694] INFO  {SecurityManager} Changing view acls groups to: 
[15:20:51,694] INFO  {SecurityManager} Changing modify acls groups to: 
[15:20:51,695] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:20:52,034] INFO  {Utils} Successfully started service 'sparkDriver' on port 33549.
[15:20:52,054] INFO  {SparkEnv} Registering MapOutputTracker
[15:20:52,069] INFO  {SparkEnv} Registering BlockManagerMaster
[15:20:52,081] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-09a5c8de-f2b3-487a-b39e-d5ea0f065080
[15:20:52,095] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:20:52,145] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:20:52,216] INFO  {log} Logging initialized @1521ms
[15:20:52,317] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:20:52,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[15:20:52,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[15:20:52,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[15:20:52,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[15:20:52,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[15:20:52,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[15:20:52,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[15:20:52,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[15:20:52,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[15:20:52,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[15:20:52,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[15:20:52,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[15:20:52,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[15:20:52,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[15:20:52,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[15:20:52,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[15:20:52,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[15:20:52,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[15:20:52,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[15:20:52,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[15:20:52,347] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[15:20:52,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[15:20:52,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[15:20:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[15:20:52,355] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:20:52,355] INFO  {Server} Started @1662ms
[15:20:52,355] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:20:52,357] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:20:52,437] INFO  {Executor} Starting executor ID driver on host localhost
[15:20:52,458] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42011.
[15:20:52,459] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:42011
[15:20:52,461] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 42011)
[15:20:52,463] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:42011 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 42011)
[15:20:52,469] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 42011)
[15:20:52,590] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[15:20:52,638] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[15:20:52,638] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[15:20:52,639] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[15:20:52,640] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[15:20:52,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[15:20:52,656] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:20:54,514] INFO  {FileSourceStrategy} Pruning directories with: 
[15:20:54,515] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:20:54,519] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:20:54,520] INFO  {FileSourceStrategy} Pushed Filters: 
[15:20:54,625] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:20:54,670] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:20:54,672] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:42011 (size: 14.6 KB, free: 1128.9 MB)
[15:20:54,678] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[15:20:54,682] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:20:55,165] INFO  {CodeGenerator} Code generated in 212.542165 ms
[15:20:55,258] INFO  {SparkContext} Starting job: show at Main.scala:34
[15:20:55,275] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[15:20:55,276] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[15:20:55,276] INFO  {DAGScheduler} Parents of final stage: List()
[15:20:55,277] INFO  {DAGScheduler} Missing parents: List()
[15:20:55,281] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[15:20:55,328] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:20:55,330] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[15:20:55,331] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:42011 (size: 6.6 KB, free: 1128.9 MB)
[15:20:55,332] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:20:55,335] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[15:20:55,337] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:20:55,374] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:20:55,381] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:20:55,419] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:20:55,434] INFO  {CodeGenerator} Code generated in 12.233766 ms
[15:20:55,468] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2808 bytes result sent to driver
[15:20:55,474] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 119 ms on localhost (1/1)
[15:20:55,475] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:20:55,481] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.135 s
[15:20:55,487] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.229493 s
[15:20:55,526] INFO  {CodeGenerator} Code generated in 23.259092 ms
[15:20:55,585] INFO  {FileSourceStrategy} Pruning directories with: 
[15:20:55,585] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:20:55,586] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:20:55,586] INFO  {FileSourceStrategy} Pushed Filters: 
[15:20:55,594] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:20:55,625] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:20:55,630] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:42011 (size: 14.6 KB, free: 1128.9 MB)
[15:20:55,633] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[15:20:55,634] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:20:55,639] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:42011 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:20:55,644] INFO  {ContextCleaner} Cleaned accumulator 0
[15:20:55,644] INFO  {ContextCleaner} Cleaned accumulator 1
[15:20:55,646] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:42011 in memory (size: 6.6 KB, free: 1128.9 MB)
[15:20:55,696] INFO  {CodeGenerator} Code generated in 37.891235 ms
[15:20:55,713] INFO  {SparkContext} Starting job: show at Main.scala:43
[15:20:55,740] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[15:20:55,740] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[15:20:55,740] INFO  {DAGScheduler} Parents of final stage: List()
[15:20:55,740] INFO  {DAGScheduler} Missing parents: List()
[15:20:55,740] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[15:20:55,745] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.7 MB)
[15:20:55,748] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[15:20:55,749] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:42011 (size: 8.2 KB, free: 1128.9 MB)
[15:20:55,751] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:20:55,751] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[15:20:55,752] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:20:55,754] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:20:55,754] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:20:55,769] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:20:55,792] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3492 bytes result sent to driver
[15:20:55,794] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
[15:20:55,794] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:20:55,794] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.042 s
[15:20:55,795] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.056061 s
[15:20:55,818] INFO  {CodeGenerator} Code generated in 15.280736 ms
[15:20:55,893] INFO  {FileSourceStrategy} Pruning directories with: 
[15:20:55,894] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:20:55,894] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:20:55,894] INFO  {FileSourceStrategy} Pushed Filters: 
[15:20:55,899] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:20:55,907] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:20:55,908] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:42011 (size: 14.6 KB, free: 1128.9 MB)
[15:20:55,909] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:52
[15:20:55,909] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:20:55,961] INFO  {CodeGenerator} Code generated in 38.387577 ms
[15:20:55,970] INFO  {SparkContext} Starting job: show at Main.scala:52
[15:20:55,971] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[15:20:55,971] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[15:20:55,971] INFO  {DAGScheduler} Parents of final stage: List()
[15:20:55,971] INFO  {DAGScheduler} Missing parents: List()
[15:20:55,972] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52), which has no missing parents
[15:20:55,976] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.6 MB)
[15:20:55,977] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.5 MB)
[15:20:55,978] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:42011 (size: 9.6 KB, free: 1128.9 MB)
[15:20:55,978] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:20:55,978] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52)
[15:20:55,979] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:20:55,980] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:20:55,980] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:20:55,989] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:20:55,997] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:20:55,999] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 19 ms on localhost (1/1)
[15:20:55,999] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:20:55,999] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.020 s
[15:20:55,999] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.029482 s
[15:20:56,020] INFO  {CodeGenerator} Code generated in 18.656321 ms
[15:20:56,066] INFO  {FileSourceStrategy} Pruning directories with: 
[15:20:56,066] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:20:56,067] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:20:56,067] INFO  {FileSourceStrategy} Pushed Filters: 
[15:20:56,072] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[15:20:56,082] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:20:56,083] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:42011 (size: 14.6 KB, free: 1128.8 MB)
[15:20:56,084] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:62
[15:20:56,084] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:20:56,157] INFO  {CodeGenerator} Code generated in 49.392406 ms
[15:20:56,167] INFO  {SparkContext} Starting job: show at Main.scala:62
[15:20:56,168] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[15:20:56,168] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[15:20:56,168] INFO  {DAGScheduler} Parents of final stage: List()
[15:20:56,168] INFO  {DAGScheduler} Missing parents: List()
[15:20:56,169] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62), which has no missing parents
[15:20:56,171] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.4 MB)
[15:20:56,173] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.4 MB)
[15:20:56,174] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:42011 (size: 10.9 KB, free: 1128.8 MB)
[15:20:56,174] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:20:56,174] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62)
[15:20:56,175] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:20:56,176] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:20:56,177] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:20:56,189] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:20:56,198] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:20:56,200] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 24 ms on localhost (1/1)
[15:20:56,200] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:20:56,200] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.025 s
[15:20:56,200] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.032819 s
[15:20:56,219] INFO  {CodeGenerator} Code generated in 16.278048 ms
[15:20:56,386] INFO  {ContextCleaner} Cleaned accumulator 47
[15:20:56,387] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:42011 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:20:56,391] INFO  {ContextCleaner} Cleaned accumulator 46
[15:20:56,392] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:42011 in memory (size: 8.2 KB, free: 1128.9 MB)
[15:20:56,394] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:42011 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:20:56,396] INFO  {ContextCleaner} Cleaned accumulator 92
[15:20:56,396] INFO  {ContextCleaner} Cleaned accumulator 93
[15:20:56,397] INFO  {FileSourceStrategy} Pruning directories with: 
[15:20:56,398] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:20:56,398] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:42011 in memory (size: 9.6 KB, free: 1128.9 MB)
[15:20:56,398] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:20:56,398] INFO  {FileSourceStrategy} Pushed Filters: 
[15:20:56,399] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:42011 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:20:56,400] INFO  {ContextCleaner} Cleaned accumulator 138
[15:20:56,400] INFO  {ContextCleaner} Cleaned accumulator 139
[15:20:56,401] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:42011 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:20:56,403] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:20:56,412] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:20:56,412] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:42011 (size: 14.6 KB, free: 1128.9 MB)
[15:20:56,413] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:66
[15:20:56,414] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:20:56,459] INFO  {CodeGenerator} Code generated in 12.913125 ms
[15:20:56,483] INFO  {CodeGenerator} Code generated in 19.1141 ms
[15:20:56,515] INFO  {SparkContext} Starting job: collect at Main.scala:66
[15:20:56,518] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:66)
[15:20:56,519] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:66) with 1 output partitions
[15:20:56,519] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:66)
[15:20:56,519] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[15:20:56,519] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[15:20:56,520] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66), which has no missing parents
[15:20:56,527] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[15:20:56,529] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[15:20:56,529] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:42011 (size: 8.3 KB, free: 1128.9 MB)
[15:20:56,530] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:20:56,531] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66)
[15:20:56,532] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:20:56,535] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[15:20:56,535] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:20:56,557] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:20:56,834] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[15:20:56,837] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 305 ms on localhost (1/1)
[15:20:56,837] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:20:56,838] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:66) finished in 0.306 s
[15:20:56,838] INFO  {DAGScheduler} looking for newly runnable stages
[15:20:56,838] INFO  {DAGScheduler} running: Set()
[15:20:56,839] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[15:20:56,839] INFO  {DAGScheduler} failed: Set()
[15:20:56,840] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66), which has no missing parents
[15:20:56,845] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[15:20:56,846] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[15:20:56,847] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:42011 (size: 3.9 KB, free: 1128.9 MB)
[15:20:56,848] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[15:20:56,848] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66)
[15:20:56,848] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:20:56,854] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[15:20:56,854] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:20:56,866] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[15:20:56,868] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[15:20:56,880] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1955 bytes result sent to driver
[15:20:56,881] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 30 ms on localhost (1/1)
[15:20:56,881] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:20:56,882] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:66) finished in 0.031 s
[15:20:56,882] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:66, took 0.366540 s
[15:20:56,892] INFO  {CodeGenerator} Code generated in 6.663548 ms
[15:20:56,960] INFO  {FileSourceStrategy} Pruning directories with: 
[15:20:56,960] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:20:56,961] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:20:56,961] INFO  {FileSourceStrategy} Pushed Filters: 
[15:20:56,965] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:20:56,973] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:20:56,975] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:42011 (size: 14.6 KB, free: 1128.9 MB)
[15:20:56,976] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:86
[15:20:56,976] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:20:57,060] INFO  {CodeGenerator} Code generated in 65.052093 ms
[15:20:57,071] INFO  {SparkContext} Starting job: show at Main.scala:86
[15:20:57,071] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[15:20:57,071] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:86)
[15:20:57,072] INFO  {DAGScheduler} Parents of final stage: List()
[15:20:57,072] INFO  {DAGScheduler} Missing parents: List()
[15:20:57,072] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[15:20:57,075] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 57.2 KB, free 1128.5 MB)
[15:20:57,079] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1128.5 MB)
[15:20:57,080] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:42011 (size: 14.5 KB, free: 1128.8 MB)
[15:20:57,080] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[15:20:57,080] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86)
[15:20:57,080] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[15:20:57,082] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:20:57,082] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[15:20:57,091] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:20:57,099] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3559 bytes result sent to driver
[15:20:57,100] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 18 ms on localhost (1/1)
[15:20:57,100] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[15:20:57,100] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:86) finished in 0.019 s
[15:20:57,101] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.030058 s
[15:20:57,119] INFO  {CodeGenerator} Code generated in 15.931291 ms
[15:20:57,145] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:20:57,150] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:20:57,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[15:20:57,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[15:20:57,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[15:20:57,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[15:20:57,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[15:20:57,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[15:20:57,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[15:20:57,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[15:20:57,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[15:20:57,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[15:20:57,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[15:20:57,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[15:20:57,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[15:20:57,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[15:20:57,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[15:20:57,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[15:20:57,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[15:20:57,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[15:20:57,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[15:20:57,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[15:20:57,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[15:20:57,156] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[15:20:57,156] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[15:20:57,156] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[15:20:57,158] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:20:57,170] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:20:57,177] INFO  {MemoryStore} MemoryStore cleared
[15:20:57,178] INFO  {BlockManager} BlockManager stopped
[15:20:57,180] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:20:57,182] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:20:57,184] INFO  {SparkContext} Successfully stopped SparkContext
[15:20:57,184] INFO  {ShutdownHookManager} Shutdown hook called
[15:20:57,185] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-55e6ecb4-1bf2-42dc-b757-0540fcfb58ab
[15:25:20,818] INFO  {SparkContext} Running Spark version 2.0.1
[15:25:21,080] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:25:21,188] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:25:21,192] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:25:21,281] INFO  {SecurityManager} Changing view acls to: victor
[15:25:21,282] INFO  {SecurityManager} Changing modify acls to: victor
[15:25:21,283] INFO  {SecurityManager} Changing view acls groups to: 
[15:25:21,284] INFO  {SecurityManager} Changing modify acls groups to: 
[15:25:21,284] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:25:21,653] INFO  {Utils} Successfully started service 'sparkDriver' on port 36583.
[15:25:21,671] INFO  {SparkEnv} Registering MapOutputTracker
[15:25:21,687] INFO  {SparkEnv} Registering BlockManagerMaster
[15:25:21,700] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-4455c288-4b89-4f58-9008-f8a407e2b205
[15:25:21,714] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:25:21,775] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:25:21,853] INFO  {log} Logging initialized @1648ms
[15:25:21,970] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:25:21,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[15:25:21,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[15:25:21,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[15:25:21,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[15:25:21,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[15:25:21,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[15:25:21,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[15:25:21,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[15:25:21,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[15:25:21,989] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[15:25:21,989] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[15:25:21,989] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[15:25:21,989] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[15:25:21,989] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[15:25:21,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[15:25:21,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[15:25:21,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[15:25:21,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[15:25:21,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[15:25:21,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[15:25:21,997] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[15:25:21,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[15:25:21,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[15:25:22,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[15:25:22,007] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[15:25:22,007] INFO  {Server} Started @1803ms
[15:25:22,007] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:25:22,009] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:25:22,112] INFO  {Executor} Starting executor ID driver on host localhost
[15:25:22,141] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37005.
[15:25:22,143] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:37005
[15:25:22,146] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 37005)
[15:25:22,150] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:37005 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 37005)
[15:25:22,153] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 37005)
[15:25:22,291] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[15:25:22,334] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL,null,AVAILABLE}
[15:25:22,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/json,null,AVAILABLE}
[15:25:22,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@24f360b2{/SQL/execution,null,AVAILABLE}
[15:25:22,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution/json,null,AVAILABLE}
[15:25:22,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6cea706c{/static/sql,null,AVAILABLE}
[15:25:22,351] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:25:24,296] INFO  {FileSourceStrategy} Pruning directories with: 
[15:25:24,297] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:25:24,302] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:25:24,302] INFO  {FileSourceStrategy} Pushed Filters: 
[15:25:24,414] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:25:24,458] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:25:24,460] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:37005 (size: 14.6 KB, free: 1128.9 MB)
[15:25:24,466] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[15:25:24,469] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:25:24,956] INFO  {CodeGenerator} Code generated in 214.834005 ms
[15:25:25,045] INFO  {SparkContext} Starting job: show at Main.scala:34
[15:25:25,060] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[15:25:25,061] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[15:25:25,061] INFO  {DAGScheduler} Parents of final stage: List()
[15:25:25,062] INFO  {DAGScheduler} Missing parents: List()
[15:25:25,066] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[15:25:25,110] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:25:25,112] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[15:25:25,113] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:37005 (size: 6.6 KB, free: 1128.9 MB)
[15:25:25,114] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:25:25,117] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[15:25:25,118] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:25:25,169] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:25:25,178] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:25:25,217] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:25:25,236] INFO  {CodeGenerator} Code generated in 14.912933 ms
[15:25:25,269] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[15:25:25,278] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 133 ms on localhost (1/1)
[15:25:25,279] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:25:25,284] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.156 s
[15:25:25,292] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.246282 s
[15:25:25,332] INFO  {CodeGenerator} Code generated in 26.341986 ms
[15:25:25,401] INFO  {FileSourceStrategy} Pruning directories with: 
[15:25:25,402] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:25:25,402] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:25:25,403] INFO  {FileSourceStrategy} Pushed Filters: 
[15:25:25,413] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:25:25,417] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:37005 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:25:25,420] INFO  {ContextCleaner} Cleaned accumulator 0
[15:25:25,420] INFO  {ContextCleaner} Cleaned accumulator 1
[15:25:25,421] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:37005 in memory (size: 6.6 KB, free: 1128.9 MB)
[15:25:25,425] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:25:25,426] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:37005 (size: 14.6 KB, free: 1128.9 MB)
[15:25:25,428] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[15:25:25,428] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:25:25,493] INFO  {CodeGenerator} Code generated in 41.013859 ms
[15:25:25,509] INFO  {SparkContext} Starting job: show at Main.scala:43
[15:25:25,510] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[15:25:25,510] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[15:25:25,510] INFO  {DAGScheduler} Parents of final stage: List()
[15:25:25,510] INFO  {DAGScheduler} Missing parents: List()
[15:25:25,511] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[15:25:25,515] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.7 MB)
[15:25:25,517] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[15:25:25,517] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:37005 (size: 8.2 KB, free: 1128.9 MB)
[15:25:25,518] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:25:25,518] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[15:25:25,518] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:25:25,521] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:25:25,521] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:25:25,530] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:25:25,544] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:25:25,546] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 27 ms on localhost (1/1)
[15:25:25,546] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:25:25,547] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.027 s
[15:25:25,547] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.038019 s
[15:25:25,580] INFO  {CodeGenerator} Code generated in 18.720484 ms
[15:25:25,676] INFO  {FileSourceStrategy} Pruning directories with: 
[15:25:25,676] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:25:25,677] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:25:25,677] INFO  {FileSourceStrategy} Pushed Filters: 
[15:25:25,683] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:25:25,693] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:25:25,693] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:37005 (size: 14.6 KB, free: 1128.9 MB)
[15:25:25,694] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:52
[15:25:25,695] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:25:25,752] INFO  {CodeGenerator} Code generated in 42.262646 ms
[15:25:25,761] INFO  {SparkContext} Starting job: show at Main.scala:52
[15:25:25,762] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[15:25:25,762] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[15:25:25,762] INFO  {DAGScheduler} Parents of final stage: List()
[15:25:25,763] INFO  {DAGScheduler} Missing parents: List()
[15:25:25,763] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52), which has no missing parents
[15:25:25,767] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.6 MB)
[15:25:25,769] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.5 MB)
[15:25:25,769] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:37005 (size: 9.6 KB, free: 1128.9 MB)
[15:25:25,770] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:25:25,770] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52)
[15:25:25,770] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:25:25,772] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:25:25,772] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:25:25,782] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:25:25,790] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:25:25,792] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 21 ms on localhost (1/1)
[15:25:25,792] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:25:25,793] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.022 s
[15:25:25,793] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.031906 s
[15:25:25,812] INFO  {CodeGenerator} Code generated in 16.373282 ms
[15:25:25,876] INFO  {FileSourceStrategy} Pruning directories with: 
[15:25:25,876] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:25:25,877] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:25:25,877] INFO  {FileSourceStrategy} Pushed Filters: 
[15:25:25,886] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[15:25:25,899] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:25:25,900] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:37005 (size: 14.6 KB, free: 1128.8 MB)
[15:25:25,901] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:62
[15:25:25,901] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:25:25,981] INFO  {CodeGenerator} Code generated in 56.09201 ms
[15:25:25,992] INFO  {SparkContext} Starting job: show at Main.scala:62
[15:25:25,993] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[15:25:25,993] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[15:25:25,993] INFO  {DAGScheduler} Parents of final stage: List()
[15:25:25,993] INFO  {DAGScheduler} Missing parents: List()
[15:25:25,994] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62), which has no missing parents
[15:25:25,996] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.4 MB)
[15:25:25,998] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.4 MB)
[15:25:25,999] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:37005 (size: 10.9 KB, free: 1128.8 MB)
[15:25:26,000] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:25:26,000] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62)
[15:25:26,000] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:25:26,002] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:25:26,002] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:25:26,010] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:25:26,018] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:25:26,019] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 18 ms on localhost (1/1)
[15:25:26,020] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:25:26,020] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.019 s
[15:25:26,020] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.027858 s
[15:25:26,038] INFO  {CodeGenerator} Code generated in 15.635927 ms
[15:25:26,193] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:37005 in memory (size: 9.6 KB, free: 1128.8 MB)
[15:25:26,194] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:37005 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:25:26,195] INFO  {ContextCleaner} Cleaned accumulator 138
[15:25:26,195] INFO  {ContextCleaner} Cleaned accumulator 139
[15:25:26,195] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:37005 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:25:26,196] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:37005 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:25:26,197] INFO  {ContextCleaner} Cleaned accumulator 46
[15:25:26,197] INFO  {ContextCleaner} Cleaned accumulator 47
[15:25:26,198] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:37005 in memory (size: 8.2 KB, free: 1128.9 MB)
[15:25:26,199] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:37005 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:25:26,199] INFO  {ContextCleaner} Cleaned accumulator 92
[15:25:26,199] INFO  {ContextCleaner} Cleaned accumulator 93
[15:25:26,201] INFO  {FileSourceStrategy} Pruning directories with: 
[15:25:26,201] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:25:26,201] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:25:26,202] INFO  {FileSourceStrategy} Pushed Filters: 
[15:25:26,205] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:25:26,212] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:25:26,213] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:37005 (size: 14.6 KB, free: 1128.9 MB)
[15:25:26,214] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:66
[15:25:26,214] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:25:26,268] INFO  {CodeGenerator} Code generated in 17.844336 ms
[15:25:26,298] INFO  {CodeGenerator} Code generated in 22.847948 ms
[15:25:26,336] INFO  {SparkContext} Starting job: collect at Main.scala:66
[15:25:26,339] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:66)
[15:25:26,340] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:66) with 1 output partitions
[15:25:26,340] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:66)
[15:25:26,340] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[15:25:26,340] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[15:25:26,342] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66), which has no missing parents
[15:25:26,349] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[15:25:26,351] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[15:25:26,351] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:37005 (size: 8.3 KB, free: 1128.9 MB)
[15:25:26,352] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:25:26,353] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66)
[15:25:26,354] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:25:26,356] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[15:25:26,357] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:25:26,374] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:25:26,651] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[15:25:26,653] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 299 ms on localhost (1/1)
[15:25:26,653] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:25:26,654] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:66) finished in 0.300 s
[15:25:26,655] INFO  {DAGScheduler} looking for newly runnable stages
[15:25:26,655] INFO  {DAGScheduler} running: Set()
[15:25:26,656] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[15:25:26,656] INFO  {DAGScheduler} failed: Set()
[15:25:26,658] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66), which has no missing parents
[15:25:26,664] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[15:25:26,665] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[15:25:26,666] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:37005 (size: 3.9 KB, free: 1128.9 MB)
[15:25:26,666] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[15:25:26,666] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66)
[15:25:26,666] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:25:26,672] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[15:25:26,673] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:25:26,686] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[15:25:26,688] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[15:25:26,701] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[15:25:26,702] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 32 ms on localhost (1/1)
[15:25:26,702] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:25:26,702] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:66) finished in 0.032 s
[15:25:26,703] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:66, took 0.366107 s
[15:25:26,712] INFO  {CodeGenerator} Code generated in 6.686661 ms
[15:25:26,769] INFO  {FileSourceStrategy} Pruning directories with: 
[15:25:26,769] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:25:26,770] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:25:26,770] INFO  {FileSourceStrategy} Pushed Filters: 
[15:25:26,773] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:25:26,782] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:25:26,783] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:37005 (size: 14.6 KB, free: 1128.9 MB)
[15:25:26,783] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:86
[15:25:26,784] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:25:26,860] INFO  {CodeGenerator} Code generated in 57.041688 ms
[15:25:26,868] INFO  {SparkContext} Starting job: show at Main.scala:86
[15:25:26,869] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[15:25:26,869] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:86)
[15:25:26,869] INFO  {DAGScheduler} Parents of final stage: List()
[15:25:26,869] INFO  {DAGScheduler} Missing parents: List()
[15:25:26,870] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[15:25:26,872] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 57.2 KB, free 1128.5 MB)
[15:25:26,874] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1128.5 MB)
[15:25:26,876] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:37005 (size: 14.5 KB, free: 1128.8 MB)
[15:25:26,877] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[15:25:26,877] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86)
[15:25:26,877] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[15:25:26,879] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:25:26,879] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[15:25:26,889] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:25:26,895] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3559 bytes result sent to driver
[15:25:26,896] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 18 ms on localhost (1/1)
[15:25:26,896] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[15:25:26,897] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:86) finished in 0.019 s
[15:25:26,897] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.028413 s
[15:25:26,912] INFO  {CodeGenerator} Code generated in 13.150052 ms
[15:25:26,921] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:25:26,926] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[15:25:26,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[15:25:26,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[15:25:26,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[15:25:26,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[15:25:26,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[15:25:26,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[15:25:26,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[15:25:26,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[15:25:26,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[15:25:26,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[15:25:26,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[15:25:26,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[15:25:26,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[15:25:26,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[15:25:26,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[15:25:26,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[15:25:26,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[15:25:26,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[15:25:26,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[15:25:26,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[15:25:26,932] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[15:25:26,932] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[15:25:26,932] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[15:25:26,932] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[15:25:26,934] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:25:26,943] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:25:26,950] INFO  {MemoryStore} MemoryStore cleared
[15:25:26,951] INFO  {BlockManager} BlockManager stopped
[15:25:26,953] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:25:26,956] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:25:26,962] INFO  {SparkContext} Successfully stopped SparkContext
[15:25:26,963] INFO  {ShutdownHookManager} Shutdown hook called
[15:25:26,964] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-1f43c95f-44e4-4f72-b595-d6098b96d98c
[15:26:13,035] INFO  {SparkContext} Running Spark version 2.0.1
[15:26:13,283] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:26:13,378] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:26:13,378] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:26:13,445] INFO  {SecurityManager} Changing view acls to: victor
[15:26:13,446] INFO  {SecurityManager} Changing modify acls to: victor
[15:26:13,447] INFO  {SecurityManager} Changing view acls groups to: 
[15:26:13,447] INFO  {SecurityManager} Changing modify acls groups to: 
[15:26:13,448] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:26:13,790] INFO  {Utils} Successfully started service 'sparkDriver' on port 45027.
[15:26:13,806] INFO  {SparkEnv} Registering MapOutputTracker
[15:26:13,821] INFO  {SparkEnv} Registering BlockManagerMaster
[15:26:13,833] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-57895c20-32c1-42fd-8830-f2da50d77edb
[15:26:13,847] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:26:13,903] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:26:13,975] INFO  {log} Logging initialized @1540ms
[15:26:14,080] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:26:14,098] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[15:26:14,099] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[15:26:14,099] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[15:26:14,100] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[15:26:14,101] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[15:26:14,101] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[15:26:14,101] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[15:26:14,101] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[15:26:14,102] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[15:26:14,102] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[15:26:14,102] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[15:26:14,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[15:26:14,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[15:26:14,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[15:26:14,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[15:26:14,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[15:26:14,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[15:26:14,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[15:26:14,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[15:26:14,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[15:26:14,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[15:26:14,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[15:26:14,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[15:26:14,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[15:26:14,124] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:26:14,124] INFO  {Server} Started @1690ms
[15:26:14,124] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:26:14,126] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:26:14,233] INFO  {Executor} Starting executor ID driver on host localhost
[15:26:14,266] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40829.
[15:26:14,268] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:40829
[15:26:14,270] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 40829)
[15:26:14,273] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:40829 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 40829)
[15:26:14,276] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 40829)
[15:26:14,402] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[15:26:14,449] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[15:26:14,450] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[15:26:14,451] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[15:26:14,452] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[15:26:14,454] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[15:26:14,471] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:26:16,343] INFO  {FileSourceStrategy} Pruning directories with: 
[15:26:16,344] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:26:16,349] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:26:16,350] INFO  {FileSourceStrategy} Pushed Filters: 
[15:26:16,456] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:26:16,502] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:26:16,503] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:40829 (size: 14.6 KB, free: 1128.9 MB)
[15:26:16,511] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[15:26:16,516] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:26:17,049] INFO  {CodeGenerator} Code generated in 233.818782 ms
[15:26:17,143] INFO  {SparkContext} Starting job: show at Main.scala:34
[15:26:17,159] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[15:26:17,160] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[15:26:17,160] INFO  {DAGScheduler} Parents of final stage: List()
[15:26:17,161] INFO  {DAGScheduler} Missing parents: List()
[15:26:17,167] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[15:26:17,212] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:26:17,214] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KB, free 1128.7 MB)
[15:26:17,214] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:40829 (size: 6.7 KB, free: 1128.9 MB)
[15:26:17,215] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:26:17,218] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[15:26:17,220] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:26:17,256] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:26:17,263] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:26:17,300] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:26:17,318] INFO  {CodeGenerator} Code generated in 14.205982 ms
[15:26:17,354] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[15:26:17,363] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 125 ms on localhost (1/1)
[15:26:17,365] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:26:17,370] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.142 s
[15:26:17,376] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.232373 s
[15:26:17,418] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:40829 in memory (size: 6.7 KB, free: 1128.9 MB)
[15:26:17,426] INFO  {CodeGenerator} Code generated in 20.385093 ms
[15:26:17,477] INFO  {FileSourceStrategy} Pruning directories with: 
[15:26:17,478] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:26:17,478] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:26:17,478] INFO  {FileSourceStrategy} Pushed Filters: 
[15:26:17,485] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:26:17,497] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:26:17,498] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:40829 (size: 14.6 KB, free: 1128.9 MB)
[15:26:17,499] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[15:26:17,499] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:26:17,549] INFO  {CodeGenerator} Code generated in 33.370288 ms
[15:26:17,561] INFO  {SparkContext} Starting job: show at Main.scala:43
[15:26:17,562] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[15:26:17,562] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[15:26:17,563] INFO  {DAGScheduler} Parents of final stage: List()
[15:26:17,563] INFO  {DAGScheduler} Missing parents: List()
[15:26:17,563] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[15:26:17,568] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[15:26:17,569] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[15:26:17,570] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:40829 (size: 8.2 KB, free: 1128.9 MB)
[15:26:17,571] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:26:17,571] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[15:26:17,571] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:26:17,573] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:26:17,574] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:26:17,588] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:26:17,605] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:26:17,607] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on localhost (1/1)
[15:26:17,607] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:26:17,607] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.035 s
[15:26:17,608] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.046156 s
[15:26:17,638] INFO  {CodeGenerator} Code generated in 18.093485 ms
[15:26:17,731] INFO  {FileSourceStrategy} Pruning directories with: 
[15:26:17,731] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:26:17,731] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:26:17,731] INFO  {FileSourceStrategy} Pushed Filters: 
[15:26:17,737] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[15:26:17,745] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:26:17,746] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:40829 (size: 14.6 KB, free: 1128.8 MB)
[15:26:17,746] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:52
[15:26:17,747] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:26:17,804] INFO  {CodeGenerator} Code generated in 42.215949 ms
[15:26:17,814] INFO  {SparkContext} Starting job: show at Main.scala:52
[15:26:17,815] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[15:26:17,815] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[15:26:17,815] INFO  {DAGScheduler} Parents of final stage: List()
[15:26:17,815] INFO  {DAGScheduler} Missing parents: List()
[15:26:17,816] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52), which has no missing parents
[15:26:17,821] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[15:26:17,823] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[15:26:17,823] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:40829 (size: 9.6 KB, free: 1128.8 MB)
[15:26:17,824] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:26:17,824] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52)
[15:26:17,825] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:26:17,827] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:26:17,827] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:26:17,836] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:26:17,846] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:26:17,847] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 22 ms on localhost (1/1)
[15:26:17,847] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:26:17,848] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.023 s
[15:26:17,848] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.034029 s
[15:26:17,876] INFO  {CodeGenerator} Code generated in 25.632538 ms
[15:26:17,936] INFO  {FileSourceStrategy} Pruning directories with: 
[15:26:17,936] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:26:17,937] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:26:17,937] INFO  {FileSourceStrategy} Pushed Filters: 
[15:26:17,943] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[15:26:17,951] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.3 MB)
[15:26:17,952] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:40829 (size: 14.6 KB, free: 1128.8 MB)
[15:26:17,952] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:62
[15:26:17,953] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:26:18,017] INFO  {CodeGenerator} Code generated in 46.259202 ms
[15:26:18,026] INFO  {SparkContext} Starting job: show at Main.scala:62
[15:26:18,027] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[15:26:18,027] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[15:26:18,027] INFO  {DAGScheduler} Parents of final stage: List()
[15:26:18,028] INFO  {DAGScheduler} Missing parents: List()
[15:26:18,028] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62), which has no missing parents
[15:26:18,030] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[15:26:18,032] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[15:26:18,032] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:40829 (size: 10.9 KB, free: 1128.8 MB)
[15:26:18,033] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:26:18,033] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62)
[15:26:18,033] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:26:18,035] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:26:18,035] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:26:18,046] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:26:18,055] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3575 bytes result sent to driver
[15:26:18,056] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 23 ms on localhost (1/1)
[15:26:18,056] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:26:18,057] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.024 s
[15:26:18,057] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.030641 s
[15:26:18,073] INFO  {CodeGenerator} Code generated in 13.851802 ms
[15:26:18,244] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:40829 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:26:18,245] INFO  {ContextCleaner} Cleaned accumulator 0
[15:26:18,245] INFO  {ContextCleaner} Cleaned accumulator 1
[15:26:18,246] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:40829 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:26:18,247] INFO  {ContextCleaner} Cleaned accumulator 46
[15:26:18,247] INFO  {ContextCleaner} Cleaned accumulator 47
[15:26:18,247] INFO  {FileSourceStrategy} Pruning directories with: 
[15:26:18,247] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:26:18,247] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:40829 in memory (size: 8.2 KB, free: 1128.9 MB)
[15:26:18,248] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:26:18,248] INFO  {FileSourceStrategy} Pushed Filters: 
[15:26:18,249] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:40829 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:26:18,251] INFO  {ContextCleaner} Cleaned accumulator 92
[15:26:18,251] INFO  {ContextCleaner} Cleaned accumulator 93
[15:26:18,252] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[15:26:18,253] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:40829 in memory (size: 9.6 KB, free: 1128.9 MB)
[15:26:18,254] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:40829 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:26:18,255] INFO  {ContextCleaner} Cleaned accumulator 138
[15:26:18,255] INFO  {ContextCleaner} Cleaned accumulator 139
[15:26:18,256] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:40829 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:26:18,261] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:26:18,261] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:40829 (size: 14.6 KB, free: 1128.9 MB)
[15:26:18,262] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:66
[15:26:18,262] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:26:18,307] INFO  {CodeGenerator} Code generated in 13.987812 ms
[15:26:18,335] INFO  {CodeGenerator} Code generated in 21.337953 ms
[15:26:18,367] INFO  {SparkContext} Starting job: collect at Main.scala:66
[15:26:18,371] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:66)
[15:26:18,372] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:66) with 1 output partitions
[15:26:18,372] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:66)
[15:26:18,372] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[15:26:18,372] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[15:26:18,373] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66), which has no missing parents
[15:26:18,378] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[15:26:18,380] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[15:26:18,380] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:40829 (size: 8.3 KB, free: 1128.9 MB)
[15:26:18,381] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:26:18,382] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66)
[15:26:18,383] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:26:18,385] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[15:26:18,385] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:26:18,401] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:26:18,688] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[15:26:18,690] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 307 ms on localhost (1/1)
[15:26:18,690] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:26:18,691] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:66) finished in 0.308 s
[15:26:18,691] INFO  {DAGScheduler} looking for newly runnable stages
[15:26:18,692] INFO  {DAGScheduler} running: Set()
[15:26:18,692] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[15:26:18,693] INFO  {DAGScheduler} failed: Set()
[15:26:18,694] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66), which has no missing parents
[15:26:18,699] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[15:26:18,700] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[15:26:18,701] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:40829 (size: 3.9 KB, free: 1128.9 MB)
[15:26:18,702] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[15:26:18,702] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66)
[15:26:18,702] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:26:18,707] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[15:26:18,707] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:26:18,722] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[15:26:18,724] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[15:26:18,740] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[15:26:18,741] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 35 ms on localhost (1/1)
[15:26:18,741] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:26:18,741] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:66) finished in 0.036 s
[15:26:18,742] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:66, took 0.374131 s
[15:26:18,751] INFO  {CodeGenerator} Code generated in 6.323292 ms
[15:26:18,815] INFO  {FileSourceStrategy} Pruning directories with: 
[15:26:18,815] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:26:18,816] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:26:18,816] INFO  {FileSourceStrategy} Pushed Filters: 
[15:26:18,819] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:26:18,827] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:26:18,827] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:40829 (size: 14.6 KB, free: 1128.9 MB)
[15:26:18,828] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:86
[15:26:18,828] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:26:18,914] INFO  {CodeGenerator} Code generated in 63.929887 ms
[15:26:18,924] INFO  {SparkContext} Starting job: show at Main.scala:86
[15:26:18,925] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[15:26:18,925] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:86)
[15:26:18,925] INFO  {DAGScheduler} Parents of final stage: List()
[15:26:18,926] INFO  {DAGScheduler} Missing parents: List()
[15:26:18,926] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[15:26:18,929] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 57.2 KB, free 1128.5 MB)
[15:26:18,930] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[15:26:18,931] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:40829 (size: 14.6 KB, free: 1128.8 MB)
[15:26:18,932] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[15:26:18,932] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86)
[15:26:18,932] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[15:26:18,934] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:26:18,934] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[15:26:18,945] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:26:18,952] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3559 bytes result sent to driver
[15:26:18,953] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 20 ms on localhost (1/1)
[15:26:18,954] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[15:26:18,954] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:86) finished in 0.022 s
[15:26:18,954] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.029754 s
[15:26:18,971] INFO  {CodeGenerator} Code generated in 14.075648 ms
[15:26:18,980] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:26:18,984] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:26:18,986] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[15:26:18,986] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[15:26:18,986] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[15:26:18,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[15:26:18,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[15:26:18,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[15:26:18,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[15:26:18,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[15:26:18,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[15:26:18,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[15:26:18,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[15:26:18,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[15:26:18,987] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[15:26:18,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[15:26:18,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[15:26:18,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[15:26:18,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[15:26:18,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[15:26:18,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[15:26:18,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[15:26:18,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[15:26:18,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[15:26:18,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[15:26:18,988] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[15:26:18,990] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:26:19,002] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:26:19,010] INFO  {MemoryStore} MemoryStore cleared
[15:26:19,010] INFO  {BlockManager} BlockManager stopped
[15:26:19,012] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:26:19,015] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:26:19,020] INFO  {SparkContext} Successfully stopped SparkContext
[15:26:19,020] INFO  {ShutdownHookManager} Shutdown hook called
[15:26:19,021] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-5360f810-c1ac-4b96-a3e3-26bfce6c84d3
[15:27:27,013] INFO  {SparkContext} Running Spark version 2.0.1
[15:27:27,259] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:27:27,378] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:27:27,379] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:27:27,462] INFO  {SecurityManager} Changing view acls to: victor
[15:27:27,463] INFO  {SecurityManager} Changing modify acls to: victor
[15:27:27,464] INFO  {SecurityManager} Changing view acls groups to: 
[15:27:27,465] INFO  {SecurityManager} Changing modify acls groups to: 
[15:27:27,466] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:27:27,789] INFO  {Utils} Successfully started service 'sparkDriver' on port 34547.
[15:27:27,805] INFO  {SparkEnv} Registering MapOutputTracker
[15:27:27,821] INFO  {SparkEnv} Registering BlockManagerMaster
[15:27:27,834] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-246eb79b-7491-4e4d-adbf-bbf44976e667
[15:27:27,850] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:27:27,900] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:27:27,970] INFO  {log} Logging initialized @1682ms
[15:27:28,074] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:27:28,091] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[15:27:28,092] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[15:27:28,092] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[15:27:28,092] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[15:27:28,092] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[15:27:28,093] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[15:27:28,093] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[15:27:28,094] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[15:27:28,094] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[15:27:28,095] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[15:27:28,095] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[15:27:28,096] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[15:27:28,096] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[15:27:28,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[15:27:28,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[15:27:28,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[15:27:28,098] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[15:27:28,098] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[15:27:28,098] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[15:27:28,099] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[15:27:28,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[15:27:28,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[15:27:28,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[15:27:28,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[15:27:28,117] INFO  {ServerConnector} Started ServerConnector@44d3d266{HTTP/1.1}{0.0.0.0:4040}
[15:27:28,117] INFO  {Server} Started @1830ms
[15:27:28,117] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:27:28,120] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:27:28,217] INFO  {Executor} Starting executor ID driver on host localhost
[15:27:28,243] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34443.
[15:27:28,244] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:34443
[15:27:28,246] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 34443)
[15:27:28,249] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:34443 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 34443)
[15:27:28,252] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 34443)
[15:27:28,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[15:27:28,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@759fad4{/SQL,null,AVAILABLE}
[15:27:28,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53499d85{/SQL/json,null,AVAILABLE}
[15:27:28,430] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/execution,null,AVAILABLE}
[15:27:28,431] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL/execution/json,null,AVAILABLE}
[15:27:28,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@24f360b2{/static/sql,null,AVAILABLE}
[15:27:28,448] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:27:30,331] INFO  {FileSourceStrategy} Pruning directories with: 
[15:27:30,332] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:27:30,336] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:27:30,337] INFO  {FileSourceStrategy} Pushed Filters: 
[15:27:30,444] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:27:30,494] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:27:30,496] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:34443 (size: 14.6 KB, free: 1128.9 MB)
[15:27:30,503] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[15:27:30,508] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:27:30,989] INFO  {CodeGenerator} Code generated in 208.577626 ms
[15:27:31,081] INFO  {SparkContext} Starting job: show at Main.scala:34
[15:27:31,096] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[15:27:31,097] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[15:27:31,097] INFO  {DAGScheduler} Parents of final stage: List()
[15:27:31,099] INFO  {DAGScheduler} Missing parents: List()
[15:27:31,104] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[15:27:31,145] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:27:31,147] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[15:27:31,148] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:34443 (size: 6.6 KB, free: 1128.9 MB)
[15:27:31,148] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:27:31,151] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[15:27:31,153] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:27:31,191] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:27:31,198] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:27:31,238] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:27:31,255] INFO  {CodeGenerator} Code generated in 13.187562 ms
[15:27:31,290] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[15:27:31,299] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 126 ms on localhost (1/1)
[15:27:31,300] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:27:31,306] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.144 s
[15:27:31,312] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.230661 s
[15:27:31,346] INFO  {CodeGenerator} Code generated in 18.039518 ms
[15:27:31,415] INFO  {FileSourceStrategy} Pruning directories with: 
[15:27:31,415] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:27:31,416] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:27:31,416] INFO  {FileSourceStrategy} Pushed Filters: 
[15:27:31,423] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:27:31,428] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:34443 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:27:31,433] INFO  {ContextCleaner} Cleaned accumulator 0
[15:27:31,433] INFO  {ContextCleaner} Cleaned accumulator 1
[15:27:31,435] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:34443 in memory (size: 6.6 KB, free: 1128.9 MB)
[15:27:31,436] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:27:31,437] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:34443 (size: 14.6 KB, free: 1128.9 MB)
[15:27:31,439] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[15:27:31,439] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:27:31,502] INFO  {CodeGenerator} Code generated in 39.604893 ms
[15:27:31,519] INFO  {SparkContext} Starting job: show at Main.scala:43
[15:27:31,521] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[15:27:31,521] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[15:27:31,521] INFO  {DAGScheduler} Parents of final stage: List()
[15:27:31,521] INFO  {DAGScheduler} Missing parents: List()
[15:27:31,521] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[15:27:31,526] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.7 MB)
[15:27:31,531] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[15:27:31,532] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:34443 (size: 8.2 KB, free: 1128.9 MB)
[15:27:31,532] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:27:31,533] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[15:27:31,533] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:27:31,536] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:27:31,536] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:27:31,550] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:27:31,569] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:27:31,574] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 40 ms on localhost (1/1)
[15:27:31,574] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:27:31,575] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.039 s
[15:27:31,575] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.055491 s
[15:27:31,605] INFO  {CodeGenerator} Code generated in 19.051625 ms
[15:27:31,684] INFO  {FileSourceStrategy} Pruning directories with: 
[15:27:31,684] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:27:31,686] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:27:31,686] INFO  {FileSourceStrategy} Pushed Filters: 
[15:27:31,692] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:27:31,700] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:27:31,701] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:34443 (size: 14.6 KB, free: 1128.9 MB)
[15:27:31,701] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:52
[15:27:31,701] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:27:31,770] INFO  {CodeGenerator} Code generated in 48.871733 ms
[15:27:31,783] INFO  {SparkContext} Starting job: show at Main.scala:52
[15:27:31,784] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[15:27:31,784] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[15:27:31,784] INFO  {DAGScheduler} Parents of final stage: List()
[15:27:31,784] INFO  {DAGScheduler} Missing parents: List()
[15:27:31,784] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52), which has no missing parents
[15:27:31,788] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.6 MB)
[15:27:31,790] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.5 MB)
[15:27:31,790] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:34443 (size: 9.6 KB, free: 1128.9 MB)
[15:27:31,791] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:27:31,791] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52)
[15:27:31,791] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:27:31,793] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:27:31,793] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:27:31,805] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:27:31,818] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:27:31,822] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (1/1)
[15:27:31,823] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:27:31,823] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.031 s
[15:27:31,823] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.040599 s
[15:27:31,842] INFO  {CodeGenerator} Code generated in 15.900401 ms
[15:27:31,884] INFO  {FileSourceStrategy} Pruning directories with: 
[15:27:31,884] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:27:31,885] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:27:31,885] INFO  {FileSourceStrategy} Pushed Filters: 
[15:27:31,890] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[15:27:31,899] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:27:31,900] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:34443 (size: 14.6 KB, free: 1128.8 MB)
[15:27:31,901] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:62
[15:27:31,901] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:27:31,966] INFO  {CodeGenerator} Code generated in 43.481923 ms
[15:27:31,976] INFO  {SparkContext} Starting job: show at Main.scala:62
[15:27:31,977] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[15:27:31,977] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[15:27:31,977] INFO  {DAGScheduler} Parents of final stage: List()
[15:27:31,978] INFO  {DAGScheduler} Missing parents: List()
[15:27:31,978] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62), which has no missing parents
[15:27:31,982] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.4 MB)
[15:27:31,986] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.4 MB)
[15:27:31,987] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:34443 (size: 10.9 KB, free: 1128.8 MB)
[15:27:31,987] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:27:31,988] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62)
[15:27:31,988] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:27:31,990] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:27:31,990] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:27:31,999] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:27:32,007] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:27:32,008] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on localhost (1/1)
[15:27:32,008] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:27:32,009] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.020 s
[15:27:32,009] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.032863 s
[15:27:32,025] INFO  {CodeGenerator} Code generated in 13.560078 ms
[15:27:32,192] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:34443 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:27:32,193] INFO  {ContextCleaner} Cleaned accumulator 46
[15:27:32,193] INFO  {ContextCleaner} Cleaned accumulator 47
[15:27:32,194] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:34443 in memory (size: 8.2 KB, free: 1128.9 MB)
[15:27:32,195] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:34443 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:27:32,195] INFO  {ContextCleaner} Cleaned accumulator 92
[15:27:32,196] INFO  {ContextCleaner} Cleaned accumulator 93
[15:27:32,198] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:34443 in memory (size: 9.6 KB, free: 1128.9 MB)
[15:27:32,200] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:34443 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:27:32,201] INFO  {ContextCleaner} Cleaned accumulator 138
[15:27:32,202] INFO  {ContextCleaner} Cleaned accumulator 139
[15:27:32,203] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:34443 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:27:32,207] INFO  {FileSourceStrategy} Pruning directories with: 
[15:27:32,208] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:27:32,208] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:27:32,208] INFO  {FileSourceStrategy} Pushed Filters: 
[15:27:32,214] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:27:32,228] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:27:32,228] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:34443 (size: 14.6 KB, free: 1128.9 MB)
[15:27:32,229] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:66
[15:27:32,229] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:27:32,282] INFO  {CodeGenerator} Code generated in 14.204968 ms
[15:27:32,307] INFO  {CodeGenerator} Code generated in 19.98923 ms
[15:27:32,343] INFO  {SparkContext} Starting job: collect at Main.scala:66
[15:27:32,347] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:66)
[15:27:32,348] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:66) with 1 output partitions
[15:27:32,348] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:66)
[15:27:32,348] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[15:27:32,348] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[15:27:32,350] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66), which has no missing parents
[15:27:32,360] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[15:27:32,362] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[15:27:32,363] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:34443 (size: 8.3 KB, free: 1128.9 MB)
[15:27:32,364] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:27:32,366] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66)
[15:27:32,366] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:27:32,369] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[15:27:32,369] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:27:32,388] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:27:32,741] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[15:27:32,745] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 377 ms on localhost (1/1)
[15:27:32,745] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:27:32,746] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:66) finished in 0.378 s
[15:27:32,746] INFO  {DAGScheduler} looking for newly runnable stages
[15:27:32,746] INFO  {DAGScheduler} running: Set()
[15:27:32,747] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[15:27:32,747] INFO  {DAGScheduler} failed: Set()
[15:27:32,748] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66), which has no missing parents
[15:27:32,752] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[15:27:32,754] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[15:27:32,754] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:34443 (size: 3.9 KB, free: 1128.9 MB)
[15:27:32,755] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[15:27:32,755] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66)
[15:27:32,755] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:27:32,761] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[15:27:32,762] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:27:32,776] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[15:27:32,777] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[15:27:32,790] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[15:27:32,791] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 31 ms on localhost (1/1)
[15:27:32,791] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:27:32,792] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:66) finished in 0.032 s
[15:27:32,792] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:66, took 0.448686 s
[15:27:32,805] INFO  {CodeGenerator} Code generated in 8.70015 ms
[15:27:32,883] INFO  {FileSourceStrategy} Pruning directories with: 
[15:27:32,884] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:27:32,884] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:27:32,884] INFO  {FileSourceStrategy} Pushed Filters: 
[15:27:32,887] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:27:32,895] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:27:32,895] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:34443 (size: 14.6 KB, free: 1128.9 MB)
[15:27:32,896] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:86
[15:27:32,896] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:27:32,972] INFO  {CodeGenerator} Code generated in 56.057437 ms
[15:27:32,981] INFO  {SparkContext} Starting job: show at Main.scala:86
[15:27:32,982] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[15:27:32,982] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:86)
[15:27:32,982] INFO  {DAGScheduler} Parents of final stage: List()
[15:27:32,982] INFO  {DAGScheduler} Missing parents: List()
[15:27:32,983] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[15:27:32,985] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 57.2 KB, free 1128.5 MB)
[15:27:32,987] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[15:27:32,988] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:34443 (size: 14.6 KB, free: 1128.8 MB)
[15:27:32,988] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[15:27:32,989] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86)
[15:27:32,989] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[15:27:32,990] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:27:32,991] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[15:27:33,001] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:27:33,010] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3559 bytes result sent to driver
[15:27:33,011] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 22 ms on localhost (1/1)
[15:27:33,012] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[15:27:33,012] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:86) finished in 0.023 s
[15:27:33,013] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.031448 s
[15:27:33,035] INFO  {CodeGenerator} Code generated in 18.372354 ms
[15:27:33,048] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:27:33,054] INFO  {ServerConnector} Stopped ServerConnector@44d3d266{HTTP/1.1}{0.0.0.0:4040}
[15:27:33,056] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[15:27:33,057] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[15:27:33,057] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[15:27:33,057] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[15:27:33,057] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[15:27:33,057] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[15:27:33,057] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[15:27:33,057] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[15:27:33,057] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[15:27:33,058] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[15:27:33,058] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[15:27:33,058] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[15:27:33,058] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[15:27:33,058] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[15:27:33,058] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[15:27:33,058] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[15:27:33,058] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[15:27:33,059] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[15:27:33,059] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[15:27:33,059] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[15:27:33,059] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[15:27:33,059] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[15:27:33,059] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[15:27:33,059] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[15:27:33,062] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:27:33,075] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:27:33,088] INFO  {MemoryStore} MemoryStore cleared
[15:27:33,089] INFO  {BlockManager} BlockManager stopped
[15:27:33,091] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:27:33,094] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:27:33,104] INFO  {SparkContext} Successfully stopped SparkContext
[15:27:33,104] INFO  {ShutdownHookManager} Shutdown hook called
[15:27:33,106] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-4a843aee-e115-4765-8f06-befe88a2972f
[15:29:07,853] INFO  {SparkContext} Running Spark version 2.0.1
[15:29:08,084] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:29:08,197] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:29:08,198] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:29:08,270] INFO  {SecurityManager} Changing view acls to: victor
[15:29:08,271] INFO  {SecurityManager} Changing modify acls to: victor
[15:29:08,273] INFO  {SecurityManager} Changing view acls groups to: 
[15:29:08,276] INFO  {SecurityManager} Changing modify acls groups to: 
[15:29:08,277] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:29:08,670] INFO  {Utils} Successfully started service 'sparkDriver' on port 40243.
[15:29:08,696] INFO  {SparkEnv} Registering MapOutputTracker
[15:29:08,713] INFO  {SparkEnv} Registering BlockManagerMaster
[15:29:08,725] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-4863dc0e-678a-4c5e-b9bb-52d1b8a0a6c1
[15:29:08,741] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:29:08,808] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:29:08,889] INFO  {log} Logging initialized @1694ms
[15:29:08,989] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:29:09,006] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[15:29:09,006] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[15:29:09,006] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[15:29:09,007] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[15:29:09,007] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[15:29:09,007] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[15:29:09,008] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[15:29:09,008] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[15:29:09,008] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[15:29:09,008] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[15:29:09,009] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[15:29:09,009] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[15:29:09,009] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[15:29:09,009] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[15:29:09,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[15:29:09,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[15:29:09,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[15:29:09,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[15:29:09,011] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[15:29:09,011] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[15:29:09,020] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[15:29:09,020] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[15:29:09,021] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[15:29:09,021] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[15:29:09,030] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:29:09,030] INFO  {Server} Started @1835ms
[15:29:09,030] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:29:09,033] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:29:09,141] INFO  {Executor} Starting executor ID driver on host localhost
[15:29:09,167] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34625.
[15:29:09,168] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:34625
[15:29:09,169] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 34625)
[15:29:09,171] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:34625 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 34625)
[15:29:09,174] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 34625)
[15:29:09,293] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[15:29:09,360] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[15:29:09,361] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[15:29:09,362] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[15:29:09,363] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[15:29:09,365] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[15:29:09,384] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:29:11,229] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:11,230] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:11,235] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:11,236] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:11,343] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:29:11,387] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:29:11,389] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:34625 (size: 14.6 KB, free: 1128.9 MB)
[15:29:11,396] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[15:29:11,400] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:11,885] INFO  {CodeGenerator} Code generated in 215.539482 ms
[15:29:11,973] INFO  {SparkContext} Starting job: show at Main.scala:34
[15:29:11,992] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[15:29:11,992] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[15:29:11,993] INFO  {DAGScheduler} Parents of final stage: List()
[15:29:11,994] INFO  {DAGScheduler} Missing parents: List()
[15:29:11,998] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[15:29:12,038] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:29:12,041] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KB, free 1128.7 MB)
[15:29:12,041] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:34625 (size: 6.7 KB, free: 1128.9 MB)
[15:29:12,042] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:29:12,045] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[15:29:12,046] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:29:12,090] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:29:12,099] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:29:12,139] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:12,157] INFO  {CodeGenerator} Code generated in 14.576106 ms
[15:29:12,190] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[15:29:12,200] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 131 ms on localhost (1/1)
[15:29:12,203] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:29:12,207] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.151 s
[15:29:12,214] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.240215 s
[15:29:12,249] INFO  {CodeGenerator} Code generated in 22.305533 ms
[15:29:12,324] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:12,324] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:12,325] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:12,325] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:12,334] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:34625 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:29:12,335] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:29:12,338] INFO  {ContextCleaner} Cleaned accumulator 0
[15:29:12,338] INFO  {ContextCleaner} Cleaned accumulator 1
[15:29:12,339] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:34625 in memory (size: 6.7 KB, free: 1128.9 MB)
[15:29:12,351] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:29:12,351] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:34625 (size: 14.6 KB, free: 1128.9 MB)
[15:29:12,353] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[15:29:12,353] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:12,419] INFO  {CodeGenerator} Code generated in 42.710332 ms
[15:29:12,436] INFO  {SparkContext} Starting job: show at Main.scala:43
[15:29:12,437] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[15:29:12,437] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[15:29:12,437] INFO  {DAGScheduler} Parents of final stage: List()
[15:29:12,437] INFO  {DAGScheduler} Missing parents: List()
[15:29:12,438] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[15:29:12,441] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.7 MB)
[15:29:12,443] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[15:29:12,443] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:34625 (size: 8.2 KB, free: 1128.9 MB)
[15:29:12,444] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:29:12,444] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[15:29:12,444] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:29:12,446] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:29:12,447] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:29:12,458] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:12,479] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:29:12,481] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on localhost (1/1)
[15:29:12,481] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:29:12,482] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.036 s
[15:29:12,482] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.045777 s
[15:29:12,510] INFO  {CodeGenerator} Code generated in 20.456224 ms
[15:29:12,589] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:12,589] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:12,590] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:12,590] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:12,596] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:29:12,604] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:29:12,604] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:34625 (size: 14.6 KB, free: 1128.9 MB)
[15:29:12,605] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:52
[15:29:12,605] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:12,659] INFO  {CodeGenerator} Code generated in 39.383429 ms
[15:29:12,667] INFO  {SparkContext} Starting job: show at Main.scala:52
[15:29:12,668] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[15:29:12,668] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[15:29:12,668] INFO  {DAGScheduler} Parents of final stage: List()
[15:29:12,668] INFO  {DAGScheduler} Missing parents: List()
[15:29:12,669] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52), which has no missing parents
[15:29:12,672] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.6 MB)
[15:29:12,674] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.5 MB)
[15:29:12,674] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:34625 (size: 9.6 KB, free: 1128.9 MB)
[15:29:12,675] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:29:12,675] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52)
[15:29:12,675] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:29:12,677] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:29:12,677] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:29:12,690] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:12,702] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:29:12,703] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on localhost (1/1)
[15:29:12,703] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:29:12,703] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.027 s
[15:29:12,704] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.036186 s
[15:29:12,720] INFO  {CodeGenerator} Code generated in 14.155464 ms
[15:29:12,777] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:12,778] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:12,780] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:12,780] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:12,786] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[15:29:12,798] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:29:12,798] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:34625 (size: 14.6 KB, free: 1128.8 MB)
[15:29:12,799] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:62
[15:29:12,800] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:12,876] INFO  {CodeGenerator} Code generated in 49.797315 ms
[15:29:12,885] INFO  {SparkContext} Starting job: show at Main.scala:62
[15:29:12,886] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[15:29:12,886] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[15:29:12,886] INFO  {DAGScheduler} Parents of final stage: List()
[15:29:12,886] INFO  {DAGScheduler} Missing parents: List()
[15:29:12,887] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62), which has no missing parents
[15:29:12,889] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.4 MB)
[15:29:12,891] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.4 MB)
[15:29:12,891] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:34625 (size: 10.9 KB, free: 1128.8 MB)
[15:29:12,892] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:29:12,892] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62)
[15:29:12,892] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:29:12,894] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:29:12,894] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:29:12,904] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:12,912] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:29:12,914] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 21 ms on localhost (1/1)
[15:29:12,914] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:29:12,914] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.022 s
[15:29:12,914] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.028963 s
[15:29:12,932] INFO  {CodeGenerator} Code generated in 15.869894 ms
[15:29:13,096] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:34625 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:29:13,096] INFO  {ContextCleaner} Cleaned accumulator 46
[15:29:13,096] INFO  {ContextCleaner} Cleaned accumulator 47
[15:29:13,097] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:34625 in memory (size: 8.2 KB, free: 1128.9 MB)
[15:29:13,098] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:34625 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:29:13,099] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:13,099] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:13,100] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:13,100] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:13,103] INFO  {ContextCleaner} Cleaned accumulator 92
[15:29:13,103] INFO  {ContextCleaner} Cleaned accumulator 93
[15:29:13,104] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:29:13,104] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:34625 in memory (size: 9.6 KB, free: 1128.9 MB)
[15:29:13,105] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:34625 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:29:13,106] INFO  {ContextCleaner} Cleaned accumulator 138
[15:29:13,106] INFO  {ContextCleaner} Cleaned accumulator 139
[15:29:13,106] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:34625 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:29:13,112] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:29:13,113] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:34625 (size: 14.6 KB, free: 1128.9 MB)
[15:29:13,114] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:66
[15:29:13,114] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:13,163] INFO  {CodeGenerator} Code generated in 15.983007 ms
[15:29:13,191] INFO  {CodeGenerator} Code generated in 23.137073 ms
[15:29:13,226] INFO  {SparkContext} Starting job: collect at Main.scala:66
[15:29:13,229] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:66)
[15:29:13,230] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:66) with 1 output partitions
[15:29:13,230] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:66)
[15:29:13,231] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[15:29:13,231] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[15:29:13,232] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66), which has no missing parents
[15:29:13,241] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[15:29:13,242] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[15:29:13,243] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:34625 (size: 8.3 KB, free: 1128.9 MB)
[15:29:13,243] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:29:13,245] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66)
[15:29:13,245] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:29:13,248] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[15:29:13,249] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:29:13,268] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:13,533] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[15:29:13,535] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 289 ms on localhost (1/1)
[15:29:13,535] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:29:13,536] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:66) finished in 0.290 s
[15:29:13,537] INFO  {DAGScheduler} looking for newly runnable stages
[15:29:13,537] INFO  {DAGScheduler} running: Set()
[15:29:13,538] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[15:29:13,538] INFO  {DAGScheduler} failed: Set()
[15:29:13,539] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66), which has no missing parents
[15:29:13,544] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[15:29:13,545] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[15:29:13,545] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:34625 (size: 3.9 KB, free: 1128.9 MB)
[15:29:13,546] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[15:29:13,546] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66)
[15:29:13,546] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:29:13,551] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[15:29:13,552] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:29:13,567] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[15:29:13,568] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 6 ms
[15:29:13,584] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[15:29:13,586] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 35 ms on localhost (1/1)
[15:29:13,586] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:29:13,586] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:66) finished in 0.036 s
[15:29:13,586] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:66, took 0.359722 s
[15:29:13,597] INFO  {CodeGenerator} Code generated in 7.209483 ms
[15:29:13,663] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:13,664] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:13,664] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:13,665] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:13,668] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:29:13,678] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:29:13,679] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:34625 (size: 14.6 KB, free: 1128.9 MB)
[15:29:13,680] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:86
[15:29:13,680] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:13,755] INFO  {CodeGenerator} Code generated in 56.991803 ms
[15:29:13,764] INFO  {SparkContext} Starting job: show at Main.scala:86
[15:29:13,765] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[15:29:13,765] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:86)
[15:29:13,765] INFO  {DAGScheduler} Parents of final stage: List()
[15:29:13,765] INFO  {DAGScheduler} Missing parents: List()
[15:29:13,765] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[15:29:13,767] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 57.2 KB, free 1128.5 MB)
[15:29:13,769] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[15:29:13,770] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:34625 (size: 14.6 KB, free: 1128.8 MB)
[15:29:13,770] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[15:29:13,770] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86)
[15:29:13,770] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[15:29:13,772] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:29:13,772] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[15:29:13,780] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:13,787] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3559 bytes result sent to driver
[15:29:13,788] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 17 ms on localhost (1/1)
[15:29:13,789] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[15:29:13,789] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:86) finished in 0.018 s
[15:29:13,789] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.024987 s
[15:29:13,805] INFO  {CodeGenerator} Code generated in 13.652488 ms
[15:29:13,813] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:29:13,817] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:29:13,819] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[15:29:13,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[15:29:13,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[15:29:13,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[15:29:13,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[15:29:13,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[15:29:13,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[15:29:13,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[15:29:13,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[15:29:13,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[15:29:13,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[15:29:13,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[15:29:13,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[15:29:13,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[15:29:13,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[15:29:13,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[15:29:13,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[15:29:13,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[15:29:13,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[15:29:13,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[15:29:13,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[15:29:13,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[15:29:13,822] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[15:29:13,822] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[15:29:13,823] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:29:13,838] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:29:13,847] INFO  {MemoryStore} MemoryStore cleared
[15:29:13,848] INFO  {BlockManager} BlockManager stopped
[15:29:13,849] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:29:13,852] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:29:13,857] INFO  {SparkContext} Successfully stopped SparkContext
[15:29:13,858] INFO  {ShutdownHookManager} Shutdown hook called
[15:29:13,858] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-e4c458f5-1894-4529-800e-3705f6dac5d1
[15:29:47,635] INFO  {SparkContext} Running Spark version 2.0.1
[15:29:47,881] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:29:47,982] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:29:47,983] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:29:48,070] INFO  {SecurityManager} Changing view acls to: victor
[15:29:48,071] INFO  {SecurityManager} Changing modify acls to: victor
[15:29:48,072] INFO  {SecurityManager} Changing view acls groups to: 
[15:29:48,072] INFO  {SecurityManager} Changing modify acls groups to: 
[15:29:48,073] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:29:48,377] INFO  {Utils} Successfully started service 'sparkDriver' on port 39975.
[15:29:48,393] INFO  {SparkEnv} Registering MapOutputTracker
[15:29:48,408] INFO  {SparkEnv} Registering BlockManagerMaster
[15:29:48,420] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-f44746a1-b1c3-49fc-84f2-6b28dad633d0
[15:29:48,434] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:29:48,484] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:29:48,558] INFO  {log} Logging initialized @1586ms
[15:29:48,659] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:29:48,674] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[15:29:48,674] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[15:29:48,675] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[15:29:48,675] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[15:29:48,675] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[15:29:48,675] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[15:29:48,675] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[15:29:48,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[15:29:48,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[15:29:48,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[15:29:48,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[15:29:48,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[15:29:48,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[15:29:48,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[15:29:48,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[15:29:48,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[15:29:48,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[15:29:48,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[15:29:48,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[15:29:48,678] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[15:29:48,684] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[15:29:48,684] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[15:29:48,685] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[15:29:48,685] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[15:29:48,691] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:29:48,691] INFO  {Server} Started @1721ms
[15:29:48,692] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:29:48,694] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:29:48,774] INFO  {Executor} Starting executor ID driver on host localhost
[15:29:48,794] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41273.
[15:29:48,795] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:41273
[15:29:48,796] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 41273)
[15:29:48,799] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:41273 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 41273)
[15:29:48,801] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 41273)
[15:29:48,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[15:29:48,974] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[15:29:48,974] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[15:29:48,975] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[15:29:48,976] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[15:29:48,977] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[15:29:48,991] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:29:50,884] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:50,886] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:50,890] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:50,891] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:50,997] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:29:51,041] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:29:51,043] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:41273 (size: 14.6 KB, free: 1128.9 MB)
[15:29:51,049] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:34
[15:29:51,053] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:51,528] INFO  {CodeGenerator} Code generated in 206.428962 ms
[15:29:51,619] INFO  {SparkContext} Starting job: show at Main.scala:34
[15:29:51,634] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[15:29:51,635] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[15:29:51,635] INFO  {DAGScheduler} Parents of final stage: List()
[15:29:51,636] INFO  {DAGScheduler} Missing parents: List()
[15:29:51,640] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
[15:29:51,684] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:29:51,686] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[15:29:51,686] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:41273 (size: 6.6 KB, free: 1128.9 MB)
[15:29:51,687] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:29:51,690] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34)
[15:29:51,691] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:29:51,734] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:29:51,740] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:29:51,777] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:51,791] INFO  {CodeGenerator} Code generated in 10.429153 ms
[15:29:51,823] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[15:29:51,830] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 121 ms on localhost (1/1)
[15:29:51,832] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:29:51,834] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.135 s
[15:29:51,839] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.220536 s
[15:29:51,879] INFO  {CodeGenerator} Code generated in 21.203141 ms
[15:29:51,913] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:41273 in memory (size: 6.6 KB, free: 1128.9 MB)
[15:29:51,943] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:51,943] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:51,943] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:51,943] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:51,950] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:29:51,961] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:29:51,962] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:41273 (size: 14.6 KB, free: 1128.9 MB)
[15:29:51,963] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:43
[15:29:51,963] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:52,018] INFO  {CodeGenerator} Code generated in 38.876947 ms
[15:29:52,030] INFO  {SparkContext} Starting job: show at Main.scala:43
[15:29:52,031] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[15:29:52,031] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[15:29:52,031] INFO  {DAGScheduler} Parents of final stage: List()
[15:29:52,031] INFO  {DAGScheduler} Missing parents: List()
[15:29:52,032] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43), which has no missing parents
[15:29:52,036] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[15:29:52,038] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1128.6 MB)
[15:29:52,039] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:41273 (size: 8.1 KB, free: 1128.9 MB)
[15:29:52,040] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:29:52,040] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:43)
[15:29:52,040] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:29:52,043] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:29:52,044] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:29:52,054] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:52,069] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:29:52,071] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on localhost (1/1)
[15:29:52,071] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:29:52,071] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.030 s
[15:29:52,072] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.041981 s
[15:29:52,096] INFO  {CodeGenerator} Code generated in 16.053236 ms
[15:29:52,194] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:52,194] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:52,195] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:52,195] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:52,200] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[15:29:52,210] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:29:52,211] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:41273 (size: 14.6 KB, free: 1128.8 MB)
[15:29:52,212] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:52
[15:29:52,212] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:52,271] INFO  {CodeGenerator} Code generated in 42.624846 ms
[15:29:52,285] INFO  {SparkContext} Starting job: show at Main.scala:52
[15:29:52,285] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[15:29:52,286] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[15:29:52,286] INFO  {DAGScheduler} Parents of final stage: List()
[15:29:52,286] INFO  {DAGScheduler} Missing parents: List()
[15:29:52,286] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52), which has no missing parents
[15:29:52,290] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[15:29:52,291] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[15:29:52,292] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:41273 (size: 9.6 KB, free: 1128.8 MB)
[15:29:52,292] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:29:52,292] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:52)
[15:29:52,293] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:29:52,294] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:29:52,295] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:29:52,304] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:52,312] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3566 bytes result sent to driver
[15:29:52,313] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 20 ms on localhost (1/1)
[15:29:52,314] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:29:52,314] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.021 s
[15:29:52,314] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.029514 s
[15:29:52,333] INFO  {CodeGenerator} Code generated in 16.382895 ms
[15:29:52,377] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:52,377] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:52,378] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:52,378] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:52,385] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[15:29:52,397] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.3 MB)
[15:29:52,398] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:41273 (size: 14.6 KB, free: 1128.8 MB)
[15:29:52,399] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:62
[15:29:52,399] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:52,465] INFO  {CodeGenerator} Code generated in 44.935444 ms
[15:29:52,475] INFO  {SparkContext} Starting job: show at Main.scala:62
[15:29:52,476] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[15:29:52,476] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[15:29:52,476] INFO  {DAGScheduler} Parents of final stage: List()
[15:29:52,476] INFO  {DAGScheduler} Missing parents: List()
[15:29:52,477] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62), which has no missing parents
[15:29:52,479] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[15:29:52,481] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[15:29:52,481] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:41273 (size: 10.9 KB, free: 1128.8 MB)
[15:29:52,482] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:29:52,482] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:62)
[15:29:52,482] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:29:52,484] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:29:52,484] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:29:52,496] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:52,506] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:29:52,508] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on localhost (1/1)
[15:29:52,508] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:29:52,508] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.025 s
[15:29:52,509] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.033261 s
[15:29:52,529] INFO  {CodeGenerator} Code generated in 17.472228 ms
[15:29:52,698] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:41273 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:29:52,700] INFO  {ContextCleaner} Cleaned accumulator 0
[15:29:52,700] INFO  {ContextCleaner} Cleaned accumulator 1
[15:29:52,701] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:52,701] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:41273 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:29:52,701] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:52,702] INFO  {ContextCleaner} Cleaned accumulator 46
[15:29:52,702] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:52,702] INFO  {ContextCleaner} Cleaned accumulator 47
[15:29:52,702] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:52,703] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:41273 in memory (size: 8.1 KB, free: 1128.9 MB)
[15:29:52,705] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:41273 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:29:52,705] INFO  {ContextCleaner} Cleaned accumulator 92
[15:29:52,705] INFO  {ContextCleaner} Cleaned accumulator 93
[15:29:52,706] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:41273 in memory (size: 9.6 KB, free: 1128.9 MB)
[15:29:52,707] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:41273 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:29:52,708] INFO  {ContextCleaner} Cleaned accumulator 138
[15:29:52,708] INFO  {ContextCleaner} Cleaned accumulator 139
[15:29:52,709] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:41273 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:29:52,709] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:29:52,717] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:29:52,717] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:41273 (size: 14.6 KB, free: 1128.9 MB)
[15:29:52,718] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:66
[15:29:52,718] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:52,761] INFO  {CodeGenerator} Code generated in 13.73026 ms
[15:29:52,788] INFO  {CodeGenerator} Code generated in 21.835469 ms
[15:29:52,823] INFO  {SparkContext} Starting job: collect at Main.scala:66
[15:29:52,826] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:66)
[15:29:52,827] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:66) with 1 output partitions
[15:29:52,827] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:66)
[15:29:52,828] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[15:29:52,828] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[15:29:52,829] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66), which has no missing parents
[15:29:52,837] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[15:29:52,838] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[15:29:52,839] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:41273 (size: 8.3 KB, free: 1128.9 MB)
[15:29:52,839] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:29:52,841] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:66)
[15:29:52,841] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:29:52,844] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[15:29:52,844] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:29:52,863] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:53,151] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[15:29:53,153] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 311 ms on localhost (1/1)
[15:29:53,153] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:29:53,155] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:66) finished in 0.314 s
[15:29:53,156] INFO  {DAGScheduler} looking for newly runnable stages
[15:29:53,156] INFO  {DAGScheduler} running: Set()
[15:29:53,157] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[15:29:53,157] INFO  {DAGScheduler} failed: Set()
[15:29:53,159] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66), which has no missing parents
[15:29:53,163] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[15:29:53,165] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[15:29:53,165] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:41273 (size: 3.9 KB, free: 1128.9 MB)
[15:29:53,166] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[15:29:53,166] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:66)
[15:29:53,166] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:29:53,171] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[15:29:53,171] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:29:53,186] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[15:29:53,188] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 6 ms
[15:29:53,201] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[15:29:53,202] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 33 ms on localhost (1/1)
[15:29:53,202] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:29:53,203] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:66) finished in 0.034 s
[15:29:53,203] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:66, took 0.379908 s
[15:29:53,215] INFO  {CodeGenerator} Code generated in 8.859766 ms
[15:29:53,293] INFO  {FileSourceStrategy} Pruning directories with: 
[15:29:53,293] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:29:53,294] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:29:53,294] INFO  {FileSourceStrategy} Pushed Filters: 
[15:29:53,298] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:29:53,308] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:29:53,309] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:41273 (size: 14.6 KB, free: 1128.9 MB)
[15:29:53,310] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:86
[15:29:53,310] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:29:53,412] INFO  {CodeGenerator} Code generated in 70.405126 ms
[15:29:53,421] INFO  {SparkContext} Starting job: show at Main.scala:86
[15:29:53,422] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[15:29:53,422] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:86)
[15:29:53,422] INFO  {DAGScheduler} Parents of final stage: List()
[15:29:53,423] INFO  {DAGScheduler} Missing parents: List()
[15:29:53,423] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[15:29:53,425] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 57.2 KB, free 1128.5 MB)
[15:29:53,427] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1128.5 MB)
[15:29:53,427] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:41273 (size: 14.5 KB, free: 1128.8 MB)
[15:29:53,428] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[15:29:53,428] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:86)
[15:29:53,428] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[15:29:53,430] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:29:53,430] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[15:29:53,439] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:29:53,447] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3559 bytes result sent to driver
[15:29:53,448] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 18 ms on localhost (1/1)
[15:29:53,448] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[15:29:53,448] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:86) finished in 0.019 s
[15:29:53,449] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.026939 s
[15:29:53,466] INFO  {CodeGenerator} Code generated in 15.296506 ms
[15:29:53,477] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:29:53,481] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:29:53,483] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[15:29:53,483] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[15:29:53,483] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[15:29:53,483] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[15:29:53,484] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[15:29:53,484] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[15:29:53,484] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[15:29:53,484] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[15:29:53,484] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[15:29:53,484] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[15:29:53,484] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[15:29:53,484] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[15:29:53,484] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[15:29:53,485] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[15:29:53,485] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[15:29:53,485] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[15:29:53,485] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[15:29:53,485] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[15:29:53,485] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[15:29:53,485] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[15:29:53,485] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[15:29:53,485] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[15:29:53,485] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[15:29:53,486] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[15:29:53,487] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:29:53,496] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:29:53,502] INFO  {MemoryStore} MemoryStore cleared
[15:29:53,502] INFO  {BlockManager} BlockManager stopped
[15:29:53,505] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:29:53,508] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:29:53,509] INFO  {SparkContext} Successfully stopped SparkContext
[15:29:53,509] INFO  {ShutdownHookManager} Shutdown hook called
[15:29:53,510] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-5387b704-faac-4e5b-a9e5-31371de29b3f
[15:33:34,449] INFO  {SparkContext} Running Spark version 2.0.1
[15:33:34,667] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:33:34,769] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:33:34,769] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:33:34,854] INFO  {SecurityManager} Changing view acls to: victor
[15:33:34,855] INFO  {SecurityManager} Changing modify acls to: victor
[15:33:34,855] INFO  {SecurityManager} Changing view acls groups to: 
[15:33:34,856] INFO  {SecurityManager} Changing modify acls groups to: 
[15:33:34,857] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:33:35,204] INFO  {Utils} Successfully started service 'sparkDriver' on port 42399.
[15:33:35,220] INFO  {SparkEnv} Registering MapOutputTracker
[15:33:35,235] INFO  {SparkEnv} Registering BlockManagerMaster
[15:33:35,247] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-10d7ae09-bcb7-45a5-b4d7-60ed2cfc2b92
[15:33:35,261] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:33:35,309] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:33:35,383] INFO  {log} Logging initialized @1575ms
[15:33:35,488] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:33:35,505] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[15:33:35,505] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[15:33:35,505] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[15:33:35,506] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[15:33:35,506] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[15:33:35,506] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[15:33:35,506] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[15:33:35,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[15:33:35,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[15:33:35,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[15:33:35,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[15:33:35,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[15:33:35,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[15:33:35,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[15:33:35,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[15:33:35,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[15:33:35,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[15:33:35,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[15:33:35,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[15:33:35,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[15:33:35,515] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[15:33:35,516] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[15:33:35,517] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[15:33:35,517] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[15:33:35,524] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:33:35,524] INFO  {Server} Started @1717ms
[15:33:35,524] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:33:35,527] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:33:35,615] INFO  {Executor} Starting executor ID driver on host localhost
[15:33:35,635] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32939.
[15:33:35,636] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:32939
[15:33:35,637] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 32939)
[15:33:35,640] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:32939 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 32939)
[15:33:35,643] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 32939)
[15:33:35,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[15:33:35,808] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[15:33:35,809] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[15:33:35,810] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[15:33:35,810] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[15:33:35,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[15:33:35,827] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:33:37,693] INFO  {FileSourceStrategy} Pruning directories with: 
[15:33:37,695] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:33:37,699] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:33:37,700] INFO  {FileSourceStrategy} Pushed Filters: 
[15:33:37,802] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:33:37,846] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:33:37,848] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:32939 (size: 14.6 KB, free: 1128.9 MB)
[15:33:37,854] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:35
[15:33:37,858] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:33:38,358] INFO  {CodeGenerator} Code generated in 209.753912 ms
[15:33:38,452] INFO  {SparkContext} Starting job: show at Main.scala:35
[15:33:38,469] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[15:33:38,469] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[15:33:38,470] INFO  {DAGScheduler} Parents of final stage: List()
[15:33:38,471] INFO  {DAGScheduler} Missing parents: List()
[15:33:38,475] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:35), which has no missing parents
[15:33:38,523] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:33:38,525] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[15:33:38,526] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:32939 (size: 6.6 KB, free: 1128.9 MB)
[15:33:38,526] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:33:38,529] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:35)
[15:33:38,531] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:33:38,570] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:33:38,578] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:33:38,617] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:33:38,635] INFO  {CodeGenerator} Code generated in 14.423073 ms
[15:33:38,668] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[15:33:38,675] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 123 ms on localhost (1/1)
[15:33:38,676] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:33:38,680] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.139 s
[15:33:38,686] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.233708 s
[15:33:38,720] INFO  {CodeGenerator} Code generated in 18.049472 ms
[15:33:38,769] INFO  {FileSourceStrategy} Pruning directories with: 
[15:33:38,769] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:33:38,769] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:33:38,770] INFO  {FileSourceStrategy} Pushed Filters: 
[15:33:38,777] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:33:38,806] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:33:38,808] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:32939 (size: 14.6 KB, free: 1128.9 MB)
[15:33:38,810] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:44
[15:33:38,810] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:33:38,823] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:32939 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:33:38,829] INFO  {ContextCleaner} Cleaned accumulator 0
[15:33:38,829] INFO  {ContextCleaner} Cleaned accumulator 1
[15:33:38,830] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:32939 in memory (size: 6.6 KB, free: 1128.9 MB)
[15:33:38,874] INFO  {CodeGenerator} Code generated in 42.157526 ms
[15:33:38,886] INFO  {SparkContext} Starting job: show at Main.scala:44
[15:33:38,887] INFO  {DAGScheduler} Got job 1 (show at Main.scala:44) with 1 output partitions
[15:33:38,887] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:44)
[15:33:38,887] INFO  {DAGScheduler} Parents of final stage: List()
[15:33:38,887] INFO  {DAGScheduler} Missing parents: List()
[15:33:38,887] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:44), which has no missing parents
[15:33:38,890] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.7 MB)
[15:33:38,892] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[15:33:38,893] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:32939 (size: 8.2 KB, free: 1128.9 MB)
[15:33:38,893] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:33:38,893] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:44)
[15:33:38,894] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:33:38,896] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:33:38,896] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:33:38,910] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:33:38,927] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:33:38,929] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on localhost (1/1)
[15:33:38,929] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:33:38,929] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:44) finished in 0.035 s
[15:33:38,929] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:44, took 0.043670 s
[15:33:38,953] INFO  {CodeGenerator} Code generated in 15.054472 ms
[15:33:39,038] INFO  {FileSourceStrategy} Pruning directories with: 
[15:33:39,038] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:33:39,039] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:33:39,039] INFO  {FileSourceStrategy} Pushed Filters: 
[15:33:39,044] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:33:39,052] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:33:39,052] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:32939 (size: 14.6 KB, free: 1128.9 MB)
[15:33:39,053] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:53
[15:33:39,054] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:33:39,114] INFO  {CodeGenerator} Code generated in 45.985534 ms
[15:33:39,123] INFO  {SparkContext} Starting job: show at Main.scala:53
[15:33:39,124] INFO  {DAGScheduler} Got job 2 (show at Main.scala:53) with 1 output partitions
[15:33:39,124] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:53)
[15:33:39,124] INFO  {DAGScheduler} Parents of final stage: List()
[15:33:39,124] INFO  {DAGScheduler} Missing parents: List()
[15:33:39,125] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53), which has no missing parents
[15:33:39,129] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.6 MB)
[15:33:39,131] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.5 MB)
[15:33:39,131] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:32939 (size: 9.6 KB, free: 1128.9 MB)
[15:33:39,132] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:33:39,132] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53)
[15:33:39,132] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:33:39,135] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:33:39,135] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:33:39,145] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:33:39,155] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:33:39,157] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 24 ms on localhost (1/1)
[15:33:39,157] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:33:39,158] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:53) finished in 0.024 s
[15:33:39,158] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:53, took 0.034743 s
[15:33:39,176] INFO  {CodeGenerator} Code generated in 15.368643 ms
[15:33:39,213] INFO  {FileSourceStrategy} Pruning directories with: 
[15:33:39,213] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:33:39,214] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:33:39,214] INFO  {FileSourceStrategy} Pushed Filters: 
[15:33:39,219] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[15:33:39,228] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:33:39,229] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:32939 (size: 14.6 KB, free: 1128.8 MB)
[15:33:39,229] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:63
[15:33:39,230] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:33:39,294] INFO  {CodeGenerator} Code generated in 47.160156 ms
[15:33:39,304] INFO  {SparkContext} Starting job: show at Main.scala:63
[15:33:39,305] INFO  {DAGScheduler} Got job 3 (show at Main.scala:63) with 1 output partitions
[15:33:39,305] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:63)
[15:33:39,305] INFO  {DAGScheduler} Parents of final stage: List()
[15:33:39,305] INFO  {DAGScheduler} Missing parents: List()
[15:33:39,305] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63), which has no missing parents
[15:33:39,308] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.4 MB)
[15:33:39,309] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.4 MB)
[15:33:39,310] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:32939 (size: 10.9 KB, free: 1128.8 MB)
[15:33:39,311] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:33:39,311] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63)
[15:33:39,311] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:33:39,313] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:33:39,313] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:33:39,322] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:33:39,332] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:33:39,333] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 22 ms on localhost (1/1)
[15:33:39,333] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:33:39,333] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:63) finished in 0.022 s
[15:33:39,334] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:63, took 0.029887 s
[15:33:39,352] INFO  {CodeGenerator} Code generated in 16.095864 ms
[15:33:39,361] INFO  {FileSourceStrategy} Pruning directories with: 
[15:33:39,362] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:33:39,362] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:33:39,362] INFO  {FileSourceStrategy} Pushed Filters: 
[15:33:39,366] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.2 MB)
[15:33:39,379] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.2 MB)
[15:33:39,381] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:32939 (size: 14.6 KB, free: 1128.8 MB)
[15:33:39,382] INFO  {SparkContext} Created broadcast 8 from show at Main.scala:67
[15:33:39,382] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:33:39,397] INFO  {CodeGenerator} Code generated in 8.378873 ms
[15:33:39,409] INFO  {SparkContext} Starting job: show at Main.scala:67
[15:33:39,410] INFO  {DAGScheduler} Got job 4 (show at Main.scala:67) with 1 output partitions
[15:33:39,410] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:67)
[15:33:39,411] INFO  {DAGScheduler} Parents of final stage: List()
[15:33:39,411] INFO  {DAGScheduler} Missing parents: List()
[15:33:39,411] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:67), which has no missing parents
[15:33:39,413] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 7.2 KB, free 1128.2 MB)
[15:33:39,415] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.2 MB)
[15:33:39,415] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:32939 (size: 3.9 KB, free: 1128.8 MB)
[15:33:39,416] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:33:39,416] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:67)
[15:33:39,416] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:33:39,418] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:33:39,418] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:33:39,425] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:33:39,429] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2286 bytes result sent to driver
[15:33:39,430] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 12 ms on localhost (1/1)
[15:33:39,430] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:33:39,430] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:67) finished in 0.014 s
[15:33:39,430] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:67, took 0.020694 s
[15:33:39,440] INFO  {CodeGenerator} Code generated in 8.060724 ms
[15:33:39,508] INFO  {FileSourceStrategy} Pruning directories with: 
[15:33:39,508] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:33:39,509] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:33:39,509] INFO  {FileSourceStrategy} Pushed Filters: 
[15:33:39,512] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 131.0 KB, free 1128.1 MB)
[15:33:39,522] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.1 MB)
[15:33:39,522] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:32939 (size: 14.6 KB, free: 1128.8 MB)
[15:33:39,523] INFO  {SparkContext} Created broadcast 10 from show at Main.scala:90
[15:33:39,523] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:33:39,613] INFO  {CodeGenerator} Code generated in 65.330627 ms
[15:33:39,622] INFO  {SparkContext} Starting job: show at Main.scala:90
[15:33:39,623] INFO  {DAGScheduler} Got job 5 (show at Main.scala:90) with 1 output partitions
[15:33:39,623] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:90)
[15:33:39,623] INFO  {DAGScheduler} Parents of final stage: List()
[15:33:39,623] INFO  {DAGScheduler} Missing parents: List()
[15:33:39,624] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at show at Main.scala:90), which has no missing parents
[15:33:39,627] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 57.2 KB, free 1128.0 MB)
[15:33:39,629] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1128.0 MB)
[15:33:39,630] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:32939 (size: 14.5 KB, free: 1128.8 MB)
[15:33:39,631] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[15:33:39,631] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at show at Main.scala:90)
[15:33:39,631] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:33:39,632] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:33:39,633] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:33:39,641] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:33:39,652] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 3559 bytes result sent to driver
[15:33:39,653] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 22 ms on localhost (1/1)
[15:33:39,653] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:33:39,653] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:90) finished in 0.022 s
[15:33:39,654] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:90, took 0.031577 s
[15:33:39,673] INFO  {CodeGenerator} Code generated in 16.633816 ms
[15:33:39,685] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:33:39,799] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:32939 in memory (size: 9.6 KB, free: 1128.8 MB)
[15:33:39,801] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:32939 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:33:39,801] INFO  {ContextCleaner} Cleaned accumulator 46
[15:33:39,802] INFO  {ContextCleaner} Cleaned accumulator 47
[15:33:39,803] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:32939 in memory (size: 8.2 KB, free: 1128.8 MB)
[15:33:39,804] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:33:39,804] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:32939 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:33:39,805] INFO  {ContextCleaner} Cleaned accumulator 92
[15:33:39,805] INFO  {ContextCleaner} Cleaned accumulator 93
[15:33:39,806] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:32939 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:33:39,806] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[15:33:39,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[15:33:39,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[15:33:39,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[15:33:39,807] INFO  {ContextCleaner} Cleaned accumulator 138
[15:33:39,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[15:33:39,807] INFO  {ContextCleaner} Cleaned accumulator 139
[15:33:39,808] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[15:33:39,808] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[15:33:39,808] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[15:33:39,808] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[15:33:39,808] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[15:33:39,808] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[15:33:39,808] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[15:33:39,808] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[15:33:39,809] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[15:33:39,809] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 80.216.145.125:32939 in memory (size: 3.9 KB, free: 1128.8 MB)
[15:33:39,809] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[15:33:39,809] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[15:33:39,809] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[15:33:39,809] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[15:33:39,809] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[15:33:39,810] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[15:33:39,810] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[15:33:39,810] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[15:33:39,810] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[15:33:39,810] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[15:33:39,811] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 80.216.145.125:32939 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:33:39,812] INFO  {ContextCleaner} Cleaned accumulator 230
[15:33:39,812] INFO  {ContextCleaner} Cleaned accumulator 231
[15:33:39,812] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:33:39,813] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 80.216.145.125:32939 in memory (size: 14.5 KB, free: 1128.9 MB)
[15:33:39,815] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:32939 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:33:39,826] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:33:39,833] INFO  {MemoryStore} MemoryStore cleared
[15:33:39,833] INFO  {BlockManager} BlockManager stopped
[15:33:39,835] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:33:39,839] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:33:39,846] INFO  {SparkContext} Successfully stopped SparkContext
[15:33:39,847] INFO  {ShutdownHookManager} Shutdown hook called
[15:33:39,847] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-ff967eed-36dd-4263-8585-59100703e4bb
[15:33:55,879] INFO  {SparkContext} Running Spark version 2.0.1
[15:33:56,089] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:33:56,189] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:33:56,190] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:33:56,257] INFO  {SecurityManager} Changing view acls to: victor
[15:33:56,258] INFO  {SecurityManager} Changing modify acls to: victor
[15:33:56,259] INFO  {SecurityManager} Changing view acls groups to: 
[15:33:56,260] INFO  {SecurityManager} Changing modify acls groups to: 
[15:33:56,260] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:33:56,635] INFO  {Utils} Successfully started service 'sparkDriver' on port 39291.
[15:33:56,655] INFO  {SparkEnv} Registering MapOutputTracker
[15:33:56,670] INFO  {SparkEnv} Registering BlockManagerMaster
[15:33:56,681] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-5c69741a-ef45-4640-aa8a-beefb7b459cb
[15:33:56,695] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:33:56,754] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:33:56,826] INFO  {log} Logging initialized @1548ms
[15:33:56,940] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:33:56,956] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[15:33:56,956] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[15:33:56,956] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[15:33:56,956] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[15:33:56,957] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[15:33:56,957] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[15:33:56,957] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[15:33:56,957] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[15:33:56,957] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[15:33:56,957] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[15:33:56,958] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[15:33:56,958] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[15:33:56,958] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[15:33:56,958] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[15:33:56,958] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[15:33:56,959] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[15:33:56,959] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[15:33:56,959] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[15:33:56,959] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[15:33:56,959] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[15:33:56,965] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[15:33:56,965] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[15:33:56,966] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[15:33:56,966] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[15:33:56,973] INFO  {ServerConnector} Started ServerConnector@6e4bee83{HTTP/1.1}{0.0.0.0:4040}
[15:33:56,973] INFO  {Server} Started @1695ms
[15:33:56,973] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:33:56,975] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:33:57,055] INFO  {Executor} Starting executor ID driver on host localhost
[15:33:57,077] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43271.
[15:33:57,078] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:43271
[15:33:57,080] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 43271)
[15:33:57,083] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:43271 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 43271)
[15:33:57,086] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 43271)
[15:33:57,211] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[15:33:57,267] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@759fad4{/SQL,null,AVAILABLE}
[15:33:57,267] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53499d85{/SQL/json,null,AVAILABLE}
[15:33:57,268] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/execution,null,AVAILABLE}
[15:33:57,268] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL/execution/json,null,AVAILABLE}
[15:33:57,270] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@24f360b2{/static/sql,null,AVAILABLE}
[15:33:57,284] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:33:59,122] INFO  {FileSourceStrategy} Pruning directories with: 
[15:33:59,123] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:33:59,128] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:33:59,128] INFO  {FileSourceStrategy} Pushed Filters: 
[15:33:59,234] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:33:59,277] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:33:59,280] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:43271 (size: 14.6 KB, free: 1128.9 MB)
[15:33:59,285] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:35
[15:33:59,289] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:33:59,783] INFO  {CodeGenerator} Code generated in 216.830855 ms
[15:33:59,873] INFO  {SparkContext} Starting job: show at Main.scala:35
[15:33:59,888] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[15:33:59,888] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[15:33:59,888] INFO  {DAGScheduler} Parents of final stage: List()
[15:33:59,889] INFO  {DAGScheduler} Missing parents: List()
[15:33:59,893] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:35), which has no missing parents
[15:33:59,940] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:33:59,944] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[15:33:59,944] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:43271 (size: 6.6 KB, free: 1128.9 MB)
[15:33:59,945] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:33:59,949] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:35)
[15:33:59,950] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:33:59,991] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:34:00,000] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:34:00,040] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:34:00,055] INFO  {CodeGenerator} Code generated in 11.851679 ms
[15:34:00,089] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[15:34:00,096] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 126 ms on localhost (1/1)
[15:34:00,097] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:34:00,100] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.141 s
[15:34:00,107] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.233485 s
[15:34:00,148] INFO  {CodeGenerator} Code generated in 25.935747 ms
[15:34:00,182] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:43271 in memory (size: 6.6 KB, free: 1128.9 MB)
[15:34:00,222] INFO  {FileSourceStrategy} Pruning directories with: 
[15:34:00,222] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:34:00,223] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:34:00,223] INFO  {FileSourceStrategy} Pushed Filters: 
[15:34:00,235] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:34:00,247] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:34:00,248] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:43271 (size: 14.6 KB, free: 1128.9 MB)
[15:34:00,250] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:44
[15:34:00,250] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:34:00,297] INFO  {CodeGenerator} Code generated in 31.476457 ms
[15:34:00,308] INFO  {SparkContext} Starting job: show at Main.scala:44
[15:34:00,309] INFO  {DAGScheduler} Got job 1 (show at Main.scala:44) with 1 output partitions
[15:34:00,310] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:44)
[15:34:00,310] INFO  {DAGScheduler} Parents of final stage: List()
[15:34:00,310] INFO  {DAGScheduler} Missing parents: List()
[15:34:00,310] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:44), which has no missing parents
[15:34:00,315] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[15:34:00,317] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[15:34:00,318] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:43271 (size: 8.2 KB, free: 1128.9 MB)
[15:34:00,319] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:34:00,319] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:44)
[15:34:00,319] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:34:00,322] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:34:00,322] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:34:00,333] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:34:00,347] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:34:00,348] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[15:34:00,348] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:34:00,349] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:44) finished in 0.028 s
[15:34:00,349] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:44, took 0.040273 s
[15:34:00,372] INFO  {CodeGenerator} Code generated in 15.307024 ms
[15:34:00,460] INFO  {FileSourceStrategy} Pruning directories with: 
[15:34:00,461] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:34:00,461] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:34:00,462] INFO  {FileSourceStrategy} Pushed Filters: 
[15:34:00,467] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[15:34:00,475] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:34:00,476] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:43271 (size: 14.6 KB, free: 1128.8 MB)
[15:34:00,477] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:53
[15:34:00,477] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:34:00,537] INFO  {CodeGenerator} Code generated in 45.36371 ms
[15:34:00,551] INFO  {SparkContext} Starting job: show at Main.scala:53
[15:34:00,552] INFO  {DAGScheduler} Got job 2 (show at Main.scala:53) with 1 output partitions
[15:34:00,552] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:53)
[15:34:00,552] INFO  {DAGScheduler} Parents of final stage: List()
[15:34:00,553] INFO  {DAGScheduler} Missing parents: List()
[15:34:00,553] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53), which has no missing parents
[15:34:00,557] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[15:34:00,559] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[15:34:00,559] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:43271 (size: 9.6 KB, free: 1128.8 MB)
[15:34:00,560] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:34:00,560] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53)
[15:34:00,560] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:34:00,562] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:34:00,563] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:34:00,572] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:34:00,581] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:34:00,582] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 21 ms on localhost (1/1)
[15:34:00,582] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:34:00,583] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:53) finished in 0.022 s
[15:34:00,583] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:53, took 0.031718 s
[15:34:00,601] INFO  {CodeGenerator} Code generated in 15.483308 ms
[15:34:00,641] INFO  {FileSourceStrategy} Pruning directories with: 
[15:34:00,641] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:34:00,641] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:34:00,642] INFO  {FileSourceStrategy} Pushed Filters: 
[15:34:00,646] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[15:34:00,654] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.3 MB)
[15:34:00,656] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:43271 (size: 14.6 KB, free: 1128.8 MB)
[15:34:00,657] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:63
[15:34:00,657] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:34:00,727] INFO  {CodeGenerator} Code generated in 49.013935 ms
[15:34:00,738] INFO  {SparkContext} Starting job: show at Main.scala:63
[15:34:00,738] INFO  {DAGScheduler} Got job 3 (show at Main.scala:63) with 1 output partitions
[15:34:00,739] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:63)
[15:34:00,739] INFO  {DAGScheduler} Parents of final stage: List()
[15:34:00,739] INFO  {DAGScheduler} Missing parents: List()
[15:34:00,739] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63), which has no missing parents
[15:34:00,742] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[15:34:00,743] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[15:34:00,744] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:43271 (size: 10.9 KB, free: 1128.8 MB)
[15:34:00,744] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:34:00,745] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63)
[15:34:00,745] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:34:00,746] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:34:00,747] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:34:00,755] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:34:00,765] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:34:00,766] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 21 ms on localhost (1/1)
[15:34:00,766] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:34:00,767] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:63) finished in 0.022 s
[15:34:00,767] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:63, took 0.029219 s
[15:34:00,783] INFO  {CodeGenerator} Code generated in 13.985103 ms
[15:34:00,794] INFO  {FileSourceStrategy} Pruning directories with: 
[15:34:00,795] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:34:00,795] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:34:00,795] INFO  {FileSourceStrategy} Pushed Filters: 
[15:34:00,800] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.1 MB)
[15:34:00,808] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.1 MB)
[15:34:00,808] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:43271 (size: 14.6 KB, free: 1128.8 MB)
[15:34:00,809] INFO  {SparkContext} Created broadcast 8 from show at Main.scala:67
[15:34:00,809] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:34:00,825] INFO  {CodeGenerator} Code generated in 6.941592 ms
[15:34:00,839] INFO  {SparkContext} Starting job: show at Main.scala:67
[15:34:00,841] INFO  {DAGScheduler} Got job 4 (show at Main.scala:67) with 1 output partitions
[15:34:00,841] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:67)
[15:34:00,841] INFO  {DAGScheduler} Parents of final stage: List()
[15:34:00,842] INFO  {DAGScheduler} Missing parents: List()
[15:34:00,842] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:67), which has no missing parents
[15:34:00,845] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 7.2 KB, free 1128.1 MB)
[15:34:00,847] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.1 MB)
[15:34:00,848] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:43271 (size: 3.9 KB, free: 1128.8 MB)
[15:34:00,850] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:34:00,850] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:67)
[15:34:00,851] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:34:00,854] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:34:00,855] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:34:00,861] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:34:00,868] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2286 bytes result sent to driver
[15:34:00,869] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 17 ms on localhost (1/1)
[15:34:00,869] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:34:00,869] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:67) finished in 0.017 s
[15:34:00,870] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:67, took 0.030259 s
[15:34:00,880] INFO  {CodeGenerator} Code generated in 8.669091 ms
[15:34:00,945] INFO  {FileSourceStrategy} Pruning directories with: 
[15:34:00,946] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:34:00,946] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:34:00,946] INFO  {FileSourceStrategy} Pushed Filters: 
[15:34:00,950] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 131.0 KB, free 1127.9 MB)
[15:34:00,959] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1127.9 MB)
[15:34:00,959] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:43271 (size: 14.6 KB, free: 1128.8 MB)
[15:34:00,960] INFO  {SparkContext} Created broadcast 10 from show at Main.scala:90
[15:34:00,960] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:34:01,056] INFO  {CodeGenerator} Code generated in 71.087225 ms
[15:34:01,065] INFO  {SparkContext} Starting job: show at Main.scala:90
[15:34:01,066] INFO  {DAGScheduler} Got job 5 (show at Main.scala:90) with 1 output partitions
[15:34:01,066] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:90)
[15:34:01,066] INFO  {DAGScheduler} Parents of final stage: List()
[15:34:01,067] INFO  {DAGScheduler} Missing parents: List()
[15:34:01,067] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at show at Main.scala:90), which has no missing parents
[15:34:01,069] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 57.2 KB, free 1127.9 MB)
[15:34:01,071] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1127.9 MB)
[15:34:01,072] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:43271 (size: 14.5 KB, free: 1128.8 MB)
[15:34:01,072] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[15:34:01,072] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at show at Main.scala:90)
[15:34:01,072] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:34:01,074] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:34:01,074] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:34:01,086] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:34:01,101] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 3559 bytes result sent to driver
[15:34:01,102] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 29 ms on localhost (1/1)
[15:34:01,102] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:34:01,103] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:90) finished in 0.029 s
[15:34:01,103] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:90, took 0.037417 s
[15:34:01,127] INFO  {CodeGenerator} Code generated in 21.368865 ms
[15:34:01,254] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:34:01,256] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:43271 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:34:01,257] INFO  {ContextCleaner} Cleaned accumulator 0
[15:34:01,258] INFO  {ContextCleaner} Cleaned accumulator 1
[15:34:01,259] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:43271 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:34:01,259] INFO  {ContextCleaner} Cleaned accumulator 46
[15:34:01,260] INFO  {ContextCleaner} Cleaned accumulator 47
[15:34:01,260] INFO  {ServerConnector} Stopped ServerConnector@6e4bee83{HTTP/1.1}{0.0.0.0:4040}
[15:34:01,260] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:43271 in memory (size: 8.2 KB, free: 1128.8 MB)
[15:34:01,261] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:43271 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:34:01,262] INFO  {ContextCleaner} Cleaned accumulator 92
[15:34:01,262] INFO  {ContextCleaner} Cleaned accumulator 93
[15:34:01,263] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[15:34:01,263] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:43271 in memory (size: 9.6 KB, free: 1128.8 MB)
[15:34:01,263] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[15:34:01,263] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[15:34:01,263] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[15:34:01,263] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[15:34:01,263] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[15:34:01,264] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[15:34:01,264] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[15:34:01,264] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[15:34:01,264] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:43271 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:34:01,264] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[15:34:01,264] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[15:34:01,264] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[15:34:01,264] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[15:34:01,264] INFO  {ContextCleaner} Cleaned accumulator 138
[15:34:01,265] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[15:34:01,265] INFO  {ContextCleaner} Cleaned accumulator 139
[15:34:01,265] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[15:34:01,265] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[15:34:01,265] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[15:34:01,265] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[15:34:01,265] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[15:34:01,265] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[15:34:01,266] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[15:34:01,266] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[15:34:01,266] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:43271 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:34:01,266] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[15:34:01,266] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[15:34:01,267] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 80.216.145.125:43271 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:34:01,268] INFO  {ContextCleaner} Cleaned accumulator 184
[15:34:01,268] INFO  {ContextCleaner} Cleaned accumulator 185
[15:34:01,268] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:34:01,269] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 80.216.145.125:43271 in memory (size: 3.9 KB, free: 1128.9 MB)
[15:34:01,270] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 80.216.145.125:43271 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:34:01,280] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:34:01,286] INFO  {MemoryStore} MemoryStore cleared
[15:34:01,287] INFO  {BlockManager} BlockManager stopped
[15:34:01,288] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:34:01,291] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:34:01,300] INFO  {SparkContext} Successfully stopped SparkContext
[15:34:01,301] INFO  {ShutdownHookManager} Shutdown hook called
[15:34:01,302] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-d950f560-b9b4-455e-8ee6-44aba0b06cfd
[15:38:44,373] INFO  {SparkContext} Running Spark version 2.0.1
[15:38:44,588] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:38:44,681] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:38:44,681] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:38:44,765] INFO  {SecurityManager} Changing view acls to: victor
[15:38:44,766] INFO  {SecurityManager} Changing modify acls to: victor
[15:38:44,767] INFO  {SecurityManager} Changing view acls groups to: 
[15:38:44,768] INFO  {SecurityManager} Changing modify acls groups to: 
[15:38:44,769] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:38:45,114] INFO  {Utils} Successfully started service 'sparkDriver' on port 35739.
[15:38:45,132] INFO  {SparkEnv} Registering MapOutputTracker
[15:38:45,147] INFO  {SparkEnv} Registering BlockManagerMaster
[15:38:45,160] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-b39686db-a06c-460e-b987-1317865b335d
[15:38:45,174] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:38:45,225] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:38:45,296] INFO  {log} Logging initialized @1529ms
[15:38:45,401] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:38:45,418] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[15:38:45,418] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[15:38:45,418] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[15:38:45,419] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[15:38:45,419] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[15:38:45,419] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[15:38:45,420] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[15:38:45,420] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[15:38:45,420] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[15:38:45,420] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[15:38:45,421] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[15:38:45,421] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[15:38:45,421] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[15:38:45,422] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[15:38:45,422] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[15:38:45,422] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[15:38:45,422] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[15:38:45,423] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[15:38:45,423] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[15:38:45,423] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[15:38:45,432] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[15:38:45,432] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[15:38:45,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[15:38:45,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[15:38:45,442] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:38:45,442] INFO  {Server} Started @1676ms
[15:38:45,442] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:38:45,445] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:38:45,539] INFO  {Executor} Starting executor ID driver on host localhost
[15:38:45,561] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34755.
[15:38:45,561] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:34755
[15:38:45,563] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 34755)
[15:38:45,565] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:34755 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 34755)
[15:38:45,568] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 34755)
[15:38:45,684] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[15:38:45,731] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[15:38:45,732] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[15:38:45,733] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[15:38:45,734] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[15:38:45,736] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[15:38:45,753] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:38:47,581] INFO  {FileSourceStrategy} Pruning directories with: 
[15:38:47,583] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:38:47,587] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:38:47,588] INFO  {FileSourceStrategy} Pushed Filters: 
[15:38:47,689] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:38:47,733] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:38:47,735] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:34755 (size: 14.6 KB, free: 1128.9 MB)
[15:38:47,741] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:35
[15:38:47,745] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:38:48,219] INFO  {CodeGenerator} Code generated in 209.39217 ms
[15:38:48,307] INFO  {SparkContext} Starting job: show at Main.scala:35
[15:38:48,321] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[15:38:48,322] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[15:38:48,322] INFO  {DAGScheduler} Parents of final stage: List()
[15:38:48,323] INFO  {DAGScheduler} Missing parents: List()
[15:38:48,328] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:35), which has no missing parents
[15:38:48,370] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:38:48,372] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[15:38:48,373] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:34755 (size: 6.6 KB, free: 1128.9 MB)
[15:38:48,374] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:38:48,377] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:35)
[15:38:48,378] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:38:48,418] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:38:48,425] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:38:48,461] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:38:48,475] INFO  {CodeGenerator} Code generated in 10.521787 ms
[15:38:48,506] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[15:38:48,515] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 117 ms on localhost (1/1)
[15:38:48,517] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:38:48,522] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.135 s
[15:38:48,528] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.221163 s
[15:38:48,561] INFO  {CodeGenerator} Code generated in 19.357639 ms
[15:38:48,590] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:34755 in memory (size: 6.6 KB, free: 1128.9 MB)
[15:38:48,637] INFO  {FileSourceStrategy} Pruning directories with: 
[15:38:48,637] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:38:48,638] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:38:48,638] INFO  {FileSourceStrategy} Pushed Filters: 
[15:38:48,645] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:38:48,655] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:38:48,656] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:34755 (size: 14.6 KB, free: 1128.9 MB)
[15:38:48,658] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:44
[15:38:48,658] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:38:48,704] INFO  {CodeGenerator} Code generated in 31.052075 ms
[15:38:48,716] INFO  {SparkContext} Starting job: show at Main.scala:44
[15:38:48,717] INFO  {DAGScheduler} Got job 1 (show at Main.scala:44) with 1 output partitions
[15:38:48,717] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:44)
[15:38:48,717] INFO  {DAGScheduler} Parents of final stage: List()
[15:38:48,717] INFO  {DAGScheduler} Missing parents: List()
[15:38:48,718] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:44), which has no missing parents
[15:38:48,721] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.6 MB)
[15:38:48,722] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.6 MB)
[15:38:48,723] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:34755 (size: 8.2 KB, free: 1128.9 MB)
[15:38:48,723] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:38:48,724] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:44)
[15:38:48,724] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:38:48,726] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:38:48,726] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:38:48,736] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:38:48,750] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:38:48,752] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 27 ms on localhost (1/1)
[15:38:48,752] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:38:48,752] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:44) finished in 0.028 s
[15:38:48,753] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:44, took 0.036563 s
[15:38:48,774] INFO  {CodeGenerator} Code generated in 15.091564 ms
[15:38:48,866] INFO  {FileSourceStrategy} Pruning directories with: 
[15:38:48,866] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:38:48,866] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:38:48,866] INFO  {FileSourceStrategy} Pushed Filters: 
[15:38:48,871] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[15:38:48,880] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:38:48,881] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:34755 (size: 14.6 KB, free: 1128.8 MB)
[15:38:48,881] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:53
[15:38:48,882] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:38:48,940] INFO  {CodeGenerator} Code generated in 42.489087 ms
[15:38:48,950] INFO  {SparkContext} Starting job: show at Main.scala:53
[15:38:48,951] INFO  {DAGScheduler} Got job 2 (show at Main.scala:53) with 1 output partitions
[15:38:48,951] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:53)
[15:38:48,951] INFO  {DAGScheduler} Parents of final stage: List()
[15:38:48,951] INFO  {DAGScheduler} Missing parents: List()
[15:38:48,952] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53), which has no missing parents
[15:38:48,955] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[15:38:48,957] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.4 MB)
[15:38:48,957] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:34755 (size: 9.6 KB, free: 1128.8 MB)
[15:38:48,958] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:38:48,958] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53)
[15:38:48,958] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:38:48,960] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:38:48,960] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:38:48,969] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:38:48,978] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:38:48,980] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 21 ms on localhost (1/1)
[15:38:48,980] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:38:48,980] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:53) finished in 0.021 s
[15:38:48,981] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:53, took 0.030363 s
[15:38:48,997] INFO  {CodeGenerator} Code generated in 14.030527 ms
[15:38:49,034] INFO  {FileSourceStrategy} Pruning directories with: 
[15:38:49,034] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:38:49,034] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:38:49,034] INFO  {FileSourceStrategy} Pushed Filters: 
[15:38:49,039] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[15:38:49,047] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.3 MB)
[15:38:49,047] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:34755 (size: 14.6 KB, free: 1128.8 MB)
[15:38:49,048] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:63
[15:38:49,048] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:38:49,112] INFO  {CodeGenerator} Code generated in 45.493507 ms
[15:38:49,123] INFO  {SparkContext} Starting job: show at Main.scala:63
[15:38:49,124] INFO  {DAGScheduler} Got job 3 (show at Main.scala:63) with 1 output partitions
[15:38:49,124] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:63)
[15:38:49,124] INFO  {DAGScheduler} Parents of final stage: List()
[15:38:49,124] INFO  {DAGScheduler} Missing parents: List()
[15:38:49,125] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63), which has no missing parents
[15:38:49,128] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.2 MB)
[15:38:49,130] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.2 MB)
[15:38:49,131] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:34755 (size: 10.9 KB, free: 1128.8 MB)
[15:38:49,131] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:38:49,132] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63)
[15:38:49,132] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:38:49,134] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:38:49,134] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:38:49,146] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:38:49,156] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:38:49,158] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 26 ms on localhost (1/1)
[15:38:49,158] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:38:49,158] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:63) finished in 0.026 s
[15:38:49,159] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:63, took 0.035532 s
[15:38:49,175] INFO  {CodeGenerator} Code generated in 14.156909 ms
[15:38:49,447] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:34755 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:38:49,450] INFO  {ContextCleaner} Cleaned accumulator 0
[15:38:49,450] INFO  {ContextCleaner} Cleaned accumulator 1
[15:38:49,451] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:34755 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:38:49,453] INFO  {ContextCleaner} Cleaned accumulator 46
[15:38:49,453] INFO  {ContextCleaner} Cleaned accumulator 47
[15:38:49,454] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:34755 in memory (size: 8.2 KB, free: 1128.9 MB)
[15:38:49,456] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:34755 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:38:49,456] INFO  {ContextCleaner} Cleaned accumulator 92
[15:38:49,456] INFO  {ContextCleaner} Cleaned accumulator 93
[15:38:49,458] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:34755 in memory (size: 9.6 KB, free: 1128.9 MB)
[15:38:49,459] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:34755 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:38:49,460] INFO  {ContextCleaner} Cleaned accumulator 138
[15:38:49,460] INFO  {ContextCleaner} Cleaned accumulator 139
[15:38:49,461] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:34755 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:38:49,540] INFO  {FileSourceStrategy} Pruning directories with: 
[15:38:49,540] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:38:49,540] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:38:49,540] INFO  {FileSourceStrategy} Pushed Filters: 
[15:38:49,547] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:38:49,559] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:38:49,560] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:34755 (size: 14.6 KB, free: 1128.9 MB)
[15:38:49,564] INFO  {SparkContext} Created broadcast 8 from show at Main.scala:70
[15:38:49,564] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:38:49,595] INFO  {CodeGenerator} Code generated in 11.07002 ms
[15:38:49,604] INFO  {SparkContext} Starting job: show at Main.scala:70
[15:38:49,605] INFO  {DAGScheduler} Got job 4 (show at Main.scala:70) with 1 output partitions
[15:38:49,605] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:70)
[15:38:49,605] INFO  {DAGScheduler} Parents of final stage: List()
[15:38:49,606] INFO  {DAGScheduler} Missing parents: List()
[15:38:49,606] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:70), which has no missing parents
[15:38:49,608] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 10.6 KB, free 1128.7 MB)
[15:38:49,610] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.8 KB, free 1128.7 MB)
[15:38:49,611] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:34755 (size: 4.8 KB, free: 1128.9 MB)
[15:38:49,612] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:38:49,612] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at show at Main.scala:70)
[15:38:49,613] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:38:49,614] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:38:49,614] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:38:49,619] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:38:49,623] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1282 bytes result sent to driver
[15:38:49,624] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 11 ms on localhost (1/1)
[15:38:49,624] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:38:49,624] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:70) finished in 0.011 s
[15:38:49,625] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:70, took 0.020091 s
[15:38:49,632] INFO  {CodeGenerator} Code generated in 5.957249 ms
[15:38:49,693] INFO  {FileSourceStrategy} Pruning directories with: 
[15:38:49,693] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:38:49,694] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:38:49,694] INFO  {FileSourceStrategy} Pushed Filters: 
[15:38:49,698] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:38:49,706] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:38:49,706] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:34755 (size: 14.6 KB, free: 1128.9 MB)
[15:38:49,707] INFO  {SparkContext} Created broadcast 10 from show at Main.scala:95
[15:38:49,707] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:38:49,793] INFO  {CodeGenerator} Code generated in 63.723588 ms
[15:38:49,802] INFO  {SparkContext} Starting job: show at Main.scala:95
[15:38:49,803] INFO  {DAGScheduler} Got job 5 (show at Main.scala:95) with 1 output partitions
[15:38:49,803] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:95)
[15:38:49,803] INFO  {DAGScheduler} Parents of final stage: List()
[15:38:49,803] INFO  {DAGScheduler} Missing parents: List()
[15:38:49,804] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at show at Main.scala:95), which has no missing parents
[15:38:49,806] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 57.2 KB, free 1128.5 MB)
[15:38:49,808] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1128.5 MB)
[15:38:49,808] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:34755 (size: 14.5 KB, free: 1128.9 MB)
[15:38:49,809] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[15:38:49,809] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at show at Main.scala:95)
[15:38:49,809] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:38:49,810] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:38:49,811] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:38:49,818] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:38:49,827] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 3559 bytes result sent to driver
[15:38:49,828] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 19 ms on localhost (1/1)
[15:38:49,828] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:38:49,829] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:95) finished in 0.020 s
[15:38:49,829] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:95, took 0.026767 s
[15:38:49,848] INFO  {CodeGenerator} Code generated in 17.169656 ms
[15:38:49,856] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:38:49,862] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:38:49,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[15:38:49,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[15:38:49,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[15:38:49,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[15:38:49,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[15:38:49,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[15:38:49,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[15:38:49,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[15:38:49,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[15:38:49,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[15:38:49,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[15:38:49,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[15:38:49,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[15:38:49,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[15:38:49,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[15:38:49,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[15:38:49,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[15:38:49,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[15:38:49,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[15:38:49,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[15:38:49,867] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[15:38:49,867] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[15:38:49,867] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[15:38:49,867] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[15:38:49,869] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:38:49,881] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:38:49,888] INFO  {MemoryStore} MemoryStore cleared
[15:38:49,889] INFO  {BlockManager} BlockManager stopped
[15:38:49,891] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:38:49,895] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:38:49,899] INFO  {SparkContext} Successfully stopped SparkContext
[15:38:49,900] INFO  {ShutdownHookManager} Shutdown hook called
[15:38:49,901] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-d01cfbfc-5376-48d5-a1ce-c68b1a07d2a9
[15:41:03,421] INFO  {SparkContext} Running Spark version 2.0.1
[15:41:03,664] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:41:03,763] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:41:03,763] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:41:03,830] INFO  {SecurityManager} Changing view acls to: victor
[15:41:03,831] INFO  {SecurityManager} Changing modify acls to: victor
[15:41:03,831] INFO  {SecurityManager} Changing view acls groups to: 
[15:41:03,832] INFO  {SecurityManager} Changing modify acls groups to: 
[15:41:03,832] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:41:04,164] INFO  {Utils} Successfully started service 'sparkDriver' on port 45773.
[15:41:04,181] INFO  {SparkEnv} Registering MapOutputTracker
[15:41:04,195] INFO  {SparkEnv} Registering BlockManagerMaster
[15:41:04,208] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-a2dbb16e-cb24-4cdf-a9cd-992443f9b3eb
[15:41:04,222] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:41:04,272] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:41:04,344] INFO  {log} Logging initialized @1548ms
[15:41:04,444] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:41:04,460] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[15:41:04,460] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[15:41:04,460] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[15:41:04,460] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[15:41:04,461] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[15:41:04,461] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[15:41:04,461] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[15:41:04,461] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[15:41:04,461] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[15:41:04,461] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[15:41:04,462] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[15:41:04,462] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[15:41:04,462] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[15:41:04,462] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[15:41:04,462] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[15:41:04,463] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[15:41:04,463] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[15:41:04,463] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[15:41:04,463] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[15:41:04,463] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[15:41:04,469] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[15:41:04,469] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[15:41:04,470] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[15:41:04,470] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[15:41:04,476] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:41:04,477] INFO  {Server} Started @1681ms
[15:41:04,477] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:41:04,479] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:41:04,560] INFO  {Executor} Starting executor ID driver on host localhost
[15:41:04,583] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39387.
[15:41:04,584] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:39387
[15:41:04,586] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 39387)
[15:41:04,589] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:39387 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 39387)
[15:41:04,592] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 39387)
[15:41:04,732] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[15:41:04,781] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[15:41:04,781] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[15:41:04,782] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[15:41:04,782] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[15:41:04,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[15:41:04,798] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:41:06,724] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:06,726] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:06,730] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:06,731] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:06,833] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:41:06,878] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:41:06,880] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:39387 (size: 14.6 KB, free: 1128.9 MB)
[15:41:06,886] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:35
[15:41:06,889] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:07,380] INFO  {CodeGenerator} Code generated in 214.753479 ms
[15:41:07,469] INFO  {SparkContext} Starting job: show at Main.scala:35
[15:41:07,487] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[15:41:07,487] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[15:41:07,488] INFO  {DAGScheduler} Parents of final stage: List()
[15:41:07,489] INFO  {DAGScheduler} Missing parents: List()
[15:41:07,496] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:35), which has no missing parents
[15:41:07,542] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:41:07,545] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[15:41:07,545] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:39387 (size: 6.6 KB, free: 1128.9 MB)
[15:41:07,546] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:41:07,549] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:35)
[15:41:07,550] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:41:07,587] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:41:07,593] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:41:07,632] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:07,650] INFO  {CodeGenerator} Code generated in 14.802294 ms
[15:41:07,686] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[15:41:07,692] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 125 ms on localhost (1/1)
[15:41:07,693] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:41:07,697] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.139 s
[15:41:07,704] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.235001 s
[15:41:07,741] INFO  {CodeGenerator} Code generated in 22.578612 ms
[15:41:07,791] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:07,791] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:07,792] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:07,792] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:07,798] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:41:07,826] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:41:07,827] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:39387 (size: 14.6 KB, free: 1128.9 MB)
[15:41:07,828] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:44
[15:41:07,828] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:07,843] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:39387 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:41:07,850] INFO  {ContextCleaner} Cleaned accumulator 0
[15:41:07,850] INFO  {ContextCleaner} Cleaned accumulator 1
[15:41:07,852] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:39387 in memory (size: 6.6 KB, free: 1128.9 MB)
[15:41:07,894] INFO  {CodeGenerator} Code generated in 44.680646 ms
[15:41:07,910] INFO  {SparkContext} Starting job: show at Main.scala:44
[15:41:07,912] INFO  {DAGScheduler} Got job 1 (show at Main.scala:44) with 1 output partitions
[15:41:07,912] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:44)
[15:41:07,912] INFO  {DAGScheduler} Parents of final stage: List()
[15:41:07,912] INFO  {DAGScheduler} Missing parents: List()
[15:41:07,913] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:44), which has no missing parents
[15:41:07,917] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.7 MB)
[15:41:07,919] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[15:41:07,920] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:39387 (size: 8.2 KB, free: 1128.9 MB)
[15:41:07,921] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:41:07,921] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:44)
[15:41:07,921] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:41:07,924] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:41:07,924] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:41:07,934] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:07,949] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:41:07,951] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[15:41:07,951] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:41:07,951] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:44) finished in 0.029 s
[15:41:07,952] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:44, took 0.041058 s
[15:41:07,981] INFO  {CodeGenerator} Code generated in 20.318579 ms
[15:41:08,065] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:08,065] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:08,065] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:08,066] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:08,071] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:41:08,079] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:41:08,079] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:39387 (size: 14.6 KB, free: 1128.9 MB)
[15:41:08,080] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:53
[15:41:08,080] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:08,135] INFO  {CodeGenerator} Code generated in 40.111012 ms
[15:41:08,145] INFO  {SparkContext} Starting job: show at Main.scala:53
[15:41:08,146] INFO  {DAGScheduler} Got job 2 (show at Main.scala:53) with 1 output partitions
[15:41:08,146] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:53)
[15:41:08,146] INFO  {DAGScheduler} Parents of final stage: List()
[15:41:08,146] INFO  {DAGScheduler} Missing parents: List()
[15:41:08,147] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53), which has no missing parents
[15:41:08,151] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.6 MB)
[15:41:08,161] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.5 MB)
[15:41:08,162] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:39387 (size: 9.6 KB, free: 1128.9 MB)
[15:41:08,162] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:41:08,163] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53)
[15:41:08,163] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:41:08,165] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:41:08,165] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:41:08,174] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:08,184] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:41:08,185] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 22 ms on localhost (1/1)
[15:41:08,185] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:41:08,186] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:53) finished in 0.022 s
[15:41:08,186] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:53, took 0.041112 s
[15:41:08,204] INFO  {CodeGenerator} Code generated in 15.680119 ms
[15:41:08,246] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:08,246] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:08,247] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:08,247] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:08,251] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[15:41:08,261] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:41:08,261] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:39387 (size: 14.6 KB, free: 1128.8 MB)
[15:41:08,262] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:63
[15:41:08,262] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:08,338] INFO  {CodeGenerator} Code generated in 55.140102 ms
[15:41:08,348] INFO  {SparkContext} Starting job: show at Main.scala:63
[15:41:08,349] INFO  {DAGScheduler} Got job 3 (show at Main.scala:63) with 1 output partitions
[15:41:08,349] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:63)
[15:41:08,349] INFO  {DAGScheduler} Parents of final stage: List()
[15:41:08,349] INFO  {DAGScheduler} Missing parents: List()
[15:41:08,350] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63), which has no missing parents
[15:41:08,352] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.4 MB)
[15:41:08,354] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.4 MB)
[15:41:08,355] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:39387 (size: 10.9 KB, free: 1128.8 MB)
[15:41:08,356] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:41:08,356] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63)
[15:41:08,356] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:41:08,358] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:41:08,359] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:41:08,370] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:08,380] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:41:08,382] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 24 ms on localhost (1/1)
[15:41:08,382] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:41:08,382] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:63) finished in 0.025 s
[15:41:08,383] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:63, took 0.034303 s
[15:41:08,400] INFO  {CodeGenerator} Code generated in 14.75995 ms
[15:41:08,566] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:39387 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:41:08,568] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:39387 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:41:08,568] INFO  {ContextCleaner} Cleaned accumulator 139
[15:41:08,568] INFO  {ContextCleaner} Cleaned accumulator 46
[15:41:08,568] INFO  {ContextCleaner} Cleaned accumulator 47
[15:41:08,569] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:39387 in memory (size: 8.2 KB, free: 1128.9 MB)
[15:41:08,570] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:39387 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:41:08,570] INFO  {ContextCleaner} Cleaned accumulator 92
[15:41:08,570] INFO  {ContextCleaner} Cleaned accumulator 93
[15:41:08,572] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:39387 in memory (size: 9.6 KB, free: 1128.9 MB)
[15:41:08,573] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:08,573] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:39387 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:41:08,573] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:08,573] INFO  {ContextCleaner} Cleaned accumulator 138
[15:41:08,573] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:08,573] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:08,577] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:41:08,585] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:41:08,586] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:39387 (size: 14.6 KB, free: 1128.9 MB)
[15:41:08,586] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:68
[15:41:08,587] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:08,631] INFO  {CodeGenerator} Code generated in 14.116281 ms
[15:41:08,656] INFO  {CodeGenerator} Code generated in 19.46028 ms
[15:41:08,686] INFO  {SparkContext} Starting job: collect at Main.scala:68
[15:41:08,689] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:68)
[15:41:08,690] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:68) with 1 output partitions
[15:41:08,690] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:68)
[15:41:08,690] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[15:41:08,691] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[15:41:08,692] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:68), which has no missing parents
[15:41:08,701] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[15:41:08,703] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[15:41:08,703] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:39387 (size: 8.3 KB, free: 1128.9 MB)
[15:41:08,704] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:41:08,706] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:68)
[15:41:08,706] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:41:08,710] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[15:41:08,710] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:41:08,724] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:09,000] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[15:41:09,002] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 295 ms on localhost (1/1)
[15:41:09,002] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:41:09,003] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:68) finished in 0.296 s
[15:41:09,004] INFO  {DAGScheduler} looking for newly runnable stages
[15:41:09,004] INFO  {DAGScheduler} running: Set()
[15:41:09,005] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[15:41:09,005] INFO  {DAGScheduler} failed: Set()
[15:41:09,006] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:68), which has no missing parents
[15:41:09,012] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[15:41:09,013] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[15:41:09,013] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:39387 (size: 3.9 KB, free: 1128.9 MB)
[15:41:09,014] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[15:41:09,015] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:68)
[15:41:09,015] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:41:09,019] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[15:41:09,019] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:41:09,031] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[15:41:09,032] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[15:41:09,045] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[15:41:09,046] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 29 ms on localhost (1/1)
[15:41:09,046] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:41:09,047] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:68) finished in 0.030 s
[15:41:09,048] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:68, took 0.361482 s
[15:41:09,058] INFO  {CodeGenerator} Code generated in 7.436305 ms
[15:41:09,116] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:09,116] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:09,117] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:09,117] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:09,120] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:41:09,127] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:41:09,128] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:39387 (size: 14.6 KB, free: 1128.9 MB)
[15:41:09,129] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:89
[15:41:09,129] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:09,208] INFO  {CodeGenerator} Code generated in 58.852444 ms
[15:41:09,216] INFO  {SparkContext} Starting job: show at Main.scala:89
[15:41:09,217] INFO  {DAGScheduler} Got job 5 (show at Main.scala:89) with 1 output partitions
[15:41:09,217] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:89)
[15:41:09,217] INFO  {DAGScheduler} Parents of final stage: List()
[15:41:09,218] INFO  {DAGScheduler} Missing parents: List()
[15:41:09,218] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:89), which has no missing parents
[15:41:09,221] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 57.2 KB, free 1128.5 MB)
[15:41:09,223] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[15:41:09,224] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:39387 (size: 14.6 KB, free: 1128.8 MB)
[15:41:09,224] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[15:41:09,224] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:89)
[15:41:09,225] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[15:41:09,226] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:41:09,227] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[15:41:09,234] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:09,239] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3559 bytes result sent to driver
[15:41:09,240] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 15 ms on localhost (1/1)
[15:41:09,240] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[15:41:09,241] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:89) finished in 0.015 s
[15:41:09,241] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:89, took 0.024307 s
[15:41:09,257] INFO  {CodeGenerator} Code generated in 13.403557 ms
[15:41:09,265] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:41:09,271] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:41:09,273] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[15:41:09,273] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[15:41:09,273] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[15:41:09,274] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[15:41:09,274] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[15:41:09,274] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[15:41:09,274] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[15:41:09,274] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[15:41:09,274] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[15:41:09,274] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[15:41:09,274] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[15:41:09,274] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[15:41:09,275] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[15:41:09,275] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[15:41:09,275] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[15:41:09,275] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[15:41:09,275] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[15:41:09,275] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[15:41:09,275] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[15:41:09,275] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[15:41:09,275] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[15:41:09,275] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[15:41:09,275] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[15:41:09,276] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[15:41:09,278] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:41:09,289] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:41:09,297] INFO  {MemoryStore} MemoryStore cleared
[15:41:09,297] INFO  {BlockManager} BlockManager stopped
[15:41:09,298] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:41:09,302] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:41:09,312] INFO  {SparkContext} Successfully stopped SparkContext
[15:41:09,312] INFO  {ShutdownHookManager} Shutdown hook called
[15:41:09,313] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-29a8234c-e10a-4d1d-9ef4-046fece72c0d
[15:41:19,967] INFO  {SparkContext} Running Spark version 2.0.1
[15:41:20,195] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:41:20,280] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:41:20,281] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:41:20,354] INFO  {SecurityManager} Changing view acls to: victor
[15:41:20,355] INFO  {SecurityManager} Changing modify acls to: victor
[15:41:20,356] INFO  {SecurityManager} Changing view acls groups to: 
[15:41:20,357] INFO  {SecurityManager} Changing modify acls groups to: 
[15:41:20,358] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:41:20,721] INFO  {Utils} Successfully started service 'sparkDriver' on port 37593.
[15:41:20,738] INFO  {SparkEnv} Registering MapOutputTracker
[15:41:20,753] INFO  {SparkEnv} Registering BlockManagerMaster
[15:41:20,766] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-c40abc53-bd8a-4e16-86dd-95f673441b97
[15:41:20,780] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:41:20,844] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:41:20,926] INFO  {log} Logging initialized @1540ms
[15:41:21,032] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:41:21,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:41:21,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:41:21,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:41:21,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:41:21,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:41:21,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:41:21,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:41:21,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:41:21,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:41:21,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:41:21,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:41:21,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:41:21,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:41:21,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:41:21,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:41:21,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:41:21,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:41:21,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:41:21,052] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:41:21,052] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:41:21,057] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:41:21,058] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:41:21,059] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:41:21,059] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:41:21,065] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:41:21,065] INFO  {Server} Started @1680ms
[15:41:21,065] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:41:21,067] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:41:21,141] INFO  {Executor} Starting executor ID driver on host localhost
[15:41:21,164] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36819.
[15:41:21,165] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:36819
[15:41:21,167] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 36819)
[15:41:21,170] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:36819 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 36819)
[15:41:21,173] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 36819)
[15:41:21,304] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:41:21,347] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[15:41:21,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[15:41:21,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[15:41:21,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[15:41:21,352] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[15:41:21,366] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:41:23,225] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:23,226] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:23,231] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:23,231] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:23,338] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:41:23,387] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:41:23,390] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:36819 (size: 14.6 KB, free: 1128.9 MB)
[15:41:23,398] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:35
[15:41:23,402] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:23,893] INFO  {CodeGenerator} Code generated in 216.108873 ms
[15:41:23,985] INFO  {SparkContext} Starting job: show at Main.scala:35
[15:41:24,004] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[15:41:24,004] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[15:41:24,004] INFO  {DAGScheduler} Parents of final stage: List()
[15:41:24,006] INFO  {DAGScheduler} Missing parents: List()
[15:41:24,010] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:35), which has no missing parents
[15:41:24,053] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 13.5 KB, free 1128.7 MB)
[15:41:24,056] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[15:41:24,056] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:36819 (size: 6.6 KB, free: 1128.9 MB)
[15:41:24,057] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:41:24,060] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:35)
[15:41:24,061] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:41:24,102] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:41:24,109] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:41:24,149] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:24,167] INFO  {CodeGenerator} Code generated in 15.197978 ms
[15:41:24,203] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2721 bytes result sent to driver
[15:41:24,210] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 128 ms on localhost (1/1)
[15:41:24,211] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:41:24,215] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.145 s
[15:41:24,220] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.234145 s
[15:41:24,258] INFO  {CodeGenerator} Code generated in 19.439922 ms
[15:41:24,309] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:24,309] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:24,309] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:24,310] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:24,316] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:41:24,348] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:41:24,352] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:36819 (size: 14.6 KB, free: 1128.9 MB)
[15:41:24,354] INFO  {SparkContext} Created broadcast 2 from show at Main.scala:44
[15:41:24,354] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:24,360] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 80.216.145.125:36819 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:41:24,366] INFO  {ContextCleaner} Cleaned accumulator 0
[15:41:24,366] INFO  {ContextCleaner} Cleaned accumulator 1
[15:41:24,367] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:36819 in memory (size: 6.6 KB, free: 1128.9 MB)
[15:41:24,425] INFO  {CodeGenerator} Code generated in 47.285179 ms
[15:41:24,439] INFO  {SparkContext} Starting job: show at Main.scala:44
[15:41:24,440] INFO  {DAGScheduler} Got job 1 (show at Main.scala:44) with 1 output partitions
[15:41:24,440] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:44)
[15:41:24,440] INFO  {DAGScheduler} Parents of final stage: List()
[15:41:24,440] INFO  {DAGScheduler} Missing parents: List()
[15:41:24,440] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:44), which has no missing parents
[15:41:24,443] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 20.9 KB, free 1128.7 MB)
[15:41:24,445] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 1128.7 MB)
[15:41:24,446] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:36819 (size: 8.2 KB, free: 1128.9 MB)
[15:41:24,447] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:41:24,447] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Main.scala:44)
[15:41:24,447] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:41:24,450] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:41:24,450] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:41:24,464] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:24,484] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3405 bytes result sent to driver
[15:41:24,486] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (1/1)
[15:41:24,486] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:41:24,486] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:44) finished in 0.039 s
[15:41:24,487] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:44, took 0.047795 s
[15:41:24,511] INFO  {CodeGenerator} Code generated in 17.441824 ms
[15:41:24,593] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:24,593] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:24,594] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:24,594] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:24,599] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:41:24,607] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:41:24,608] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:36819 (size: 14.6 KB, free: 1128.9 MB)
[15:41:24,609] INFO  {SparkContext} Created broadcast 4 from show at Main.scala:53
[15:41:24,609] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:24,671] INFO  {CodeGenerator} Code generated in 45.197276 ms
[15:41:24,679] INFO  {SparkContext} Starting job: show at Main.scala:53
[15:41:24,681] INFO  {DAGScheduler} Got job 2 (show at Main.scala:53) with 1 output partitions
[15:41:24,681] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:53)
[15:41:24,681] INFO  {DAGScheduler} Parents of final stage: List()
[15:41:24,681] INFO  {DAGScheduler} Missing parents: List()
[15:41:24,681] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53), which has no missing parents
[15:41:24,686] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 29.5 KB, free 1128.6 MB)
[15:41:24,688] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KB, free 1128.5 MB)
[15:41:24,688] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:36819 (size: 9.6 KB, free: 1128.9 MB)
[15:41:24,689] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:41:24,689] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at Main.scala:53)
[15:41:24,689] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:41:24,691] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:41:24,691] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:41:24,704] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:24,715] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 3479 bytes result sent to driver
[15:41:24,716] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 26 ms on localhost (1/1)
[15:41:24,716] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:41:24,717] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:53) finished in 0.027 s
[15:41:24,717] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:53, took 0.037390 s
[15:41:24,740] INFO  {CodeGenerator} Code generated in 20.134476 ms
[15:41:24,799] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:24,799] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:24,800] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:24,800] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:24,808] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.4 MB)
[15:41:24,820] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.4 MB)
[15:41:24,821] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:36819 (size: 14.6 KB, free: 1128.8 MB)
[15:41:24,823] INFO  {SparkContext} Created broadcast 6 from show at Main.scala:63
[15:41:24,823] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:24,899] INFO  {CodeGenerator} Code generated in 51.629057 ms
[15:41:24,910] INFO  {SparkContext} Starting job: show at Main.scala:63
[15:41:24,912] INFO  {DAGScheduler} Got job 3 (show at Main.scala:63) with 1 output partitions
[15:41:24,912] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:63)
[15:41:24,912] INFO  {DAGScheduler} Parents of final stage: List()
[15:41:24,912] INFO  {DAGScheduler} Missing parents: List()
[15:41:24,912] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63), which has no missing parents
[15:41:24,915] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 35.4 KB, free 1128.4 MB)
[15:41:24,917] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KB, free 1128.4 MB)
[15:41:24,917] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:36819 (size: 10.9 KB, free: 1128.8 MB)
[15:41:24,918] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:41:24,918] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at Main.scala:63)
[15:41:24,918] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:41:24,920] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:41:24,920] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:41:24,929] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:24,937] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 3488 bytes result sent to driver
[15:41:24,938] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 19 ms on localhost (1/1)
[15:41:24,938] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:41:24,938] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:63) finished in 0.019 s
[15:41:24,939] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:63, took 0.027987 s
[15:41:24,956] INFO  {CodeGenerator} Code generated in 14.935051 ms
[15:41:25,121] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:36819 in memory (size: 14.6 KB, free: 1128.8 MB)
[15:41:25,122] INFO  {ContextCleaner} Cleaned accumulator 46
[15:41:25,122] INFO  {ContextCleaner} Cleaned accumulator 47
[15:41:25,122] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.125:36819 in memory (size: 8.2 KB, free: 1128.9 MB)
[15:41:25,124] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.125:36819 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:41:25,124] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:25,124] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:25,124] INFO  {ContextCleaner} Cleaned accumulator 92
[15:41:25,125] INFO  {ContextCleaner} Cleaned accumulator 93
[15:41:25,125] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:25,125] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:25,125] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.125:36819 in memory (size: 9.6 KB, free: 1128.9 MB)
[15:41:25,126] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 80.216.145.125:36819 in memory (size: 14.6 KB, free: 1128.9 MB)
[15:41:25,126] INFO  {ContextCleaner} Cleaned accumulator 138
[15:41:25,127] INFO  {ContextCleaner} Cleaned accumulator 139
[15:41:25,127] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 80.216.145.125:36819 in memory (size: 10.9 KB, free: 1128.9 MB)
[15:41:25,131] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:41:25,141] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:41:25,141] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.125:36819 (size: 14.6 KB, free: 1128.9 MB)
[15:41:25,142] INFO  {SparkContext} Created broadcast 8 from collect at Main.scala:68
[15:41:25,142] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:25,190] INFO  {CodeGenerator} Code generated in 15.192732 ms
[15:41:25,217] INFO  {CodeGenerator} Code generated in 21.448778 ms
[15:41:25,255] INFO  {SparkContext} Starting job: collect at Main.scala:68
[15:41:25,260] INFO  {DAGScheduler} Registering RDD 14 (collect at Main.scala:68)
[15:41:25,261] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:68) with 1 output partitions
[15:41:25,261] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:68)
[15:41:25,261] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[15:41:25,261] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[15:41:25,263] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:68), which has no missing parents
[15:41:25,273] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 19.8 KB, free 1128.7 MB)
[15:41:25,275] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 1128.7 MB)
[15:41:25,276] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.125:36819 (size: 8.3 KB, free: 1128.9 MB)
[15:41:25,276] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[15:41:25,278] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at collect at Main.scala:68)
[15:41:25,278] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:41:25,281] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[15:41:25,281] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:41:25,297] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:25,574] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1888 bytes result sent to driver
[15:41:25,577] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 297 ms on localhost (1/1)
[15:41:25,577] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:41:25,577] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:68) finished in 0.298 s
[15:41:25,578] INFO  {DAGScheduler} looking for newly runnable stages
[15:41:25,578] INFO  {DAGScheduler} running: Set()
[15:41:25,578] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[15:41:25,579] INFO  {DAGScheduler} failed: Set()
[15:41:25,580] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:68), which has no missing parents
[15:41:25,585] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[15:41:25,587] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[15:41:25,587] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.125:36819 (size: 3.9 KB, free: 1128.9 MB)
[15:41:25,588] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[15:41:25,588] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at collect at Main.scala:68)
[15:41:25,588] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:41:25,592] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[15:41:25,592] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:41:25,605] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[15:41:25,606] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[15:41:25,618] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[15:41:25,619] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 29 ms on localhost (1/1)
[15:41:25,620] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:41:25,620] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:68) finished in 0.030 s
[15:41:25,620] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:68, took 0.364812 s
[15:41:25,629] INFO  {CodeGenerator} Code generated in 5.955253 ms
[15:41:25,687] INFO  {FileSourceStrategy} Pruning directories with: 
[15:41:25,687] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:41:25,687] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:41:25,688] INFO  {FileSourceStrategy} Pushed Filters: 
[15:41:25,691] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[15:41:25,698] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[15:41:25,699] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 80.216.145.125:36819 (size: 14.6 KB, free: 1128.9 MB)
[15:41:25,699] INFO  {SparkContext} Created broadcast 11 from show at Main.scala:89
[15:41:25,700] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:41:25,777] INFO  {CodeGenerator} Code generated in 58.199505 ms
[15:41:25,785] INFO  {SparkContext} Starting job: show at Main.scala:89
[15:41:25,786] INFO  {DAGScheduler} Got job 5 (show at Main.scala:89) with 1 output partitions
[15:41:25,786] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:89)
[15:41:25,786] INFO  {DAGScheduler} Parents of final stage: List()
[15:41:25,787] INFO  {DAGScheduler} Missing parents: List()
[15:41:25,787] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:89), which has no missing parents
[15:41:25,790] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 57.2 KB, free 1128.5 MB)
[15:41:25,791] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[15:41:25,792] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 80.216.145.125:36819 (size: 14.6 KB, free: 1128.8 MB)
[15:41:25,793] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[15:41:25,793] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at Main.scala:89)
[15:41:25,793] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[15:41:25,794] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:41:25,795] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[15:41:25,805] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:41:25,811] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 3559 bytes result sent to driver
[15:41:25,812] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 19 ms on localhost (1/1)
[15:41:25,813] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[15:41:25,813] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:89) finished in 0.020 s
[15:41:25,813] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:89, took 0.027619 s
[15:41:25,829] INFO  {CodeGenerator} Code generated in 13.44776 ms
[15:41:25,838] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:41:25,844] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:41:25,846] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:41:25,847] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:41:25,847] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:41:25,847] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:41:25,847] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:41:25,847] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:41:25,847] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:41:25,847] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:41:25,848] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:41:25,848] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:41:25,848] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:41:25,848] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:41:25,848] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:41:25,848] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:41:25,848] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:41:25,849] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:41:25,849] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:41:25,849] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:41:25,849] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:41:25,849] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:41:25,849] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:41:25,849] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:41:25,849] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:41:25,850] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:41:25,851] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:41:25,862] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:41:25,870] INFO  {MemoryStore} MemoryStore cleared
[15:41:25,870] INFO  {BlockManager} BlockManager stopped
[15:41:25,872] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:41:25,875] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:41:25,877] INFO  {SparkContext} Successfully stopped SparkContext
[15:41:25,878] INFO  {ShutdownHookManager} Shutdown hook called
[15:41:25,879] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-e0d8e6e5-b832-4236-96fa-4634156dbba7
[15:42:17,340] INFO  {SparkContext} Running Spark version 2.0.1
[15:42:17,549] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:42:17,649] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:42:17,650] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:42:17,716] INFO  {SecurityManager} Changing view acls to: victor
[15:42:17,717] INFO  {SecurityManager} Changing modify acls to: victor
[15:42:17,717] INFO  {SecurityManager} Changing view acls groups to: 
[15:42:17,718] INFO  {SecurityManager} Changing modify acls groups to: 
[15:42:17,719] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:42:18,036] INFO  {Utils} Successfully started service 'sparkDriver' on port 44667.
[15:42:18,055] INFO  {SparkEnv} Registering MapOutputTracker
[15:42:18,070] INFO  {SparkEnv} Registering BlockManagerMaster
[15:42:18,081] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-fdd3cb35-6b02-4769-bac4-296e00037c02
[15:42:18,095] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:42:18,154] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:42:18,225] INFO  {log} Logging initialized @1499ms
[15:42:18,323] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:42:18,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[15:42:18,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[15:42:18,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[15:42:18,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[15:42:18,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[15:42:18,339] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[15:42:18,339] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[15:42:18,339] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[15:42:18,339] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[15:42:18,339] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[15:42:18,339] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[15:42:18,340] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[15:42:18,340] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[15:42:18,340] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[15:42:18,340] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[15:42:18,340] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[15:42:18,341] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[15:42:18,341] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[15:42:18,341] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[15:42:18,341] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[15:42:18,347] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[15:42:18,347] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[15:42:18,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[15:42:18,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[15:42:18,354] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:42:18,354] INFO  {Server} Started @1630ms
[15:42:18,355] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:42:18,357] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:42:18,448] INFO  {Executor} Starting executor ID driver on host localhost
[15:42:18,469] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33139.
[15:42:18,470] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:33139
[15:42:18,471] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 33139)
[15:42:18,474] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:33139 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 33139)
[15:42:18,479] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 33139)
[15:42:18,605] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[15:42:18,647] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[15:42:18,648] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[15:42:18,648] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[15:42:18,649] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[15:42:18,650] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[15:42:18,665] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:42:20,395] INFO  {FileSourceStrategy} Pruning directories with: 
[15:42:20,398] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:42:20,402] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:42:20,403] INFO  {FileSourceStrategy} Pushed Filters: 
[15:42:20,511] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:42:20,554] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:42:20,556] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:33139 (size: 14.6 KB, free: 1128.9 MB)
[15:42:20,561] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:42:20,566] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:42:21,000] INFO  {CodeGenerator} Code generated in 188.148515 ms
[15:42:21,201] INFO  {CodeGenerator} Code generated in 27.207789 ms
[15:42:21,251] INFO  {SparkContext} Starting job: show at Main.scala:35
[15:42:21,267] INFO  {DAGScheduler} Got job 0 (show at Main.scala:35) with 1 output partitions
[15:42:21,267] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:35)
[15:42:21,268] INFO  {DAGScheduler} Parents of final stage: List()
[15:42:21,271] INFO  {DAGScheduler} Missing parents: List()
[15:42:21,275] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:35), which has no missing parents
[15:42:21,331] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[15:42:21,333] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[15:42:21,334] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.125:33139 (size: 8.5 KB, free: 1128.9 MB)
[15:42:21,335] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[15:42:21,338] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:35)
[15:42:21,339] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[15:42:21,377] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:42:21,383] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:42:21,425] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[15:42:21,437] INFO  {CodeGenerator} Code generated in 8.966855 ms
[15:42:21,581] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[15:42:21,582] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 80.216.145.125:33139 (size: 1239.2 KB, free: 1127.7 MB)
[15:42:21,594] INFO  {CodeGenerator} Code generated in 3.975064 ms
[15:42:21,618] INFO  {CodeGenerator} Code generated in 18.808877 ms
[15:42:21,637] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[15:42:21,643] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[15:42:21,652] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 292 ms on localhost (1/1)
[15:42:21,653] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[15:42:21,657] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:35) finished in 0.309 s
[15:42:21,663] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:35, took 0.411503 s
[15:42:21,705] INFO  {CodeGenerator} Code generated in 20.614675 ms
[15:42:21,827] INFO  {CodeGenerator} Code generated in 41.472215 ms
[15:42:21,845] INFO  {SparkContext} Starting job: show at Main.scala:44
[15:42:21,846] INFO  {DAGScheduler} Got job 1 (show at Main.scala:44) with 1 output partitions
[15:42:21,847] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:44)
[15:42:21,847] INFO  {DAGScheduler} Parents of final stage: List()
[15:42:21,849] INFO  {DAGScheduler} Missing parents: List()
[15:42:21,850] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:44), which has no missing parents
[15:42:21,854] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[15:42:21,856] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[15:42:21,857] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.125:33139 (size: 10.0 KB, free: 1127.7 MB)
[15:42:21,857] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[15:42:21,857] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:44)
[15:42:21,857] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[15:42:21,863] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:42:21,863] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[15:42:21,874] INFO  {BlockManager} Found block rdd_2_0 locally
[15:42:21,890] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[15:42:21,891] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[15:42:21,894] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (1/1)
[15:42:21,894] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[15:42:21,894] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:44) finished in 0.034 s
[15:42:21,895] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:44, took 0.049180 s
[15:42:21,924] INFO  {CodeGenerator} Code generated in 19.588197 ms
[15:42:22,110] INFO  {ContextCleaner} Cleaned accumulator 3
[15:42:22,110] INFO  {ContextCleaner} Cleaned accumulator 4
[15:42:22,128] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.125:33139 in memory (size: 8.5 KB, free: 1127.7 MB)
[15:42:22,138] INFO  {ContextCleaner} Cleaned accumulator 49
[15:42:22,139] INFO  {ContextCleaner} Cleaned accumulator 50
[15:42:22,141] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.125:33139 in memory (size: 10.0 KB, free: 1127.7 MB)
[15:42:22,178] INFO  {CodeGenerator} Code generated in 47.314102 ms
[15:42:22,191] INFO  {SparkContext} Starting job: show at Main.scala:53
[15:42:22,192] INFO  {DAGScheduler} Got job 2 (show at Main.scala:53) with 1 output partitions
[15:42:22,193] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:53)
[15:42:22,193] INFO  {DAGScheduler} Parents of final stage: List()
[15:42:22,193] INFO  {DAGScheduler} Missing parents: List()
[15:42:22,194] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:53), which has no missing parents
[15:42:22,198] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[15:42:22,201] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[15:42:22,202] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.125:33139 (size: 11.7 KB, free: 1127.7 MB)
[15:42:22,203] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[15:42:22,203] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:53)
[15:42:22,204] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[15:42:22,206] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:42:22,206] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[15:42:22,212] INFO  {BlockManager} Found block rdd_2_0 locally
[15:42:22,227] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[15:42:22,228] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[15:42:22,230] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 26 ms on localhost (1/1)
[15:42:22,230] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[15:42:22,231] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:53) finished in 0.026 s
[15:42:22,231] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:53, took 0.039640 s
[15:42:22,255] INFO  {CodeGenerator} Code generated in 19.888698 ms
[15:42:22,371] INFO  {CodeGenerator} Code generated in 45.34555 ms
[15:42:22,381] INFO  {SparkContext} Starting job: show at Main.scala:63
[15:42:22,382] INFO  {DAGScheduler} Got job 3 (show at Main.scala:63) with 1 output partitions
[15:42:22,382] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:63)
[15:42:22,382] INFO  {DAGScheduler} Parents of final stage: List()
[15:42:22,383] INFO  {DAGScheduler} Missing parents: List()
[15:42:22,383] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:63), which has no missing parents
[15:42:22,387] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[15:42:22,389] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[15:42:22,389] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.125:33139 (size: 13.3 KB, free: 1127.7 MB)
[15:42:22,390] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[15:42:22,390] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:63)
[15:42:22,390] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[15:42:22,392] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:42:22,392] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[15:42:22,398] INFO  {BlockManager} Found block rdd_2_0 locally
[15:42:22,407] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[15:42:22,408] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[15:42:22,409] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 18 ms on localhost (1/1)
[15:42:22,409] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[15:42:22,409] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:63) finished in 0.018 s
[15:42:22,410] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:63, took 0.028433 s
[15:42:22,425] INFO  {CodeGenerator} Code generated in 13.079347 ms
[15:42:22,545] INFO  {CodeGenerator} Code generated in 14.295353 ms
[15:42:22,570] INFO  {CodeGenerator} Code generated in 19.033866 ms
[15:42:22,602] INFO  {SparkContext} Starting job: collect at Main.scala:68
[15:42:22,606] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:68)
[15:42:22,607] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:68) with 1 output partitions
[15:42:22,607] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:68)
[15:42:22,607] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[15:42:22,607] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[15:42:22,609] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:68), which has no missing parents
[15:42:22,616] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[15:42:22,617] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[15:42:22,618] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.125:33139 (size: 10.2 KB, free: 1127.6 MB)
[15:42:22,618] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[15:42:22,620] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:68)
[15:42:22,620] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[15:42:22,623] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[15:42:22,623] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[15:42:22,629] INFO  {BlockManager} Found block rdd_2_0 locally
[15:42:22,893] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2412 bytes result sent to driver
[15:42:22,895] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 274 ms on localhost (1/1)
[15:42:22,895] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[15:42:22,896] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:68) finished in 0.275 s
[15:42:22,897] INFO  {DAGScheduler} looking for newly runnable stages
[15:42:22,898] INFO  {DAGScheduler} running: Set()
[15:42:22,898] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[15:42:22,899] INFO  {DAGScheduler} failed: Set()
[15:42:22,900] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:68), which has no missing parents
[15:42:22,904] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[15:42:22,906] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[15:42:22,907] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.125:33139 (size: 3.9 KB, free: 1127.6 MB)
[15:42:22,907] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[15:42:22,908] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:68)
[15:42:22,908] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[15:42:22,910] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[15:42:22,911] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[15:42:22,922] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[15:42:22,923] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[15:42:22,935] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[15:42:22,936] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 27 ms on localhost (1/1)
[15:42:22,936] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[15:42:22,936] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:68) finished in 0.028 s
[15:42:22,937] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:68, took 0.334469 s
[15:42:22,947] INFO  {CodeGenerator} Code generated in 6.258765 ms
[15:42:23,072] INFO  {CodeGenerator} Code generated in 51.838646 ms
[15:42:23,081] INFO  {SparkContext} Starting job: show at Main.scala:89
[15:42:23,082] INFO  {DAGScheduler} Got job 5 (show at Main.scala:89) with 1 output partitions
[15:42:23,082] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:89)
[15:42:23,082] INFO  {DAGScheduler} Parents of final stage: List()
[15:42:23,083] INFO  {DAGScheduler} Missing parents: List()
[15:42:23,083] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[23] at show at Main.scala:89), which has no missing parents
[15:42:23,085] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[15:42:23,087] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[15:42:23,088] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.125:33139 (size: 16.4 KB, free: 1127.6 MB)
[15:42:23,088] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[15:42:23,089] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at show at Main.scala:89)
[15:42:23,089] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[15:42:23,090] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[15:42:23,091] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[15:42:23,095] INFO  {BlockManager} Found block rdd_2_0 locally
[15:42:23,104] WARN  {Executor} 1 block locks were not released by TID = 6:
[rdd_2_0]
[15:42:23,105] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 4083 bytes result sent to driver
[15:42:23,106] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 17 ms on localhost (1/1)
[15:42:23,106] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[15:42:23,106] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:89) finished in 0.017 s
[15:42:23,107] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:89, took 0.025490 s
[15:42:23,123] INFO  {CodeGenerator} Code generated in 13.851473 ms
[15:42:23,132] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:42:23,136] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:42:23,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[15:42:23,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[15:42:23,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[15:42:23,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[15:42:23,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[15:42:23,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[15:42:23,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[15:42:23,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[15:42:23,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[15:42:23,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[15:42:23,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[15:42:23,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[15:42:23,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[15:42:23,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[15:42:23,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[15:42:23,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[15:42:23,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[15:42:23,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[15:42:23,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[15:42:23,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[15:42:23,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[15:42:23,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[15:42:23,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[15:42:23,143] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[15:42:23,144] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:42:23,165] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:42:23,172] INFO  {MemoryStore} MemoryStore cleared
[15:42:23,172] INFO  {BlockManager} BlockManager stopped
[15:42:23,174] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:42:23,177] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:42:23,180] INFO  {SparkContext} Successfully stopped SparkContext
[15:42:23,181] INFO  {ShutdownHookManager} Shutdown hook called
[15:42:23,181] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-3d2cd3f2-da6f-48bf-9df5-72fb18d65095
[15:44:28,010] INFO  {SparkContext} Running Spark version 2.0.1
[15:44:28,225] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:44:28,307] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:44:28,308] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:44:28,385] INFO  {SecurityManager} Changing view acls to: victor
[15:44:28,385] INFO  {SecurityManager} Changing modify acls to: victor
[15:44:28,386] INFO  {SecurityManager} Changing view acls groups to: 
[15:44:28,386] INFO  {SecurityManager} Changing modify acls groups to: 
[15:44:28,387] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:44:28,752] INFO  {Utils} Successfully started service 'sparkDriver' on port 41053.
[15:44:28,772] INFO  {SparkEnv} Registering MapOutputTracker
[15:44:28,796] INFO  {SparkEnv} Registering BlockManagerMaster
[15:44:28,809] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-3c7e9b08-45c9-4d31-b115-0b02e77673d1
[15:44:28,823] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:44:28,876] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:44:28,951] INFO  {log} Logging initialized @1533ms
[15:44:29,054] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:44:29,073] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[15:44:29,073] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[15:44:29,073] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[15:44:29,074] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[15:44:29,074] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[15:44:29,074] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[15:44:29,074] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[15:44:29,075] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[15:44:29,075] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[15:44:29,075] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[15:44:29,076] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[15:44:29,076] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[15:44:29,076] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[15:44:29,077] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[15:44:29,077] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[15:44:29,077] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[15:44:29,077] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[15:44:29,078] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[15:44:29,078] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[15:44:29,078] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[15:44:29,089] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[15:44:29,089] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[15:44:29,090] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[15:44:29,091] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[15:44:29,100] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:44:29,100] INFO  {Server} Started @1684ms
[15:44:29,101] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:44:29,103] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:44:29,217] INFO  {Executor} Starting executor ID driver on host localhost
[15:44:29,245] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46737.
[15:44:29,247] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:46737
[15:44:29,249] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 46737)
[15:44:29,252] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:46737 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 46737)
[15:44:29,255] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 46737)
[15:44:29,390] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[15:44:29,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[15:44:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[15:44:29,438] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[15:44:29,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[15:44:29,442] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[15:44:29,458] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:44:31,226] INFO  {FileSourceStrategy} Pruning directories with: 
[15:44:31,229] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:44:31,234] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:44:31,235] INFO  {FileSourceStrategy} Pushed Filters: 
[15:44:31,341] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:44:31,385] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:44:31,386] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:46737 (size: 14.6 KB, free: 1128.9 MB)
[15:44:31,392] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:44:31,395] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[15:44:31,827] INFO  {CodeGenerator} Code generated in 188.192533 ms
[15:44:31,920] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:44:31,926] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[15:44:31,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[15:44:31,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[15:44:31,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[15:44:31,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[15:44:31,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[15:44:31,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[15:44:31,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[15:44:31,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[15:44:31,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[15:44:31,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[15:44:31,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[15:44:31,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[15:44:31,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[15:44:31,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[15:44:31,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[15:44:31,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[15:44:31,931] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[15:44:31,932] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[15:44:31,932] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[15:44:31,932] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[15:44:31,932] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[15:44:31,932] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[15:44:31,932] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[15:44:31,932] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[15:44:31,934] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:44:31,942] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:44:31,947] INFO  {MemoryStore} MemoryStore cleared
[15:44:31,947] INFO  {BlockManager} BlockManager stopped
[15:44:31,953] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:44:31,957] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:44:31,958] INFO  {SparkContext} Successfully stopped SparkContext
[15:44:31,959] INFO  {ShutdownHookManager} Shutdown hook called
[15:44:31,960] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f029aac1-a1ae-4faa-ab99-950391f9c216
[15:46:05,125] INFO  {SparkContext} Running Spark version 2.0.1
[15:46:05,325] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:46:05,408] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:46:05,408] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:46:05,485] INFO  {SecurityManager} Changing view acls to: victor
[15:46:05,486] INFO  {SecurityManager} Changing modify acls to: victor
[15:46:05,486] INFO  {SecurityManager} Changing view acls groups to: 
[15:46:05,487] INFO  {SecurityManager} Changing modify acls groups to: 
[15:46:05,488] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:46:05,834] INFO  {Utils} Successfully started service 'sparkDriver' on port 44927.
[15:46:05,855] INFO  {SparkEnv} Registering MapOutputTracker
[15:46:05,872] INFO  {SparkEnv} Registering BlockManagerMaster
[15:46:05,885] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-a9980003-eccf-44bb-a4e2-73dd6f25e13c
[15:46:05,899] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:46:05,949] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:46:06,019] INFO  {log} Logging initialized @1490ms
[15:46:06,118] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:46:06,133] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:46:06,134] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:46:06,134] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:46:06,134] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:46:06,134] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:46:06,134] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:46:06,135] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:46:06,135] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:46:06,135] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:46:06,135] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:46:06,135] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:46:06,135] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:46:06,136] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:46:06,136] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:46:06,136] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:46:06,136] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:46:06,136] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:46:06,137] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:46:06,137] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:46:06,137] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:46:06,143] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:46:06,144] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:46:06,144] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:46:06,145] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:46:06,151] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:46:06,151] INFO  {Server} Started @1623ms
[15:46:06,151] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:46:06,153] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:46:06,228] INFO  {Executor} Starting executor ID driver on host localhost
[15:46:06,252] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46097.
[15:46:06,253] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:46097
[15:46:06,254] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 46097)
[15:46:06,258] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:46097 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 46097)
[15:46:06,260] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 46097)
[15:46:06,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:46:06,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[15:46:06,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[15:46:06,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[15:46:06,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[15:46:06,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[15:46:06,444] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:46:08,234] INFO  {FileSourceStrategy} Pruning directories with: 
[15:46:08,237] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:46:08,243] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:46:08,244] INFO  {FileSourceStrategy} Pushed Filters: 
[15:46:08,353] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:46:08,397] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:46:08,398] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:46097 (size: 14.6 KB, free: 1128.9 MB)
[15:46:08,404] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:46:08,408] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:46:08,843] INFO  {CodeGenerator} Code generated in 191.715255 ms
[15:46:08,933] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:46:08,937] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:46:08,939] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:46:08,939] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:46:08,939] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:46:08,939] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:46:08,939] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:46:08,939] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:46:08,940] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:46:08,940] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:46:08,940] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:46:08,940] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:46:08,940] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:46:08,940] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:46:08,940] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:46:08,940] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:46:08,940] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:46:08,941] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:46:08,941] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:46:08,941] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:46:08,941] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:46:08,941] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:46:08,941] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:46:08,941] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:46:08,942] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:46:08,942] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:46:08,944] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:46:08,951] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:46:08,957] INFO  {MemoryStore} MemoryStore cleared
[15:46:08,958] INFO  {BlockManager} BlockManager stopped
[15:46:08,964] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:46:08,967] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:46:08,969] INFO  {SparkContext} Successfully stopped SparkContext
[15:46:08,970] INFO  {ShutdownHookManager} Shutdown hook called
[15:46:08,971] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-63f6c28e-31b2-4af1-b41f-e2f242433180
[15:47:06,969] INFO  {SparkContext} Running Spark version 2.0.1
[15:47:07,181] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:47:07,258] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:47:07,259] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:47:07,336] INFO  {SecurityManager} Changing view acls to: victor
[15:47:07,337] INFO  {SecurityManager} Changing modify acls to: victor
[15:47:07,338] INFO  {SecurityManager} Changing view acls groups to: 
[15:47:07,339] INFO  {SecurityManager} Changing modify acls groups to: 
[15:47:07,340] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:47:07,682] INFO  {Utils} Successfully started service 'sparkDriver' on port 37599.
[15:47:07,702] INFO  {SparkEnv} Registering MapOutputTracker
[15:47:07,716] INFO  {SparkEnv} Registering BlockManagerMaster
[15:47:07,728] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-59086dbe-eccf-42ed-996f-8687370d3bc3
[15:47:07,741] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:47:07,801] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:47:07,871] INFO  {log} Logging initialized @1473ms
[15:47:07,976] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:47:07,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:47:07,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:47:07,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:47:07,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:47:07,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:47:07,994] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:47:07,994] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:47:07,994] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:47:07,994] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:47:07,995] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:47:07,995] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:47:07,995] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:47:07,995] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:47:07,995] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:47:07,996] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:47:07,996] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:47:07,996] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:47:07,996] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:47:07,996] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:47:07,997] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:47:08,003] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:47:08,003] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:47:08,004] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:47:08,004] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:47:08,010] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:47:08,010] INFO  {Server} Started @1613ms
[15:47:08,011] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:47:08,014] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:47:08,097] INFO  {Executor} Starting executor ID driver on host localhost
[15:47:08,122] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42205.
[15:47:08,123] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:42205
[15:47:08,125] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 42205)
[15:47:08,127] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:42205 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 42205)
[15:47:08,130] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 42205)
[15:47:08,249] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:47:08,295] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[15:47:08,296] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[15:47:08,297] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[15:47:08,298] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[15:47:08,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[15:47:08,316] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:47:10,162] INFO  {FileSourceStrategy} Pruning directories with: 
[15:47:10,170] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:47:10,180] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:47:10,181] INFO  {FileSourceStrategy} Pushed Filters: 
[15:47:10,295] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:47:10,340] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:47:10,342] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:42205 (size: 14.6 KB, free: 1128.9 MB)
[15:47:10,348] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:47:10,351] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:47:10,772] INFO  {CodeGenerator} Code generated in 182.383248 ms
[15:47:10,883] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:47:10,887] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:47:10,889] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:47:10,889] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:47:10,889] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:47:10,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:47:10,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:47:10,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:47:10,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:47:10,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:47:10,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:47:10,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:47:10,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:47:10,890] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:47:10,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:47:10,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:47:10,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:47:10,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:47:10,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:47:10,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:47:10,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:47:10,891] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:47:10,892] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:47:10,892] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:47:10,892] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:47:10,892] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:47:10,893] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:47:10,902] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:47:10,908] INFO  {MemoryStore} MemoryStore cleared
[15:47:10,909] INFO  {BlockManager} BlockManager stopped
[15:47:10,915] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:47:10,918] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:47:10,919] INFO  {SparkContext} Successfully stopped SparkContext
[15:47:10,920] INFO  {ShutdownHookManager} Shutdown hook called
[15:47:10,921] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-5b288c6b-3f1f-4857-9ef6-eedba77edbda
[15:47:24,180] INFO  {SparkContext} Running Spark version 2.0.1
[15:47:24,387] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:47:24,475] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:47:24,475] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:47:24,550] INFO  {SecurityManager} Changing view acls to: victor
[15:47:24,551] INFO  {SecurityManager} Changing modify acls to: victor
[15:47:24,551] INFO  {SecurityManager} Changing view acls groups to: 
[15:47:24,552] INFO  {SecurityManager} Changing modify acls groups to: 
[15:47:24,552] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:47:24,913] INFO  {Utils} Successfully started service 'sparkDriver' on port 43549.
[15:47:24,931] INFO  {SparkEnv} Registering MapOutputTracker
[15:47:24,945] INFO  {SparkEnv} Registering BlockManagerMaster
[15:47:24,956] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-4dfe3fbe-e6fc-40b1-ab36-354d11717f12
[15:47:24,970] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:47:25,019] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:47:25,088] INFO  {log} Logging initialized @1471ms
[15:47:25,190] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:47:25,205] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:47:25,205] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:47:25,206] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:47:25,206] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:47:25,206] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:47:25,206] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:47:25,206] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:47:25,207] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:47:25,207] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:47:25,207] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:47:25,207] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:47:25,207] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:47:25,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:47:25,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:47:25,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:47:25,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:47:25,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:47:25,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:47:25,209] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:47:25,209] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:47:25,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:47:25,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:47:25,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:47:25,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:47:25,227] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:47:25,227] INFO  {Server} Started @1612ms
[15:47:25,227] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:47:25,230] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:47:25,318] INFO  {Executor} Starting executor ID driver on host localhost
[15:47:25,343] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45245.
[15:47:25,344] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:45245
[15:47:25,345] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 45245)
[15:47:25,348] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:45245 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 45245)
[15:47:25,350] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 45245)
[15:47:25,469] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:47:25,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[15:47:25,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[15:47:25,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[15:47:25,513] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[15:47:25,514] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[15:47:25,529] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:47:27,293] INFO  {FileSourceStrategy} Pruning directories with: 
[15:47:27,296] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:47:27,301] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:47:27,301] INFO  {FileSourceStrategy} Pushed Filters: 
[15:47:27,409] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:47:27,453] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:47:27,455] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:45245 (size: 14.6 KB, free: 1128.9 MB)
[15:47:27,461] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:47:27,467] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:47:27,904] INFO  {CodeGenerator} Code generated in 193.911224 ms
[15:47:28,006] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:47:28,011] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:47:28,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:47:28,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:47:28,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:47:28,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:47:28,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:47:28,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:47:28,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:47:28,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:47:28,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:47:28,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:47:28,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:47:28,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:47:28,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:47:28,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:47:28,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:47:28,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:47:28,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:47:28,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:47:28,017] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:47:28,017] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:47:28,017] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:47:28,017] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:47:28,017] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:47:28,017] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:47:28,018] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:47:28,026] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:47:28,031] INFO  {MemoryStore} MemoryStore cleared
[15:47:28,031] INFO  {BlockManager} BlockManager stopped
[15:47:28,037] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:47:28,040] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:47:28,053] INFO  {SparkContext} Successfully stopped SparkContext
[15:47:28,054] INFO  {ShutdownHookManager} Shutdown hook called
[15:47:28,055] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-8b505a13-9bbb-410e-baae-39b29d77b946
[15:47:36,102] INFO  {SparkContext} Running Spark version 2.0.1
[15:47:36,301] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:47:36,391] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:47:36,392] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:47:36,461] INFO  {SecurityManager} Changing view acls to: victor
[15:47:36,461] INFO  {SecurityManager} Changing modify acls to: victor
[15:47:36,462] INFO  {SecurityManager} Changing view acls groups to: 
[15:47:36,462] INFO  {SecurityManager} Changing modify acls groups to: 
[15:47:36,463] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:47:36,806] INFO  {Utils} Successfully started service 'sparkDriver' on port 35731.
[15:47:36,825] INFO  {SparkEnv} Registering MapOutputTracker
[15:47:36,841] INFO  {SparkEnv} Registering BlockManagerMaster
[15:47:36,853] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-fe246a6f-f9c4-43b8-a53d-27b7e2524f32
[15:47:36,867] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:47:36,924] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:47:36,996] INFO  {log} Logging initialized @1483ms
[15:47:37,095] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:47:37,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:47:37,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:47:37,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:47:37,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:47:37,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:47:37,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:47:37,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:47:37,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:47:37,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:47:37,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:47:37,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:47:37,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:47:37,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:47:37,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:47:37,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:47:37,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:47:37,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:47:37,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:47:37,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:47:37,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:47:37,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:47:37,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:47:37,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:47:37,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:47:37,127] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:47:37,127] INFO  {Server} Started @1615ms
[15:47:37,128] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:47:37,130] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:47:37,210] INFO  {Executor} Starting executor ID driver on host localhost
[15:47:37,235] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37999.
[15:47:37,236] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:37999
[15:47:37,238] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 37999)
[15:47:37,242] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:37999 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 37999)
[15:47:37,245] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 37999)
[15:47:37,366] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:47:37,409] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL,null,AVAILABLE}
[15:47:37,410] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/json,null,AVAILABLE}
[15:47:37,410] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution,null,AVAILABLE}
[15:47:37,411] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/execution/json,null,AVAILABLE}
[15:47:37,412] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54107f42{/static/sql,null,AVAILABLE}
[15:47:37,426] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:47:39,189] INFO  {FileSourceStrategy} Pruning directories with: 
[15:47:39,191] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:47:39,196] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:47:39,196] INFO  {FileSourceStrategy} Pushed Filters: 
[15:47:39,310] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:47:39,360] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:47:39,362] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:37999 (size: 14.6 KB, free: 1128.9 MB)
[15:47:39,367] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:47:39,371] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:47:39,841] INFO  {CodeGenerator} Code generated in 216.653325 ms
[15:47:39,952] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:47:39,956] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:47:39,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:47:39,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:47:39,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:47:39,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:47:39,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:47:39,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:47:39,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:47:39,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:47:39,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:47:39,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:47:39,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:47:39,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:47:39,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:47:39,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:47:39,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:47:39,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:47:39,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:47:39,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:47:39,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:47:39,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:47:39,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:47:39,960] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:47:39,960] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:47:39,960] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:47:39,961] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:47:39,969] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:47:39,976] INFO  {MemoryStore} MemoryStore cleared
[15:47:39,977] INFO  {BlockManager} BlockManager stopped
[15:47:39,982] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:47:39,987] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:47:39,988] INFO  {SparkContext} Successfully stopped SparkContext
[15:47:39,989] INFO  {ShutdownHookManager} Shutdown hook called
[15:47:39,990] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a6c88920-d00e-4711-81c4-f01765e9c79b
[15:47:48,742] INFO  {SparkContext} Running Spark version 2.0.1
[15:47:48,971] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:47:49,074] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:47:49,075] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:47:49,155] INFO  {SecurityManager} Changing view acls to: victor
[15:47:49,156] INFO  {SecurityManager} Changing modify acls to: victor
[15:47:49,157] INFO  {SecurityManager} Changing view acls groups to: 
[15:47:49,158] INFO  {SecurityManager} Changing modify acls groups to: 
[15:47:49,158] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:47:49,499] INFO  {Utils} Successfully started service 'sparkDriver' on port 37417.
[15:47:49,517] INFO  {SparkEnv} Registering MapOutputTracker
[15:47:49,532] INFO  {SparkEnv} Registering BlockManagerMaster
[15:47:49,545] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-6f1a1738-8792-40ed-8020-6183db733688
[15:47:49,560] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:47:49,613] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:47:49,686] INFO  {log} Logging initialized @1525ms
[15:47:49,793] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:47:49,809] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:47:49,809] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:47:49,810] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:47:49,810] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:47:49,810] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:47:49,810] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:47:49,810] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:47:49,810] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:47:49,811] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:47:49,811] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:47:49,811] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:47:49,811] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:47:49,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:47:49,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:47:49,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:47:49,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:47:49,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:47:49,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:47:49,813] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:47:49,813] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:47:49,819] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:47:49,819] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:47:49,820] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:47:49,820] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:47:49,828] INFO  {ServerConnector} Started ServerConnector@cef745e{HTTP/1.1}{0.0.0.0:4040}
[15:47:49,829] INFO  {Server} Started @1668ms
[15:47:49,829] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:47:49,831] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:47:49,918] INFO  {Executor} Starting executor ID driver on host localhost
[15:47:49,943] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41637.
[15:47:49,944] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:41637
[15:47:49,946] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 41637)
[15:47:49,949] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:41637 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 41637)
[15:47:49,952] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 41637)
[15:47:50,074] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:47:50,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL,null,AVAILABLE}
[15:47:50,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/json,null,AVAILABLE}
[15:47:50,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution,null,AVAILABLE}
[15:47:50,123] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/execution/json,null,AVAILABLE}
[15:47:50,124] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54107f42{/static/sql,null,AVAILABLE}
[15:47:50,142] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:47:52,015] INFO  {FileSourceStrategy} Pruning directories with: 
[15:47:52,018] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:47:52,023] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:47:52,024] INFO  {FileSourceStrategy} Pushed Filters: 
[15:47:52,140] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:47:52,207] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:47:52,209] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:41637 (size: 14.6 KB, free: 1128.9 MB)
[15:47:52,218] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:47:52,223] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:47:52,719] INFO  {CodeGenerator} Code generated in 212.736091 ms
[15:47:52,825] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:47:52,830] INFO  {ServerConnector} Stopped ServerConnector@cef745e{HTTP/1.1}{0.0.0.0:4040}
[15:47:52,832] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:47:52,832] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:47:52,833] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:47:52,833] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:47:52,833] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:47:52,833] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:47:52,833] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:47:52,834] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:47:52,834] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:47:52,834] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:47:52,834] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:47:52,834] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:47:52,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:47:52,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:47:52,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:47:52,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:47:52,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:47:52,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:47:52,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:47:52,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:47:52,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:47:52,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:47:52,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:47:52,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:47:52,838] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:47:52,847] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:47:52,852] INFO  {MemoryStore} MemoryStore cleared
[15:47:52,852] INFO  {BlockManager} BlockManager stopped
[15:47:52,857] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:47:52,861] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:47:52,875] INFO  {SparkContext} Successfully stopped SparkContext
[15:47:52,877] INFO  {ShutdownHookManager} Shutdown hook called
[15:47:52,877] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-220e0274-40ef-4100-915b-b08a182e2861
[15:48:07,728] INFO  {SparkContext} Running Spark version 2.0.1
[15:48:07,926] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:48:08,028] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:48:08,029] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:48:08,109] INFO  {SecurityManager} Changing view acls to: victor
[15:48:08,110] INFO  {SecurityManager} Changing modify acls to: victor
[15:48:08,110] INFO  {SecurityManager} Changing view acls groups to: 
[15:48:08,111] INFO  {SecurityManager} Changing modify acls groups to: 
[15:48:08,112] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:48:08,443] INFO  {Utils} Successfully started service 'sparkDriver' on port 43973.
[15:48:08,461] INFO  {SparkEnv} Registering MapOutputTracker
[15:48:08,476] INFO  {SparkEnv} Registering BlockManagerMaster
[15:48:08,488] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-5def21b3-e42a-425b-8dc2-1f3d7e76f4c7
[15:48:08,502] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:48:08,558] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:48:08,627] INFO  {log} Logging initialized @1503ms
[15:48:08,730] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:48:08,745] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:48:08,745] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:48:08,746] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:48:08,746] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:48:08,746] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:48:08,746] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:48:08,746] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:48:08,746] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:48:08,747] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:48:08,747] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:48:08,747] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:48:08,747] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:48:08,747] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:48:08,748] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:48:08,748] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:48:08,748] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:48:08,748] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:48:08,748] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:48:08,748] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:48:08,749] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:48:08,754] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:48:08,755] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:48:08,755] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:48:08,756] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:48:08,761] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:48:08,762] INFO  {Server} Started @1638ms
[15:48:08,762] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:48:08,764] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:48:08,837] INFO  {Executor} Starting executor ID driver on host localhost
[15:48:08,861] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40013.
[15:48:08,861] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:40013
[15:48:08,863] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 40013)
[15:48:08,866] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:40013 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 40013)
[15:48:08,869] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 40013)
[15:48:08,984] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:48:09,030] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[15:48:09,030] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[15:48:09,031] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[15:48:09,032] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[15:48:09,033] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[15:48:09,046] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:48:10,820] INFO  {FileSourceStrategy} Pruning directories with: 
[15:48:10,822] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:48:10,829] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:48:10,829] INFO  {FileSourceStrategy} Pushed Filters: 
[15:48:10,941] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:48:10,989] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:48:10,990] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:40013 (size: 14.6 KB, free: 1128.9 MB)
[15:48:10,997] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:48:11,001] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:48:11,440] INFO  {CodeGenerator} Code generated in 194.495946 ms
[15:48:11,540] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:48:11,544] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:48:11,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:48:11,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:48:11,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:48:11,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:48:11,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:48:11,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:48:11,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:48:11,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:48:11,546] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:48:11,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:48:11,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:48:11,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:48:11,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:48:11,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:48:11,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:48:11,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:48:11,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:48:11,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:48:11,547] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:48:11,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:48:11,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:48:11,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:48:11,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:48:11,548] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:48:11,549] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:48:11,559] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:48:11,564] INFO  {MemoryStore} MemoryStore cleared
[15:48:11,564] INFO  {BlockManager} BlockManager stopped
[15:48:11,569] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:48:11,582] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:48:11,584] INFO  {SparkContext} Successfully stopped SparkContext
[15:48:11,584] INFO  {ShutdownHookManager} Shutdown hook called
[15:48:11,585] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-4227c604-7e8c-4a8e-9322-9a5236349da0
[15:48:25,971] INFO  {SparkContext} Running Spark version 2.0.1
[15:48:26,179] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:48:26,272] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:48:26,273] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:48:26,341] INFO  {SecurityManager} Changing view acls to: victor
[15:48:26,342] INFO  {SecurityManager} Changing modify acls to: victor
[15:48:26,343] INFO  {SecurityManager} Changing view acls groups to: 
[15:48:26,344] INFO  {SecurityManager} Changing modify acls groups to: 
[15:48:26,345] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:48:26,667] INFO  {Utils} Successfully started service 'sparkDriver' on port 46519.
[15:48:26,685] INFO  {SparkEnv} Registering MapOutputTracker
[15:48:26,704] INFO  {SparkEnv} Registering BlockManagerMaster
[15:48:26,717] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-52b940e1-f3b8-472a-8bb3-72483883f410
[15:48:26,731] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:48:26,782] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:48:26,856] INFO  {log} Logging initialized @1430ms
[15:48:26,964] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:48:26,983] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[15:48:26,984] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[15:48:26,984] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[15:48:26,984] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[15:48:26,985] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[15:48:26,985] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[15:48:26,985] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[15:48:26,985] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[15:48:26,986] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[15:48:26,986] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[15:48:26,986] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[15:48:26,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[15:48:26,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[15:48:26,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[15:48:26,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[15:48:26,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[15:48:26,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[15:48:26,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[15:48:26,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[15:48:26,989] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[15:48:26,995] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[15:48:26,996] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[15:48:26,997] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[15:48:26,997] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[15:48:27,003] INFO  {ServerConnector} Started ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[15:48:27,004] INFO  {Server} Started @1579ms
[15:48:27,004] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:48:27,006] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:48:27,091] INFO  {Executor} Starting executor ID driver on host localhost
[15:48:27,116] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44889.
[15:48:27,117] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:44889
[15:48:27,119] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 44889)
[15:48:27,121] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:44889 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 44889)
[15:48:27,124] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 44889)
[15:48:27,245] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[15:48:27,291] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL,null,AVAILABLE}
[15:48:27,291] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/json,null,AVAILABLE}
[15:48:27,292] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution,null,AVAILABLE}
[15:48:27,293] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/execution/json,null,AVAILABLE}
[15:48:27,295] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54107f42{/static/sql,null,AVAILABLE}
[15:48:27,312] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:48:29,032] INFO  {FileSourceStrategy} Pruning directories with: 
[15:48:29,035] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:48:29,040] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:48:29,041] INFO  {FileSourceStrategy} Pushed Filters: 
[15:48:29,156] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:48:29,211] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:48:29,214] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:44889 (size: 14.6 KB, free: 1128.9 MB)
[15:48:29,219] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:48:29,223] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:48:29,655] INFO  {CodeGenerator} Code generated in 187.259021 ms
[15:48:29,743] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:48:29,749] INFO  {ServerConnector} Stopped ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[15:48:29,751] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[15:48:29,751] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[15:48:29,751] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[15:48:29,751] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[15:48:29,751] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[15:48:29,751] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[15:48:29,752] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[15:48:29,752] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[15:48:29,752] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[15:48:29,752] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[15:48:29,752] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[15:48:29,752] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[15:48:29,752] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[15:48:29,753] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[15:48:29,753] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[15:48:29,753] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[15:48:29,753] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[15:48:29,753] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[15:48:29,753] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[15:48:29,753] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[15:48:29,753] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[15:48:29,754] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[15:48:29,754] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[15:48:29,754] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[15:48:29,755] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:48:29,764] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:48:29,774] INFO  {MemoryStore} MemoryStore cleared
[15:48:29,774] INFO  {BlockManager} BlockManager stopped
[15:48:29,781] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:48:29,784] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:48:29,785] INFO  {SparkContext} Successfully stopped SparkContext
[15:48:29,786] INFO  {ShutdownHookManager} Shutdown hook called
[15:48:29,786] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-1103f8f3-9f98-44dc-bf2a-af5d1a8ca251
[15:50:19,023] INFO  {SparkContext} Running Spark version 2.0.1
[15:50:19,248] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:50:19,347] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:50:19,348] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:50:19,419] INFO  {SecurityManager} Changing view acls to: victor
[15:50:19,420] INFO  {SecurityManager} Changing modify acls to: victor
[15:50:19,420] INFO  {SecurityManager} Changing view acls groups to: 
[15:50:19,421] INFO  {SecurityManager} Changing modify acls groups to: 
[15:50:19,421] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:50:19,751] INFO  {Utils} Successfully started service 'sparkDriver' on port 44833.
[15:50:19,769] INFO  {SparkEnv} Registering MapOutputTracker
[15:50:19,783] INFO  {SparkEnv} Registering BlockManagerMaster
[15:50:19,795] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-61243a58-b238-41ff-b869-d85be452f192
[15:50:19,809] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:50:19,860] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:50:19,929] INFO  {log} Logging initialized @1492ms
[15:50:20,031] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:50:20,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:50:20,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:50:20,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:50:20,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:50:20,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:50:20,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:50:20,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:50:20,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:50:20,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:50:20,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:50:20,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:50:20,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:50:20,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:50:20,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:50:20,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:50:20,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:50:20,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:50:20,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:50:20,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:50:20,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:50:20,057] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:50:20,057] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:50:20,058] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:50:20,058] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:50:20,065] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:50:20,065] INFO  {Server} Started @1630ms
[15:50:20,065] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:50:20,067] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:50:20,142] INFO  {Executor} Starting executor ID driver on host localhost
[15:50:20,167] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42129.
[15:50:20,168] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:42129
[15:50:20,170] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 42129)
[15:50:20,173] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:42129 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 42129)
[15:50:20,176] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 42129)
[15:50:20,298] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:50:20,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[15:50:20,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[15:50:20,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[15:50:20,352] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[15:50:20,353] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[15:50:20,366] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:50:22,142] INFO  {FileSourceStrategy} Pruning directories with: 
[15:50:22,145] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:50:22,151] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:50:22,152] INFO  {FileSourceStrategy} Pushed Filters: 
[15:50:22,258] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:50:22,302] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:50:22,304] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:42129 (size: 14.6 KB, free: 1128.9 MB)
[15:50:22,309] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:50:22,312] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:50:22,786] INFO  {CodeGenerator} Code generated in 207.09407 ms
[15:50:22,891] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:50:22,895] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:50:22,897] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:50:22,897] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:50:22,897] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:50:22,897] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:50:22,897] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:50:22,897] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:50:22,897] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:50:22,898] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:50:22,898] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:50:22,898] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:50:22,898] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:50:22,898] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:50:22,898] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:50:22,898] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:50:22,898] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:50:22,898] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:50:22,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:50:22,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:50:22,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:50:22,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:50:22,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:50:22,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:50:22,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:50:22,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:50:22,901] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:50:22,909] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:50:22,918] INFO  {MemoryStore} MemoryStore cleared
[15:50:22,919] INFO  {BlockManager} BlockManager stopped
[15:50:22,924] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:50:22,927] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:50:22,939] INFO  {SparkContext} Successfully stopped SparkContext
[15:50:22,940] INFO  {ShutdownHookManager} Shutdown hook called
[15:50:22,941] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-cf640a84-ca13-4586-94c7-a5be98466f1b
[15:50:40,305] INFO  {SparkContext} Running Spark version 2.0.1
[15:50:40,516] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:50:40,618] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:50:40,619] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:50:40,690] INFO  {SecurityManager} Changing view acls to: victor
[15:50:40,690] INFO  {SecurityManager} Changing modify acls to: victor
[15:50:40,691] INFO  {SecurityManager} Changing view acls groups to: 
[15:50:40,692] INFO  {SecurityManager} Changing modify acls groups to: 
[15:50:40,692] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:50:41,032] INFO  {Utils} Successfully started service 'sparkDriver' on port 41753.
[15:50:41,050] INFO  {SparkEnv} Registering MapOutputTracker
[15:50:41,065] INFO  {SparkEnv} Registering BlockManagerMaster
[15:50:41,077] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-c50177a0-bb6b-4d26-941c-c53aa3a43895
[15:50:41,091] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:50:41,138] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:50:41,210] INFO  {log} Logging initialized @1494ms
[15:50:41,310] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:50:41,326] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[15:50:41,326] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[15:50:41,326] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[15:50:41,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[15:50:41,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[15:50:41,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[15:50:41,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[15:50:41,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[15:50:41,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[15:50:41,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[15:50:41,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[15:50:41,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[15:50:41,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[15:50:41,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[15:50:41,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[15:50:41,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[15:50:41,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[15:50:41,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[15:50:41,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[15:50:41,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[15:50:41,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[15:50:41,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[15:50:41,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[15:50:41,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[15:50:41,343] INFO  {ServerConnector} Started ServerConnector@635c5cc{HTTP/1.1}{0.0.0.0:4040}
[15:50:41,343] INFO  {Server} Started @1629ms
[15:50:41,343] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:50:41,345] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:50:41,422] INFO  {Executor} Starting executor ID driver on host localhost
[15:50:41,449] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38749.
[15:50:41,450] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:38749
[15:50:41,452] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 38749)
[15:50:41,455] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:38749 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 38749)
[15:50:41,458] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 38749)
[15:50:41,577] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[15:50:41,623] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL,null,AVAILABLE}
[15:50:41,624] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/json,null,AVAILABLE}
[15:50:41,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution,null,AVAILABLE}
[15:50:41,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/execution/json,null,AVAILABLE}
[15:50:41,628] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54107f42{/static/sql,null,AVAILABLE}
[15:50:41,641] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:50:43,421] INFO  {FileSourceStrategy} Pruning directories with: 
[15:50:43,424] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:50:43,429] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:50:43,429] INFO  {FileSourceStrategy} Pushed Filters: 
[15:50:43,538] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:50:43,583] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:50:43,585] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:38749 (size: 14.6 KB, free: 1128.9 MB)
[15:50:43,592] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:50:43,597] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:50:44,047] INFO  {CodeGenerator} Code generated in 191.69474 ms
[15:50:44,135] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:50:44,141] INFO  {ServerConnector} Stopped ServerConnector@635c5cc{HTTP/1.1}{0.0.0.0:4040}
[15:50:44,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[15:50:44,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[15:50:44,143] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[15:50:44,143] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[15:50:44,143] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[15:50:44,143] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[15:50:44,143] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[15:50:44,143] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[15:50:44,143] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[15:50:44,143] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[15:50:44,144] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[15:50:44,144] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[15:50:44,144] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[15:50:44,144] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[15:50:44,144] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[15:50:44,144] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[15:50:44,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[15:50:44,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[15:50:44,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[15:50:44,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[15:50:44,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[15:50:44,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[15:50:44,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[15:50:44,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[15:50:44,147] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:50:44,156] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:50:44,161] INFO  {MemoryStore} MemoryStore cleared
[15:50:44,161] INFO  {BlockManager} BlockManager stopped
[15:50:44,166] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:50:44,169] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:50:44,170] INFO  {SparkContext} Successfully stopped SparkContext
[15:50:44,171] INFO  {ShutdownHookManager} Shutdown hook called
[15:50:44,172] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-85f70b1a-02a3-4e20-8b98-a97fdb507c77
[15:51:20,344] INFO  {SparkContext} Running Spark version 2.0.1
[15:51:20,550] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:51:20,644] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:51:20,644] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:51:20,712] INFO  {SecurityManager} Changing view acls to: victor
[15:51:20,712] INFO  {SecurityManager} Changing modify acls to: victor
[15:51:20,713] INFO  {SecurityManager} Changing view acls groups to: 
[15:51:20,714] INFO  {SecurityManager} Changing modify acls groups to: 
[15:51:20,714] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:51:21,044] INFO  {Utils} Successfully started service 'sparkDriver' on port 39185.
[15:51:21,061] INFO  {SparkEnv} Registering MapOutputTracker
[15:51:21,078] INFO  {SparkEnv} Registering BlockManagerMaster
[15:51:21,093] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-90130088-193a-48c2-b8ab-c9f0f5bf7086
[15:51:21,107] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:51:21,157] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:51:21,227] INFO  {log} Logging initialized @1443ms
[15:51:21,331] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:51:21,346] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:51:21,346] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:51:21,347] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:51:21,347] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:51:21,347] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:51:21,347] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:51:21,347] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:51:21,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:51:21,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:51:21,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:51:21,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:51:21,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:51:21,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:51:21,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:51:21,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:51:21,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:51:21,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:51:21,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:51:21,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:51:21,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:51:21,356] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:51:21,356] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:51:21,357] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:51:21,357] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:51:21,363] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:51:21,364] INFO  {Server} Started @1580ms
[15:51:21,364] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:51:21,366] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:51:21,440] INFO  {Executor} Starting executor ID driver on host localhost
[15:51:21,462] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39573.
[15:51:21,463] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:39573
[15:51:21,464] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 39573)
[15:51:21,468] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:39573 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 39573)
[15:51:21,472] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 39573)
[15:51:21,595] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:51:21,638] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[15:51:21,639] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[15:51:21,639] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[15:51:21,640] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[15:51:21,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[15:51:21,655] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:51:23,412] INFO  {FileSourceStrategy} Pruning directories with: 
[15:51:23,416] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:51:23,420] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:51:23,421] INFO  {FileSourceStrategy} Pushed Filters: 
[15:51:23,529] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:51:23,578] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:51:23,580] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:39573 (size: 14.6 KB, free: 1128.9 MB)
[15:51:23,585] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:51:23,589] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:51:24,037] INFO  {CodeGenerator} Code generated in 192.891669 ms
[15:51:24,138] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:51:24,144] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:51:24,146] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:51:24,146] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:51:24,146] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:51:24,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:51:24,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:51:24,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:51:24,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:51:24,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:51:24,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:51:24,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:51:24,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:51:24,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:51:24,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:51:24,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:51:24,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:51:24,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:51:24,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:51:24,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:51:24,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:51:24,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:51:24,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:51:24,149] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:51:24,149] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:51:24,149] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:51:24,150] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:51:24,159] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:51:24,165] INFO  {MemoryStore} MemoryStore cleared
[15:51:24,166] INFO  {BlockManager} BlockManager stopped
[15:51:24,171] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:51:24,174] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:51:24,175] INFO  {SparkContext} Successfully stopped SparkContext
[15:51:24,176] INFO  {ShutdownHookManager} Shutdown hook called
[15:51:24,187] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-cd5e4cc8-580d-4aff-842e-2bb14a3c362e
[15:51:41,457] INFO  {SparkContext} Running Spark version 2.0.1
[15:51:41,671] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:51:41,760] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.125 instead (on interface enp5s0)
[15:51:41,761] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:51:41,830] INFO  {SecurityManager} Changing view acls to: victor
[15:51:41,831] INFO  {SecurityManager} Changing modify acls to: victor
[15:51:41,832] INFO  {SecurityManager} Changing view acls groups to: 
[15:51:41,832] INFO  {SecurityManager} Changing modify acls groups to: 
[15:51:41,833] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:51:42,166] INFO  {Utils} Successfully started service 'sparkDriver' on port 46481.
[15:51:42,182] INFO  {SparkEnv} Registering MapOutputTracker
[15:51:42,197] INFO  {SparkEnv} Registering BlockManagerMaster
[15:51:42,209] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-233b39b8-f6b2-426e-9c24-26df4b8af142
[15:51:42,223] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:51:42,284] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:51:42,352] INFO  {log} Logging initialized @1493ms
[15:51:42,450] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:51:42,465] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[15:51:42,465] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[15:51:42,466] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[15:51:42,466] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[15:51:42,466] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[15:51:42,466] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[15:51:42,466] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[15:51:42,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[15:51:42,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[15:51:42,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[15:51:42,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[15:51:42,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[15:51:42,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[15:51:42,468] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[15:51:42,468] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[15:51:42,468] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[15:51:42,468] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[15:51:42,468] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[15:51:42,468] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[15:51:42,469] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[15:51:42,474] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[15:51:42,475] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[15:51:42,476] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[15:51:42,476] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[15:51:42,482] INFO  {ServerConnector} Started ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[15:51:42,482] INFO  {Server} Started @1624ms
[15:51:42,482] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:51:42,484] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.125:4040
[15:51:42,563] INFO  {Executor} Starting executor ID driver on host localhost
[15:51:42,585] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35113.
[15:51:42,586] INFO  {NettyBlockTransferService} Server created on 80.216.145.125:35113
[15:51:42,587] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.125, 35113)
[15:51:42,590] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.125:35113 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.125, 35113)
[15:51:42,593] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.125, 35113)
[15:51:42,716] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[15:51:42,760] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL,null,AVAILABLE}
[15:51:42,761] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/json,null,AVAILABLE}
[15:51:42,761] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution,null,AVAILABLE}
[15:51:42,762] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b11ef33{/SQL/execution/json,null,AVAILABLE}
[15:51:42,763] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@21ec5d87{/static/sql,null,AVAILABLE}
[15:51:42,777] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:51:44,506] INFO  {FileSourceStrategy} Pruning directories with: 
[15:51:44,509] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:51:44,514] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:51:44,515] INFO  {FileSourceStrategy} Pushed Filters: 
[15:51:44,627] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:51:44,673] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:51:44,675] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.125:35113 (size: 14.6 KB, free: 1128.9 MB)
[15:51:44,681] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:51:44,684] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:51:45,131] INFO  {CodeGenerator} Code generated in 193.943395 ms
[15:51:45,502] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:51:45,506] INFO  {ServerConnector} Stopped ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[15:51:45,509] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[15:51:45,509] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[15:51:45,509] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[15:51:45,509] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[15:51:45,509] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[15:51:45,510] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[15:51:45,510] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[15:51:45,510] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[15:51:45,510] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[15:51:45,510] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[15:51:45,510] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[15:51:45,510] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[15:51:45,510] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[15:51:45,510] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[15:51:45,511] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[15:51:45,511] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[15:51:45,511] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[15:51:45,511] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[15:51:45,511] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[15:51:45,511] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[15:51:45,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[15:51:45,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[15:51:45,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[15:51:45,512] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[15:51:45,514] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.125:4040
[15:51:45,522] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:51:45,527] INFO  {MemoryStore} MemoryStore cleared
[15:51:45,527] INFO  {BlockManager} BlockManager stopped
[15:51:45,533] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:51:45,536] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:51:45,538] INFO  {SparkContext} Successfully stopped SparkContext
[15:51:45,538] INFO  {ShutdownHookManager} Shutdown hook called
[15:51:45,539] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-c72dd154-e11b-42a2-95ad-da96acb5caa0
[15:55:03,320] INFO  {SparkContext} Running Spark version 2.0.1
[15:55:03,563] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:55:03,672] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[15:55:03,672] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:55:03,759] INFO  {SecurityManager} Changing view acls to: victor
[15:55:03,760] INFO  {SecurityManager} Changing modify acls to: victor
[15:55:03,761] INFO  {SecurityManager} Changing view acls groups to: 
[15:55:03,762] INFO  {SecurityManager} Changing modify acls groups to: 
[15:55:03,763] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:55:04,123] INFO  {Utils} Successfully started service 'sparkDriver' on port 36209.
[15:55:04,142] INFO  {SparkEnv} Registering MapOutputTracker
[15:55:04,159] INFO  {SparkEnv} Registering BlockManagerMaster
[15:55:04,171] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-6793d223-f336-4722-af43-103ebc091fb0
[15:55:04,185] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:55:04,247] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:55:04,318] INFO  {log} Logging initialized @1650ms
[15:55:04,421] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:55:04,438] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:55:04,438] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:55:04,438] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:55:04,438] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:55:04,439] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:55:04,439] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:55:04,439] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:55:04,439] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:55:04,439] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:55:04,439] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:55:04,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:55:04,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:55:04,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:55:04,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:55:04,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:55:04,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:55:04,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:55:04,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:55:04,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:55:04,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:55:04,447] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:55:04,448] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:55:04,448] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:55:04,449] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:55:04,455] INFO  {ServerConnector} Started ServerConnector@6ff21b64{HTTP/1.1}{0.0.0.0:4040}
[15:55:04,455] INFO  {Server} Started @1788ms
[15:55:04,456] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:55:04,458] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[15:55:04,535] INFO  {Executor} Starting executor ID driver on host localhost
[15:55:04,561] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45823.
[15:55:04,562] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:45823
[15:55:04,564] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 45823)
[15:55:04,567] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:45823 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 45823)
[15:55:04,571] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 45823)
[15:55:04,689] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b6579e8{/metrics/json,null,AVAILABLE}
[15:55:04,734] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53499d85{/SQL,null,AVAILABLE}
[15:55:04,734] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@782a4fff{/SQL/json,null,AVAILABLE}
[15:55:04,735] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL/execution,null,AVAILABLE}
[15:55:04,736] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1133ec6e{/SQL/execution/json,null,AVAILABLE}
[15:55:04,738] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/static/sql,null,AVAILABLE}
[15:55:04,753] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:55:06,531] INFO  {FileSourceStrategy} Pruning directories with: 
[15:55:06,534] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:55:06,539] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:55:06,539] INFO  {FileSourceStrategy} Pushed Filters: 
[15:55:06,648] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:55:06,694] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:55:06,696] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:45823 (size: 14.6 KB, free: 1128.9 MB)
[15:55:06,703] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:55:06,707] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:55:07,148] INFO  {CodeGenerator} Code generated in 196.546464 ms
[15:55:07,434] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:55:07,439] INFO  {ServerConnector} Stopped ServerConnector@6ff21b64{HTTP/1.1}{0.0.0.0:4040}
[15:55:07,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:55:07,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:55:07,442] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:55:07,442] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:55:07,442] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:55:07,442] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:55:07,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:55:07,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:55:07,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:55:07,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:55:07,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:55:07,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:55:07,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:55:07,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:55:07,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:55:07,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:55:07,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:55:07,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:55:07,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:55:07,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:55:07,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:55:07,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:55:07,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:55:07,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:55:07,448] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[15:55:07,457] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:55:07,466] INFO  {MemoryStore} MemoryStore cleared
[15:55:07,466] INFO  {BlockManager} BlockManager stopped
[15:55:07,472] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:55:07,477] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:55:07,490] INFO  {SparkContext} Successfully stopped SparkContext
[15:55:07,491] INFO  {ShutdownHookManager} Shutdown hook called
[15:55:07,492] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-d23155e0-53f0-4b40-98d4-94282e2b853a
[15:57:35,742] INFO  {SparkContext} Running Spark version 2.0.1
[15:57:35,948] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:57:36,040] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[15:57:36,040] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:57:36,117] INFO  {SecurityManager} Changing view acls to: victor
[15:57:36,118] INFO  {SecurityManager} Changing modify acls to: victor
[15:57:36,119] INFO  {SecurityManager} Changing view acls groups to: 
[15:57:36,120] INFO  {SecurityManager} Changing modify acls groups to: 
[15:57:36,121] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:57:36,454] INFO  {Utils} Successfully started service 'sparkDriver' on port 40989.
[15:57:36,474] INFO  {SparkEnv} Registering MapOutputTracker
[15:57:36,495] INFO  {SparkEnv} Registering BlockManagerMaster
[15:57:36,507] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-1d53f17e-246c-4133-b7b7-bf56eadb8a1c
[15:57:36,520] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:57:36,574] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:57:36,642] INFO  {log} Logging initialized @1505ms
[15:57:36,743] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:57:36,757] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[15:57:36,758] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[15:57:36,758] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[15:57:36,758] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[15:57:36,758] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[15:57:36,758] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[15:57:36,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[15:57:36,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[15:57:36,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[15:57:36,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[15:57:36,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[15:57:36,760] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[15:57:36,760] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[15:57:36,760] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[15:57:36,760] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[15:57:36,760] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[15:57:36,760] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[15:57:36,761] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[15:57:36,761] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[15:57:36,761] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[15:57:36,767] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[15:57:36,768] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[15:57:36,769] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[15:57:36,769] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[15:57:36,775] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[15:57:36,776] INFO  {Server} Started @1640ms
[15:57:36,776] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:57:36,778] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[15:57:36,865] INFO  {Executor} Starting executor ID driver on host localhost
[15:57:36,891] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38131.
[15:57:36,892] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:38131
[15:57:36,894] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 38131)
[15:57:36,897] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:38131 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 38131)
[15:57:36,899] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 38131)
[15:57:37,019] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[15:57:37,074] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[15:57:37,075] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[15:57:37,076] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[15:57:37,076] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[15:57:37,078] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[15:57:37,090] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[15:57:38,846] INFO  {FileSourceStrategy} Pruning directories with: 
[15:57:38,849] INFO  {FileSourceStrategy} Post-Scan Filters: 
[15:57:38,854] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[15:57:38,854] INFO  {FileSourceStrategy} Pushed Filters: 
[15:57:38,962] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[15:57:39,005] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[15:57:39,007] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:38131 (size: 14.6 KB, free: 1128.9 MB)
[15:57:39,013] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[15:57:39,016] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[15:57:39,466] INFO  {CodeGenerator} Code generated in 206.446621 ms
[15:57:39,827] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:57:39,832] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[15:57:39,834] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[15:57:39,834] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[15:57:39,834] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[15:57:39,834] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[15:57:39,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[15:57:39,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[15:57:39,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[15:57:39,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[15:57:39,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[15:57:39,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[15:57:39,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[15:57:39,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[15:57:39,835] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[15:57:39,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[15:57:39,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[15:57:39,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[15:57:39,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[15:57:39,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[15:57:39,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[15:57:39,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[15:57:39,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[15:57:39,836] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[15:57:39,837] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[15:57:39,837] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[15:57:39,838] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[15:57:39,847] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:57:39,851] INFO  {MemoryStore} MemoryStore cleared
[15:57:39,852] INFO  {BlockManager} BlockManager stopped
[15:57:39,868] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:57:39,872] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:57:39,875] INFO  {SparkContext} Successfully stopped SparkContext
[15:57:39,875] INFO  {ShutdownHookManager} Shutdown hook called
[15:57:39,876] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-5cd5d0b8-d2c1-4468-ab60-206647bf3a11
[16:00:16,815] INFO  {SparkContext} Running Spark version 2.0.1
[16:00:17,032] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:00:17,127] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:00:17,128] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:00:17,205] INFO  {SecurityManager} Changing view acls to: victor
[16:00:17,206] INFO  {SecurityManager} Changing modify acls to: victor
[16:00:17,207] INFO  {SecurityManager} Changing view acls groups to: 
[16:00:17,209] INFO  {SecurityManager} Changing modify acls groups to: 
[16:00:17,209] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:00:17,576] INFO  {Utils} Successfully started service 'sparkDriver' on port 42635.
[16:00:17,596] INFO  {SparkEnv} Registering MapOutputTracker
[16:00:17,611] INFO  {SparkEnv} Registering BlockManagerMaster
[16:00:17,623] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-6fe35e1b-99a9-4758-9ad8-63f6cad9a297
[16:00:17,638] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:00:17,686] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:00:17,762] INFO  {log} Logging initialized @1513ms
[16:00:17,866] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:00:17,885] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[16:00:17,885] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[16:00:17,885] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[16:00:17,886] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[16:00:17,886] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[16:00:17,886] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[16:00:17,887] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[16:00:17,887] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[16:00:17,887] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[16:00:17,887] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[16:00:17,888] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[16:00:17,888] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[16:00:17,888] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[16:00:17,888] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[16:00:17,889] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[16:00:17,889] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[16:00:17,889] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[16:00:17,890] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[16:00:17,890] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[16:00:17,890] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[16:00:17,898] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[16:00:17,899] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[16:00:17,900] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[16:00:17,900] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[16:00:17,909] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:00:17,909] INFO  {Server} Started @1660ms
[16:00:17,909] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:00:17,912] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:00:18,009] INFO  {Executor} Starting executor ID driver on host localhost
[16:00:18,034] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37251.
[16:00:18,035] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:37251
[16:00:18,037] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 37251)
[16:00:18,040] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:37251 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 37251)
[16:00:18,044] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 37251)
[16:00:18,172] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[16:00:18,230] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[16:00:18,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[16:00:18,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[16:00:18,233] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[16:00:18,235] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[16:00:18,252] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:00:20,055] INFO  {FileSourceStrategy} Pruning directories with: 
[16:00:20,058] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:00:20,064] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:00:20,064] INFO  {FileSourceStrategy} Pushed Filters: 
[16:00:20,179] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:00:20,223] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:00:20,225] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:37251 (size: 14.6 KB, free: 1128.9 MB)
[16:00:20,230] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[16:00:20,233] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:00:20,663] INFO  {CodeGenerator} Code generated in 190.776131 ms
[16:00:20,858] INFO  {CodeGenerator} Code generated in 27.955665 ms
[16:00:20,904] INFO  {SparkContext} Starting job: show at Main.scala:33
[16:00:20,919] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[16:00:20,920] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[16:00:20,920] INFO  {DAGScheduler} Parents of final stage: List()
[16:00:20,924] INFO  {DAGScheduler} Missing parents: List()
[16:00:20,928] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[16:00:20,989] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:00:20,991] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:00:20,992] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:37251 (size: 8.4 KB, free: 1128.9 MB)
[16:00:20,992] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:00:20,996] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[16:00:20,998] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:00:21,038] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:00:21,046] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:00:21,089] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:00:21,115] INFO  {CodeGenerator} Code generated in 22.669613 ms
[16:00:21,244] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:00:21,245] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:37251 (size: 1239.2 KB, free: 1127.7 MB)
[16:00:21,255] INFO  {CodeGenerator} Code generated in 4.333942 ms
[16:00:21,282] INFO  {CodeGenerator} Code generated in 20.322575 ms
[16:00:21,302] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:00:21,309] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:00:21,321] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 299 ms on localhost (1/1)
[16:00:21,322] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:00:21,326] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.316 s
[16:00:21,331] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.426268 s
[16:00:21,362] INFO  {CodeGenerator} Code generated in 17.066913 ms
[16:00:21,454] INFO  {CodeGenerator} Code generated in 29.16103 ms
[16:00:21,465] INFO  {SparkContext} Starting job: show at Main.scala:42
[16:00:21,466] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[16:00:21,466] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[16:00:21,466] INFO  {DAGScheduler} Parents of final stage: List()
[16:00:21,469] INFO  {DAGScheduler} Missing parents: List()
[16:00:21,469] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[16:00:21,475] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:00:21,477] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:00:21,478] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:37251 (size: 10.0 KB, free: 1127.7 MB)
[16:00:21,478] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:00:21,479] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[16:00:21,479] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:00:21,484] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:00:21,485] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:00:21,497] INFO  {BlockManager} Found block rdd_2_0 locally
[16:00:21,513] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:00:21,514] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:00:21,516] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on localhost (1/1)
[16:00:21,517] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:00:21,517] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.035 s
[16:00:21,518] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.052645 s
[16:00:21,548] INFO  {CodeGenerator} Code generated in 20.911545 ms
[16:00:21,763] INFO  {ContextCleaner} Cleaned accumulator 3
[16:00:21,763] INFO  {ContextCleaner} Cleaned accumulator 4
[16:00:21,779] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:37251 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:00:21,782] INFO  {ContextCleaner} Cleaned accumulator 49
[16:00:21,782] INFO  {ContextCleaner} Cleaned accumulator 50
[16:00:21,783] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:37251 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:00:21,840] INFO  {CodeGenerator} Code generated in 52.580192 ms
[16:00:21,857] INFO  {SparkContext} Starting job: show at Main.scala:51
[16:00:21,859] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[16:00:21,859] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[16:00:21,859] INFO  {DAGScheduler} Parents of final stage: List()
[16:00:21,860] INFO  {DAGScheduler} Missing parents: List()
[16:00:21,861] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[16:00:21,865] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:00:21,867] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:00:21,868] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:37251 (size: 11.7 KB, free: 1127.7 MB)
[16:00:21,869] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:00:21,869] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[16:00:21,869] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:00:21,872] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:00:21,873] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:00:21,882] INFO  {BlockManager} Found block rdd_2_0 locally
[16:00:21,896] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:00:21,897] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:00:21,899] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (1/1)
[16:00:21,899] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:00:21,900] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.030 s
[16:00:21,901] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.043041 s
[16:00:21,926] INFO  {CodeGenerator} Code generated in 21.396194 ms
[16:00:22,063] INFO  {CodeGenerator} Code generated in 59.580956 ms
[16:00:22,078] INFO  {SparkContext} Starting job: show at Main.scala:61
[16:00:22,079] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[16:00:22,080] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[16:00:22,080] INFO  {DAGScheduler} Parents of final stage: List()
[16:00:22,080] INFO  {DAGScheduler} Missing parents: List()
[16:00:22,080] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[16:00:22,084] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:00:22,086] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:00:22,086] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:37251 (size: 13.3 KB, free: 1127.7 MB)
[16:00:22,087] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:00:22,087] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[16:00:22,087] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:00:22,089] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:00:22,089] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:00:22,095] INFO  {BlockManager} Found block rdd_2_0 locally
[16:00:22,104] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:00:22,104] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:00:22,106] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 17 ms on localhost (1/1)
[16:00:22,106] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:00:22,106] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.018 s
[16:00:22,107] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.027984 s
[16:00:22,122] INFO  {CodeGenerator} Code generated in 13.234301 ms
[16:00:22,237] INFO  {CodeGenerator} Code generated in 47.500561 ms
[16:00:22,247] INFO  {SparkContext} Starting job: show at Main.scala:77
[16:00:22,248] INFO  {DAGScheduler} Got job 4 (show at Main.scala:77) with 1 output partitions
[16:00:22,248] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:77)
[16:00:22,248] INFO  {DAGScheduler} Parents of final stage: List()
[16:00:22,249] INFO  {DAGScheduler} Missing parents: List()
[16:00:22,249] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77), which has no missing parents
[16:00:22,253] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:00:22,256] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:00:22,256] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:37251 (size: 15.1 KB, free: 1127.6 MB)
[16:00:22,257] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:00:22,257] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77)
[16:00:22,257] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:00:22,259] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:00:22,259] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:00:22,265] INFO  {BlockManager} Found block rdd_2_0 locally
[16:00:22,274] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:00:22,276] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4020 bytes result sent to driver
[16:00:22,277] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 19 ms on localhost (1/1)
[16:00:22,277] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:00:22,277] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:77) finished in 0.020 s
[16:00:22,278] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:77, took 0.030538 s
[16:00:22,295] INFO  {CodeGenerator} Code generated in 14.681126 ms
[16:00:22,449] INFO  {CodeGenerator} Code generated in 73.544871 ms
[16:00:22,460] INFO  {SparkContext} Starting job: show at Main.scala:86
[16:00:22,461] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[16:00:22,461] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:86)
[16:00:22,461] INFO  {DAGScheduler} Parents of final stage: List()
[16:00:22,462] INFO  {DAGScheduler} Missing parents: List()
[16:00:22,463] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[16:00:22,469] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[16:00:22,471] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:00:22,472] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:37251 (size: 16.4 KB, free: 1127.6 MB)
[16:00:22,472] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:00:22,473] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86)
[16:00:22,473] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:00:22,475] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:00:22,475] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:00:22,481] INFO  {BlockManager} Found block rdd_2_0 locally
[16:00:22,496] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:00:22,497] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4083 bytes result sent to driver
[16:00:22,498] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 24 ms on localhost (1/1)
[16:00:22,498] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:00:22,499] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:86) finished in 0.026 s
[16:00:22,501] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.040599 s
[16:00:22,525] INFO  {CodeGenerator} Code generated in 20.423422 ms
[16:00:22,547] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:00:22,556] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:00:22,559] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[16:00:22,560] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[16:00:22,560] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[16:00:22,560] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[16:00:22,560] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[16:00:22,560] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[16:00:22,560] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[16:00:22,561] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[16:00:22,561] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[16:00:22,561] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[16:00:22,561] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[16:00:22,561] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[16:00:22,561] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[16:00:22,562] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[16:00:22,562] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[16:00:22,562] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[16:00:22,562] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[16:00:22,562] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[16:00:22,562] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[16:00:22,562] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[16:00:22,562] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[16:00:22,563] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[16:00:22,563] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[16:00:22,563] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[16:00:22,565] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:00:22,580] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:00:22,596] INFO  {MemoryStore} MemoryStore cleared
[16:00:22,597] INFO  {BlockManager} BlockManager stopped
[16:00:22,598] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:00:22,603] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:00:22,606] INFO  {SparkContext} Successfully stopped SparkContext
[16:00:22,606] INFO  {ShutdownHookManager} Shutdown hook called
[16:00:22,607] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-c8a465ef-37eb-4cac-ad0a-cbcfdd992233
[16:02:34,148] INFO  {SparkContext} Running Spark version 2.0.1
[16:02:34,390] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:02:34,488] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:02:34,489] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:02:34,576] INFO  {SecurityManager} Changing view acls to: victor
[16:02:34,577] INFO  {SecurityManager} Changing modify acls to: victor
[16:02:34,578] INFO  {SecurityManager} Changing view acls groups to: 
[16:02:34,579] INFO  {SecurityManager} Changing modify acls groups to: 
[16:02:34,580] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:02:34,904] INFO  {Utils} Successfully started service 'sparkDriver' on port 45367.
[16:02:34,920] INFO  {SparkEnv} Registering MapOutputTracker
[16:02:34,936] INFO  {SparkEnv} Registering BlockManagerMaster
[16:02:34,948] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-35c6ad2b-ad11-47b3-9714-3189de950149
[16:02:34,961] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:02:35,014] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:02:35,083] INFO  {log} Logging initialized @1512ms
[16:02:35,183] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:02:35,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:02:35,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:02:35,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:02:35,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:02:35,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:02:35,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:02:35,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:02:35,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:02:35,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:02:35,199] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:02:35,199] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:02:35,199] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:02:35,199] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:02:35,199] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:02:35,200] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:02:35,200] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:02:35,200] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:02:35,200] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:02:35,200] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:02:35,200] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:02:35,206] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:02:35,207] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:02:35,207] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:02:35,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:02:35,213] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:02:35,214] INFO  {Server} Started @1644ms
[16:02:35,214] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:02:35,216] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:02:35,294] INFO  {Executor} Starting executor ID driver on host localhost
[16:02:35,317] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41127.
[16:02:35,318] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:41127
[16:02:35,320] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 41127)
[16:02:35,323] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:41127 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 41127)
[16:02:35,326] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 41127)
[16:02:35,449] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:02:35,500] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:02:35,501] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:02:35,502] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:02:35,502] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:02:35,504] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:02:35,520] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:02:37,277] INFO  {FileSourceStrategy} Pruning directories with: 
[16:02:37,280] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:02:37,285] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:02:37,286] INFO  {FileSourceStrategy} Pushed Filters: 
[16:02:37,394] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:02:37,438] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:02:37,440] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:41127 (size: 14.6 KB, free: 1128.9 MB)
[16:02:37,446] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[16:02:37,449] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:02:37,899] INFO  {CodeGenerator} Code generated in 202.283483 ms
[16:02:38,097] INFO  {CodeGenerator} Code generated in 28.440278 ms
[16:02:38,145] INFO  {SparkContext} Starting job: show at Main.scala:33
[16:02:38,163] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[16:02:38,164] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[16:02:38,164] INFO  {DAGScheduler} Parents of final stage: List()
[16:02:38,168] INFO  {DAGScheduler} Missing parents: List()
[16:02:38,172] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[16:02:38,233] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:02:38,235] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:02:38,236] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:41127 (size: 8.5 KB, free: 1128.9 MB)
[16:02:38,237] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:02:38,240] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[16:02:38,241] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:02:38,278] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:02:38,288] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:02:38,329] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:02:38,354] INFO  {CodeGenerator} Code generated in 9.953391 ms
[16:02:38,480] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:02:38,480] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:41127 (size: 1239.2 KB, free: 1127.7 MB)
[16:02:38,490] INFO  {CodeGenerator} Code generated in 3.814015 ms
[16:02:38,514] INFO  {CodeGenerator} Code generated in 19.050046 ms
[16:02:38,534] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:02:38,540] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:02:38,553] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 292 ms on localhost (1/1)
[16:02:38,555] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:02:38,558] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.309 s
[16:02:38,563] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.417849 s
[16:02:38,592] INFO  {CodeGenerator} Code generated in 16.250393 ms
[16:02:38,682] INFO  {CodeGenerator} Code generated in 29.385188 ms
[16:02:38,694] INFO  {SparkContext} Starting job: show at Main.scala:42
[16:02:38,695] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[16:02:38,695] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[16:02:38,695] INFO  {DAGScheduler} Parents of final stage: List()
[16:02:38,697] INFO  {DAGScheduler} Missing parents: List()
[16:02:38,698] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[16:02:38,702] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:02:38,703] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:02:38,704] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:41127 (size: 10.0 KB, free: 1127.7 MB)
[16:02:38,705] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:02:38,705] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[16:02:38,705] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:02:38,710] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:02:38,711] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:02:38,722] INFO  {BlockManager} Found block rdd_2_0 locally
[16:02:38,736] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:02:38,737] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:02:38,739] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on localhost (1/1)
[16:02:38,739] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:02:38,739] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.031 s
[16:02:38,740] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.045659 s
[16:02:38,768] INFO  {CodeGenerator} Code generated in 20.377021 ms
[16:02:38,954] INFO  {ContextCleaner} Cleaned accumulator 3
[16:02:38,954] INFO  {ContextCleaner} Cleaned accumulator 4
[16:02:38,977] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:41127 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:02:38,983] INFO  {ContextCleaner} Cleaned accumulator 49
[16:02:38,983] INFO  {ContextCleaner} Cleaned accumulator 50
[16:02:38,984] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:41127 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:02:39,027] INFO  {CodeGenerator} Code generated in 37.491617 ms
[16:02:39,037] INFO  {SparkContext} Starting job: show at Main.scala:51
[16:02:39,038] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[16:02:39,038] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[16:02:39,038] INFO  {DAGScheduler} Parents of final stage: List()
[16:02:39,039] INFO  {DAGScheduler} Missing parents: List()
[16:02:39,040] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[16:02:39,043] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:02:39,045] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:02:39,046] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:41127 (size: 11.7 KB, free: 1127.7 MB)
[16:02:39,046] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:02:39,047] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[16:02:39,047] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:02:39,048] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:02:39,049] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:02:39,055] INFO  {BlockManager} Found block rdd_2_0 locally
[16:02:39,064] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:02:39,065] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:02:39,066] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 19 ms on localhost (1/1)
[16:02:39,067] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:02:39,071] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.020 s
[16:02:39,072] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.033965 s
[16:02:39,096] INFO  {CodeGenerator} Code generated in 20.090028 ms
[16:02:39,244] INFO  {CodeGenerator} Code generated in 63.296136 ms
[16:02:39,259] INFO  {SparkContext} Starting job: show at Main.scala:61
[16:02:39,260] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[16:02:39,260] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[16:02:39,260] INFO  {DAGScheduler} Parents of final stage: List()
[16:02:39,260] INFO  {DAGScheduler} Missing parents: List()
[16:02:39,261] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[16:02:39,265] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:02:39,268] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:02:39,269] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:41127 (size: 13.3 KB, free: 1127.7 MB)
[16:02:39,270] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:02:39,270] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[16:02:39,270] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:02:39,272] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:02:39,273] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:02:39,282] INFO  {BlockManager} Found block rdd_2_0 locally
[16:02:39,295] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:02:39,296] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:02:39,298] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.027 s
[16:02:39,299] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 26 ms on localhost (1/1)
[16:02:39,299] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:02:39,299] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.040099 s
[16:02:39,329] INFO  {CodeGenerator} Code generated in 26.167924 ms
[16:02:39,480] INFO  {CodeGenerator} Code generated in 54.158647 ms
[16:02:39,489] INFO  {SparkContext} Starting job: show at Main.scala:77
[16:02:39,490] INFO  {DAGScheduler} Got job 4 (show at Main.scala:77) with 1 output partitions
[16:02:39,491] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:77)
[16:02:39,491] INFO  {DAGScheduler} Parents of final stage: List()
[16:02:39,491] INFO  {DAGScheduler} Missing parents: List()
[16:02:39,492] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77), which has no missing parents
[16:02:39,496] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:02:39,498] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:02:39,499] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:41127 (size: 15.1 KB, free: 1127.6 MB)
[16:02:39,500] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:02:39,500] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77)
[16:02:39,500] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:02:39,502] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:02:39,502] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:02:39,509] INFO  {BlockManager} Found block rdd_2_0 locally
[16:02:39,522] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:02:39,524] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4020 bytes result sent to driver
[16:02:39,526] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 24 ms on localhost (1/1)
[16:02:39,526] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:02:39,526] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:77) finished in 0.025 s
[16:02:39,527] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:77, took 0.037226 s
[16:02:39,550] INFO  {CodeGenerator} Code generated in 20.290529 ms
[16:02:39,712] INFO  {CodeGenerator} Code generated in 70.614535 ms
[16:02:39,727] INFO  {SparkContext} Starting job: show at Main.scala:86
[16:02:39,728] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[16:02:39,728] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:86)
[16:02:39,728] INFO  {DAGScheduler} Parents of final stage: List()
[16:02:39,729] INFO  {DAGScheduler} Missing parents: List()
[16:02:39,730] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[16:02:39,734] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[16:02:39,736] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:02:39,737] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:41127 (size: 16.4 KB, free: 1127.6 MB)
[16:02:39,738] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:02:39,738] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86)
[16:02:39,738] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:02:39,740] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:02:39,741] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:02:39,747] INFO  {BlockManager} Found block rdd_2_0 locally
[16:02:39,761] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:02:39,762] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4083 bytes result sent to driver
[16:02:39,764] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 24 ms on localhost (1/1)
[16:02:39,764] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:02:39,764] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:86) finished in 0.025 s
[16:02:39,765] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.038377 s
[16:02:39,791] INFO  {CodeGenerator} Code generated in 20.572002 ms
[16:02:40,131] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:02:40,136] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:02:40,139] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:02:40,139] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:02:40,139] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:02:40,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:02:40,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:02:40,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:02:40,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:02:40,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:02:40,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:02:40,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:02:40,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:02:40,140] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:02:40,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:02:40,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:02:40,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:02:40,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:02:40,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:02:40,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:02:40,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:02:40,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:02:40,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:02:40,141] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:02:40,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:02:40,142] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:02:40,143] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:02:40,152] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:02:40,160] INFO  {MemoryStore} MemoryStore cleared
[16:02:40,160] INFO  {BlockManager} BlockManager stopped
[16:02:40,162] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:02:40,164] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:02:40,172] INFO  {SparkContext} Successfully stopped SparkContext
[16:02:40,172] INFO  {ShutdownHookManager} Shutdown hook called
[16:02:40,173] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-acbe2c27-776a-450c-aa7e-d3c54ecaa583
[16:03:07,413] INFO  {SparkContext} Running Spark version 2.0.1
[16:03:07,619] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:03:07,709] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:03:07,710] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:03:07,784] INFO  {SecurityManager} Changing view acls to: victor
[16:03:07,785] INFO  {SecurityManager} Changing modify acls to: victor
[16:03:07,786] INFO  {SecurityManager} Changing view acls groups to: 
[16:03:07,786] INFO  {SecurityManager} Changing modify acls groups to: 
[16:03:07,787] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:03:08,152] INFO  {Utils} Successfully started service 'sparkDriver' on port 33087.
[16:03:08,170] INFO  {SparkEnv} Registering MapOutputTracker
[16:03:08,185] INFO  {SparkEnv} Registering BlockManagerMaster
[16:03:08,197] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-8e13c15d-dd98-4669-8a32-d51830513cc9
[16:03:08,210] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:03:08,256] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:03:08,324] INFO  {log} Logging initialized @1468ms
[16:03:08,422] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:03:08,438] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:03:08,439] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:03:08,439] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:03:08,439] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:03:08,439] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:03:08,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:03:08,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:03:08,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:03:08,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:03:08,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:03:08,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:03:08,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:03:08,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:03:08,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:03:08,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:03:08,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:03:08,442] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:03:08,442] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:03:08,442] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:03:08,442] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:03:08,448] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:03:08,449] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:03:08,449] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:03:08,450] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:03:08,456] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:03:08,456] INFO  {Server} Started @1602ms
[16:03:08,457] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:03:08,459] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:03:08,534] INFO  {Executor} Starting executor ID driver on host localhost
[16:03:08,557] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35131.
[16:03:08,558] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:35131
[16:03:08,559] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 35131)
[16:03:08,562] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:35131 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 35131)
[16:03:08,565] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 35131)
[16:03:08,688] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:03:08,736] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:03:08,736] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:03:08,737] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:03:08,738] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:03:08,740] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:03:08,752] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:03:10,520] INFO  {FileSourceStrategy} Pruning directories with: 
[16:03:10,522] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:03:10,528] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:03:10,529] INFO  {FileSourceStrategy} Pushed Filters: 
[16:03:10,636] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:03:10,680] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:03:10,682] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:35131 (size: 14.6 KB, free: 1128.9 MB)
[16:03:10,687] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[16:03:10,691] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:03:11,117] INFO  {CodeGenerator} Code generated in 187.104824 ms
[16:03:11,318] INFO  {CodeGenerator} Code generated in 28.192988 ms
[16:03:11,365] INFO  {SparkContext} Starting job: show at Main.scala:33
[16:03:11,384] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[16:03:11,384] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[16:03:11,385] INFO  {DAGScheduler} Parents of final stage: List()
[16:03:11,390] INFO  {DAGScheduler} Missing parents: List()
[16:03:11,396] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[16:03:11,470] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:03:11,472] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:03:11,473] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:35131 (size: 8.4 KB, free: 1128.9 MB)
[16:03:11,474] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:03:11,479] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[16:03:11,481] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:03:11,518] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:03:11,526] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:03:11,568] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:03:11,580] INFO  {CodeGenerator} Code generated in 9.075352 ms
[16:03:11,743] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:03:11,744] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:35131 (size: 1239.2 KB, free: 1127.7 MB)
[16:03:11,757] INFO  {CodeGenerator} Code generated in 5.120072 ms
[16:03:11,783] INFO  {CodeGenerator} Code generated in 19.833603 ms
[16:03:11,807] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:03:11,816] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:03:11,825] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 324 ms on localhost (1/1)
[16:03:11,826] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:03:11,830] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.339 s
[16:03:11,835] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.469625 s
[16:03:11,874] INFO  {CodeGenerator} Code generated in 21.696875 ms
[16:03:11,985] INFO  {CodeGenerator} Code generated in 40.131101 ms
[16:03:12,001] INFO  {SparkContext} Starting job: show at Main.scala:42
[16:03:12,002] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[16:03:12,003] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[16:03:12,003] INFO  {DAGScheduler} Parents of final stage: List()
[16:03:12,005] INFO  {DAGScheduler} Missing parents: List()
[16:03:12,005] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[16:03:12,010] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:03:12,013] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:03:12,013] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:35131 (size: 10.0 KB, free: 1127.7 MB)
[16:03:12,014] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:03:12,014] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[16:03:12,014] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:03:12,020] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:03:12,021] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:03:12,030] INFO  {BlockManager} Found block rdd_2_0 locally
[16:03:12,045] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:03:12,046] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:03:12,048] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on localhost (1/1)
[16:03:12,048] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:03:12,049] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.032 s
[16:03:12,049] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.048158 s
[16:03:12,082] INFO  {CodeGenerator} Code generated in 21.147971 ms
[16:03:12,268] INFO  {ContextCleaner} Cleaned accumulator 3
[16:03:12,268] INFO  {ContextCleaner} Cleaned accumulator 4
[16:03:12,283] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:35131 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:03:12,286] INFO  {ContextCleaner} Cleaned accumulator 49
[16:03:12,286] INFO  {ContextCleaner} Cleaned accumulator 50
[16:03:12,287] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:35131 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:03:12,362] INFO  {CodeGenerator} Code generated in 54.955871 ms
[16:03:12,379] INFO  {SparkContext} Starting job: show at Main.scala:51
[16:03:12,382] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[16:03:12,382] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[16:03:12,382] INFO  {DAGScheduler} Parents of final stage: List()
[16:03:12,383] INFO  {DAGScheduler} Missing parents: List()
[16:03:12,384] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[16:03:12,389] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:03:12,391] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:03:12,392] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:35131 (size: 11.7 KB, free: 1127.7 MB)
[16:03:12,392] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:03:12,393] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[16:03:12,393] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:03:12,395] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:03:12,396] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:03:12,406] INFO  {BlockManager} Found block rdd_2_0 locally
[16:03:12,419] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:03:12,420] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:03:12,422] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on localhost (1/1)
[16:03:12,422] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:03:12,423] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.028 s
[16:03:12,424] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.044111 s
[16:03:12,448] INFO  {CodeGenerator} Code generated in 21.589717 ms
[16:03:12,541] INFO  {CodeGenerator} Code generated in 37.735105 ms
[16:03:12,553] INFO  {SparkContext} Starting job: show at Main.scala:61
[16:03:12,554] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[16:03:12,554] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[16:03:12,554] INFO  {DAGScheduler} Parents of final stage: List()
[16:03:12,555] INFO  {DAGScheduler} Missing parents: List()
[16:03:12,555] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[16:03:12,559] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:03:12,561] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:03:12,561] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:35131 (size: 13.3 KB, free: 1127.7 MB)
[16:03:12,562] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:03:12,562] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[16:03:12,562] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:03:12,564] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:03:12,565] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:03:12,573] INFO  {BlockManager} Found block rdd_2_0 locally
[16:03:12,584] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:03:12,584] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:03:12,586] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 23 ms on localhost (1/1)
[16:03:12,586] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:03:12,586] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.023 s
[16:03:12,587] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.033371 s
[16:03:12,606] INFO  {CodeGenerator} Code generated in 15.800862 ms
[16:03:12,747] INFO  {CodeGenerator} Code generated in 61.790282 ms
[16:03:12,762] INFO  {SparkContext} Starting job: show at Main.scala:77
[16:03:12,763] INFO  {DAGScheduler} Got job 4 (show at Main.scala:77) with 1 output partitions
[16:03:12,764] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:77)
[16:03:12,764] INFO  {DAGScheduler} Parents of final stage: List()
[16:03:12,764] INFO  {DAGScheduler} Missing parents: List()
[16:03:12,765] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77), which has no missing parents
[16:03:12,768] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:03:12,770] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:03:12,771] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:35131 (size: 15.1 KB, free: 1127.6 MB)
[16:03:12,771] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:03:12,771] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77)
[16:03:12,772] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:03:12,774] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:03:12,774] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:03:12,781] INFO  {BlockManager} Found block rdd_2_0 locally
[16:03:12,794] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:03:12,796] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4020 bytes result sent to driver
[16:03:12,798] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 25 ms on localhost (1/1)
[16:03:12,798] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:03:12,799] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:77) finished in 0.026 s
[16:03:12,800] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:77, took 0.037797 s
[16:03:12,820] INFO  {CodeGenerator} Code generated in 16.837548 ms
[16:03:12,974] INFO  {CodeGenerator} Code generated in 68.232297 ms
[16:03:12,990] INFO  {SparkContext} Starting job: show at Main.scala:86
[16:03:12,991] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[16:03:12,991] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:86)
[16:03:12,991] INFO  {DAGScheduler} Parents of final stage: List()
[16:03:12,992] INFO  {DAGScheduler} Missing parents: List()
[16:03:12,992] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[16:03:12,997] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[16:03:12,999] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:03:12,999] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:35131 (size: 16.4 KB, free: 1127.6 MB)
[16:03:13,000] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:03:13,000] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86)
[16:03:13,000] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:03:13,002] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:03:13,003] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:03:13,009] INFO  {BlockManager} Found block rdd_2_0 locally
[16:03:13,023] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:03:13,023] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4083 bytes result sent to driver
[16:03:13,024] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 23 ms on localhost (1/1)
[16:03:13,025] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:03:13,026] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:86) finished in 0.024 s
[16:03:13,026] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.035990 s
[16:03:13,048] INFO  {CodeGenerator} Code generated in 18.414508 ms
[16:03:13,432] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:03:13,437] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:03:13,439] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:03:13,439] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:03:13,439] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:03:13,439] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:03:13,439] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:03:13,439] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:03:13,439] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:03:13,440] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:03:13,440] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:03:13,440] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:03:13,440] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:03:13,440] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:03:13,440] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:03:13,440] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:03:13,440] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:03:13,440] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:03:13,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:03:13,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:03:13,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:03:13,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:03:13,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:03:13,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:03:13,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:03:13,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:03:13,443] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:03:13,453] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:03:13,468] INFO  {MemoryStore} MemoryStore cleared
[16:03:13,468] INFO  {BlockManager} BlockManager stopped
[16:03:13,470] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:03:13,472] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:03:13,481] INFO  {SparkContext} Successfully stopped SparkContext
[16:03:13,481] INFO  {ShutdownHookManager} Shutdown hook called
[16:03:13,482] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-6410f8fc-96c6-443a-b5c1-da9171442ae8
[16:04:27,421] INFO  {SparkContext} Running Spark version 2.0.1
[16:04:27,617] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:04:27,715] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:04:27,716] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:04:27,794] INFO  {SecurityManager} Changing view acls to: victor
[16:04:27,795] INFO  {SecurityManager} Changing modify acls to: victor
[16:04:27,796] INFO  {SecurityManager} Changing view acls groups to: 
[16:04:27,797] INFO  {SecurityManager} Changing modify acls groups to: 
[16:04:27,798] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:04:28,150] INFO  {Utils} Successfully started service 'sparkDriver' on port 46545.
[16:04:28,167] INFO  {SparkEnv} Registering MapOutputTracker
[16:04:28,183] INFO  {SparkEnv} Registering BlockManagerMaster
[16:04:28,196] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-c81cf7f3-3439-4cfc-bacd-694be5958e0b
[16:04:28,211] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:04:28,273] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:04:28,349] INFO  {log} Logging initialized @1514ms
[16:04:28,458] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:04:28,473] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[16:04:28,474] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[16:04:28,474] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[16:04:28,474] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[16:04:28,474] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[16:04:28,474] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[16:04:28,475] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[16:04:28,475] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[16:04:28,475] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[16:04:28,475] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[16:04:28,475] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[16:04:28,476] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[16:04:28,476] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[16:04:28,476] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[16:04:28,476] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[16:04:28,476] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[16:04:28,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[16:04:28,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[16:04:28,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[16:04:28,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[16:04:28,484] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[16:04:28,484] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[16:04:28,485] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[16:04:28,485] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[16:04:28,495] INFO  {ServerConnector} Started ServerConnector@3cc024a7{HTTP/1.1}{0.0.0.0:4040}
[16:04:28,496] INFO  {Server} Started @1661ms
[16:04:28,496] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:04:28,498] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:04:28,582] INFO  {Executor} Starting executor ID driver on host localhost
[16:04:28,618] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42775.
[16:04:28,619] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:42775
[16:04:28,621] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 42775)
[16:04:28,624] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:42775 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 42775)
[16:04:28,628] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 42775)
[16:04:28,754] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64bc21ac{/metrics/json,null,AVAILABLE}
[16:04:28,811] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1133ec6e{/SQL,null,AVAILABLE}
[16:04:28,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54709809{/SQL/json,null,AVAILABLE}
[16:04:28,813] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/SQL/execution,null,AVAILABLE}
[16:04:28,814] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54107f42{/SQL/execution/json,null,AVAILABLE}
[16:04:28,816] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1eba372c{/static/sql,null,AVAILABLE}
[16:04:28,834] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:04:30,649] INFO  {FileSourceStrategy} Pruning directories with: 
[16:04:30,652] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:04:30,656] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:04:30,657] INFO  {FileSourceStrategy} Pushed Filters: 
[16:04:30,758] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:04:30,801] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:04:30,803] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:42775 (size: 14.6 KB, free: 1128.9 MB)
[16:04:30,809] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[16:04:30,812] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:04:31,249] INFO  {CodeGenerator} Code generated in 194.794885 ms
[16:04:31,477] INFO  {CodeGenerator} Code generated in 28.51094 ms
[16:04:31,532] INFO  {SparkContext} Starting job: show at Main.scala:33
[16:04:31,547] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[16:04:31,547] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[16:04:31,547] INFO  {DAGScheduler} Parents of final stage: List()
[16:04:31,551] INFO  {DAGScheduler} Missing parents: List()
[16:04:31,555] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[16:04:31,612] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:04:31,614] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:04:31,615] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:42775 (size: 8.4 KB, free: 1128.9 MB)
[16:04:31,615] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:04:31,619] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[16:04:31,620] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:04:31,658] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:04:31,667] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:04:31,707] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:04:31,719] INFO  {CodeGenerator} Code generated in 9.040752 ms
[16:04:31,860] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:04:31,860] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:42775 (size: 1239.2 KB, free: 1127.7 MB)
[16:04:31,872] INFO  {CodeGenerator} Code generated in 3.965761 ms
[16:04:31,896] INFO  {CodeGenerator} Code generated in 18.74747 ms
[16:04:31,916] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:04:31,922] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:04:31,931] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 291 ms on localhost (1/1)
[16:04:31,932] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:04:31,937] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.307 s
[16:04:31,942] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.409961 s
[16:04:31,978] INFO  {CodeGenerator} Code generated in 20.839157 ms
[16:04:32,073] INFO  {CodeGenerator} Code generated in 29.458233 ms
[16:04:32,085] INFO  {SparkContext} Starting job: show at Main.scala:42
[16:04:32,087] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[16:04:32,087] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[16:04:32,087] INFO  {DAGScheduler} Parents of final stage: List()
[16:04:32,089] INFO  {DAGScheduler} Missing parents: List()
[16:04:32,090] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[16:04:32,094] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:04:32,096] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:04:32,097] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:42775 (size: 10.0 KB, free: 1127.7 MB)
[16:04:32,097] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:04:32,097] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[16:04:32,098] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:04:32,102] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:04:32,103] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:04:32,112] INFO  {BlockManager} Found block rdd_2_0 locally
[16:04:32,126] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:04:32,127] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:04:32,128] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[16:04:32,129] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:04:32,129] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.029 s
[16:04:32,129] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.043889 s
[16:04:32,165] INFO  {CodeGenerator} Code generated in 22.626883 ms
[16:04:32,373] INFO  {ContextCleaner} Cleaned accumulator 3
[16:04:32,374] INFO  {ContextCleaner} Cleaned accumulator 4
[16:04:32,392] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:42775 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:04:32,397] INFO  {ContextCleaner} Cleaned accumulator 49
[16:04:32,397] INFO  {ContextCleaner} Cleaned accumulator 50
[16:04:32,398] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:42775 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:04:32,463] INFO  {CodeGenerator} Code generated in 52.456771 ms
[16:04:32,480] INFO  {SparkContext} Starting job: show at Main.scala:51
[16:04:32,481] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[16:04:32,482] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[16:04:32,482] INFO  {DAGScheduler} Parents of final stage: List()
[16:04:32,483] INFO  {DAGScheduler} Missing parents: List()
[16:04:32,483] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[16:04:32,488] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:04:32,490] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:04:32,491] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:42775 (size: 11.7 KB, free: 1127.7 MB)
[16:04:32,492] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:04:32,492] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[16:04:32,492] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:04:32,494] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:04:32,495] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:04:32,501] INFO  {BlockManager} Found block rdd_2_0 locally
[16:04:32,515] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:04:32,516] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:04:32,518] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on localhost (1/1)
[16:04:32,518] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:04:32,519] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.027 s
[16:04:32,520] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.039054 s
[16:04:32,542] INFO  {CodeGenerator} Code generated in 19.151117 ms
[16:04:32,678] INFO  {CodeGenerator} Code generated in 58.302759 ms
[16:04:32,691] INFO  {SparkContext} Starting job: show at Main.scala:61
[16:04:32,692] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[16:04:32,693] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[16:04:32,693] INFO  {DAGScheduler} Parents of final stage: List()
[16:04:32,694] INFO  {DAGScheduler} Missing parents: List()
[16:04:32,695] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[16:04:32,699] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:04:32,701] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1127.5 MB)
[16:04:32,702] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:42775 (size: 13.2 KB, free: 1127.7 MB)
[16:04:32,703] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:04:32,703] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[16:04:32,703] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:04:32,705] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:04:32,705] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:04:32,714] INFO  {BlockManager} Found block rdd_2_0 locally
[16:04:32,725] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:04:32,727] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:04:32,729] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on localhost (1/1)
[16:04:32,729] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:04:32,730] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.025 s
[16:04:32,730] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.038605 s
[16:04:32,748] INFO  {CodeGenerator} Code generated in 15.417027 ms
[16:04:32,864] INFO  {CodeGenerator} Code generated in 47.3456 ms
[16:04:32,873] INFO  {SparkContext} Starting job: show at Main.scala:77
[16:04:32,874] INFO  {DAGScheduler} Got job 4 (show at Main.scala:77) with 1 output partitions
[16:04:32,874] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:77)
[16:04:32,874] INFO  {DAGScheduler} Parents of final stage: List()
[16:04:32,874] INFO  {DAGScheduler} Missing parents: List()
[16:04:32,875] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77), which has no missing parents
[16:04:32,879] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:04:32,881] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:04:32,882] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:42775 (size: 15.0 KB, free: 1127.6 MB)
[16:04:32,883] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:04:32,883] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77)
[16:04:32,883] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:04:32,885] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:04:32,885] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:04:32,894] INFO  {BlockManager} Found block rdd_2_0 locally
[16:04:32,906] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:04:32,907] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4020 bytes result sent to driver
[16:04:32,909] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 25 ms on localhost (1/1)
[16:04:32,909] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:04:32,910] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:77) finished in 0.027 s
[16:04:32,910] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:77, took 0.037530 s
[16:04:32,926] INFO  {CodeGenerator} Code generated in 12.743146 ms
[16:04:33,045] INFO  {CodeGenerator} Code generated in 56.165739 ms
[16:04:33,056] INFO  {SparkContext} Starting job: show at Main.scala:86
[16:04:33,057] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[16:04:33,057] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:86)
[16:04:33,057] INFO  {DAGScheduler} Parents of final stage: List()
[16:04:33,057] INFO  {DAGScheduler} Missing parents: List()
[16:04:33,058] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[16:04:33,063] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[16:04:33,066] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:04:33,067] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:42775 (size: 16.4 KB, free: 1127.6 MB)
[16:04:33,067] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:04:33,067] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86)
[16:04:33,068] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:04:33,069] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:04:33,070] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:04:33,074] INFO  {BlockManager} Found block rdd_2_0 locally
[16:04:33,087] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:04:33,088] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4083 bytes result sent to driver
[16:04:33,089] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 21 ms on localhost (1/1)
[16:04:33,089] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:04:33,090] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:86) finished in 0.021 s
[16:04:33,090] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.034346 s
[16:04:33,110] INFO  {CodeGenerator} Code generated in 16.096591 ms
[16:04:33,492] INFO  {CodeGenerator} Code generated in 24.359706 ms
[16:04:33,522] INFO  {CodeGenerator} Code generated in 13.271923 ms
[16:04:33,527] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:04:33,532] INFO  {ServerConnector} Stopped ServerConnector@3cc024a7{HTTP/1.1}{0.0.0.0:4040}
[16:04:33,535] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[16:04:33,535] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[16:04:33,535] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[16:04:33,535] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[16:04:33,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[16:04:33,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[16:04:33,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[16:04:33,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[16:04:33,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[16:04:33,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[16:04:33,536] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[16:04:33,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[16:04:33,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[16:04:33,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[16:04:33,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[16:04:33,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[16:04:33,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[16:04:33,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[16:04:33,537] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[16:04:33,538] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[16:04:33,538] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[16:04:33,538] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[16:04:33,538] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[16:04:33,538] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[16:04:33,540] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:04:33,553] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:04:33,561] INFO  {MemoryStore} MemoryStore cleared
[16:04:33,562] INFO  {BlockManager} BlockManager stopped
[16:04:33,564] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:04:33,568] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:04:33,580] INFO  {SparkContext} Successfully stopped SparkContext
[16:04:33,581] INFO  {ShutdownHookManager} Shutdown hook called
[16:04:33,582] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-e65e9f6f-32f2-4878-a49c-ecb8f9ec3860
[16:12:20,152] INFO  {SparkContext} Running Spark version 2.0.1
[16:12:20,361] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:12:20,453] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:12:20,453] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:12:20,534] INFO  {SecurityManager} Changing view acls to: victor
[16:12:20,535] INFO  {SecurityManager} Changing modify acls to: victor
[16:12:20,535] INFO  {SecurityManager} Changing view acls groups to: 
[16:12:20,536] INFO  {SecurityManager} Changing modify acls groups to: 
[16:12:20,537] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:12:20,875] INFO  {Utils} Successfully started service 'sparkDriver' on port 32861.
[16:12:20,895] INFO  {SparkEnv} Registering MapOutputTracker
[16:12:20,909] INFO  {SparkEnv} Registering BlockManagerMaster
[16:12:20,921] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-2b06678b-9d7c-472a-969d-19cb36198b6e
[16:12:20,935] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:12:20,997] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:12:21,071] INFO  {log} Logging initialized @1488ms
[16:12:21,170] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:12:21,184] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:12:21,185] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:12:21,185] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:12:21,185] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:12:21,185] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:12:21,185] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:12:21,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:12:21,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:12:21,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:12:21,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:12:21,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:12:21,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:12:21,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:12:21,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:12:21,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:12:21,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:12:21,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:12:21,188] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:12:21,188] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:12:21,188] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:12:21,194] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:12:21,194] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:12:21,195] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:12:21,195] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:12:21,201] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:12:21,201] INFO  {Server} Started @1620ms
[16:12:21,201] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:12:21,203] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:12:21,279] INFO  {Executor} Starting executor ID driver on host localhost
[16:12:21,301] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35209.
[16:12:21,302] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:35209
[16:12:21,304] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 35209)
[16:12:21,307] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:35209 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 35209)
[16:12:21,309] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 35209)
[16:12:21,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:12:21,489] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:12:21,489] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:12:21,490] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:12:21,491] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:12:21,492] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:12:21,504] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:12:23,277] INFO  {FileSourceStrategy} Pruning directories with: 
[16:12:23,279] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:12:23,284] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:12:23,285] INFO  {FileSourceStrategy} Pushed Filters: 
[16:12:23,394] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:12:23,443] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:12:23,445] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:35209 (size: 14.6 KB, free: 1128.9 MB)
[16:12:23,451] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[16:12:23,454] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:12:23,892] INFO  {CodeGenerator} Code generated in 184.992899 ms
[16:12:24,085] INFO  {CodeGenerator} Code generated in 26.037246 ms
[16:12:24,132] INFO  {SparkContext} Starting job: show at Main.scala:33
[16:12:24,149] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[16:12:24,150] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[16:12:24,150] INFO  {DAGScheduler} Parents of final stage: List()
[16:12:24,154] INFO  {DAGScheduler} Missing parents: List()
[16:12:24,158] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[16:12:24,219] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:12:24,222] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:12:24,223] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:35209 (size: 8.5 KB, free: 1128.9 MB)
[16:12:24,223] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:12:24,226] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[16:12:24,228] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:12:24,265] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:12:24,272] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:12:24,314] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:12:24,325] INFO  {CodeGenerator} Code generated in 8.509212 ms
[16:12:24,468] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:12:24,468] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:35209 (size: 1239.2 KB, free: 1127.7 MB)
[16:12:24,478] INFO  {CodeGenerator} Code generated in 3.953813 ms
[16:12:24,503] INFO  {CodeGenerator} Code generated in 19.157094 ms
[16:12:24,522] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:12:24,529] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:12:24,539] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 290 ms on localhost (1/1)
[16:12:24,540] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:12:24,545] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.308 s
[16:12:24,550] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.417573 s
[16:12:24,591] INFO  {CodeGenerator} Code generated in 21.922051 ms
[16:12:24,685] INFO  {CodeGenerator} Code generated in 29.17653 ms
[16:12:24,697] INFO  {SparkContext} Starting job: show at Main.scala:42
[16:12:24,698] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[16:12:24,698] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[16:12:24,698] INFO  {DAGScheduler} Parents of final stage: List()
[16:12:24,700] INFO  {DAGScheduler} Missing parents: List()
[16:12:24,700] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[16:12:24,704] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:12:24,708] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:12:24,708] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:35209 (size: 10.0 KB, free: 1127.7 MB)
[16:12:24,709] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:12:24,709] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[16:12:24,709] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:12:24,715] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:12:24,715] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:12:24,724] INFO  {BlockManager} Found block rdd_2_0 locally
[16:12:24,737] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:12:24,739] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:12:24,740] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[16:12:24,741] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:12:24,741] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.029 s
[16:12:24,742] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.044916 s
[16:12:24,764] INFO  {CodeGenerator} Code generated in 15.261346 ms
[16:12:24,941] INFO  {ContextCleaner} Cleaned accumulator 3
[16:12:24,941] INFO  {ContextCleaner} Cleaned accumulator 4
[16:12:24,958] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:35209 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:12:24,961] INFO  {ContextCleaner} Cleaned accumulator 49
[16:12:24,961] INFO  {ContextCleaner} Cleaned accumulator 50
[16:12:24,963] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:35209 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:12:25,017] INFO  {CodeGenerator} Code generated in 50.945695 ms
[16:12:25,033] INFO  {SparkContext} Starting job: show at Main.scala:51
[16:12:25,034] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[16:12:25,034] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[16:12:25,035] INFO  {DAGScheduler} Parents of final stage: List()
[16:12:25,035] INFO  {DAGScheduler} Missing parents: List()
[16:12:25,036] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[16:12:25,041] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:12:25,044] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:12:25,044] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:35209 (size: 11.7 KB, free: 1127.7 MB)
[16:12:25,045] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:12:25,045] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[16:12:25,046] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:12:25,048] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:12:25,049] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:12:25,057] INFO  {BlockManager} Found block rdd_2_0 locally
[16:12:25,069] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:12:25,070] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:12:25,073] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.027 s
[16:12:25,073] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 26 ms on localhost (1/1)
[16:12:25,073] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:12:25,073] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.040325 s
[16:12:25,097] INFO  {CodeGenerator} Code generated in 20.097477 ms
[16:12:25,216] INFO  {CodeGenerator} Code generated in 42.500157 ms
[16:12:25,227] INFO  {SparkContext} Starting job: show at Main.scala:61
[16:12:25,228] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[16:12:25,228] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[16:12:25,228] INFO  {DAGScheduler} Parents of final stage: List()
[16:12:25,229] INFO  {DAGScheduler} Missing parents: List()
[16:12:25,230] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[16:12:25,233] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:12:25,235] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:12:25,235] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:35209 (size: 13.3 KB, free: 1127.7 MB)
[16:12:25,236] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:12:25,236] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[16:12:25,236] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:12:25,238] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:12:25,238] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:12:25,247] INFO  {BlockManager} Found block rdd_2_0 locally
[16:12:25,258] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:12:25,259] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:12:25,261] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 24 ms on localhost (1/1)
[16:12:25,261] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:12:25,261] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.024 s
[16:12:25,262] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.034839 s
[16:12:25,281] INFO  {CodeGenerator} Code generated in 16.086291 ms
[16:12:25,419] INFO  {CodeGenerator} Code generated in 64.821746 ms
[16:12:25,433] INFO  {SparkContext} Starting job: show at Main.scala:77
[16:12:25,435] INFO  {DAGScheduler} Got job 4 (show at Main.scala:77) with 1 output partitions
[16:12:25,435] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:77)
[16:12:25,435] INFO  {DAGScheduler} Parents of final stage: List()
[16:12:25,435] INFO  {DAGScheduler} Missing parents: List()
[16:12:25,436] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77), which has no missing parents
[16:12:25,440] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:12:25,442] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:12:25,443] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:35209 (size: 15.1 KB, free: 1127.6 MB)
[16:12:25,444] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:12:25,444] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77)
[16:12:25,444] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:12:25,446] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:12:25,447] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:12:25,453] INFO  {BlockManager} Found block rdd_2_0 locally
[16:12:25,466] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:12:25,468] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4020 bytes result sent to driver
[16:12:25,469] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 24 ms on localhost (1/1)
[16:12:25,470] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:12:25,470] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:77) finished in 0.025 s
[16:12:25,471] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:77, took 0.036885 s
[16:12:25,490] INFO  {CodeGenerator} Code generated in 16.315381 ms
[16:12:25,622] INFO  {CodeGenerator} Code generated in 65.609055 ms
[16:12:25,634] INFO  {SparkContext} Starting job: show at Main.scala:86
[16:12:25,635] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[16:12:25,635] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:86)
[16:12:25,635] INFO  {DAGScheduler} Parents of final stage: List()
[16:12:25,636] INFO  {DAGScheduler} Missing parents: List()
[16:12:25,636] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[16:12:25,640] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[16:12:25,643] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:12:25,643] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:35209 (size: 16.4 KB, free: 1127.6 MB)
[16:12:25,644] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:12:25,644] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86)
[16:12:25,644] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:12:25,646] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:12:25,647] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:12:25,653] INFO  {BlockManager} Found block rdd_2_0 locally
[16:12:25,666] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:12:25,667] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4083 bytes result sent to driver
[16:12:25,669] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 23 ms on localhost (1/1)
[16:12:25,669] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:12:25,669] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:86) finished in 0.024 s
[16:12:25,670] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.036299 s
[16:12:25,689] INFO  {CodeGenerator} Code generated in 15.545733 ms
[16:12:26,050] INFO  {CodeGenerator} Code generated in 8.568164 ms
[16:12:26,063] INFO  {CodeGenerator} Code generated in 4.784224 ms
[16:12:26,067] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:12:26,071] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:12:26,073] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:12:26,073] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:12:26,073] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:12:26,073] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:12:26,073] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:12:26,073] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:12:26,073] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:12:26,074] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:12:26,074] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:12:26,074] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:12:26,074] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:12:26,074] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:12:26,074] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:12:26,074] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:12:26,075] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:12:26,075] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:12:26,075] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:12:26,075] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:12:26,075] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:12:26,075] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:12:26,076] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:12:26,076] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:12:26,076] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:12:26,076] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:12:26,077] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:12:26,085] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:12:26,091] INFO  {MemoryStore} MemoryStore cleared
[16:12:26,091] INFO  {BlockManager} BlockManager stopped
[16:12:26,092] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:12:26,094] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:12:26,096] INFO  {SparkContext} Successfully stopped SparkContext
[16:12:26,096] INFO  {ShutdownHookManager} Shutdown hook called
[16:12:26,097] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-460b04ae-62d3-41d2-b22e-b208823418b0
[16:13:44,551] INFO  {SparkContext} Running Spark version 2.0.1
[16:13:44,761] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:13:44,863] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:13:44,867] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:13:44,936] INFO  {SecurityManager} Changing view acls to: victor
[16:13:44,937] INFO  {SecurityManager} Changing modify acls to: victor
[16:13:44,938] INFO  {SecurityManager} Changing view acls groups to: 
[16:13:44,938] INFO  {SecurityManager} Changing modify acls groups to: 
[16:13:44,939] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:13:45,276] INFO  {Utils} Successfully started service 'sparkDriver' on port 32913.
[16:13:45,294] INFO  {SparkEnv} Registering MapOutputTracker
[16:13:45,308] INFO  {SparkEnv} Registering BlockManagerMaster
[16:13:45,320] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-5fa6611c-c1d0-4d62-a24d-ba0344768e51
[16:13:45,335] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:13:45,387] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:13:45,459] INFO  {log} Logging initialized @1500ms
[16:13:45,565] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:13:45,581] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:13:45,582] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:13:45,582] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:13:45,582] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:13:45,582] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:13:45,583] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:13:45,583] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:13:45,583] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:13:45,583] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:13:45,583] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:13:45,583] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:13:45,584] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:13:45,584] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:13:45,584] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:13:45,584] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:13:45,584] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:13:45,585] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:13:45,585] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:13:45,585] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:13:45,585] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:13:45,591] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:13:45,592] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:13:45,592] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:13:45,593] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:13:45,600] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:13:45,600] INFO  {Server} Started @1642ms
[16:13:45,600] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:13:45,602] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:13:45,685] INFO  {Executor} Starting executor ID driver on host localhost
[16:13:45,709] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38471.
[16:13:45,709] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:38471
[16:13:45,711] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 38471)
[16:13:45,715] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:38471 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 38471)
[16:13:45,718] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 38471)
[16:13:45,861] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:13:45,910] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:13:45,910] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:13:45,911] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:13:45,912] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:13:45,914] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:13:45,930] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:13:47,776] INFO  {FileSourceStrategy} Pruning directories with: 
[16:13:47,778] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:13:47,784] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:13:47,785] INFO  {FileSourceStrategy} Pushed Filters: 
[16:13:47,900] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:13:47,947] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:13:47,949] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:38471 (size: 14.6 KB, free: 1128.9 MB)
[16:13:47,954] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[16:13:47,958] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:13:48,387] INFO  {CodeGenerator} Code generated in 186.398553 ms
[16:13:48,587] INFO  {CodeGenerator} Code generated in 28.38353 ms
[16:13:48,639] INFO  {SparkContext} Starting job: show at Main.scala:33
[16:13:48,656] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[16:13:48,657] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[16:13:48,657] INFO  {DAGScheduler} Parents of final stage: List()
[16:13:48,661] INFO  {DAGScheduler} Missing parents: List()
[16:13:48,666] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[16:13:48,724] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:13:48,726] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:13:48,727] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:38471 (size: 8.5 KB, free: 1128.9 MB)
[16:13:48,728] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:13:48,731] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[16:13:48,732] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:13:48,770] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:13:48,778] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:13:48,821] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:13:48,834] INFO  {CodeGenerator} Code generated in 9.359877 ms
[16:13:48,985] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:13:48,986] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:38471 (size: 1239.2 KB, free: 1127.7 MB)
[16:13:48,996] INFO  {CodeGenerator} Code generated in 4.713768 ms
[16:13:49,022] INFO  {CodeGenerator} Code generated in 19.781496 ms
[16:13:49,044] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:13:49,052] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4710 bytes result sent to driver
[16:13:49,065] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 311 ms on localhost (1/1)
[16:13:49,067] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:13:49,071] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.329 s
[16:13:49,076] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.437293 s
[16:13:49,109] INFO  {CodeGenerator} Code generated in 18.407211 ms
[16:13:49,205] INFO  {CodeGenerator} Code generated in 31.470824 ms
[16:13:49,218] INFO  {SparkContext} Starting job: show at Main.scala:42
[16:13:49,219] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[16:13:49,219] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[16:13:49,219] INFO  {DAGScheduler} Parents of final stage: List()
[16:13:49,221] INFO  {DAGScheduler} Missing parents: List()
[16:13:49,222] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[16:13:49,227] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:13:49,229] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:13:49,229] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:38471 (size: 10.0 KB, free: 1127.7 MB)
[16:13:49,230] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:13:49,230] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[16:13:49,230] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:13:49,235] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:13:49,236] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:13:49,248] INFO  {BlockManager} Found block rdd_2_0 locally
[16:13:49,265] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:13:49,267] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:13:49,269] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on localhost (1/1)
[16:13:49,269] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:13:49,269] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.036 s
[16:13:49,270] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.051425 s
[16:13:49,301] INFO  {CodeGenerator} Code generated in 20.658131 ms
[16:13:49,510] INFO  {ContextCleaner} Cleaned accumulator 3
[16:13:49,510] INFO  {ContextCleaner} Cleaned accumulator 4
[16:13:49,526] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:38471 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:13:49,529] INFO  {ContextCleaner} Cleaned accumulator 49
[16:13:49,529] INFO  {ContextCleaner} Cleaned accumulator 50
[16:13:49,530] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:38471 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:13:49,568] INFO  {CodeGenerator} Code generated in 54.790485 ms
[16:13:49,585] INFO  {SparkContext} Starting job: show at Main.scala:51
[16:13:49,586] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[16:13:49,586] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[16:13:49,587] INFO  {DAGScheduler} Parents of final stage: List()
[16:13:49,588] INFO  {DAGScheduler} Missing parents: List()
[16:13:49,588] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[16:13:49,593] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:13:49,596] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:13:49,596] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:38471 (size: 11.7 KB, free: 1127.7 MB)
[16:13:49,597] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:13:49,597] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[16:13:49,597] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:13:49,600] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:13:49,601] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:13:49,612] INFO  {BlockManager} Found block rdd_2_0 locally
[16:13:49,622] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:13:49,623] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:13:49,625] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on localhost (1/1)
[16:13:49,625] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:13:49,626] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.028 s
[16:13:49,626] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.041281 s
[16:13:49,644] INFO  {CodeGenerator} Code generated in 15.522603 ms
[16:13:49,750] INFO  {CodeGenerator} Code generated in 44.613902 ms
[16:13:49,761] INFO  {SparkContext} Starting job: show at Main.scala:61
[16:13:49,762] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[16:13:49,762] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[16:13:49,762] INFO  {DAGScheduler} Parents of final stage: List()
[16:13:49,762] INFO  {DAGScheduler} Missing parents: List()
[16:13:49,763] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[16:13:49,766] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:13:49,768] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:13:49,769] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:38471 (size: 13.3 KB, free: 1127.7 MB)
[16:13:49,769] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:13:49,770] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[16:13:49,770] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:13:49,771] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:13:49,772] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:13:49,778] INFO  {BlockManager} Found block rdd_2_0 locally
[16:13:49,787] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:13:49,788] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:13:49,790] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on localhost (1/1)
[16:13:49,791] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:13:49,791] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.021 s
[16:13:49,792] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.030385 s
[16:13:49,809] INFO  {CodeGenerator} Code generated in 14.306513 ms
[16:13:49,944] INFO  {CodeGenerator} Code generated in 70.201281 ms
[16:13:49,962] INFO  {SparkContext} Starting job: show at Main.scala:77
[16:13:49,963] INFO  {DAGScheduler} Got job 4 (show at Main.scala:77) with 1 output partitions
[16:13:49,963] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:77)
[16:13:49,963] INFO  {DAGScheduler} Parents of final stage: List()
[16:13:49,964] INFO  {DAGScheduler} Missing parents: List()
[16:13:49,966] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77), which has no missing parents
[16:13:49,970] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:13:49,972] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:13:49,973] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:38471 (size: 15.1 KB, free: 1127.6 MB)
[16:13:49,974] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:13:49,974] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77)
[16:13:49,974] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:13:49,976] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:13:49,976] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:13:49,984] INFO  {BlockManager} Found block rdd_2_0 locally
[16:13:50,000] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:13:50,002] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4020 bytes result sent to driver
[16:13:50,003] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 28 ms on localhost (1/1)
[16:13:50,004] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:13:50,004] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:77) finished in 0.030 s
[16:13:50,005] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:77, took 0.042415 s
[16:13:50,026] INFO  {CodeGenerator} Code generated in 18.043633 ms
[16:13:50,168] INFO  {CodeGenerator} Code generated in 60.646534 ms
[16:13:50,179] INFO  {SparkContext} Starting job: show at Main.scala:86
[16:13:50,180] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[16:13:50,180] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:86)
[16:13:50,181] INFO  {DAGScheduler} Parents of final stage: List()
[16:13:50,181] INFO  {DAGScheduler} Missing parents: List()
[16:13:50,181] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[16:13:50,185] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[16:13:50,186] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:13:50,188] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:38471 (size: 16.4 KB, free: 1127.6 MB)
[16:13:50,188] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:13:50,188] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86)
[16:13:50,188] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:13:50,190] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:13:50,191] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:13:50,197] INFO  {BlockManager} Found block rdd_2_0 locally
[16:13:50,212] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:13:50,213] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4083 bytes result sent to driver
[16:13:50,214] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 25 ms on localhost (1/1)
[16:13:50,214] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:13:50,214] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:86) finished in 0.025 s
[16:13:50,215] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.035696 s
[16:13:50,232] INFO  {CodeGenerator} Code generated in 13.619792 ms
[16:13:50,627] INFO  {CodeGenerator} Code generated in 8.977641 ms
[16:13:50,642] INFO  {CodeGenerator} Code generated in 5.969439 ms
[16:13:50,645] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:13:50,651] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:13:50,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:13:50,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:13:50,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:13:50,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:13:50,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:13:50,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:13:50,655] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:13:50,655] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:13:50,655] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:13:50,655] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:13:50,655] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:13:50,655] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:13:50,655] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:13:50,655] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:13:50,655] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:13:50,655] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:13:50,656] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:13:50,656] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:13:50,656] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:13:50,656] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:13:50,656] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:13:50,656] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:13:50,656] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:13:50,656] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:13:50,658] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:13:50,669] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:13:50,679] INFO  {MemoryStore} MemoryStore cleared
[16:13:50,680] INFO  {BlockManager} BlockManager stopped
[16:13:50,682] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:13:50,685] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:13:50,697] INFO  {SparkContext} Successfully stopped SparkContext
[16:13:50,698] INFO  {ShutdownHookManager} Shutdown hook called
[16:13:50,699] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-565e260d-b37a-4494-94d3-4941edc8b280
[16:14:04,759] INFO  {SparkContext} Running Spark version 2.0.1
[16:14:04,965] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:14:05,056] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:14:05,057] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:14:05,142] INFO  {SecurityManager} Changing view acls to: victor
[16:14:05,143] INFO  {SecurityManager} Changing modify acls to: victor
[16:14:05,143] INFO  {SecurityManager} Changing view acls groups to: 
[16:14:05,144] INFO  {SecurityManager} Changing modify acls groups to: 
[16:14:05,144] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:14:05,503] INFO  {Utils} Successfully started service 'sparkDriver' on port 36645.
[16:14:05,522] INFO  {SparkEnv} Registering MapOutputTracker
[16:14:05,536] INFO  {SparkEnv} Registering BlockManagerMaster
[16:14:05,548] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-4d1e6654-7fd9-4f03-a9ee-0ed70d8dcede
[16:14:05,561] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:14:05,620] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:14:05,689] INFO  {log} Logging initialized @1504ms
[16:14:05,789] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:14:05,804] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:14:05,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:14:05,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:14:05,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:14:05,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:14:05,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:14:05,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:14:05,806] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:14:05,806] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:14:05,806] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:14:05,806] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:14:05,806] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:14:05,806] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:14:05,807] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:14:05,807] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:14:05,807] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:14:05,807] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:14:05,807] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:14:05,808] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:14:05,808] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:14:05,813] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:14:05,814] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:14:05,815] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:14:05,815] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:14:05,821] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:14:05,821] INFO  {Server} Started @1637ms
[16:14:05,821] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:14:05,823] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:14:05,904] INFO  {Executor} Starting executor ID driver on host localhost
[16:14:05,929] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38963.
[16:14:05,930] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:38963
[16:14:05,932] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 38963)
[16:14:05,936] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:38963 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 38963)
[16:14:05,940] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 38963)
[16:14:06,068] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:14:06,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:14:06,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:14:06,118] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:14:06,118] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:14:06,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:14:06,134] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:14:07,833] INFO  {FileSourceStrategy} Pruning directories with: 
[16:14:07,835] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:14:07,840] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:14:07,841] INFO  {FileSourceStrategy} Pushed Filters: 
[16:14:07,940] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:14:07,983] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:14:07,985] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:38963 (size: 14.6 KB, free: 1128.9 MB)
[16:14:07,990] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[16:14:07,996] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:14:08,417] INFO  {CodeGenerator} Code generated in 184.882996 ms
[16:14:08,614] INFO  {CodeGenerator} Code generated in 27.499675 ms
[16:14:08,661] INFO  {SparkContext} Starting job: show at Main.scala:33
[16:14:08,677] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[16:14:08,678] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[16:14:08,678] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:08,682] INFO  {DAGScheduler} Missing parents: List()
[16:14:08,686] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[16:14:08,744] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:14:08,747] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:14:08,747] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:38963 (size: 8.4 KB, free: 1128.9 MB)
[16:14:08,748] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:14:08,752] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[16:14:08,754] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:14:08,794] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:08,804] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:14:08,867] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:14:08,877] INFO  {CodeGenerator} Code generated in 7.727116 ms
[16:14:09,018] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:14:09,019] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:38963 (size: 1239.2 KB, free: 1127.7 MB)
[16:14:09,033] INFO  {CodeGenerator} Code generated in 5.734257 ms
[16:14:09,061] INFO  {CodeGenerator} Code generated in 19.188673 ms
[16:14:09,081] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:14:09,091] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:14:09,102] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 324 ms on localhost (1/1)
[16:14:09,103] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:14:09,107] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.344 s
[16:14:09,112] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.450364 s
[16:14:09,148] INFO  {CodeGenerator} Code generated in 21.740728 ms
[16:14:09,273] INFO  {CodeGenerator} Code generated in 43.858871 ms
[16:14:09,287] INFO  {SparkContext} Starting job: show at Main.scala:42
[16:14:09,288] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[16:14:09,288] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[16:14:09,288] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:09,290] INFO  {DAGScheduler} Missing parents: List()
[16:14:09,291] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[16:14:09,296] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:14:09,298] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:14:09,298] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:38963 (size: 10.0 KB, free: 1127.7 MB)
[16:14:09,299] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:14:09,299] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[16:14:09,299] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:14:09,304] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:09,305] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:14:09,318] INFO  {BlockManager} Found block rdd_2_0 locally
[16:14:09,335] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:14:09,336] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:14:09,339] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on localhost (1/1)
[16:14:09,339] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:14:09,339] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.037 s
[16:14:09,340] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.052520 s
[16:14:09,373] INFO  {CodeGenerator} Code generated in 22.920871 ms
[16:14:09,565] INFO  {ContextCleaner} Cleaned accumulator 3
[16:14:09,565] INFO  {ContextCleaner} Cleaned accumulator 4
[16:14:09,582] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:38963 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:14:09,585] INFO  {ContextCleaner} Cleaned accumulator 49
[16:14:09,585] INFO  {ContextCleaner} Cleaned accumulator 50
[16:14:09,587] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:38963 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:14:09,642] INFO  {CodeGenerator} Code generated in 57.368098 ms
[16:14:09,660] INFO  {SparkContext} Starting job: show at Main.scala:51
[16:14:09,661] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[16:14:09,662] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[16:14:09,662] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:09,663] INFO  {DAGScheduler} Missing parents: List()
[16:14:09,663] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[16:14:09,669] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:14:09,673] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:14:09,673] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:38963 (size: 11.7 KB, free: 1127.7 MB)
[16:14:09,674] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:14:09,674] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[16:14:09,674] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:14:09,677] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:09,677] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:14:09,689] INFO  {BlockManager} Found block rdd_2_0 locally
[16:14:09,699] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:14:09,699] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:14:09,701] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 26 ms on localhost (1/1)
[16:14:09,701] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:14:09,702] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.026 s
[16:14:09,702] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.041974 s
[16:14:09,718] INFO  {CodeGenerator} Code generated in 13.078558 ms
[16:14:09,808] INFO  {CodeGenerator} Code generated in 39.255872 ms
[16:14:09,819] INFO  {SparkContext} Starting job: show at Main.scala:61
[16:14:09,820] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[16:14:09,820] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[16:14:09,820] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:09,820] INFO  {DAGScheduler} Missing parents: List()
[16:14:09,821] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[16:14:09,824] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:14:09,826] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1127.5 MB)
[16:14:09,827] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:38963 (size: 13.2 KB, free: 1127.7 MB)
[16:14:09,827] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:14:09,827] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[16:14:09,827] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:14:09,829] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:09,829] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:14:09,835] INFO  {BlockManager} Found block rdd_2_0 locally
[16:14:09,844] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:14:09,845] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:14:09,846] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 18 ms on localhost (1/1)
[16:14:09,846] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:14:09,846] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.018 s
[16:14:09,847] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.028310 s
[16:14:09,862] INFO  {CodeGenerator} Code generated in 12.782073 ms
[16:14:09,976] INFO  {CodeGenerator} Code generated in 56.274314 ms
[16:14:09,989] INFO  {SparkContext} Starting job: show at Main.scala:77
[16:14:09,990] INFO  {DAGScheduler} Got job 4 (show at Main.scala:77) with 1 output partitions
[16:14:09,990] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:77)
[16:14:09,990] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:09,991] INFO  {DAGScheduler} Missing parents: List()
[16:14:09,991] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77), which has no missing parents
[16:14:09,995] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:14:09,998] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:14:09,999] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:38963 (size: 15.1 KB, free: 1127.6 MB)
[16:14:10,000] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:14:10,001] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77)
[16:14:10,001] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:14:10,003] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:10,004] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:14:10,008] INFO  {BlockManager} Found block rdd_2_0 locally
[16:14:10,019] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:14:10,021] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4020 bytes result sent to driver
[16:14:10,023] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 20 ms on localhost (1/1)
[16:14:10,023] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:14:10,024] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:77) finished in 0.022 s
[16:14:10,025] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:77, took 0.034986 s
[16:14:10,042] INFO  {CodeGenerator} Code generated in 14.641194 ms
[16:14:10,146] INFO  {CodeGenerator} Code generated in 49.243492 ms
[16:14:10,158] INFO  {SparkContext} Starting job: show at Main.scala:86
[16:14:10,158] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[16:14:10,159] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:86)
[16:14:10,159] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:10,159] INFO  {DAGScheduler} Missing parents: List()
[16:14:10,160] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[16:14:10,164] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[16:14:10,166] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:14:10,167] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:38963 (size: 16.4 KB, free: 1127.6 MB)
[16:14:10,167] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:14:10,167] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86)
[16:14:10,168] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:14:10,169] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:10,170] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:14:10,175] INFO  {BlockManager} Found block rdd_2_0 locally
[16:14:10,189] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:14:10,190] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4083 bytes result sent to driver
[16:14:10,191] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 23 ms on localhost (1/1)
[16:14:10,191] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:14:10,192] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:86) finished in 0.023 s
[16:14:10,193] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.034969 s
[16:14:10,213] INFO  {CodeGenerator} Code generated in 17.257017 ms
[16:14:10,692] INFO  {CodeGenerator} Code generated in 13.41101 ms
[16:14:10,711] INFO  {CodeGenerator} Code generated in 5.866616 ms
[16:14:10,715] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:14:10,720] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:14:10,723] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:14:10,723] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:14:10,723] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:14:10,723] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:14:10,723] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:14:10,723] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:14:10,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:14:10,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:14:10,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:14:10,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:14:10,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:14:10,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:14:10,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:14:10,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:14:10,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:14:10,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:14:10,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:14:10,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:14:10,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:14:10,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:14:10,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:14:10,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:14:10,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:14:10,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:14:10,727] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:14:10,736] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:14:10,754] INFO  {MemoryStore} MemoryStore cleared
[16:14:10,754] INFO  {BlockManager} BlockManager stopped
[16:14:10,756] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:14:10,759] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:14:10,768] INFO  {SparkContext} Successfully stopped SparkContext
[16:14:10,769] INFO  {ShutdownHookManager} Shutdown hook called
[16:14:10,769] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-0a42bbb8-4973-42dd-87b9-225203de4a75
[16:14:44,220] INFO  {SparkContext} Running Spark version 2.0.1
[16:14:44,433] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:14:44,543] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:14:44,543] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:14:44,617] INFO  {SecurityManager} Changing view acls to: victor
[16:14:44,618] INFO  {SecurityManager} Changing modify acls to: victor
[16:14:44,619] INFO  {SecurityManager} Changing view acls groups to: 
[16:14:44,620] INFO  {SecurityManager} Changing modify acls groups to: 
[16:14:44,620] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:14:44,983] INFO  {Utils} Successfully started service 'sparkDriver' on port 45785.
[16:14:45,002] INFO  {SparkEnv} Registering MapOutputTracker
[16:14:45,017] INFO  {SparkEnv} Registering BlockManagerMaster
[16:14:45,029] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-d64ceef4-f2a4-431c-ab8f-13a7c2f73b7f
[16:14:45,044] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:14:45,103] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:14:45,177] INFO  {log} Logging initialized @1563ms
[16:14:45,279] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:14:45,296] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:14:45,296] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:14:45,297] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:14:45,297] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:14:45,297] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:14:45,297] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:14:45,298] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:14:45,298] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:14:45,299] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:14:45,299] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:14:45,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:14:45,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:14:45,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:14:45,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:14:45,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:14:45,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:14:45,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:14:45,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:14:45,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:14:45,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:14:45,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:14:45,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:14:45,316] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:14:45,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:14:45,325] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:14:45,325] INFO  {Server} Started @1712ms
[16:14:45,325] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:14:45,328] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:14:45,413] INFO  {Executor} Starting executor ID driver on host localhost
[16:14:45,439] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33497.
[16:14:45,441] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:33497
[16:14:45,442] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 33497)
[16:14:45,445] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:33497 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 33497)
[16:14:45,448] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 33497)
[16:14:45,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:14:45,617] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL,null,AVAILABLE}
[16:14:45,617] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/json,null,AVAILABLE}
[16:14:45,618] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution,null,AVAILABLE}
[16:14:45,618] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b11ef33{/SQL/execution/json,null,AVAILABLE}
[16:14:45,620] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@21ec5d87{/static/sql,null,AVAILABLE}
[16:14:45,635] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:14:47,386] INFO  {FileSourceStrategy} Pruning directories with: 
[16:14:47,390] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:14:47,395] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:14:47,396] INFO  {FileSourceStrategy} Pushed Filters: 
[16:14:47,517] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:14:47,560] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:14:47,562] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:33497 (size: 14.6 KB, free: 1128.9 MB)
[16:14:47,567] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[16:14:47,571] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:14:47,998] INFO  {CodeGenerator} Code generated in 186.945207 ms
[16:14:48,196] INFO  {CodeGenerator} Code generated in 27.109604 ms
[16:14:48,243] INFO  {SparkContext} Starting job: show at Main.scala:33
[16:14:48,258] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[16:14:48,258] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[16:14:48,259] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:48,262] INFO  {DAGScheduler} Missing parents: List()
[16:14:48,266] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[16:14:48,331] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:14:48,333] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:14:48,334] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:33497 (size: 8.4 KB, free: 1128.9 MB)
[16:14:48,335] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:14:48,338] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[16:14:48,339] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:14:48,374] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:48,382] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:14:48,426] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:14:48,438] INFO  {CodeGenerator} Code generated in 8.87818 ms
[16:14:48,571] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:14:48,571] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:33497 (size: 1239.2 KB, free: 1127.7 MB)
[16:14:48,583] INFO  {CodeGenerator} Code generated in 3.943437 ms
[16:14:48,607] INFO  {CodeGenerator} Code generated in 18.381332 ms
[16:14:48,627] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:14:48,633] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:14:48,643] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 284 ms on localhost (1/1)
[16:14:48,645] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:14:48,647] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.299 s
[16:14:48,652] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.409157 s
[16:14:48,690] INFO  {CodeGenerator} Code generated in 20.100518 ms
[16:14:48,782] INFO  {CodeGenerator} Code generated in 27.269362 ms
[16:14:48,793] INFO  {SparkContext} Starting job: show at Main.scala:42
[16:14:48,794] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[16:14:48,795] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[16:14:48,795] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:48,796] INFO  {DAGScheduler} Missing parents: List()
[16:14:48,797] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[16:14:48,801] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:14:48,803] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:14:48,804] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:33497 (size: 10.0 KB, free: 1127.7 MB)
[16:14:48,804] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:14:48,804] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[16:14:48,804] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:14:48,810] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:48,810] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:14:48,819] INFO  {BlockManager} Found block rdd_2_0 locally
[16:14:48,832] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:14:48,833] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:14:48,835] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[16:14:48,835] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:14:48,836] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.028 s
[16:14:48,836] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.042571 s
[16:14:48,858] INFO  {CodeGenerator} Code generated in 14.513397 ms
[16:14:49,017] INFO  {ContextCleaner} Cleaned accumulator 3
[16:14:49,017] INFO  {ContextCleaner} Cleaned accumulator 4
[16:14:49,031] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:33497 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:14:49,034] INFO  {ContextCleaner} Cleaned accumulator 49
[16:14:49,034] INFO  {ContextCleaner} Cleaned accumulator 50
[16:14:49,035] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:33497 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:14:49,089] INFO  {CodeGenerator} Code generated in 36.14883 ms
[16:14:49,099] INFO  {SparkContext} Starting job: show at Main.scala:51
[16:14:49,100] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[16:14:49,101] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[16:14:49,101] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:49,101] INFO  {DAGScheduler} Missing parents: List()
[16:14:49,102] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[16:14:49,105] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:14:49,107] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:14:49,108] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:33497 (size: 11.7 KB, free: 1127.7 MB)
[16:14:49,109] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:14:49,109] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[16:14:49,109] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:14:49,111] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:49,111] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:14:49,118] INFO  {BlockManager} Found block rdd_2_0 locally
[16:14:49,127] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:14:49,128] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:14:49,130] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 20 ms on localhost (1/1)
[16:14:49,130] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:14:49,131] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.021 s
[16:14:49,131] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.031451 s
[16:14:49,152] INFO  {CodeGenerator} Code generated in 17.12922 ms
[16:14:49,254] INFO  {CodeGenerator} Code generated in 45.427404 ms
[16:14:49,266] INFO  {SparkContext} Starting job: show at Main.scala:61
[16:14:49,267] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[16:14:49,267] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[16:14:49,267] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:49,267] INFO  {DAGScheduler} Missing parents: List()
[16:14:49,268] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[16:14:49,271] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:14:49,273] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1127.5 MB)
[16:14:49,274] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:33497 (size: 13.2 KB, free: 1127.7 MB)
[16:14:49,274] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:14:49,274] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[16:14:49,275] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:14:49,277] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:49,277] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:14:49,285] INFO  {BlockManager} Found block rdd_2_0 locally
[16:14:49,293] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:14:49,293] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:14:49,295] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on localhost (1/1)
[16:14:49,295] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:14:49,295] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.020 s
[16:14:49,296] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.029682 s
[16:14:49,312] INFO  {CodeGenerator} Code generated in 13.97135 ms
[16:14:49,438] INFO  {CodeGenerator} Code generated in 58.245145 ms
[16:14:49,450] INFO  {SparkContext} Starting job: show at Main.scala:77
[16:14:49,451] INFO  {DAGScheduler} Got job 4 (show at Main.scala:77) with 1 output partitions
[16:14:49,451] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:77)
[16:14:49,451] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:49,452] INFO  {DAGScheduler} Missing parents: List()
[16:14:49,452] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77), which has no missing parents
[16:14:49,456] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:14:49,458] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:14:49,459] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:33497 (size: 15.0 KB, free: 1127.6 MB)
[16:14:49,460] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:14:49,460] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77)
[16:14:49,460] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:14:49,462] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:49,462] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:14:49,470] INFO  {BlockManager} Found block rdd_2_0 locally
[16:14:49,480] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:14:49,481] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4020 bytes result sent to driver
[16:14:49,483] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 21 ms on localhost (1/1)
[16:14:49,483] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:14:49,483] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:77) finished in 0.022 s
[16:14:49,484] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:77, took 0.033436 s
[16:14:49,499] INFO  {CodeGenerator} Code generated in 12.558125 ms
[16:14:49,607] INFO  {CodeGenerator} Code generated in 47.285214 ms
[16:14:49,616] INFO  {SparkContext} Starting job: show at Main.scala:86
[16:14:49,617] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[16:14:49,617] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:86)
[16:14:49,617] INFO  {DAGScheduler} Parents of final stage: List()
[16:14:49,618] INFO  {DAGScheduler} Missing parents: List()
[16:14:49,618] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[16:14:49,622] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[16:14:49,624] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:14:49,625] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:33497 (size: 16.4 KB, free: 1127.6 MB)
[16:14:49,625] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:14:49,625] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86)
[16:14:49,625] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:14:49,627] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:14:49,628] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:14:49,632] INFO  {BlockManager} Found block rdd_2_0 locally
[16:14:49,642] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:14:49,643] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4083 bytes result sent to driver
[16:14:49,644] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 18 ms on localhost (1/1)
[16:14:49,644] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:14:49,645] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:86) finished in 0.018 s
[16:14:49,645] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.028821 s
[16:14:49,660] INFO  {CodeGenerator} Code generated in 12.369568 ms
[16:14:50,034] INFO  {CodeGenerator} Code generated in 10.143956 ms
[16:14:50,050] INFO  {CodeGenerator} Code generated in 6.813534 ms
[16:14:50,054] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:14:50,058] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:14:50,060] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:14:50,060] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:14:50,060] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:14:50,060] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:14:50,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:14:50,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:14:50,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:14:50,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:14:50,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:14:50,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:14:50,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:14:50,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:14:50,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:14:50,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:14:50,062] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:14:50,062] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:14:50,062] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:14:50,062] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:14:50,062] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:14:50,062] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:14:50,062] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:14:50,062] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:14:50,062] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:14:50,062] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:14:50,064] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:14:50,073] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:14:50,086] INFO  {MemoryStore} MemoryStore cleared
[16:14:50,086] INFO  {BlockManager} BlockManager stopped
[16:14:50,089] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:14:50,092] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:14:50,099] INFO  {SparkContext} Successfully stopped SparkContext
[16:14:50,100] INFO  {ShutdownHookManager} Shutdown hook called
[16:14:50,101] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-c96bfa8f-1490-4adc-8b09-8bffe28cdda7
[16:15:05,370] INFO  {SparkContext} Running Spark version 2.0.1
[16:15:05,576] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:15:05,665] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:15:05,666] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:15:05,742] INFO  {SecurityManager} Changing view acls to: victor
[16:15:05,742] INFO  {SecurityManager} Changing modify acls to: victor
[16:15:05,743] INFO  {SecurityManager} Changing view acls groups to: 
[16:15:05,744] INFO  {SecurityManager} Changing modify acls groups to: 
[16:15:05,744] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:15:06,104] INFO  {Utils} Successfully started service 'sparkDriver' on port 46857.
[16:15:06,120] INFO  {SparkEnv} Registering MapOutputTracker
[16:15:06,135] INFO  {SparkEnv} Registering BlockManagerMaster
[16:15:06,148] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-c9d8dfd3-387c-41e8-add2-cfe186e9c009
[16:15:06,162] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:15:06,221] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:15:06,290] INFO  {log} Logging initialized @1509ms
[16:15:06,397] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:15:06,414] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[16:15:06,414] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[16:15:06,414] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[16:15:06,415] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[16:15:06,415] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[16:15:06,415] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[16:15:06,415] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[16:15:06,416] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[16:15:06,416] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[16:15:06,416] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[16:15:06,416] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[16:15:06,417] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[16:15:06,417] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[16:15:06,417] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[16:15:06,417] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[16:15:06,418] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[16:15:06,418] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[16:15:06,418] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[16:15:06,418] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[16:15:06,419] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[16:15:06,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[16:15:06,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[16:15:06,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[16:15:06,430] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[16:15:06,436] INFO  {ServerConnector} Started ServerConnector@372d0aa1{HTTP/1.1}{0.0.0.0:4040}
[16:15:06,437] INFO  {Server} Started @1657ms
[16:15:06,437] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:15:06,439] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:15:06,535] INFO  {Executor} Starting executor ID driver on host localhost
[16:15:06,565] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40121.
[16:15:06,565] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:40121
[16:15:06,568] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 40121)
[16:15:06,571] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:40121 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 40121)
[16:15:06,575] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 40121)
[16:15:06,711] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[16:15:06,763] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL,null,AVAILABLE}
[16:15:06,763] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/json,null,AVAILABLE}
[16:15:06,764] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution,null,AVAILABLE}
[16:15:06,764] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b11ef33{/SQL/execution/json,null,AVAILABLE}
[16:15:06,766] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@21ec5d87{/static/sql,null,AVAILABLE}
[16:15:06,778] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:15:08,562] INFO  {FileSourceStrategy} Pruning directories with: 
[16:15:08,565] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:15:08,571] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:15:08,572] INFO  {FileSourceStrategy} Pushed Filters: 
[16:15:08,681] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:15:08,724] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:15:08,726] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:40121 (size: 14.6 KB, free: 1128.9 MB)
[16:15:08,733] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[16:15:08,738] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:15:09,166] INFO  {CodeGenerator} Code generated in 187.501223 ms
[16:15:09,358] INFO  {CodeGenerator} Code generated in 26.623058 ms
[16:15:09,404] INFO  {SparkContext} Starting job: show at Main.scala:33
[16:15:09,421] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[16:15:09,421] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[16:15:09,421] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:09,425] INFO  {DAGScheduler} Missing parents: List()
[16:15:09,430] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[16:15:09,501] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:15:09,504] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:15:09,504] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:40121 (size: 8.5 KB, free: 1128.9 MB)
[16:15:09,505] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:15:09,508] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[16:15:09,510] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:15:09,550] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:09,559] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:15:09,607] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:15:09,621] INFO  {CodeGenerator} Code generated in 10.955574 ms
[16:15:09,758] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:15:09,759] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:40121 (size: 1239.2 KB, free: 1127.7 MB)
[16:15:09,770] INFO  {CodeGenerator} Code generated in 3.936011 ms
[16:15:09,795] INFO  {CodeGenerator} Code generated in 18.574031 ms
[16:15:09,813] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:15:09,820] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:15:09,830] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 299 ms on localhost (1/1)
[16:15:09,832] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:15:09,836] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.316 s
[16:15:09,842] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.437549 s
[16:15:09,879] INFO  {CodeGenerator} Code generated in 20.819372 ms
[16:15:09,997] INFO  {CodeGenerator} Code generated in 39.777016 ms
[16:15:10,009] INFO  {SparkContext} Starting job: show at Main.scala:42
[16:15:10,010] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[16:15:10,010] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[16:15:10,010] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:10,013] INFO  {DAGScheduler} Missing parents: List()
[16:15:10,014] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[16:15:10,020] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:15:10,022] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:15:10,023] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:40121 (size: 10.0 KB, free: 1127.7 MB)
[16:15:10,023] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:15:10,024] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[16:15:10,024] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:15:10,030] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:10,030] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:15:10,040] INFO  {BlockManager} Found block rdd_2_0 locally
[16:15:10,054] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:15:10,054] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:15:10,056] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 29 ms on localhost (1/1)
[16:15:10,056] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:15:10,057] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.030 s
[16:15:10,057] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.047993 s
[16:15:10,079] INFO  {CodeGenerator} Code generated in 14.564423 ms
[16:15:10,295] INFO  {ContextCleaner} Cleaned accumulator 3
[16:15:10,296] INFO  {ContextCleaner} Cleaned accumulator 4
[16:15:10,311] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:40121 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:15:10,315] INFO  {ContextCleaner} Cleaned accumulator 49
[16:15:10,315] INFO  {ContextCleaner} Cleaned accumulator 50
[16:15:10,316] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:40121 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:15:10,370] INFO  {CodeGenerator} Code generated in 45.989591 ms
[16:15:10,381] INFO  {SparkContext} Starting job: show at Main.scala:51
[16:15:10,382] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[16:15:10,382] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[16:15:10,382] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:10,383] INFO  {DAGScheduler} Missing parents: List()
[16:15:10,384] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[16:15:10,388] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:15:10,390] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:15:10,391] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:40121 (size: 11.7 KB, free: 1127.7 MB)
[16:15:10,392] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:15:10,392] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[16:15:10,392] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:15:10,394] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:10,395] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:15:10,404] INFO  {BlockManager} Found block rdd_2_0 locally
[16:15:10,416] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:15:10,417] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:15:10,419] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 26 ms on localhost (1/1)
[16:15:10,419] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:15:10,419] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.026 s
[16:15:10,420] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.039052 s
[16:15:10,437] INFO  {CodeGenerator} Code generated in 14.354216 ms
[16:15:10,536] INFO  {CodeGenerator} Code generated in 47.870373 ms
[16:15:10,550] INFO  {SparkContext} Starting job: show at Main.scala:61
[16:15:10,551] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[16:15:10,551] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[16:15:10,551] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:10,551] INFO  {DAGScheduler} Missing parents: List()
[16:15:10,552] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[16:15:10,555] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:15:10,557] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:15:10,558] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:40121 (size: 13.3 KB, free: 1127.7 MB)
[16:15:10,558] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:15:10,558] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[16:15:10,559] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:15:10,560] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:10,561] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:15:10,570] INFO  {BlockManager} Found block rdd_2_0 locally
[16:15:10,579] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:15:10,579] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:15:10,581] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 22 ms on localhost (1/1)
[16:15:10,581] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:15:10,581] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.022 s
[16:15:10,582] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.032024 s
[16:15:10,597] INFO  {CodeGenerator} Code generated in 12.996561 ms
[16:15:10,738] INFO  {CodeGenerator} Code generated in 63.413743 ms
[16:15:10,753] INFO  {SparkContext} Starting job: show at Main.scala:77
[16:15:10,755] INFO  {DAGScheduler} Got job 4 (show at Main.scala:77) with 1 output partitions
[16:15:10,755] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:77)
[16:15:10,755] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:10,756] INFO  {DAGScheduler} Missing parents: List()
[16:15:10,757] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77), which has no missing parents
[16:15:10,761] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:15:10,764] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:15:10,765] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:40121 (size: 15.1 KB, free: 1127.6 MB)
[16:15:10,765] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:15:10,765] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77)
[16:15:10,766] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:15:10,768] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:10,768] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:15:10,776] INFO  {BlockManager} Found block rdd_2_0 locally
[16:15:10,790] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:15:10,792] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4020 bytes result sent to driver
[16:15:10,794] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 27 ms on localhost (1/1)
[16:15:10,794] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:15:10,795] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:77) finished in 0.029 s
[16:15:10,795] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:77, took 0.041383 s
[16:15:10,812] INFO  {CodeGenerator} Code generated in 14.848974 ms
[16:15:10,960] INFO  {CodeGenerator} Code generated in 72.97553 ms
[16:15:10,971] INFO  {SparkContext} Starting job: show at Main.scala:86
[16:15:10,972] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[16:15:10,972] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:86)
[16:15:10,972] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:10,973] INFO  {DAGScheduler} Missing parents: List()
[16:15:10,974] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[16:15:10,978] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[16:15:10,980] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:15:10,981] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:40121 (size: 16.4 KB, free: 1127.6 MB)
[16:15:10,982] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:15:10,982] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86)
[16:15:10,982] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:15:10,984] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:10,984] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:15:10,991] INFO  {BlockManager} Found block rdd_2_0 locally
[16:15:11,002] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:15:11,003] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4083 bytes result sent to driver
[16:15:11,004] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 20 ms on localhost (1/1)
[16:15:11,004] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:15:11,005] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:86) finished in 0.022 s
[16:15:11,005] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.034390 s
[16:15:11,021] INFO  {CodeGenerator} Code generated in 13.669024 ms
[16:15:11,411] INFO  {CodeGenerator} Code generated in 8.122945 ms
[16:15:11,424] INFO  {CodeGenerator} Code generated in 4.540293 ms
[16:15:11,427] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:15:11,432] INFO  {ServerConnector} Stopped ServerConnector@372d0aa1{HTTP/1.1}{0.0.0.0:4040}
[16:15:11,434] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[16:15:11,434] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[16:15:11,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[16:15:11,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[16:15:11,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[16:15:11,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[16:15:11,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[16:15:11,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[16:15:11,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[16:15:11,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[16:15:11,436] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[16:15:11,436] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[16:15:11,436] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[16:15:11,436] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[16:15:11,436] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[16:15:11,436] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[16:15:11,436] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[16:15:11,436] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[16:15:11,436] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[16:15:11,437] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[16:15:11,437] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[16:15:11,437] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[16:15:11,437] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[16:15:11,437] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[16:15:11,439] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:15:11,452] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:15:11,464] INFO  {MemoryStore} MemoryStore cleared
[16:15:11,464] INFO  {BlockManager} BlockManager stopped
[16:15:11,466] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:15:11,469] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:15:11,477] INFO  {SparkContext} Successfully stopped SparkContext
[16:15:11,478] INFO  {ShutdownHookManager} Shutdown hook called
[16:15:11,478] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-2264bc06-c1e8-49b5-bebf-a1bb59abf2df
[16:15:43,290] INFO  {SparkContext} Running Spark version 2.0.1
[16:15:43,492] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:15:43,592] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:15:43,592] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:15:43,667] INFO  {SecurityManager} Changing view acls to: victor
[16:15:43,668] INFO  {SecurityManager} Changing modify acls to: victor
[16:15:43,668] INFO  {SecurityManager} Changing view acls groups to: 
[16:15:43,669] INFO  {SecurityManager} Changing modify acls groups to: 
[16:15:43,669] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:15:43,995] INFO  {Utils} Successfully started service 'sparkDriver' on port 43113.
[16:15:44,013] INFO  {SparkEnv} Registering MapOutputTracker
[16:15:44,028] INFO  {SparkEnv} Registering BlockManagerMaster
[16:15:44,040] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-da94444a-d371-48a6-bb69-bceb205017a3
[16:15:44,053] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:15:44,103] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:15:44,173] INFO  {log} Logging initialized @1481ms
[16:15:44,271] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:15:44,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:15:44,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:15:44,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:15:44,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:15:44,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:15:44,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:15:44,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:15:44,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:15:44,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:15:44,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:15:44,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:15:44,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:15:44,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:15:44,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:15:44,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:15:44,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:15:44,290] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:15:44,290] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:15:44,290] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:15:44,290] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:15:44,297] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:15:44,297] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:15:44,298] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:15:44,298] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:15:44,307] INFO  {ServerConnector} Started ServerConnector@75604877{HTTP/1.1}{0.0.0.0:4040}
[16:15:44,307] INFO  {Server} Started @1616ms
[16:15:44,307] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:15:44,310] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:15:44,388] INFO  {Executor} Starting executor ID driver on host localhost
[16:15:44,412] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45057.
[16:15:44,413] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:45057
[16:15:44,415] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 45057)
[16:15:44,420] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:45057 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 45057)
[16:15:44,425] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 45057)
[16:15:44,596] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@72ccd81a{/metrics/json,null,AVAILABLE}
[16:15:44,651] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL,null,AVAILABLE}
[16:15:44,652] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1133ec6e{/SQL/json,null,AVAILABLE}
[16:15:44,653] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/SQL/execution,null,AVAILABLE}
[16:15:44,654] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/SQL/execution/json,null,AVAILABLE}
[16:15:44,656] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bd7f8dc{/static/sql,null,AVAILABLE}
[16:15:44,672] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:15:46,496] INFO  {FileSourceStrategy} Pruning directories with: 
[16:15:46,499] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:15:46,504] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:15:46,505] INFO  {FileSourceStrategy} Pushed Filters: 
[16:15:46,618] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:15:46,663] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:15:46,665] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:45057 (size: 14.6 KB, free: 1128.9 MB)
[16:15:46,673] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[16:15:46,678] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:15:47,119] INFO  {CodeGenerator} Code generated in 186.172439 ms
[16:15:47,316] INFO  {CodeGenerator} Code generated in 27.526521 ms
[16:15:47,362] INFO  {SparkContext} Starting job: show at Main.scala:33
[16:15:47,379] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[16:15:47,379] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[16:15:47,380] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:47,385] INFO  {DAGScheduler} Missing parents: List()
[16:15:47,389] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[16:15:47,456] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:15:47,459] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:15:47,459] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:45057 (size: 8.5 KB, free: 1128.9 MB)
[16:15:47,460] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:15:47,464] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[16:15:47,466] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:15:47,502] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:47,510] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:15:47,556] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:15:47,570] INFO  {CodeGenerator} Code generated in 10.14142 ms
[16:15:47,712] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:15:47,714] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:45057 (size: 1239.2 KB, free: 1127.7 MB)
[16:15:47,724] INFO  {CodeGenerator} Code generated in 4.067131 ms
[16:15:47,749] INFO  {CodeGenerator} Code generated in 18.90679 ms
[16:15:47,770] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:15:47,777] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:15:47,789] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 302 ms on localhost (1/1)
[16:15:47,791] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:15:47,794] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.319 s
[16:15:47,798] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.435585 s
[16:15:47,828] INFO  {CodeGenerator} Code generated in 15.969501 ms
[16:15:47,919] INFO  {CodeGenerator} Code generated in 29.511445 ms
[16:15:47,931] INFO  {SparkContext} Starting job: show at Main.scala:42
[16:15:47,932] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[16:15:47,932] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[16:15:47,932] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:47,934] INFO  {DAGScheduler} Missing parents: List()
[16:15:47,934] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[16:15:47,939] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:15:47,941] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:15:47,941] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:45057 (size: 10.0 KB, free: 1127.7 MB)
[16:15:47,942] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:15:47,942] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[16:15:47,942] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:15:47,947] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:47,948] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:15:47,957] INFO  {BlockManager} Found block rdd_2_0 locally
[16:15:47,971] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:15:47,972] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:15:47,974] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[16:15:47,974] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:15:47,974] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.029 s
[16:15:47,975] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.043614 s
[16:15:47,997] INFO  {CodeGenerator} Code generated in 15.103058 ms
[16:15:48,206] INFO  {ContextCleaner} Cleaned accumulator 3
[16:15:48,206] INFO  {ContextCleaner} Cleaned accumulator 4
[16:15:48,219] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:45057 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:15:48,222] INFO  {ContextCleaner} Cleaned accumulator 49
[16:15:48,222] INFO  {ContextCleaner} Cleaned accumulator 50
[16:15:48,223] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:45057 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:15:48,285] INFO  {CodeGenerator} Code generated in 56.473625 ms
[16:15:48,300] INFO  {SparkContext} Starting job: show at Main.scala:51
[16:15:48,301] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[16:15:48,302] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[16:15:48,302] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:48,302] INFO  {DAGScheduler} Missing parents: List()
[16:15:48,303] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[16:15:48,307] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:15:48,309] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:15:48,309] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:45057 (size: 11.7 KB, free: 1127.7 MB)
[16:15:48,310] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:15:48,310] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[16:15:48,310] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:15:48,312] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:48,312] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:15:48,318] INFO  {BlockManager} Found block rdd_2_0 locally
[16:15:48,329] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:15:48,330] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:15:48,332] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.022 s
[16:15:48,332] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 20 ms on localhost (1/1)
[16:15:48,333] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:15:48,333] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.032787 s
[16:15:48,355] INFO  {CodeGenerator} Code generated in 18.341106 ms
[16:15:48,485] INFO  {CodeGenerator} Code generated in 58.821727 ms
[16:15:48,497] INFO  {SparkContext} Starting job: show at Main.scala:61
[16:15:48,498] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[16:15:48,498] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[16:15:48,498] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:48,499] INFO  {DAGScheduler} Missing parents: List()
[16:15:48,499] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[16:15:48,503] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:15:48,506] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:15:48,507] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:45057 (size: 13.3 KB, free: 1127.7 MB)
[16:15:48,507] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:15:48,508] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[16:15:48,508] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:15:48,510] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:48,510] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:15:48,519] INFO  {BlockManager} Found block rdd_2_0 locally
[16:15:48,532] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:15:48,533] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:15:48,535] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 27 ms on localhost (1/1)
[16:15:48,535] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:15:48,535] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.027 s
[16:15:48,536] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.039050 s
[16:15:48,559] INFO  {CodeGenerator} Code generated in 18.943191 ms
[16:15:48,705] INFO  {CodeGenerator} Code generated in 63.884419 ms
[16:15:48,719] INFO  {SparkContext} Starting job: show at Main.scala:77
[16:15:48,720] INFO  {DAGScheduler} Got job 4 (show at Main.scala:77) with 1 output partitions
[16:15:48,720] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:77)
[16:15:48,720] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:48,721] INFO  {DAGScheduler} Missing parents: List()
[16:15:48,722] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77), which has no missing parents
[16:15:48,726] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:15:48,729] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:15:48,729] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:45057 (size: 15.0 KB, free: 1127.6 MB)
[16:15:48,730] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:15:48,730] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77)
[16:15:48,730] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:15:48,733] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:48,733] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:15:48,740] INFO  {BlockManager} Found block rdd_2_0 locally
[16:15:48,755] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:15:48,759] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4020 bytes result sent to driver
[16:15:48,761] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 30 ms on localhost (1/1)
[16:15:48,761] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:15:48,761] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:77) finished in 0.030 s
[16:15:48,762] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:77, took 0.042659 s
[16:15:48,783] INFO  {CodeGenerator} Code generated in 19.125122 ms
[16:15:48,942] INFO  {CodeGenerator} Code generated in 74.152817 ms
[16:15:48,956] INFO  {SparkContext} Starting job: show at Main.scala:86
[16:15:48,956] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[16:15:48,957] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:86)
[16:15:48,957] INFO  {DAGScheduler} Parents of final stage: List()
[16:15:48,957] INFO  {DAGScheduler} Missing parents: List()
[16:15:48,958] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[16:15:48,962] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.0 KB, free 1127.3 MB)
[16:15:48,964] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:15:48,965] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:45057 (size: 16.4 KB, free: 1127.6 MB)
[16:15:48,966] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:15:48,966] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86)
[16:15:48,966] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:15:48,968] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:15:48,969] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:15:48,975] INFO  {BlockManager} Found block rdd_2_0 locally
[16:15:48,989] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:15:48,990] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4081 bytes result sent to driver
[16:15:48,992] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 24 ms on localhost (1/1)
[16:15:48,992] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:15:48,995] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:86) finished in 0.027 s
[16:15:48,996] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.039913 s
[16:15:49,021] INFO  {CodeGenerator} Code generated in 22.648503 ms
[16:15:49,399] INFO  {CodeGenerator} Code generated in 9.216841 ms
[16:15:49,414] INFO  {CodeGenerator} Code generated in 6.152087 ms
[16:15:49,418] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:15:49,423] INFO  {ServerConnector} Stopped ServerConnector@75604877{HTTP/1.1}{0.0.0.0:4040}
[16:15:49,426] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:15:49,426] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:15:49,426] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:15:49,426] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:15:49,426] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:15:49,426] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:15:49,427] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:15:49,427] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:15:49,427] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:15:49,427] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:15:49,427] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:15:49,427] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:15:49,428] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:15:49,428] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:15:49,428] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:15:49,428] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:15:49,428] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:15:49,429] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:15:49,429] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:15:49,429] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:15:49,429] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:15:49,429] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:15:49,429] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:15:49,429] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:15:49,431] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:15:49,440] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:15:49,447] INFO  {MemoryStore} MemoryStore cleared
[16:15:49,448] INFO  {BlockManager} BlockManager stopped
[16:15:49,449] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:15:49,452] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:15:49,461] INFO  {SparkContext} Successfully stopped SparkContext
[16:15:49,461] INFO  {ShutdownHookManager} Shutdown hook called
[16:15:49,462] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-99d3cc53-4ad2-4134-84a2-ffc82603aa53
[16:16:26,953] INFO  {SparkContext} Running Spark version 2.0.1
[16:16:27,164] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:16:27,253] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:16:27,253] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:16:27,323] INFO  {SecurityManager} Changing view acls to: victor
[16:16:27,324] INFO  {SecurityManager} Changing modify acls to: victor
[16:16:27,326] INFO  {SecurityManager} Changing view acls groups to: 
[16:16:27,326] INFO  {SecurityManager} Changing modify acls groups to: 
[16:16:27,327] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:16:27,690] INFO  {Utils} Successfully started service 'sparkDriver' on port 40135.
[16:16:27,707] INFO  {SparkEnv} Registering MapOutputTracker
[16:16:27,722] INFO  {SparkEnv} Registering BlockManagerMaster
[16:16:27,734] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-149a719f-74f7-4767-871a-d3c1c0cb1b10
[16:16:27,749] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:16:27,799] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:16:27,871] INFO  {log} Logging initialized @1548ms
[16:16:27,975] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:16:27,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:16:27,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:16:27,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:16:27,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:16:27,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:16:27,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:16:27,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:16:27,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:16:27,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:16:27,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:16:27,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:16:27,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:16:27,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:16:27,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:16:27,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:16:27,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:16:27,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:16:27,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:16:27,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:16:27,994] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:16:28,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:16:28,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:16:28,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:16:28,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:16:28,007] INFO  {ServerConnector} Started ServerConnector@41051c8d{HTTP/1.1}{0.0.0.0:4040}
[16:16:28,007] INFO  {Server} Started @1686ms
[16:16:28,007] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:16:28,010] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:16:28,088] INFO  {Executor} Starting executor ID driver on host localhost
[16:16:28,113] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46165.
[16:16:28,114] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:46165
[16:16:28,115] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 46165)
[16:16:28,118] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:46165 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 46165)
[16:16:28,121] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 46165)
[16:16:28,251] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:16:28,299] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:16:28,299] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:16:28,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:16:28,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:16:28,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:16:28,316] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:16:30,160] INFO  {FileSourceStrategy} Pruning directories with: 
[16:16:30,163] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:16:30,168] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:16:30,169] INFO  {FileSourceStrategy} Pushed Filters: 
[16:16:30,280] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:16:30,327] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:16:30,329] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:46165 (size: 14.6 KB, free: 1128.9 MB)
[16:16:30,336] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[16:16:30,339] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:16:30,806] INFO  {CodeGenerator} Code generated in 196.788791 ms
[16:16:31,004] INFO  {CodeGenerator} Code generated in 26.473908 ms
[16:16:31,049] INFO  {SparkContext} Starting job: show at Main.scala:33
[16:16:31,066] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[16:16:31,067] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[16:16:31,067] INFO  {DAGScheduler} Parents of final stage: List()
[16:16:31,072] INFO  {DAGScheduler} Missing parents: List()
[16:16:31,076] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[16:16:31,134] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:16:31,136] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:16:31,138] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:46165 (size: 8.4 KB, free: 1128.9 MB)
[16:16:31,138] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:16:31,141] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[16:16:31,143] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:16:31,179] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:16:31,187] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:16:31,235] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:16:31,259] INFO  {CodeGenerator} Code generated in 21.412664 ms
[16:16:31,385] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:16:31,387] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:46165 (size: 1239.2 KB, free: 1127.7 MB)
[16:16:31,399] INFO  {CodeGenerator} Code generated in 4.110255 ms
[16:16:31,426] INFO  {CodeGenerator} Code generated in 20.351343 ms
[16:16:31,447] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:16:31,453] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:16:31,463] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 299 ms on localhost (1/1)
[16:16:31,465] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:16:31,469] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.315 s
[16:16:31,475] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.425875 s
[16:16:31,511] INFO  {CodeGenerator} Code generated in 19.269882 ms
[16:16:31,618] INFO  {CodeGenerator} Code generated in 33.752897 ms
[16:16:31,634] INFO  {SparkContext} Starting job: show at Main.scala:42
[16:16:31,635] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[16:16:31,636] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[16:16:31,636] INFO  {DAGScheduler} Parents of final stage: List()
[16:16:31,638] INFO  {DAGScheduler} Missing parents: List()
[16:16:31,639] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[16:16:31,644] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:16:31,646] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:16:31,647] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:46165 (size: 10.0 KB, free: 1127.7 MB)
[16:16:31,647] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:16:31,647] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[16:16:31,647] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:16:31,653] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:16:31,653] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:16:31,663] INFO  {BlockManager} Found block rdd_2_0 locally
[16:16:31,676] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:16:31,677] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:16:31,679] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[16:16:31,679] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:16:31,679] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.029 s
[16:16:31,680] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.045448 s
[16:16:31,701] INFO  {CodeGenerator} Code generated in 14.332386 ms
[16:16:31,873] INFO  {ContextCleaner} Cleaned accumulator 3
[16:16:31,873] INFO  {ContextCleaner} Cleaned accumulator 4
[16:16:31,887] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:46165 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:16:31,893] INFO  {ContextCleaner} Cleaned accumulator 49
[16:16:31,893] INFO  {ContextCleaner} Cleaned accumulator 50
[16:16:31,894] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:46165 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:16:31,960] INFO  {CodeGenerator} Code generated in 49.337149 ms
[16:16:31,975] INFO  {SparkContext} Starting job: show at Main.scala:51
[16:16:31,976] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[16:16:31,977] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[16:16:31,977] INFO  {DAGScheduler} Parents of final stage: List()
[16:16:31,977] INFO  {DAGScheduler} Missing parents: List()
[16:16:31,978] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[16:16:31,982] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:16:31,984] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:16:31,984] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:46165 (size: 11.7 KB, free: 1127.7 MB)
[16:16:31,985] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:16:31,985] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[16:16:31,986] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:16:31,988] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:16:31,988] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:16:31,998] INFO  {BlockManager} Found block rdd_2_0 locally
[16:16:32,010] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:16:32,011] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:16:32,013] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on localhost (1/1)
[16:16:32,013] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:16:32,014] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.027 s
[16:16:32,014] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.038595 s
[16:16:32,029] INFO  {CodeGenerator} Code generated in 12.282786 ms
[16:16:32,119] INFO  {CodeGenerator} Code generated in 39.475487 ms
[16:16:32,130] INFO  {SparkContext} Starting job: show at Main.scala:61
[16:16:32,131] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[16:16:32,131] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[16:16:32,131] INFO  {DAGScheduler} Parents of final stage: List()
[16:16:32,131] INFO  {DAGScheduler} Missing parents: List()
[16:16:32,132] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[16:16:32,136] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:16:32,138] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1127.5 MB)
[16:16:32,140] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:46165 (size: 13.2 KB, free: 1127.7 MB)
[16:16:32,141] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:16:32,141] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[16:16:32,141] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:16:32,143] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:16:32,144] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:16:32,151] INFO  {BlockManager} Found block rdd_2_0 locally
[16:16:32,161] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:16:32,162] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:16:32,163] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 21 ms on localhost (1/1)
[16:16:32,163] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:16:32,163] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.022 s
[16:16:32,164] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.033869 s
[16:16:32,180] INFO  {CodeGenerator} Code generated in 14.468532 ms
[16:16:32,312] INFO  {CodeGenerator} Code generated in 61.6882 ms
[16:16:32,328] INFO  {SparkContext} Starting job: show at Main.scala:77
[16:16:32,329] INFO  {DAGScheduler} Got job 4 (show at Main.scala:77) with 1 output partitions
[16:16:32,329] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:77)
[16:16:32,329] INFO  {DAGScheduler} Parents of final stage: List()
[16:16:32,330] INFO  {DAGScheduler} Missing parents: List()
[16:16:32,330] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77), which has no missing parents
[16:16:32,335] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:16:32,338] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:16:32,338] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:46165 (size: 15.0 KB, free: 1127.6 MB)
[16:16:32,339] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:16:32,339] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:77)
[16:16:32,339] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:16:32,341] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:16:32,342] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:16:32,349] INFO  {BlockManager} Found block rdd_2_0 locally
[16:16:32,362] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:16:32,364] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4107 bytes result sent to driver
[16:16:32,366] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 26 ms on localhost (1/1)
[16:16:32,366] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:16:32,367] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:77) finished in 0.027 s
[16:16:32,367] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:77, took 0.039190 s
[16:16:32,384] INFO  {CodeGenerator} Code generated in 14.792096 ms
[16:16:32,529] INFO  {CodeGenerator} Code generated in 67.961374 ms
[16:16:32,542] INFO  {SparkContext} Starting job: show at Main.scala:86
[16:16:32,543] INFO  {DAGScheduler} Got job 5 (show at Main.scala:86) with 1 output partitions
[16:16:32,543] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:86)
[16:16:32,543] INFO  {DAGScheduler} Parents of final stage: List()
[16:16:32,543] INFO  {DAGScheduler} Missing parents: List()
[16:16:32,545] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86), which has no missing parents
[16:16:32,549] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[16:16:32,551] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:16:32,552] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:46165 (size: 16.4 KB, free: 1127.6 MB)
[16:16:32,552] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:16:32,553] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:86)
[16:16:32,553] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:16:32,554] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:16:32,555] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:16:32,561] INFO  {BlockManager} Found block rdd_2_0 locally
[16:16:32,574] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:16:32,575] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4083 bytes result sent to driver
[16:16:32,576] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 23 ms on localhost (1/1)
[16:16:32,576] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:16:32,577] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:86) finished in 0.024 s
[16:16:32,578] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:86, took 0.036377 s
[16:16:32,602] INFO  {CodeGenerator} Code generated in 20.827191 ms
[16:16:32,968] INFO  {CodeGenerator} Code generated in 8.136946 ms
[16:16:32,981] INFO  {CodeGenerator} Code generated in 4.603619 ms
[16:16:32,985] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:16:32,989] INFO  {ServerConnector} Stopped ServerConnector@41051c8d{HTTP/1.1}{0.0.0.0:4040}
[16:16:32,990] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:16:32,991] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:16:32,991] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:16:32,991] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:16:32,991] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:16:32,991] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:16:32,991] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:16:32,991] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:16:32,992] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:16:32,992] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:16:32,992] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:16:32,992] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:16:32,992] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:16:32,992] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:16:32,992] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:16:32,992] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:16:32,993] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:16:32,993] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:16:32,993] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:16:32,993] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:16:32,993] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:16:32,993] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:16:32,994] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:16:32,994] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:16:32,995] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:16:33,005] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:16:33,011] INFO  {MemoryStore} MemoryStore cleared
[16:16:33,011] INFO  {BlockManager} BlockManager stopped
[16:16:33,013] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:16:33,016] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:16:33,017] INFO  {SparkContext} Successfully stopped SparkContext
[16:16:33,018] INFO  {ShutdownHookManager} Shutdown hook called
[16:16:33,018] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-0e0338ea-f25a-410d-bdd6-830207a68872
[16:18:13,421] INFO  {SparkContext} Running Spark version 2.0.1
[16:18:13,647] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:18:13,749] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:18:13,750] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:18:13,823] INFO  {SecurityManager} Changing view acls to: victor
[16:18:13,823] INFO  {SecurityManager} Changing modify acls to: victor
[16:18:13,824] INFO  {SecurityManager} Changing view acls groups to: 
[16:18:13,824] INFO  {SecurityManager} Changing modify acls groups to: 
[16:18:13,825] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:18:14,149] INFO  {Utils} Successfully started service 'sparkDriver' on port 36571.
[16:18:14,165] INFO  {SparkEnv} Registering MapOutputTracker
[16:18:14,179] INFO  {SparkEnv} Registering BlockManagerMaster
[16:18:14,191] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-80bab5f4-1d16-44ea-8a39-32b96114a89b
[16:18:14,204] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:18:14,253] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:18:14,322] INFO  {log} Logging initialized @1487ms
[16:18:14,440] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:18:14,455] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:18:14,455] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:18:14,455] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:18:14,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:18:14,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:18:14,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:18:14,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:18:14,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:18:14,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:18:14,457] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:18:14,457] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:18:14,457] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:18:14,457] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:18:14,457] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:18:14,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:18:14,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:18:14,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:18:14,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:18:14,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:18:14,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:18:14,464] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:18:14,465] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:18:14,465] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:18:14,466] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:18:14,472] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:18:14,472] INFO  {Server} Started @1639ms
[16:18:14,472] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:18:14,474] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:18:14,550] INFO  {Executor} Starting executor ID driver on host localhost
[16:18:14,572] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34427.
[16:18:14,573] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:34427
[16:18:14,575] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 34427)
[16:18:14,578] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:34427 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 34427)
[16:18:14,581] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 34427)
[16:18:14,704] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:18:14,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:18:14,759] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:18:14,760] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:18:14,760] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:18:14,762] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:18:14,775] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:18:16,554] INFO  {FileSourceStrategy} Pruning directories with: 
[16:18:16,557] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:18:16,561] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:18:16,562] INFO  {FileSourceStrategy} Pushed Filters: 
[16:18:16,667] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:18:16,710] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:18:16,711] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:34427 (size: 14.6 KB, free: 1128.9 MB)
[16:18:16,717] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:18:16,720] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:18:17,156] INFO  {CodeGenerator} Code generated in 187.338188 ms
[16:18:17,347] INFO  {CodeGenerator} Code generated in 25.787567 ms
[16:18:17,395] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:18:17,411] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:18:17,412] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:18:17,412] INFO  {DAGScheduler} Parents of final stage: List()
[16:18:17,416] INFO  {DAGScheduler} Missing parents: List()
[16:18:17,420] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:18:17,489] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:18:17,491] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:18:17,492] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:34427 (size: 8.4 KB, free: 1128.9 MB)
[16:18:17,493] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:18:17,497] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:18:17,499] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:18:17,536] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:18:17,545] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:18:17,601] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:18:17,612] INFO  {CodeGenerator} Code generated in 8.469579 ms
[16:18:17,734] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:18:17,735] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:34427 (size: 1239.2 KB, free: 1127.7 MB)
[16:18:17,745] INFO  {CodeGenerator} Code generated in 3.864955 ms
[16:18:17,770] INFO  {CodeGenerator} Code generated in 18.885847 ms
[16:18:17,789] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:18:17,795] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:18:17,802] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 283 ms on localhost (1/1)
[16:18:17,804] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:18:17,808] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.300 s
[16:18:17,815] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.420146 s
[16:18:17,851] INFO  {CodeGenerator} Code generated in 21.269397 ms
[16:18:17,941] INFO  {CodeGenerator} Code generated in 28.040394 ms
[16:18:17,952] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:18:17,954] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:18:17,954] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:18:17,954] INFO  {DAGScheduler} Parents of final stage: List()
[16:18:17,956] INFO  {DAGScheduler} Missing parents: List()
[16:18:17,957] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:18:17,963] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:18:17,965] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:18:17,965] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:34427 (size: 10.0 KB, free: 1127.7 MB)
[16:18:17,966] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:18:17,966] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:18:17,966] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:18:17,972] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:18:17,973] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:18:17,986] INFO  {BlockManager} Found block rdd_2_0 locally
[16:18:18,000] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:18:18,002] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:18:18,004] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on localhost (1/1)
[16:18:18,004] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:18:18,005] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.035 s
[16:18:18,006] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.053440 s
[16:18:18,033] INFO  {CodeGenerator} Code generated in 19.013978 ms
[16:18:18,241] INFO  {ContextCleaner} Cleaned accumulator 3
[16:18:18,241] INFO  {ContextCleaner} Cleaned accumulator 4
[16:18:18,261] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:34427 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:18:18,264] INFO  {ContextCleaner} Cleaned accumulator 49
[16:18:18,265] INFO  {ContextCleaner} Cleaned accumulator 50
[16:18:18,265] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:34427 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:18:18,321] INFO  {CodeGenerator} Code generated in 49.65397 ms
[16:18:18,339] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:18:18,340] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:18:18,341] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:18:18,341] INFO  {DAGScheduler} Parents of final stage: List()
[16:18:18,342] INFO  {DAGScheduler} Missing parents: List()
[16:18:18,342] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:18:18,347] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:18:18,350] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:18:18,350] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:34427 (size: 11.7 KB, free: 1127.7 MB)
[16:18:18,351] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:18:18,351] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:18:18,351] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:18:18,354] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:18:18,354] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:18:18,363] INFO  {BlockManager} Found block rdd_2_0 locally
[16:18:18,375] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:18:18,376] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:18:18,378] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 26 ms on localhost (1/1)
[16:18:18,379] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:18:18,380] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.027 s
[16:18:18,381] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.041850 s
[16:18:18,404] INFO  {CodeGenerator} Code generated in 19.080405 ms
[16:18:18,551] INFO  {CodeGenerator} Code generated in 62.462073 ms
[16:18:18,565] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:18:18,566] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:18:18,566] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:18:18,566] INFO  {DAGScheduler} Parents of final stage: List()
[16:18:18,566] INFO  {DAGScheduler} Missing parents: List()
[16:18:18,567] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:18:18,571] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:18:18,573] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:18:18,574] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:34427 (size: 13.3 KB, free: 1127.7 MB)
[16:18:18,574] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:18:18,575] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:18:18,575] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:18:18,577] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:18:18,577] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:18:18,588] INFO  {BlockManager} Found block rdd_2_0 locally
[16:18:18,598] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:18:18,599] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:18:18,601] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on localhost (1/1)
[16:18:18,601] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:18:18,601] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.026 s
[16:18:18,602] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.036533 s
[16:18:18,621] INFO  {CodeGenerator} Code generated in 16.717485 ms
[16:18:18,774] INFO  {CodeGenerator} Code generated in 63.899264 ms
[16:18:18,788] INFO  {SparkContext} Starting job: show at Main.scala:78
[16:18:18,803] INFO  {DAGScheduler} Got job 4 (show at Main.scala:78) with 1 output partitions
[16:18:18,803] INFO  {DAGScheduler} Final stage: ResultStage 4 (show at Main.scala:78)
[16:18:18,803] INFO  {DAGScheduler} Parents of final stage: List()
[16:18:18,804] INFO  {DAGScheduler} Missing parents: List()
[16:18:18,804] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:78), which has no missing parents
[16:18:18,808] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[16:18:18,810] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:18:18,810] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:34427 (size: 15.1 KB, free: 1127.6 MB)
[16:18:18,811] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:18:18,811] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at Main.scala:78)
[16:18:18,811] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:18:18,813] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:18:18,813] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:18:18,819] INFO  {BlockManager} Found block rdd_2_0 locally
[16:18:18,830] WARN  {Executor} 1 block locks were not released by TID = 4:
[rdd_2_0]
[16:18:18,832] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 4020 bytes result sent to driver
[16:18:18,836] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 23 ms on localhost (1/1)
[16:18:18,836] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:18:18,837] INFO  {DAGScheduler} ResultStage 4 (show at Main.scala:78) finished in 0.024 s
[16:18:18,838] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:78, took 0.035731 s
[16:18:18,862] INFO  {CodeGenerator} Code generated in 19.772648 ms
[16:18:19,018] INFO  {CodeGenerator} Code generated in 68.499064 ms
[16:18:19,030] INFO  {SparkContext} Starting job: show at Main.scala:87
[16:18:19,031] INFO  {DAGScheduler} Got job 5 (show at Main.scala:87) with 1 output partitions
[16:18:19,031] INFO  {DAGScheduler} Final stage: ResultStage 5 (show at Main.scala:87)
[16:18:19,031] INFO  {DAGScheduler} Parents of final stage: List()
[16:18:19,032] INFO  {DAGScheduler} Missing parents: List()
[16:18:19,033] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:87), which has no missing parents
[16:18:19,037] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[16:18:19,039] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[16:18:19,040] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:34427 (size: 16.4 KB, free: 1127.6 MB)
[16:18:19,041] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:18:19,041] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at Main.scala:87)
[16:18:19,041] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:18:19,043] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:18:19,043] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:18:19,051] INFO  {BlockManager} Found block rdd_2_0 locally
[16:18:19,064] WARN  {Executor} 1 block locks were not released by TID = 5:
[rdd_2_0]
[16:18:19,065] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 4083 bytes result sent to driver
[16:18:19,066] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 24 ms on localhost (1/1)
[16:18:19,066] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:18:19,067] INFO  {DAGScheduler} ResultStage 5 (show at Main.scala:87) finished in 0.024 s
[16:18:19,068] INFO  {DAGScheduler} Job 5 finished: show at Main.scala:87, took 0.037374 s
[16:18:19,090] INFO  {CodeGenerator} Code generated in 19.181558 ms
[16:18:19,416] INFO  {CodeGenerator} Code generated in 13.038351 ms
[16:18:19,424] INFO  {SparkContext} Starting job: first at LinearRegression.scala:163
[16:18:19,425] INFO  {DAGScheduler} Got job 6 (first at LinearRegression.scala:163) with 1 output partitions
[16:18:19,425] INFO  {DAGScheduler} Final stage: ResultStage 6 (first at LinearRegression.scala:163)
[16:18:19,425] INFO  {DAGScheduler} Parents of final stage: List()
[16:18:19,426] INFO  {DAGScheduler} Missing parents: List()
[16:18:19,426] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[23] at first at LinearRegression.scala:163), which has no missing parents
[16:18:19,429] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.2 KB, free 1127.3 MB)
[16:18:19,430] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1127.3 MB)
[16:18:19,431] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:34427 (size: 9.7 KB, free: 1127.6 MB)
[16:18:19,431] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:18:19,432] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at first at LinearRegression.scala:163)
[16:18:19,432] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:18:19,433] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:18:19,434] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:18:19,437] INFO  {BlockManager} Found block rdd_2_0 locally
[16:18:19,441] WARN  {Executor} 1 block locks were not released by TID = 6:
[rdd_2_0]
[16:18:19,441] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1844 bytes result sent to driver
[16:18:19,443] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 10 ms on localhost (1/1)
[16:18:19,443] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:18:19,443] INFO  {DAGScheduler} ResultStage 6 (first at LinearRegression.scala:163) finished in 0.011 s
[16:18:19,443] INFO  {DAGScheduler} Job 6 finished: first at LinearRegression.scala:163, took 0.019134 s
[16:18:19,451] INFO  {CodeGenerator} Code generated in 6.402656 ms
[16:18:19,617] INFO  {CodeGenerator} Code generated in 27.533389 ms
[16:18:19,679] INFO  {SparkContext} Starting job: treeAggregate at WeightedLeastSquares.scala:81
[16:18:19,680] INFO  {DAGScheduler} Got job 7 (treeAggregate at WeightedLeastSquares.scala:81) with 1 output partitions
[16:18:19,680] INFO  {DAGScheduler} Final stage: ResultStage 7 (treeAggregate at WeightedLeastSquares.scala:81)
[16:18:19,680] INFO  {DAGScheduler} Parents of final stage: List()
[16:18:19,681] INFO  {DAGScheduler} Missing parents: List()
[16:18:19,681] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[29] at treeAggregate at WeightedLeastSquares.scala:81), which has no missing parents
[16:18:19,685] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 42.1 KB, free 1127.2 MB)
[16:18:19,687] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.2 MB)
[16:18:19,688] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:34427 (size: 14.4 KB, free: 1127.6 MB)
[16:18:19,689] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:18:19,689] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[29] at treeAggregate at WeightedLeastSquares.scala:81)
[16:18:19,689] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:18:19,692] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5966 bytes)
[16:18:19,693] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:18:19,700] INFO  {BlockManager} Found block rdd_2_0 locally
[16:18:19,714] INFO  {CodeGenerator} Code generated in 8.147556 ms
[16:18:19,739] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
[16:18:19,739] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[16:18:19,913] INFO  {ContextCleaner} Cleaned accumulator 95
[16:18:19,913] INFO  {ContextCleaner} Cleaned accumulator 96
[16:18:19,914] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:34427 in memory (size: 11.7 KB, free: 1127.6 MB)
[16:18:19,915] INFO  {ContextCleaner} Cleaned accumulator 141
[16:18:19,915] INFO  {ContextCleaner} Cleaned accumulator 142
[16:18:19,916] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:34427 in memory (size: 9.7 KB, free: 1127.6 MB)
[16:18:19,918] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:34427 in memory (size: 16.4 KB, free: 1127.6 MB)
[16:18:19,919] INFO  {ContextCleaner} Cleaned accumulator 279
[16:18:19,919] INFO  {ContextCleaner} Cleaned accumulator 280
[16:18:19,920] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:34427 in memory (size: 13.3 KB, free: 1127.6 MB)
[16:18:19,921] INFO  {ContextCleaner} Cleaned accumulator 187
[16:18:19,921] INFO  {ContextCleaner} Cleaned accumulator 188
[16:18:19,922] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:34427 in memory (size: 15.1 KB, free: 1127.7 MB)
[16:18:19,922] INFO  {ContextCleaner} Cleaned accumulator 233
[16:18:19,923] INFO  {ContextCleaner} Cleaned accumulator 234
[16:18:20,273] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 2430 bytes result sent to driver
[16:18:20,274] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 584 ms on localhost (1/1)
[16:18:20,274] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:18:20,275] INFO  {DAGScheduler} ResultStage 7 (treeAggregate at WeightedLeastSquares.scala:81) finished in 0.585 s
[16:18:20,275] INFO  {DAGScheduler} Job 7 finished: treeAggregate at WeightedLeastSquares.scala:81, took 0.596594 s
[16:18:20,278] INFO  {WeightedLeastSquares} Number of instances: 6724.
[16:18:20,304] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
[16:18:20,304] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[16:18:20,632] INFO  {CodeGenerator} Code generated in 17.991029 ms
[16:18:20,667] INFO  {SparkContext} Starting job: aggregate at RegressionMetrics.scala:57
[16:18:20,668] INFO  {DAGScheduler} Got job 8 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
[16:18:20,669] INFO  {DAGScheduler} Final stage: ResultStage 8 (aggregate at RegressionMetrics.scala:57)
[16:18:20,669] INFO  {DAGScheduler} Parents of final stage: List()
[16:18:20,669] INFO  {DAGScheduler} Missing parents: List()
[16:18:20,670] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[35] at map at RegressionMetrics.scala:55), which has no missing parents
[16:18:20,673] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 41.1 KB, free 1127.5 MB)
[16:18:20,679] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1127.5 MB)
[16:18:20,679] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:34427 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:18:20,680] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:34427 (size: 14.5 KB, free: 1127.7 MB)
[16:18:20,680] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:18:20,680] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at map at RegressionMetrics.scala:55)
[16:18:20,680] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:18:20,682] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5962 bytes)
[16:18:20,682] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:18:20,689] INFO  {BlockManager} Found block rdd_2_0 locally
[16:18:20,700] INFO  {CodeGenerator} Code generated in 6.94541 ms
[16:18:21,006] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 2208 bytes result sent to driver
[16:18:21,008] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 326 ms on localhost (1/1)
[16:18:21,008] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:18:21,008] INFO  {DAGScheduler} ResultStage 8 (aggregate at RegressionMetrics.scala:57) finished in 0.327 s
[16:18:21,009] INFO  {DAGScheduler} Job 8 finished: aggregate at RegressionMetrics.scala:57, took 0.340937 s
[16:18:21,027] INFO  {SparkContext} Starting job: sum at RegressionMetrics.scala:71
[16:18:21,028] INFO  {DAGScheduler} Got job 9 (sum at RegressionMetrics.scala:71) with 1 output partitions
[16:18:21,028] INFO  {DAGScheduler} Final stage: ResultStage 9 (sum at RegressionMetrics.scala:71)
[16:18:21,028] INFO  {DAGScheduler} Parents of final stage: List()
[16:18:21,029] INFO  {DAGScheduler} Missing parents: List()
[16:18:21,029] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[36] at map at RegressionMetrics.scala:69), which has no missing parents
[16:18:21,032] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 40.7 KB, free 1127.5 MB)
[16:18:21,034] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.4 MB)
[16:18:21,035] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:34427 (size: 14.4 KB, free: 1127.6 MB)
[16:18:21,036] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:18:21,036] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at map at RegressionMetrics.scala:69)
[16:18:21,036] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:18:21,038] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[16:18:21,038] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:18:21,044] INFO  {BlockManager} Found block rdd_2_0 locally
[16:18:21,122] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 192.168.0.103:34427 in memory (size: 14.5 KB, free: 1127.7 MB)
[16:18:21,275] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 1859 bytes result sent to driver
[16:18:21,276] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 239 ms on localhost (1/1)
[16:18:21,276] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:18:21,277] INFO  {DAGScheduler} ResultStage 9 (sum at RegressionMetrics.scala:71) finished in 0.239 s
[16:18:21,278] INFO  {DAGScheduler} Job 9 finished: sum at RegressionMetrics.scala:71, took 0.250299 s
[16:18:21,362] INFO  {CodeGenerator} Code generated in 8.490344 ms
[16:18:21,373] INFO  {CodeGenerator} Code generated in 7.757072 ms
[16:18:21,402] INFO  {SparkContext} Starting job: count at LinearRegression.scala:643
[16:18:21,405] INFO  {DAGScheduler} Registering RDD 39 (count at LinearRegression.scala:643)
[16:18:21,407] INFO  {DAGScheduler} Got job 10 (count at LinearRegression.scala:643) with 1 output partitions
[16:18:21,407] INFO  {DAGScheduler} Final stage: ResultStage 11 (count at LinearRegression.scala:643)
[16:18:21,407] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 10)
[16:18:21,407] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 10)
[16:18:21,408] INFO  {DAGScheduler} Submitting ShuffleMapStage 10 (MapPartitionsRDD[39] at count at LinearRegression.scala:643), which has no missing parents
[16:18:21,414] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 14.0 KB, free 1127.5 MB)
[16:18:21,415] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1127.5 MB)
[16:18:21,416] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:34427 (size: 6.8 KB, free: 1127.7 MB)
[16:18:21,416] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[16:18:21,418] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[39] at count at LinearRegression.scala:643)
[16:18:21,418] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[16:18:21,420] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5979 bytes)
[16:18:21,421] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[16:18:21,425] INFO  {BlockManager} Found block rdd_2_0 locally
[16:18:21,438] INFO  {CodeGenerator} Code generated in 12.416413 ms
[16:18:21,474] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 2411 bytes result sent to driver
[16:18:21,476] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 58 ms on localhost (1/1)
[16:18:21,476] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[16:18:21,477] INFO  {DAGScheduler} ShuffleMapStage 10 (count at LinearRegression.scala:643) finished in 0.059 s
[16:18:21,479] INFO  {DAGScheduler} looking for newly runnable stages
[16:18:21,479] INFO  {DAGScheduler} running: Set()
[16:18:21,480] INFO  {DAGScheduler} waiting: Set(ResultStage 11)
[16:18:21,480] INFO  {DAGScheduler} failed: Set()
[16:18:21,481] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[42] at count at LinearRegression.scala:643), which has no missing parents
[16:18:21,485] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 7.0 KB, free 1127.5 MB)
[16:18:21,486] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1127.5 MB)
[16:18:21,487] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:34427 (size: 3.7 KB, free: 1127.7 MB)
[16:18:21,487] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[16:18:21,487] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[42] at count at LinearRegression.scala:643)
[16:18:21,487] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[16:18:21,490] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, ANY, 5318 bytes)
[16:18:21,490] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[16:18:21,502] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:18:21,504] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[16:18:21,517] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 1960 bytes result sent to driver
[16:18:21,518] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 30 ms on localhost (1/1)
[16:18:21,518] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[16:18:21,518] INFO  {DAGScheduler} ResultStage 11 (count at LinearRegression.scala:643) finished in 0.030 s
[16:18:21,519] INFO  {DAGScheduler} Job 10 finished: count at LinearRegression.scala:643, took 0.116171 s
[16:18:21,527] INFO  {CodeGenerator} Code generated in 5.467613 ms
[16:18:21,668] INFO  {CodeGenerator} Code generated in 7.853999 ms
[16:18:21,680] INFO  {CodeGenerator} Code generated in 4.718615 ms
[16:18:21,684] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:18:21,688] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:18:21,690] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:18:21,690] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:18:21,690] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:18:21,690] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:18:21,690] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:18:21,690] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:18:21,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:18:21,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:18:21,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:18:21,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:18:21,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:18:21,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:18:21,691] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:18:21,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:18:21,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:18:21,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:18:21,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:18:21,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:18:21,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:18:21,692] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:18:21,693] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:18:21,693] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:18:21,693] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:18:21,693] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:18:21,695] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:18:21,706] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:18:21,716] INFO  {MemoryStore} MemoryStore cleared
[16:18:21,717] INFO  {BlockManager} BlockManager stopped
[16:18:21,718] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:18:21,721] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:18:21,723] INFO  {SparkContext} Successfully stopped SparkContext
[16:18:21,723] INFO  {ShutdownHookManager} Shutdown hook called
[16:18:21,731] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-dbb01f0e-2f82-418c-a765-d92aef46001e
[16:25:28,292] INFO  {SparkContext} Running Spark version 2.0.1
[16:25:28,519] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:25:28,614] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:25:28,615] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:25:28,691] INFO  {SecurityManager} Changing view acls to: victor
[16:25:28,692] INFO  {SecurityManager} Changing modify acls to: victor
[16:25:28,692] INFO  {SecurityManager} Changing view acls groups to: 
[16:25:28,693] INFO  {SecurityManager} Changing modify acls groups to: 
[16:25:28,693] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:25:29,034] INFO  {Utils} Successfully started service 'sparkDriver' on port 42361.
[16:25:29,049] INFO  {SparkEnv} Registering MapOutputTracker
[16:25:29,064] INFO  {SparkEnv} Registering BlockManagerMaster
[16:25:29,076] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-a2f82b53-10e2-41f7-88f8-d55dca3b6be5
[16:25:29,089] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:25:29,140] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:25:29,208] INFO  {log} Logging initialized @1482ms
[16:25:29,306] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:25:29,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:25:29,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:25:29,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:25:29,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:25:29,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:25:29,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:25:29,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:25:29,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:25:29,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:25:29,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:25:29,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:25:29,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:25:29,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:25:29,324] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:25:29,324] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:25:29,324] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:25:29,325] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:25:29,325] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:25:29,325] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:25:29,325] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:25:29,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:25:29,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:25:29,332] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:25:29,332] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:25:29,338] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:25:29,338] INFO  {Server} Started @1613ms
[16:25:29,339] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:25:29,341] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:25:29,414] INFO  {Executor} Starting executor ID driver on host localhost
[16:25:29,435] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40701.
[16:25:29,435] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:40701
[16:25:29,437] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 40701)
[16:25:29,440] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:40701 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 40701)
[16:25:29,442] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 40701)
[16:25:29,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:25:29,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:25:29,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:25:29,599] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:25:29,599] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:25:29,601] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:25:29,613] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:25:31,466] INFO  {FileSourceStrategy} Pruning directories with: 
[16:25:31,469] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:25:31,474] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:25:31,474] INFO  {FileSourceStrategy} Pushed Filters: 
[16:25:31,579] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:25:31,622] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:25:31,623] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:40701 (size: 14.6 KB, free: 1128.9 MB)
[16:25:31,629] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:25:31,632] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:25:32,066] INFO  {CodeGenerator} Code generated in 186.923985 ms
[16:25:32,257] INFO  {CodeGenerator} Code generated in 26.713857 ms
[16:25:32,304] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:25:32,319] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:25:32,319] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:25:32,319] INFO  {DAGScheduler} Parents of final stage: List()
[16:25:32,323] INFO  {DAGScheduler} Missing parents: List()
[16:25:32,327] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:25:32,384] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:25:32,386] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:25:32,387] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:40701 (size: 8.4 KB, free: 1128.9 MB)
[16:25:32,388] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:25:32,391] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:25:32,393] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:25:32,430] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:25:32,439] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:25:32,482] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:25:32,494] INFO  {CodeGenerator} Code generated in 8.872169 ms
[16:25:32,632] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:25:32,633] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:40701 (size: 1239.2 KB, free: 1127.7 MB)
[16:25:32,645] INFO  {CodeGenerator} Code generated in 4.047752 ms
[16:25:32,672] INFO  {CodeGenerator} Code generated in 20.209069 ms
[16:25:32,692] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:25:32,699] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:25:32,712] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 297 ms on localhost (1/1)
[16:25:32,714] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:25:32,717] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.315 s
[16:25:32,723] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.419234 s
[16:25:32,757] INFO  {CodeGenerator} Code generated in 16.94124 ms
[16:25:32,849] INFO  {CodeGenerator} Code generated in 28.40706 ms
[16:25:32,860] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:25:32,861] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:25:32,861] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:25:32,861] INFO  {DAGScheduler} Parents of final stage: List()
[16:25:32,863] INFO  {DAGScheduler} Missing parents: List()
[16:25:32,864] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:25:32,868] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:25:32,869] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:25:32,870] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:40701 (size: 10.0 KB, free: 1127.7 MB)
[16:25:32,871] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:25:32,871] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:25:32,871] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:25:32,876] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:25:32,876] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:25:32,885] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:32,899] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:25:32,900] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:25:32,902] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[16:25:32,902] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:25:32,902] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.029 s
[16:25:32,903] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.042240 s
[16:25:32,925] INFO  {CodeGenerator} Code generated in 14.787536 ms
[16:25:33,126] INFO  {ContextCleaner} Cleaned accumulator 3
[16:25:33,126] INFO  {ContextCleaner} Cleaned accumulator 4
[16:25:33,144] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:40701 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:25:33,147] INFO  {ContextCleaner} Cleaned accumulator 49
[16:25:33,148] INFO  {ContextCleaner} Cleaned accumulator 50
[16:25:33,148] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:40701 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:25:33,171] INFO  {CodeGenerator} Code generated in 45.107542 ms
[16:25:33,181] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:25:33,182] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:25:33,183] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:25:33,183] INFO  {DAGScheduler} Parents of final stage: List()
[16:25:33,184] INFO  {DAGScheduler} Missing parents: List()
[16:25:33,184] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:25:33,189] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:25:33,191] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:25:33,191] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:40701 (size: 11.7 KB, free: 1127.7 MB)
[16:25:33,192] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:25:33,192] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:25:33,192] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:25:33,194] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:25:33,195] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:25:33,202] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:33,213] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:25:33,214] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4090 bytes result sent to driver
[16:25:33,218] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 24 ms on localhost (1/1)
[16:25:33,218] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:25:33,218] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.025 s
[16:25:33,219] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.037615 s
[16:25:33,246] INFO  {CodeGenerator} Code generated in 22.53663 ms
[16:25:33,368] INFO  {CodeGenerator} Code generated in 51.070443 ms
[16:25:33,379] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:25:33,380] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:25:33,381] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:25:33,381] INFO  {DAGScheduler} Parents of final stage: List()
[16:25:33,381] INFO  {DAGScheduler} Missing parents: List()
[16:25:33,382] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:25:33,385] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:25:33,387] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:25:33,388] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:40701 (size: 13.3 KB, free: 1127.7 MB)
[16:25:33,389] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:25:33,389] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:25:33,389] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:25:33,391] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:25:33,392] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:25:33,401] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:33,412] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:25:33,413] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4099 bytes result sent to driver
[16:25:33,415] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on localhost (1/1)
[16:25:33,415] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:25:33,416] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.026 s
[16:25:33,416] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.036591 s
[16:25:33,434] INFO  {CodeGenerator} Code generated in 15.377091 ms
[16:25:33,545] INFO  {CodeGenerator} Code generated in 14.547822 ms
[16:25:33,569] INFO  {CodeGenerator} Code generated in 18.363737 ms
[16:25:33,599] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:25:33,602] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:25:33,602] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:25:33,602] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:25:33,603] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:25:33,603] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:25:33,604] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:25:33,610] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:25:33,612] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:25:33,612] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:40701 (size: 10.1 KB, free: 1127.6 MB)
[16:25:33,613] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:25:33,614] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:25:33,614] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:25:33,617] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:25:33,617] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:25:33,624] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:33,877] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:25:33,880] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 265 ms on localhost (1/1)
[16:25:33,880] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:25:33,881] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.266 s
[16:25:33,882] INFO  {DAGScheduler} looking for newly runnable stages
[16:25:33,882] INFO  {DAGScheduler} running: Set()
[16:25:33,883] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:25:33,883] INFO  {DAGScheduler} failed: Set()
[16:25:33,885] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:25:33,890] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:25:33,892] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:25:33,892] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:40701 (size: 3.9 KB, free: 1127.6 MB)
[16:25:33,893] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:25:33,893] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:25:33,893] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:25:33,897] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:25:33,897] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:25:33,914] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:25:33,916] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 7 ms
[16:25:33,934] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:25:33,936] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 40 ms on localhost (1/1)
[16:25:33,936] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:25:33,936] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.042 s
[16:25:33,937] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.337727 s
[16:25:33,947] INFO  {CodeGenerator} Code generated in 6.053866 ms
[16:25:33,988] INFO  {CodeGenerator} Code generated in 8.572809 ms
[16:25:34,010] INFO  {CodeGenerator} Code generated in 17.828021 ms
[16:25:34,026] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:25:34,027] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:25:34,027] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:25:34,027] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:25:34,027] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:25:34,027] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:25:34,029] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:25:34,032] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:25:34,034] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:25:34,034] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:40701 (size: 10.1 KB, free: 1127.6 MB)
[16:25:34,035] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:25:34,035] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:25:34,035] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:25:34,037] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:25:34,037] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:25:34,042] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:34,132] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:40701 in memory (size: 11.7 KB, free: 1127.6 MB)
[16:25:34,132] INFO  {ContextCleaner} Cleaned accumulator 141
[16:25:34,133] INFO  {ContextCleaner} Cleaned accumulator 142
[16:25:34,134] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:40701 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:25:34,136] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:40701 in memory (size: 3.9 KB, free: 1127.7 MB)
[16:25:34,136] INFO  {ContextCleaner} Cleaned accumulator 288
[16:25:34,137] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:40701 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 187
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 188
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 189
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 190
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 191
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 192
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 193
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 194
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 195
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 196
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 197
[16:25:34,138] INFO  {ContextCleaner} Cleaned accumulator 198
[16:25:34,139] INFO  {ContextCleaner} Cleaned accumulator 199
[16:25:34,145] INFO  {ContextCleaner} Cleaned shuffle 0
[16:25:34,173] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:25:34,174] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 138 ms on localhost (1/1)
[16:25:34,174] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:25:34,175] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.138 s
[16:25:34,175] INFO  {DAGScheduler} looking for newly runnable stages
[16:25:34,175] INFO  {DAGScheduler} running: Set()
[16:25:34,175] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:25:34,175] INFO  {DAGScheduler} failed: Set()
[16:25:34,175] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:25:34,177] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:25:34,178] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:25:34,179] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:40701 (size: 3.9 KB, free: 1127.7 MB)
[16:25:34,179] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:25:34,180] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:25:34,180] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:25:34,181] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:25:34,182] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:25:34,184] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:25:34,184] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:25:34,188] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:25:34,189] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (1/1)
[16:25:34,189] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:25:34,189] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.009 s
[16:25:34,189] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.163264 s
[16:25:34,292] INFO  {CodeGenerator} Code generated in 46.530336 ms
[16:25:34,301] INFO  {SparkContext} Starting job: show at Main.scala:80
[16:25:34,302] INFO  {DAGScheduler} Got job 6 (show at Main.scala:80) with 1 output partitions
[16:25:34,302] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:80)
[16:25:34,302] INFO  {DAGScheduler} Parents of final stage: List()
[16:25:34,303] INFO  {DAGScheduler} Missing parents: List()
[16:25:34,303] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:80), which has no missing parents
[16:25:34,306] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:25:34,308] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:25:34,309] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:40701 (size: 15.0 KB, free: 1127.6 MB)
[16:25:34,310] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:25:34,310] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:80)
[16:25:34,310] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:25:34,312] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:25:34,313] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:25:34,319] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:34,327] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:25:34,328] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:25:34,329] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 18 ms on localhost (1/1)
[16:25:34,329] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:25:34,329] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:80) finished in 0.019 s
[16:25:34,330] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:80, took 0.028208 s
[16:25:34,345] INFO  {CodeGenerator} Code generated in 13.197952 ms
[16:25:34,454] INFO  {CodeGenerator} Code generated in 53.141611 ms
[16:25:34,462] INFO  {SparkContext} Starting job: show at Main.scala:89
[16:25:34,463] INFO  {DAGScheduler} Got job 7 (show at Main.scala:89) with 1 output partitions
[16:25:34,463] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:89)
[16:25:34,463] INFO  {DAGScheduler} Parents of final stage: List()
[16:25:34,464] INFO  {DAGScheduler} Missing parents: List()
[16:25:34,464] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:89), which has no missing parents
[16:25:34,467] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:25:34,471] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:25:34,472] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:40701 (size: 16.4 KB, free: 1127.6 MB)
[16:25:34,472] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:25:34,473] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:89)
[16:25:34,473] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:25:34,475] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:25:34,475] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:25:34,479] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:34,486] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:25:34,487] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:25:34,488] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 15 ms on localhost (1/1)
[16:25:34,488] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:25:34,489] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:89) finished in 0.015 s
[16:25:34,489] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:89, took 0.026997 s
[16:25:34,506] INFO  {CodeGenerator} Code generated in 14.62188 ms
[16:25:34,633] INFO  {CodeGenerator} Code generated in 14.480362 ms
[16:25:34,639] INFO  {SparkContext} Starting job: first at LinearRegression.scala:163
[16:25:34,640] INFO  {DAGScheduler} Got job 8 (first at LinearRegression.scala:163) with 1 output partitions
[16:25:34,640] INFO  {DAGScheduler} Final stage: ResultStage 10 (first at LinearRegression.scala:163)
[16:25:34,640] INFO  {DAGScheduler} Parents of final stage: List()
[16:25:34,641] INFO  {DAGScheduler} Missing parents: List()
[16:25:34,641] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163), which has no missing parents
[16:25:34,643] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 24.2 KB, free 1127.3 MB)
[16:25:34,645] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1127.3 MB)
[16:25:34,645] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:40701 (size: 9.7 KB, free: 1127.6 MB)
[16:25:34,646] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[16:25:34,646] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163)
[16:25:34,646] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[16:25:34,648] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:25:34,648] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[16:25:34,651] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:34,655] WARN  {Executor} 1 block locks were not released by TID = 10:
[rdd_2_0]
[16:25:34,656] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 1844 bytes result sent to driver
[16:25:34,656] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 9 ms on localhost (1/1)
[16:25:34,657] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[16:25:34,657] INFO  {DAGScheduler} ResultStage 10 (first at LinearRegression.scala:163) finished in 0.010 s
[16:25:34,657] INFO  {DAGScheduler} Job 8 finished: first at LinearRegression.scala:163, took 0.017674 s
[16:25:34,664] INFO  {CodeGenerator} Code generated in 5.139735 ms
[16:25:34,758] INFO  {CodeGenerator} Code generated in 26.11532 ms
[16:25:34,811] INFO  {SparkContext} Starting job: treeAggregate at WeightedLeastSquares.scala:81
[16:25:34,812] INFO  {DAGScheduler} Got job 9 (treeAggregate at WeightedLeastSquares.scala:81) with 1 output partitions
[16:25:34,812] INFO  {DAGScheduler} Final stage: ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81)
[16:25:34,812] INFO  {DAGScheduler} Parents of final stage: List()
[16:25:34,812] INFO  {DAGScheduler} Missing parents: List()
[16:25:34,813] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81), which has no missing parents
[16:25:34,815] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 42.1 KB, free 1127.3 MB)
[16:25:34,816] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.3 MB)
[16:25:34,817] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:40701 (size: 14.4 KB, free: 1127.6 MB)
[16:25:34,817] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[16:25:34,817] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81)
[16:25:34,817] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[16:25:34,819] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5967 bytes)
[16:25:34,819] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[16:25:34,824] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:34,835] INFO  {CodeGenerator} Code generated in 5.965089 ms
[16:25:34,844] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
[16:25:34,845] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[16:25:34,960] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 192.168.0.103:40701 in memory (size: 16.4 KB, free: 1127.6 MB)
[16:25:34,961] INFO  {ContextCleaner} Cleaned accumulator 481
[16:25:34,961] INFO  {ContextCleaner} Cleaned accumulator 482
[16:25:34,962] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 192.168.0.103:40701 in memory (size: 9.7 KB, free: 1127.6 MB)
[16:25:34,964] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:40701 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:25:34,965] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:40701 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:25:34,966] INFO  {ContextCleaner} Cleaned accumulator 389
[16:25:34,966] INFO  {ContextCleaner} Cleaned accumulator 390
[16:25:34,967] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 192.168.0.103:40701 in memory (size: 15.0 KB, free: 1127.7 MB)
[16:25:34,967] INFO  {ContextCleaner} Cleaned accumulator 435
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 436
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 289
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 290
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 291
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 292
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 293
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 294
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 295
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 296
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 297
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 298
[16:25:34,968] INFO  {ContextCleaner} Cleaned accumulator 299
[16:25:34,969] INFO  {ContextCleaner} Cleaned accumulator 300
[16:25:34,969] INFO  {ContextCleaner} Cleaned shuffle 1
[16:25:35,151] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 2430 bytes result sent to driver
[16:25:35,153] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 335 ms on localhost (1/1)
[16:25:35,153] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[16:25:35,153] INFO  {DAGScheduler} ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81) finished in 0.335 s
[16:25:35,153] INFO  {DAGScheduler} Job 9 finished: treeAggregate at WeightedLeastSquares.scala:81, took 0.342541 s
[16:25:35,156] INFO  {WeightedLeastSquares} Number of instances: 6724.
[16:25:35,164] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
[16:25:35,165] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[16:25:35,476] INFO  {CodeGenerator} Code generated in 18.649079 ms
[16:25:35,509] INFO  {SparkContext} Starting job: aggregate at RegressionMetrics.scala:57
[16:25:35,510] INFO  {DAGScheduler} Got job 10 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
[16:25:35,510] INFO  {DAGScheduler} Final stage: ResultStage 12 (aggregate at RegressionMetrics.scala:57)
[16:25:35,510] INFO  {DAGScheduler} Parents of final stage: List()
[16:25:35,510] INFO  {DAGScheduler} Missing parents: List()
[16:25:35,511] INFO  {DAGScheduler} Submitting ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55), which has no missing parents
[16:25:35,513] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 41.1 KB, free 1127.5 MB)
[16:25:35,515] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1127.4 MB)
[16:25:35,516] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 192.168.0.103:40701 (size: 14.5 KB, free: 1127.6 MB)
[16:25:35,516] INFO  {SparkContext} Created broadcast 13 from broadcast at DAGScheduler.scala:1012
[16:25:35,516] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55)
[16:25:35,516] INFO  {TaskSchedulerImpl} Adding task set 12.0 with 1 tasks
[16:25:35,518] INFO  {TaskSetManager} Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5963 bytes)
[16:25:35,518] INFO  {Executor} Running task 0.0 in stage 12.0 (TID 12)
[16:25:35,523] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:35,535] INFO  {CodeGenerator} Code generated in 7.063988 ms
[16:25:35,699] INFO  {BlockManagerInfo} Removed broadcast_12_piece0 on 192.168.0.103:40701 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:25:35,821] INFO  {Executor} Finished task 0.0 in stage 12.0 (TID 12). 2281 bytes result sent to driver
[16:25:35,822] INFO  {TaskSetManager} Finished task 0.0 in stage 12.0 (TID 12) in 305 ms on localhost (1/1)
[16:25:35,823] INFO  {TaskSchedulerImpl} Removed TaskSet 12.0, whose tasks have all completed, from pool 
[16:25:35,823] INFO  {DAGScheduler} ResultStage 12 (aggregate at RegressionMetrics.scala:57) finished in 0.306 s
[16:25:35,823] INFO  {DAGScheduler} Job 10 finished: aggregate at RegressionMetrics.scala:57, took 0.314502 s
[16:25:35,838] INFO  {SparkContext} Starting job: sum at RegressionMetrics.scala:71
[16:25:35,839] INFO  {DAGScheduler} Got job 11 (sum at RegressionMetrics.scala:71) with 1 output partitions
[16:25:35,839] INFO  {DAGScheduler} Final stage: ResultStage 13 (sum at RegressionMetrics.scala:71)
[16:25:35,839] INFO  {DAGScheduler} Parents of final stage: List()
[16:25:35,840] INFO  {DAGScheduler} Missing parents: List()
[16:25:35,840] INFO  {DAGScheduler} Submitting ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69), which has no missing parents
[16:25:35,842] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 40.7 KB, free 1127.5 MB)
[16:25:35,844] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.4 MB)
[16:25:35,844] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 192.168.0.103:40701 (size: 14.4 KB, free: 1127.6 MB)
[16:25:35,845] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[16:25:35,845] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69)
[16:25:35,845] INFO  {TaskSchedulerImpl} Adding task set 13.0 with 1 tasks
[16:25:35,846] INFO  {TaskSetManager} Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[16:25:35,846] INFO  {Executor} Running task 0.0 in stage 13.0 (TID 13)
[16:25:35,850] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:36,014] INFO  {BlockManagerInfo} Removed broadcast_13_piece0 on 192.168.0.103:40701 in memory (size: 14.5 KB, free: 1127.7 MB)
[16:25:36,033] INFO  {Executor} Finished task 0.0 in stage 13.0 (TID 13). 1859 bytes result sent to driver
[16:25:36,034] INFO  {TaskSetManager} Finished task 0.0 in stage 13.0 (TID 13) in 188 ms on localhost (1/1)
[16:25:36,034] INFO  {TaskSchedulerImpl} Removed TaskSet 13.0, whose tasks have all completed, from pool 
[16:25:36,034] INFO  {DAGScheduler} ResultStage 13 (sum at RegressionMetrics.scala:71) finished in 0.189 s
[16:25:36,035] INFO  {DAGScheduler} Job 11 finished: sum at RegressionMetrics.scala:71, took 0.196432 s
[16:25:36,082] INFO  {CodeGenerator} Code generated in 6.987908 ms
[16:25:36,090] INFO  {CodeGenerator} Code generated in 5.073868 ms
[16:25:36,101] INFO  {SparkContext} Starting job: count at LinearRegression.scala:643
[16:25:36,102] INFO  {DAGScheduler} Registering RDD 51 (count at LinearRegression.scala:643)
[16:25:36,102] INFO  {DAGScheduler} Got job 12 (count at LinearRegression.scala:643) with 1 output partitions
[16:25:36,102] INFO  {DAGScheduler} Final stage: ResultStage 15 (count at LinearRegression.scala:643)
[16:25:36,102] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 14)
[16:25:36,102] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 14)
[16:25:36,103] INFO  {DAGScheduler} Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643), which has no missing parents
[16:25:36,105] INFO  {MemoryStore} Block broadcast_15 stored as values in memory (estimated size 14.0 KB, free 1127.5 MB)
[16:25:36,106] INFO  {MemoryStore} Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1127.5 MB)
[16:25:36,107] INFO  {BlockManagerInfo} Added broadcast_15_piece0 in memory on 192.168.0.103:40701 (size: 6.8 KB, free: 1127.7 MB)
[16:25:36,107] INFO  {SparkContext} Created broadcast 15 from broadcast at DAGScheduler.scala:1012
[16:25:36,108] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643)
[16:25:36,108] INFO  {TaskSchedulerImpl} Adding task set 14.0 with 1 tasks
[16:25:36,109] INFO  {TaskSetManager} Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5979 bytes)
[16:25:36,109] INFO  {Executor} Running task 0.0 in stage 14.0 (TID 14)
[16:25:36,112] INFO  {BlockManager} Found block rdd_2_0 locally
[16:25:36,125] INFO  {CodeGenerator} Code generated in 12.451372 ms
[16:25:36,132] INFO  {Executor} Finished task 0.0 in stage 14.0 (TID 14). 2411 bytes result sent to driver
[16:25:36,133] INFO  {TaskSetManager} Finished task 0.0 in stage 14.0 (TID 14) in 25 ms on localhost (1/1)
[16:25:36,133] INFO  {TaskSchedulerImpl} Removed TaskSet 14.0, whose tasks have all completed, from pool 
[16:25:36,134] INFO  {DAGScheduler} ShuffleMapStage 14 (count at LinearRegression.scala:643) finished in 0.026 s
[16:25:36,134] INFO  {DAGScheduler} looking for newly runnable stages
[16:25:36,134] INFO  {DAGScheduler} running: Set()
[16:25:36,134] INFO  {DAGScheduler} waiting: Set(ResultStage 15)
[16:25:36,134] INFO  {DAGScheduler} failed: Set()
[16:25:36,135] INFO  {DAGScheduler} Submitting ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643), which has no missing parents
[16:25:36,137] INFO  {MemoryStore} Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 1127.5 MB)
[16:25:36,139] INFO  {MemoryStore} Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1127.5 MB)
[16:25:36,140] INFO  {BlockManagerInfo} Added broadcast_16_piece0 in memory on 192.168.0.103:40701 (size: 3.7 KB, free: 1127.7 MB)
[16:25:36,140] INFO  {SparkContext} Created broadcast 16 from broadcast at DAGScheduler.scala:1012
[16:25:36,141] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643)
[16:25:36,141] INFO  {TaskSchedulerImpl} Adding task set 15.0 with 1 tasks
[16:25:36,142] INFO  {TaskSetManager} Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, ANY, 5318 bytes)
[16:25:36,142] INFO  {Executor} Running task 0.0 in stage 15.0 (TID 15)
[16:25:36,145] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:25:36,145] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:25:36,148] INFO  {Executor} Finished task 0.0 in stage 15.0 (TID 15). 1873 bytes result sent to driver
[16:25:36,150] INFO  {TaskSetManager} Finished task 0.0 in stage 15.0 (TID 15) in 8 ms on localhost (1/1)
[16:25:36,150] INFO  {TaskSchedulerImpl} Removed TaskSet 15.0, whose tasks have all completed, from pool 
[16:25:36,150] INFO  {DAGScheduler} ResultStage 15 (count at LinearRegression.scala:643) finished in 0.009 s
[16:25:36,151] INFO  {DAGScheduler} Job 12 finished: count at LinearRegression.scala:643, took 0.049425 s
[16:25:36,160] INFO  {CodeGenerator} Code generated in 7.16025 ms
[16:25:36,341] INFO  {CodeGenerator} Code generated in 10.862209 ms
[16:25:36,357] INFO  {CodeGenerator} Code generated in 6.607314 ms
[16:25:36,363] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:25:36,367] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:25:36,369] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:25:36,369] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:25:36,369] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:25:36,369] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:25:36,369] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:25:36,369] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:25:36,369] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:25:36,369] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:25:36,370] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:25:36,370] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:25:36,370] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:25:36,370] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:25:36,370] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:25:36,370] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:25:36,370] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:25:36,370] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:25:36,370] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:25:36,371] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:25:36,371] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:25:36,371] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:25:36,371] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:25:36,371] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:25:36,371] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:25:36,372] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:25:36,373] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:25:36,386] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:25:36,399] INFO  {MemoryStore} MemoryStore cleared
[16:25:36,399] INFO  {BlockManager} BlockManager stopped
[16:25:36,402] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:25:36,407] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:25:36,418] INFO  {SparkContext} Successfully stopped SparkContext
[16:25:36,419] INFO  {ShutdownHookManager} Shutdown hook called
[16:25:36,420] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-7c518121-756a-49b1-aa33-877b353527e3
[16:26:26,419] INFO  {SparkContext} Running Spark version 2.0.1
[16:26:26,636] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:26:26,738] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:26:26,739] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:26:26,824] INFO  {SecurityManager} Changing view acls to: victor
[16:26:26,825] INFO  {SecurityManager} Changing modify acls to: victor
[16:26:26,826] INFO  {SecurityManager} Changing view acls groups to: 
[16:26:26,826] INFO  {SecurityManager} Changing modify acls groups to: 
[16:26:26,827] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:26:27,170] INFO  {Utils} Successfully started service 'sparkDriver' on port 39467.
[16:26:27,188] INFO  {SparkEnv} Registering MapOutputTracker
[16:26:27,204] INFO  {SparkEnv} Registering BlockManagerMaster
[16:26:27,217] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-6d3f76ad-ec68-4657-b19d-a7cf141a8d3b
[16:26:27,231] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:26:27,286] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:26:27,353] INFO  {log} Logging initialized @1514ms
[16:26:27,450] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:26:27,465] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:26:27,465] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:26:27,465] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:26:27,465] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:26:27,465] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:26:27,466] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:26:27,466] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:26:27,466] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:26:27,466] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:26:27,466] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:26:27,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:26:27,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:26:27,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:26:27,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:26:27,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:26:27,467] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:26:27,468] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:26:27,468] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:26:27,468] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:26:27,468] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:26:27,474] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:26:27,474] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:26:27,475] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:26:27,475] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:26:27,482] INFO  {ServerConnector} Started ServerConnector@6dfd7cb6{HTTP/1.1}{0.0.0.0:4040}
[16:26:27,482] INFO  {Server} Started @1644ms
[16:26:27,482] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:26:27,485] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:26:27,574] INFO  {Executor} Starting executor ID driver on host localhost
[16:26:27,599] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36689.
[16:26:27,600] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:36689
[16:26:27,602] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 36689)
[16:26:27,605] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:36689 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 36689)
[16:26:27,608] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 36689)
[16:26:27,731] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:26:27,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:26:27,788] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:26:27,789] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:26:27,789] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:26:27,791] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:26:27,803] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:26:29,515] INFO  {FileSourceStrategy} Pruning directories with: 
[16:26:29,518] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:26:29,523] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:26:29,524] INFO  {FileSourceStrategy} Pushed Filters: 
[16:26:29,629] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:26:29,673] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:26:29,674] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:36689 (size: 14.6 KB, free: 1128.9 MB)
[16:26:29,680] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:26:29,683] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:26:30,109] INFO  {CodeGenerator} Code generated in 188.840451 ms
[16:26:30,303] INFO  {CodeGenerator} Code generated in 26.701253 ms
[16:26:30,349] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:26:30,366] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:26:30,366] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:26:30,366] INFO  {DAGScheduler} Parents of final stage: List()
[16:26:30,370] INFO  {DAGScheduler} Missing parents: List()
[16:26:30,376] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:26:30,442] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:26:30,445] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:26:30,446] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:36689 (size: 8.5 KB, free: 1128.9 MB)
[16:26:30,447] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:26:30,450] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:26:30,451] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:26:30,491] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:26:30,499] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:26:30,546] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:26:30,557] INFO  {CodeGenerator} Code generated in 8.759641 ms
[16:26:30,699] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:26:30,700] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:36689 (size: 1239.2 KB, free: 1127.7 MB)
[16:26:30,710] INFO  {CodeGenerator} Code generated in 4.236732 ms
[16:26:30,735] INFO  {CodeGenerator} Code generated in 18.867715 ms
[16:26:30,755] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:26:30,761] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:26:30,772] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 300 ms on localhost (1/1)
[16:26:30,773] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:26:30,777] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.317 s
[16:26:30,781] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.432036 s
[16:26:30,812] INFO  {CodeGenerator} Code generated in 16.545241 ms
[16:26:30,903] INFO  {CodeGenerator} Code generated in 28.555262 ms
[16:26:30,915] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:26:30,916] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:26:30,916] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:26:30,916] INFO  {DAGScheduler} Parents of final stage: List()
[16:26:30,918] INFO  {DAGScheduler} Missing parents: List()
[16:26:30,918] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:26:30,923] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:26:30,925] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:26:30,925] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:36689 (size: 10.0 KB, free: 1127.7 MB)
[16:26:30,926] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:26:30,926] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:26:30,926] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:26:30,931] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:26:30,931] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:26:30,941] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:30,954] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:26:30,955] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:26:30,957] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[16:26:30,958] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:26:30,958] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.029 s
[16:26:30,959] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.043460 s
[16:26:30,980] INFO  {CodeGenerator} Code generated in 14.592878 ms
[16:26:31,165] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:36689 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:26:31,173] INFO  {ContextCleaner} Cleaned accumulator 3
[16:26:31,173] INFO  {ContextCleaner} Cleaned accumulator 4
[16:26:31,174] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:36689 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:26:31,175] INFO  {ContextCleaner} Cleaned accumulator 49
[16:26:31,175] INFO  {ContextCleaner} Cleaned accumulator 50
[16:26:31,237] INFO  {CodeGenerator} Code generated in 56.354389 ms
[16:26:31,253] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:26:31,254] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:26:31,255] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:26:31,255] INFO  {DAGScheduler} Parents of final stage: List()
[16:26:31,256] INFO  {DAGScheduler} Missing parents: List()
[16:26:31,256] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:26:31,261] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:26:31,263] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:26:31,264] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:36689 (size: 11.7 KB, free: 1127.7 MB)
[16:26:31,265] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:26:31,265] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:26:31,265] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:26:31,267] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:26:31,268] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:26:31,275] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:31,285] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:26:31,286] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:26:31,287] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 21 ms on localhost (1/1)
[16:26:31,287] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:26:31,288] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.021 s
[16:26:31,288] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.034767 s
[16:26:31,312] INFO  {CodeGenerator} Code generated in 20.118474 ms
[16:26:31,432] INFO  {CodeGenerator} Code generated in 44.980191 ms
[16:26:31,444] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:26:31,446] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:26:31,446] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:26:31,446] INFO  {DAGScheduler} Parents of final stage: List()
[16:26:31,446] INFO  {DAGScheduler} Missing parents: List()
[16:26:31,447] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:26:31,450] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:26:31,452] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:26:31,453] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:36689 (size: 13.3 KB, free: 1127.7 MB)
[16:26:31,453] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:26:31,453] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:26:31,454] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:26:31,455] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:26:31,456] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:26:31,463] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:31,472] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:26:31,473] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:26:31,475] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on localhost (1/1)
[16:26:31,475] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:26:31,475] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.021 s
[16:26:31,476] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.030732 s
[16:26:31,495] INFO  {CodeGenerator} Code generated in 17.072246 ms
[16:26:31,614] INFO  {CodeGenerator} Code generated in 13.2993 ms
[16:26:31,636] INFO  {CodeGenerator} Code generated in 17.528143 ms
[16:26:31,666] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:26:31,669] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:26:31,669] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:26:31,670] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:26:31,670] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:26:31,670] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:26:31,671] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:26:31,677] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:26:31,678] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:26:31,679] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:36689 (size: 10.1 KB, free: 1127.6 MB)
[16:26:31,679] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:26:31,681] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:26:31,681] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:26:31,684] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:26:31,684] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:26:31,690] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:31,959] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:26:31,962] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 280 ms on localhost (1/1)
[16:26:31,962] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:26:31,964] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.282 s
[16:26:31,965] INFO  {DAGScheduler} looking for newly runnable stages
[16:26:31,966] INFO  {DAGScheduler} running: Set()
[16:26:31,966] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:26:31,967] INFO  {DAGScheduler} failed: Set()
[16:26:31,969] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:26:31,974] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:26:31,977] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:26:31,978] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:36689 (size: 3.9 KB, free: 1127.6 MB)
[16:26:31,979] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:26:31,979] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:26:31,979] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:26:31,983] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:26:31,984] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:26:31,996] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:26:31,998] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 6 ms
[16:26:32,011] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:26:32,012] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 30 ms on localhost (1/1)
[16:26:32,012] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:26:32,012] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.031 s
[16:26:32,012] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.346497 s
[16:26:32,021] INFO  {CodeGenerator} Code generated in 5.694243 ms
[16:26:32,063] INFO  {CodeGenerator} Code generated in 8.952485 ms
[16:26:32,085] INFO  {CodeGenerator} Code generated in 17.888315 ms
[16:26:32,102] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:26:32,103] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:26:32,103] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:26:32,103] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:26:32,103] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:26:32,103] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:26:32,104] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:26:32,108] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:26:32,111] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:26:32,111] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:36689 (size: 10.2 KB, free: 1127.6 MB)
[16:26:32,112] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:26:32,112] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:26:32,112] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:26:32,114] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:26:32,114] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:26:32,118] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:32,211] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:36689 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:26:32,212] INFO  {ContextCleaner} Cleaned accumulator 288
[16:26:32,213] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:36689 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:26:32,214] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:36689 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:26:32,215] INFO  {ContextCleaner} Cleaned accumulator 187
[16:26:32,215] INFO  {ContextCleaner} Cleaned accumulator 188
[16:26:32,215] INFO  {ContextCleaner} Cleaned accumulator 189
[16:26:32,215] INFO  {ContextCleaner} Cleaned accumulator 190
[16:26:32,215] INFO  {ContextCleaner} Cleaned accumulator 191
[16:26:32,216] INFO  {ContextCleaner} Cleaned accumulator 192
[16:26:32,216] INFO  {ContextCleaner} Cleaned accumulator 193
[16:26:32,216] INFO  {ContextCleaner} Cleaned accumulator 194
[16:26:32,216] INFO  {ContextCleaner} Cleaned accumulator 195
[16:26:32,216] INFO  {ContextCleaner} Cleaned accumulator 196
[16:26:32,216] INFO  {ContextCleaner} Cleaned accumulator 197
[16:26:32,216] INFO  {ContextCleaner} Cleaned accumulator 198
[16:26:32,216] INFO  {ContextCleaner} Cleaned accumulator 199
[16:26:32,223] INFO  {ContextCleaner} Cleaned shuffle 0
[16:26:32,223] INFO  {ContextCleaner} Cleaned accumulator 95
[16:26:32,223] INFO  {ContextCleaner} Cleaned accumulator 96
[16:26:32,224] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:36689 in memory (size: 11.7 KB, free: 1127.7 MB)
[16:26:32,225] INFO  {ContextCleaner} Cleaned accumulator 141
[16:26:32,225] INFO  {ContextCleaner} Cleaned accumulator 142
[16:26:32,250] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:26:32,251] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 138 ms on localhost (1/1)
[16:26:32,251] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:26:32,254] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.138 s
[16:26:32,254] INFO  {DAGScheduler} looking for newly runnable stages
[16:26:32,254] INFO  {DAGScheduler} running: Set()
[16:26:32,254] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:26:32,254] INFO  {DAGScheduler} failed: Set()
[16:26:32,255] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:26:32,256] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:26:32,257] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:26:32,258] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:36689 (size: 3.9 KB, free: 1127.7 MB)
[16:26:32,259] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:26:32,259] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:26:32,259] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:26:32,261] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:26:32,261] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:26:32,265] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:26:32,265] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:26:32,269] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:26:32,269] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 9 ms on localhost (1/1)
[16:26:32,269] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:26:32,270] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.011 s
[16:26:32,270] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.167984 s
[16:26:32,390] INFO  {CodeGenerator} Code generated in 61.875682 ms
[16:26:32,402] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:26:32,403] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:26:32,404] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:26:32,404] INFO  {DAGScheduler} Parents of final stage: List()
[16:26:32,404] INFO  {DAGScheduler} Missing parents: List()
[16:26:32,405] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:26:32,408] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:26:32,410] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:26:32,410] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:36689 (size: 15.0 KB, free: 1127.6 MB)
[16:26:32,411] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:26:32,411] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:26:32,411] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:26:32,414] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:26:32,414] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:26:32,420] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:32,426] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:26:32,427] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:26:32,428] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 16 ms on localhost (1/1)
[16:26:32,428] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:26:32,429] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.017 s
[16:26:32,429] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.026284 s
[16:26:32,446] INFO  {CodeGenerator} Code generated in 13.787892 ms
[16:26:32,546] INFO  {CodeGenerator} Code generated in 46.544192 ms
[16:26:32,555] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:26:32,556] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:26:32,556] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:26:32,557] INFO  {DAGScheduler} Parents of final stage: List()
[16:26:32,557] INFO  {DAGScheduler} Missing parents: List()
[16:26:32,557] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:26:32,561] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:26:32,563] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:26:32,563] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:36689 (size: 16.4 KB, free: 1127.6 MB)
[16:26:32,564] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:26:32,564] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:26:32,564] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:26:32,565] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:26:32,566] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:26:32,570] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:32,578] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:26:32,579] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:26:32,580] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 15 ms on localhost (1/1)
[16:26:32,580] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:26:32,580] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.016 s
[16:26:32,581] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.025837 s
[16:26:32,596] INFO  {CodeGenerator} Code generated in 12.913183 ms
[16:26:32,720] INFO  {CodeGenerator} Code generated in 15.338714 ms
[16:26:32,727] INFO  {SparkContext} Starting job: first at LinearRegression.scala:163
[16:26:32,728] INFO  {DAGScheduler} Got job 8 (first at LinearRegression.scala:163) with 1 output partitions
[16:26:32,728] INFO  {DAGScheduler} Final stage: ResultStage 10 (first at LinearRegression.scala:163)
[16:26:32,728] INFO  {DAGScheduler} Parents of final stage: List()
[16:26:32,728] INFO  {DAGScheduler} Missing parents: List()
[16:26:32,728] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163), which has no missing parents
[16:26:32,733] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 24.2 KB, free 1127.3 MB)
[16:26:32,734] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1127.3 MB)
[16:26:32,735] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:36689 (size: 9.7 KB, free: 1127.6 MB)
[16:26:32,735] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[16:26:32,735] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163)
[16:26:32,736] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[16:26:32,737] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:26:32,737] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[16:26:32,740] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:32,743] WARN  {Executor} 1 block locks were not released by TID = 10:
[rdd_2_0]
[16:26:32,744] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 1844 bytes result sent to driver
[16:26:32,745] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 9 ms on localhost (1/1)
[16:26:32,745] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[16:26:32,745] INFO  {DAGScheduler} ResultStage 10 (first at LinearRegression.scala:163) finished in 0.009 s
[16:26:32,746] INFO  {DAGScheduler} Job 8 finished: first at LinearRegression.scala:163, took 0.018754 s
[16:26:32,752] INFO  {CodeGenerator} Code generated in 4.880491 ms
[16:26:32,841] INFO  {CodeGenerator} Code generated in 23.975751 ms
[16:26:32,899] INFO  {SparkContext} Starting job: treeAggregate at WeightedLeastSquares.scala:81
[16:26:32,900] INFO  {DAGScheduler} Got job 9 (treeAggregate at WeightedLeastSquares.scala:81) with 1 output partitions
[16:26:32,900] INFO  {DAGScheduler} Final stage: ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81)
[16:26:32,900] INFO  {DAGScheduler} Parents of final stage: List()
[16:26:32,901] INFO  {DAGScheduler} Missing parents: List()
[16:26:32,901] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81), which has no missing parents
[16:26:32,905] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 42.1 KB, free 1127.3 MB)
[16:26:32,906] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.3 MB)
[16:26:32,907] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:36689 (size: 14.4 KB, free: 1127.6 MB)
[16:26:32,907] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[16:26:32,908] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81)
[16:26:32,908] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[16:26:32,909] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5967 bytes)
[16:26:32,910] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[16:26:32,917] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:32,928] INFO  {CodeGenerator} Code generated in 6.795186 ms
[16:26:32,937] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
[16:26:32,938] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[16:26:33,064] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 192.168.0.103:36689 in memory (size: 9.7 KB, free: 1127.6 MB)
[16:26:33,065] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:36689 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:26:33,066] INFO  {ContextCleaner} Cleaned accumulator 389
[16:26:33,066] INFO  {ContextCleaner} Cleaned accumulator 390
[16:26:33,066] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 192.168.0.103:36689 in memory (size: 15.0 KB, free: 1127.6 MB)
[16:26:33,067] INFO  {ContextCleaner} Cleaned accumulator 435
[16:26:33,067] INFO  {ContextCleaner} Cleaned accumulator 436
[16:26:33,068] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 192.168.0.103:36689 in memory (size: 16.4 KB, free: 1127.7 MB)
[16:26:33,068] INFO  {ContextCleaner} Cleaned accumulator 481
[16:26:33,068] INFO  {ContextCleaner} Cleaned accumulator 482
[16:26:33,068] INFO  {ContextCleaner} Cleaned accumulator 289
[16:26:33,068] INFO  {ContextCleaner} Cleaned accumulator 290
[16:26:33,069] INFO  {ContextCleaner} Cleaned accumulator 291
[16:26:33,069] INFO  {ContextCleaner} Cleaned accumulator 292
[16:26:33,069] INFO  {ContextCleaner} Cleaned accumulator 293
[16:26:33,069] INFO  {ContextCleaner} Cleaned accumulator 294
[16:26:33,069] INFO  {ContextCleaner} Cleaned accumulator 295
[16:26:33,069] INFO  {ContextCleaner} Cleaned accumulator 296
[16:26:33,069] INFO  {ContextCleaner} Cleaned accumulator 297
[16:26:33,069] INFO  {ContextCleaner} Cleaned accumulator 298
[16:26:33,069] INFO  {ContextCleaner} Cleaned accumulator 299
[16:26:33,069] INFO  {ContextCleaner} Cleaned accumulator 300
[16:26:33,070] INFO  {ContextCleaner} Cleaned shuffle 1
[16:26:33,070] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:36689 in memory (size: 10.2 KB, free: 1127.7 MB)
[16:26:33,262] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 2430 bytes result sent to driver
[16:26:33,263] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 355 ms on localhost (1/1)
[16:26:33,264] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[16:26:33,264] INFO  {DAGScheduler} ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81) finished in 0.356 s
[16:26:33,265] INFO  {DAGScheduler} Job 9 finished: treeAggregate at WeightedLeastSquares.scala:81, took 0.365104 s
[16:26:33,268] INFO  {WeightedLeastSquares} Number of instances: 6724.
[16:26:33,276] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
[16:26:33,276] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[16:26:33,599] INFO  {CodeGenerator} Code generated in 18.981168 ms
[16:26:33,632] INFO  {SparkContext} Starting job: aggregate at RegressionMetrics.scala:57
[16:26:33,633] INFO  {DAGScheduler} Got job 10 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
[16:26:33,633] INFO  {DAGScheduler} Final stage: ResultStage 12 (aggregate at RegressionMetrics.scala:57)
[16:26:33,633] INFO  {DAGScheduler} Parents of final stage: List()
[16:26:33,634] INFO  {DAGScheduler} Missing parents: List()
[16:26:33,634] INFO  {DAGScheduler} Submitting ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55), which has no missing parents
[16:26:33,637] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 41.1 KB, free 1127.5 MB)
[16:26:33,639] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1127.4 MB)
[16:26:33,640] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 192.168.0.103:36689 (size: 14.5 KB, free: 1127.6 MB)
[16:26:33,640] INFO  {SparkContext} Created broadcast 13 from broadcast at DAGScheduler.scala:1012
[16:26:33,641] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55)
[16:26:33,641] INFO  {TaskSchedulerImpl} Adding task set 12.0 with 1 tasks
[16:26:33,642] INFO  {TaskSetManager} Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5963 bytes)
[16:26:33,643] INFO  {Executor} Running task 0.0 in stage 12.0 (TID 12)
[16:26:33,650] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:33,661] INFO  {CodeGenerator} Code generated in 6.730152 ms
[16:26:33,850] INFO  {BlockManagerInfo} Removed broadcast_12_piece0 on 192.168.0.103:36689 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:26:33,938] INFO  {Executor} Finished task 0.0 in stage 12.0 (TID 12). 2281 bytes result sent to driver
[16:26:33,939] INFO  {TaskSetManager} Finished task 0.0 in stage 12.0 (TID 12) in 298 ms on localhost (1/1)
[16:26:33,939] INFO  {TaskSchedulerImpl} Removed TaskSet 12.0, whose tasks have all completed, from pool 
[16:26:33,940] INFO  {DAGScheduler} ResultStage 12 (aggregate at RegressionMetrics.scala:57) finished in 0.298 s
[16:26:33,941] INFO  {DAGScheduler} Job 10 finished: aggregate at RegressionMetrics.scala:57, took 0.308422 s
[16:26:33,956] INFO  {SparkContext} Starting job: sum at RegressionMetrics.scala:71
[16:26:33,957] INFO  {DAGScheduler} Got job 11 (sum at RegressionMetrics.scala:71) with 1 output partitions
[16:26:33,957] INFO  {DAGScheduler} Final stage: ResultStage 13 (sum at RegressionMetrics.scala:71)
[16:26:33,957] INFO  {DAGScheduler} Parents of final stage: List()
[16:26:33,957] INFO  {DAGScheduler} Missing parents: List()
[16:26:33,958] INFO  {DAGScheduler} Submitting ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69), which has no missing parents
[16:26:33,961] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 40.7 KB, free 1127.5 MB)
[16:26:33,963] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.4 MB)
[16:26:33,963] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 192.168.0.103:36689 (size: 14.4 KB, free: 1127.6 MB)
[16:26:33,964] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[16:26:33,964] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69)
[16:26:33,964] INFO  {TaskSchedulerImpl} Adding task set 13.0 with 1 tasks
[16:26:33,965] INFO  {TaskSetManager} Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[16:26:33,966] INFO  {Executor} Running task 0.0 in stage 13.0 (TID 13)
[16:26:33,970] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:34,164] INFO  {Executor} Finished task 0.0 in stage 13.0 (TID 13). 1786 bytes result sent to driver
[16:26:34,165] INFO  {TaskSetManager} Finished task 0.0 in stage 13.0 (TID 13) in 200 ms on localhost (1/1)
[16:26:34,165] INFO  {TaskSchedulerImpl} Removed TaskSet 13.0, whose tasks have all completed, from pool 
[16:26:34,165] INFO  {DAGScheduler} ResultStage 13 (sum at RegressionMetrics.scala:71) finished in 0.201 s
[16:26:34,166] INFO  {DAGScheduler} Job 11 finished: sum at RegressionMetrics.scala:71, took 0.209804 s
[16:26:34,194] INFO  {BlockManagerInfo} Removed broadcast_13_piece0 on 192.168.0.103:36689 in memory (size: 14.5 KB, free: 1127.7 MB)
[16:26:34,195] INFO  {BlockManagerInfo} Removed broadcast_14_piece0 on 192.168.0.103:36689 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:26:34,196] INFO  {ContextCleaner} Cleaned accumulator 663
[16:26:34,212] INFO  {CodeGenerator} Code generated in 6.350514 ms
[16:26:34,220] INFO  {CodeGenerator} Code generated in 5.511333 ms
[16:26:34,232] INFO  {SparkContext} Starting job: count at LinearRegression.scala:643
[16:26:34,233] INFO  {DAGScheduler} Registering RDD 51 (count at LinearRegression.scala:643)
[16:26:34,233] INFO  {DAGScheduler} Got job 12 (count at LinearRegression.scala:643) with 1 output partitions
[16:26:34,233] INFO  {DAGScheduler} Final stage: ResultStage 15 (count at LinearRegression.scala:643)
[16:26:34,233] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 14)
[16:26:34,233] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 14)
[16:26:34,234] INFO  {DAGScheduler} Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643), which has no missing parents
[16:26:34,237] INFO  {MemoryStore} Block broadcast_15 stored as values in memory (estimated size 14.0 KB, free 1127.5 MB)
[16:26:34,238] INFO  {MemoryStore} Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1127.5 MB)
[16:26:34,239] INFO  {BlockManagerInfo} Added broadcast_15_piece0 in memory on 192.168.0.103:36689 (size: 6.8 KB, free: 1127.7 MB)
[16:26:34,239] INFO  {SparkContext} Created broadcast 15 from broadcast at DAGScheduler.scala:1012
[16:26:34,239] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643)
[16:26:34,240] INFO  {TaskSchedulerImpl} Adding task set 14.0 with 1 tasks
[16:26:34,241] INFO  {TaskSetManager} Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5979 bytes)
[16:26:34,241] INFO  {Executor} Running task 0.0 in stage 14.0 (TID 14)
[16:26:34,244] INFO  {BlockManager} Found block rdd_2_0 locally
[16:26:34,253] INFO  {CodeGenerator} Code generated in 8.351366 ms
[16:26:34,260] INFO  {Executor} Finished task 0.0 in stage 14.0 (TID 14). 2324 bytes result sent to driver
[16:26:34,261] INFO  {TaskSetManager} Finished task 0.0 in stage 14.0 (TID 14) in 21 ms on localhost (1/1)
[16:26:34,261] INFO  {TaskSchedulerImpl} Removed TaskSet 14.0, whose tasks have all completed, from pool 
[16:26:34,261] INFO  {DAGScheduler} ShuffleMapStage 14 (count at LinearRegression.scala:643) finished in 0.021 s
[16:26:34,262] INFO  {DAGScheduler} looking for newly runnable stages
[16:26:34,262] INFO  {DAGScheduler} running: Set()
[16:26:34,262] INFO  {DAGScheduler} waiting: Set(ResultStage 15)
[16:26:34,262] INFO  {DAGScheduler} failed: Set()
[16:26:34,262] INFO  {DAGScheduler} Submitting ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643), which has no missing parents
[16:26:34,264] INFO  {MemoryStore} Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 1127.5 MB)
[16:26:34,266] INFO  {MemoryStore} Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1127.5 MB)
[16:26:34,266] INFO  {BlockManagerInfo} Added broadcast_16_piece0 in memory on 192.168.0.103:36689 (size: 3.7 KB, free: 1127.7 MB)
[16:26:34,267] INFO  {SparkContext} Created broadcast 16 from broadcast at DAGScheduler.scala:1012
[16:26:34,267] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643)
[16:26:34,267] INFO  {TaskSchedulerImpl} Adding task set 15.0 with 1 tasks
[16:26:34,269] INFO  {TaskSetManager} Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, ANY, 5318 bytes)
[16:26:34,269] INFO  {Executor} Running task 0.0 in stage 15.0 (TID 15)
[16:26:34,272] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:26:34,272] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:26:34,275] INFO  {Executor} Finished task 0.0 in stage 15.0 (TID 15). 1873 bytes result sent to driver
[16:26:34,276] INFO  {TaskSetManager} Finished task 0.0 in stage 15.0 (TID 15) in 8 ms on localhost (1/1)
[16:26:34,276] INFO  {TaskSchedulerImpl} Removed TaskSet 15.0, whose tasks have all completed, from pool 
[16:26:34,277] INFO  {DAGScheduler} ResultStage 15 (count at LinearRegression.scala:643) finished in 0.009 s
[16:26:34,277] INFO  {DAGScheduler} Job 12 finished: count at LinearRegression.scala:643, took 0.044911 s
[16:26:34,285] INFO  {CodeGenerator} Code generated in 6.579322 ms
[16:26:34,424] INFO  {CodeGenerator} Code generated in 8.913106 ms
[16:26:34,436] INFO  {CodeGenerator} Code generated in 5.59537 ms
[16:26:34,439] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:26:34,444] INFO  {ServerConnector} Stopped ServerConnector@6dfd7cb6{HTTP/1.1}{0.0.0.0:4040}
[16:26:34,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:26:34,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:26:34,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:26:34,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:26:34,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:26:34,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:26:34,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:26:34,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:26:34,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:26:34,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:26:34,447] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:26:34,447] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:26:34,447] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:26:34,447] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:26:34,447] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:26:34,447] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:26:34,447] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:26:34,447] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:26:34,447] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:26:34,447] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:26:34,448] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:26:34,448] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:26:34,448] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:26:34,448] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:26:34,449] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:26:34,459] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:26:34,468] INFO  {MemoryStore} MemoryStore cleared
[16:26:34,469] INFO  {BlockManager} BlockManager stopped
[16:26:34,471] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:26:34,475] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:26:34,477] INFO  {SparkContext} Successfully stopped SparkContext
[16:26:34,477] INFO  {ShutdownHookManager} Shutdown hook called
[16:26:34,478] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-1f9f8cdb-903e-421f-b10c-34acd6805926
[16:27:07,009] INFO  {SparkContext} Running Spark version 2.0.1
[16:27:07,215] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:27:07,303] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:27:07,304] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:27:07,376] INFO  {SecurityManager} Changing view acls to: victor
[16:27:07,377] INFO  {SecurityManager} Changing modify acls to: victor
[16:27:07,378] INFO  {SecurityManager} Changing view acls groups to: 
[16:27:07,378] INFO  {SecurityManager} Changing modify acls groups to: 
[16:27:07,379] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:27:07,753] INFO  {Utils} Successfully started service 'sparkDriver' on port 37959.
[16:27:07,768] INFO  {SparkEnv} Registering MapOutputTracker
[16:27:07,783] INFO  {SparkEnv} Registering BlockManagerMaster
[16:27:07,794] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-f0c3dd5e-c9f5-4df8-ac65-0add094035d2
[16:27:07,808] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:27:07,850] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:27:07,921] INFO  {log} Logging initialized @1496ms
[16:27:08,025] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:27:08,040] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[16:27:08,040] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[16:27:08,040] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[16:27:08,040] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[16:27:08,041] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[16:27:08,041] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[16:27:08,041] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[16:27:08,041] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[16:27:08,041] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[16:27:08,041] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[16:27:08,042] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[16:27:08,042] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[16:27:08,042] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[16:27:08,042] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[16:27:08,042] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[16:27:08,043] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[16:27:08,043] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[16:27:08,043] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[16:27:08,043] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[16:27:08,043] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[16:27:08,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[16:27:08,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[16:27:08,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[16:27:08,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[16:27:08,056] INFO  {ServerConnector} Started ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:27:08,056] INFO  {Server} Started @1633ms
[16:27:08,056] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:27:08,059] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:27:08,132] INFO  {Executor} Starting executor ID driver on host localhost
[16:27:08,154] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45041.
[16:27:08,155] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:45041
[16:27:08,157] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 45041)
[16:27:08,160] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:45041 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 45041)
[16:27:08,164] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 45041)
[16:27:08,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[16:27:08,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL,null,AVAILABLE}
[16:27:08,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/json,null,AVAILABLE}
[16:27:08,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution,null,AVAILABLE}
[16:27:08,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b11ef33{/SQL/execution/json,null,AVAILABLE}
[16:27:08,332] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@21ec5d87{/static/sql,null,AVAILABLE}
[16:27:08,345] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:27:10,074] INFO  {FileSourceStrategy} Pruning directories with: 
[16:27:10,077] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:27:10,081] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:27:10,082] INFO  {FileSourceStrategy} Pushed Filters: 
[16:27:10,193] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:27:10,238] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:27:10,249] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:45041 (size: 14.6 KB, free: 1128.9 MB)
[16:27:10,254] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:27:10,259] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:27:10,692] INFO  {CodeGenerator} Code generated in 190.76133 ms
[16:27:10,882] INFO  {CodeGenerator} Code generated in 25.888945 ms
[16:27:10,927] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:27:10,942] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:27:10,942] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:27:10,943] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:10,946] INFO  {DAGScheduler} Missing parents: List()
[16:27:10,950] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:27:11,007] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:27:11,009] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:27:11,009] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:45041 (size: 8.5 KB, free: 1128.9 MB)
[16:27:11,010] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:27:11,013] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:27:11,014] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:27:11,049] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:11,058] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:27:11,099] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:27:11,110] INFO  {CodeGenerator} Code generated in 8.269482 ms
[16:27:11,236] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:27:11,236] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:45041 (size: 1239.2 KB, free: 1127.7 MB)
[16:27:11,248] INFO  {CodeGenerator} Code generated in 3.976378 ms
[16:27:11,274] INFO  {CodeGenerator} Code generated in 19.274136 ms
[16:27:11,294] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:27:11,301] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4550 bytes result sent to driver
[16:27:11,313] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 278 ms on localhost (1/1)
[16:27:11,314] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:27:11,317] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.293 s
[16:27:11,322] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.394797 s
[16:27:11,360] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:45041 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:27:11,375] INFO  {CodeGenerator} Code generated in 21.225131 ms
[16:27:11,468] INFO  {CodeGenerator} Code generated in 28.122599 ms
[16:27:11,480] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:27:11,481] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:27:11,481] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:27:11,481] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:11,483] INFO  {DAGScheduler} Missing parents: List()
[16:27:11,483] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:27:11,487] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:27:11,489] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:27:11,489] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:45041 (size: 10.0 KB, free: 1127.7 MB)
[16:27:11,490] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:27:11,490] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:27:11,490] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:27:11,495] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:11,496] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:27:11,505] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:11,518] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:27:11,519] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:27:11,522] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.029 s
[16:27:11,523] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[16:27:11,523] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:27:11,523] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.043006 s
[16:27:11,546] INFO  {CodeGenerator} Code generated in 14.63783 ms
[16:27:11,689] INFO  {ContextCleaner} Cleaned accumulator 3
[16:27:11,689] INFO  {ContextCleaner} Cleaned accumulator 4
[16:27:11,689] INFO  {ContextCleaner} Cleaned accumulator 49
[16:27:11,689] INFO  {ContextCleaner} Cleaned accumulator 50
[16:27:11,691] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:45041 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:27:11,794] INFO  {CodeGenerator} Code generated in 37.446507 ms
[16:27:11,805] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:27:11,806] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:27:11,806] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:27:11,806] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:11,807] INFO  {DAGScheduler} Missing parents: List()
[16:27:11,808] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:27:11,813] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:27:11,815] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:27:11,815] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:45041 (size: 11.7 KB, free: 1127.7 MB)
[16:27:11,816] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:27:11,816] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:27:11,816] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:27:11,818] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:11,818] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:27:11,826] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:11,839] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:27:11,840] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:27:11,842] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on localhost (1/1)
[16:27:11,843] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:27:11,843] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.026 s
[16:27:11,844] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.038354 s
[16:27:11,867] INFO  {CodeGenerator} Code generated in 19.759735 ms
[16:27:11,988] INFO  {CodeGenerator} Code generated in 44.981871 ms
[16:27:12,001] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:27:12,002] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:27:12,002] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:27:12,002] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:12,002] INFO  {DAGScheduler} Missing parents: List()
[16:27:12,003] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:27:12,007] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:27:12,009] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:27:12,010] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:45041 (size: 13.3 KB, free: 1127.7 MB)
[16:27:12,010] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:27:12,011] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:27:12,011] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:27:12,013] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:12,013] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:27:12,020] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:12,030] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:27:12,031] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:27:12,033] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 22 ms on localhost (1/1)
[16:27:12,033] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:27:12,034] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.022 s
[16:27:12,034] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.033412 s
[16:27:12,051] INFO  {CodeGenerator} Code generated in 14.134965 ms
[16:27:12,157] INFO  {CodeGenerator} Code generated in 14.172094 ms
[16:27:12,184] INFO  {CodeGenerator} Code generated in 21.55035 ms
[16:27:12,216] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:27:12,219] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:27:12,219] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:27:12,220] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:27:12,220] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:27:12,220] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:27:12,222] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:27:12,228] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:27:12,229] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:27:12,230] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:45041 (size: 10.2 KB, free: 1127.6 MB)
[16:27:12,230] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:27:12,232] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:27:12,232] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:27:12,235] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:27:12,236] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:27:12,242] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:12,497] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:27:12,500] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 267 ms on localhost (1/1)
[16:27:12,500] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:27:12,502] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.269 s
[16:27:12,502] INFO  {DAGScheduler} looking for newly runnable stages
[16:27:12,503] INFO  {DAGScheduler} running: Set()
[16:27:12,503] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:27:12,503] INFO  {DAGScheduler} failed: Set()
[16:27:12,505] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:27:12,508] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:27:12,510] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:27:12,510] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:45041 (size: 3.9 KB, free: 1127.6 MB)
[16:27:12,511] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:27:12,511] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:27:12,511] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:27:12,515] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:27:12,515] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:27:12,528] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:27:12,530] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[16:27:12,542] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1955 bytes result sent to driver
[16:27:12,543] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 30 ms on localhost (1/1)
[16:27:12,543] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:27:12,543] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.031 s
[16:27:12,544] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.328031 s
[16:27:12,554] INFO  {CodeGenerator} Code generated in 7.765335 ms
[16:27:12,602] INFO  {CodeGenerator} Code generated in 9.788567 ms
[16:27:12,624] INFO  {CodeGenerator} Code generated in 17.335708 ms
[16:27:12,645] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:27:12,646] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:27:12,646] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:27:12,646] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:27:12,646] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:27:12,646] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:27:12,647] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:27:12,651] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:27:12,652] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:27:12,653] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:45041 (size: 10.2 KB, free: 1127.6 MB)
[16:27:12,653] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:27:12,654] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:27:12,654] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:27:12,655] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:27:12,656] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:27:12,659] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:12,784] INFO  {ContextCleaner} Cleaned accumulator 95
[16:27:12,784] INFO  {ContextCleaner} Cleaned accumulator 96
[16:27:12,786] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:45041 in memory (size: 11.7 KB, free: 1127.6 MB)
[16:27:12,787] INFO  {ContextCleaner} Cleaned accumulator 141
[16:27:12,787] INFO  {ContextCleaner} Cleaned accumulator 142
[16:27:12,787] INFO  {ContextCleaner} Cleaned accumulator 288
[16:27:12,788] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:45041 in memory (size: 10.2 KB, free: 1127.6 MB)
[16:27:12,790] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:45041 in memory (size: 3.9 KB, free: 1127.7 MB)
[16:27:12,791] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:45041 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:27:12,792] INFO  {ContextCleaner} Cleaned accumulator 187
[16:27:12,792] INFO  {ContextCleaner} Cleaned accumulator 188
[16:27:12,792] INFO  {ContextCleaner} Cleaned accumulator 189
[16:27:12,792] INFO  {ContextCleaner} Cleaned accumulator 190
[16:27:12,792] INFO  {ContextCleaner} Cleaned accumulator 191
[16:27:12,792] INFO  {ContextCleaner} Cleaned accumulator 192
[16:27:12,792] INFO  {ContextCleaner} Cleaned accumulator 193
[16:27:12,793] INFO  {ContextCleaner} Cleaned accumulator 194
[16:27:12,793] INFO  {ContextCleaner} Cleaned accumulator 195
[16:27:12,793] INFO  {ContextCleaner} Cleaned accumulator 196
[16:27:12,793] INFO  {ContextCleaner} Cleaned accumulator 197
[16:27:12,793] INFO  {ContextCleaner} Cleaned accumulator 198
[16:27:12,793] INFO  {ContextCleaner} Cleaned accumulator 199
[16:27:12,798] INFO  {ContextCleaner} Cleaned shuffle 0
[16:27:12,812] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:27:12,814] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 159 ms on localhost (1/1)
[16:27:12,814] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:27:12,814] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.160 s
[16:27:12,814] INFO  {DAGScheduler} looking for newly runnable stages
[16:27:12,815] INFO  {DAGScheduler} running: Set()
[16:27:12,815] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:27:12,815] INFO  {DAGScheduler} failed: Set()
[16:27:12,815] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:27:12,816] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:27:12,818] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:27:12,818] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:45041 (size: 3.9 KB, free: 1127.7 MB)
[16:27:12,819] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:27:12,819] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:27:12,819] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:27:12,821] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:27:12,821] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:27:12,823] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:27:12,823] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:27:12,826] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:27:12,827] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 7 ms on localhost (1/1)
[16:27:12,828] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:27:12,828] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.009 s
[16:27:12,828] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.183342 s
[16:27:12,945] INFO  {CodeGenerator} Code generated in 44.489545 ms
[16:27:12,954] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:27:12,955] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:27:12,955] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:27:12,955] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:12,956] INFO  {DAGScheduler} Missing parents: List()
[16:27:12,956] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:27:12,959] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:27:12,960] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:27:12,961] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:45041 (size: 15.1 KB, free: 1127.6 MB)
[16:27:12,961] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:27:12,962] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:27:12,962] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:27:12,964] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:12,964] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:27:12,969] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:12,975] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:27:12,975] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:27:12,976] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 14 ms on localhost (1/1)
[16:27:12,977] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:27:12,977] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.015 s
[16:27:12,977] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.022715 s
[16:27:12,991] INFO  {CodeGenerator} Code generated in 11.750087 ms
[16:27:13,095] INFO  {CodeGenerator} Code generated in 48.070254 ms
[16:27:13,103] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:27:13,104] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:27:13,104] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:27:13,104] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:13,104] INFO  {DAGScheduler} Missing parents: List()
[16:27:13,105] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:27:13,107] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:27:13,110] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:27:13,111] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:45041 (size: 16.4 KB, free: 1127.6 MB)
[16:27:13,111] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:27:13,112] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:27:13,112] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:27:13,113] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:13,114] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:27:13,117] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:13,123] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:27:13,124] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:27:13,125] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 13 ms on localhost (1/1)
[16:27:13,126] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:27:13,126] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.014 s
[16:27:13,127] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.023255 s
[16:27:13,143] INFO  {CodeGenerator} Code generated in 14.161333 ms
[16:27:13,264] INFO  {CodeGenerator} Code generated in 13.740247 ms
[16:27:13,271] INFO  {SparkContext} Starting job: first at LinearRegression.scala:163
[16:27:13,272] INFO  {DAGScheduler} Got job 8 (first at LinearRegression.scala:163) with 1 output partitions
[16:27:13,272] INFO  {DAGScheduler} Final stage: ResultStage 10 (first at LinearRegression.scala:163)
[16:27:13,272] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:13,272] INFO  {DAGScheduler} Missing parents: List()
[16:27:13,272] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163), which has no missing parents
[16:27:13,275] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 24.2 KB, free 1127.3 MB)
[16:27:13,276] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1127.3 MB)
[16:27:13,277] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:45041 (size: 9.7 KB, free: 1127.6 MB)
[16:27:13,277] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[16:27:13,277] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163)
[16:27:13,277] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[16:27:13,279] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:13,279] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[16:27:13,282] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:13,285] WARN  {Executor} 1 block locks were not released by TID = 10:
[rdd_2_0]
[16:27:13,286] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 1844 bytes result sent to driver
[16:27:13,287] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 8 ms on localhost (1/1)
[16:27:13,287] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[16:27:13,287] INFO  {DAGScheduler} ResultStage 10 (first at LinearRegression.scala:163) finished in 0.009 s
[16:27:13,288] INFO  {DAGScheduler} Job 8 finished: first at LinearRegression.scala:163, took 0.016412 s
[16:27:13,294] INFO  {CodeGenerator} Code generated in 4.791394 ms
[16:27:13,401] INFO  {CodeGenerator} Code generated in 33.618242 ms
[16:27:13,461] INFO  {SparkContext} Starting job: treeAggregate at WeightedLeastSquares.scala:81
[16:27:13,462] INFO  {DAGScheduler} Got job 9 (treeAggregate at WeightedLeastSquares.scala:81) with 1 output partitions
[16:27:13,462] INFO  {DAGScheduler} Final stage: ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81)
[16:27:13,462] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:13,463] INFO  {DAGScheduler} Missing parents: List()
[16:27:13,463] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81), which has no missing parents
[16:27:13,466] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 42.1 KB, free 1127.3 MB)
[16:27:13,468] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.3 MB)
[16:27:13,468] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:45041 (size: 14.4 KB, free: 1127.6 MB)
[16:27:13,469] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[16:27:13,469] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81)
[16:27:13,469] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[16:27:13,471] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5967 bytes)
[16:27:13,471] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[16:27:13,477] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:13,488] INFO  {CodeGenerator} Code generated in 6.314401 ms
[16:27:13,498] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
[16:27:13,498] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[16:27:13,636] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 192.168.0.103:45041 in memory (size: 16.4 KB, free: 1127.6 MB)
[16:27:13,637] INFO  {ContextCleaner} Cleaned accumulator 481
[16:27:13,637] INFO  {ContextCleaner} Cleaned accumulator 482
[16:27:13,638] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 192.168.0.103:45041 in memory (size: 9.7 KB, free: 1127.6 MB)
[16:27:13,639] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:45041 in memory (size: 10.2 KB, free: 1127.6 MB)
[16:27:13,640] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:45041 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:27:13,641] INFO  {ContextCleaner} Cleaned accumulator 389
[16:27:13,641] INFO  {ContextCleaner} Cleaned accumulator 390
[16:27:13,642] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 192.168.0.103:45041 in memory (size: 15.1 KB, free: 1127.7 MB)
[16:27:13,643] INFO  {ContextCleaner} Cleaned accumulator 435
[16:27:13,643] INFO  {ContextCleaner} Cleaned accumulator 436
[16:27:13,643] INFO  {ContextCleaner} Cleaned accumulator 289
[16:27:13,643] INFO  {ContextCleaner} Cleaned accumulator 290
[16:27:13,643] INFO  {ContextCleaner} Cleaned accumulator 291
[16:27:13,643] INFO  {ContextCleaner} Cleaned accumulator 292
[16:27:13,643] INFO  {ContextCleaner} Cleaned accumulator 293
[16:27:13,644] INFO  {ContextCleaner} Cleaned accumulator 294
[16:27:13,644] INFO  {ContextCleaner} Cleaned accumulator 295
[16:27:13,644] INFO  {ContextCleaner} Cleaned accumulator 296
[16:27:13,644] INFO  {ContextCleaner} Cleaned accumulator 297
[16:27:13,644] INFO  {ContextCleaner} Cleaned accumulator 298
[16:27:13,644] INFO  {ContextCleaner} Cleaned accumulator 299
[16:27:13,644] INFO  {ContextCleaner} Cleaned accumulator 300
[16:27:13,645] INFO  {ContextCleaner} Cleaned shuffle 1
[16:27:13,782] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 2343 bytes result sent to driver
[16:27:13,783] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 313 ms on localhost (1/1)
[16:27:13,783] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[16:27:13,784] INFO  {DAGScheduler} ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81) finished in 0.314 s
[16:27:13,785] INFO  {DAGScheduler} Job 9 finished: treeAggregate at WeightedLeastSquares.scala:81, took 0.323110 s
[16:27:13,787] INFO  {WeightedLeastSquares} Number of instances: 6724.
[16:27:13,794] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
[16:27:13,794] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[16:27:14,111] INFO  {CodeGenerator} Code generated in 17.945032 ms
[16:27:14,143] INFO  {SparkContext} Starting job: aggregate at RegressionMetrics.scala:57
[16:27:14,144] INFO  {DAGScheduler} Got job 10 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
[16:27:14,144] INFO  {DAGScheduler} Final stage: ResultStage 12 (aggregate at RegressionMetrics.scala:57)
[16:27:14,144] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:14,145] INFO  {DAGScheduler} Missing parents: List()
[16:27:14,145] INFO  {DAGScheduler} Submitting ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55), which has no missing parents
[16:27:14,147] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 41.1 KB, free 1127.5 MB)
[16:27:14,149] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1127.4 MB)
[16:27:14,149] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 192.168.0.103:45041 (size: 14.5 KB, free: 1127.6 MB)
[16:27:14,150] INFO  {SparkContext} Created broadcast 13 from broadcast at DAGScheduler.scala:1012
[16:27:14,150] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55)
[16:27:14,150] INFO  {TaskSchedulerImpl} Adding task set 12.0 with 1 tasks
[16:27:14,151] INFO  {TaskSetManager} Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5963 bytes)
[16:27:14,152] INFO  {Executor} Running task 0.0 in stage 12.0 (TID 12)
[16:27:14,157] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:14,167] INFO  {CodeGenerator} Code generated in 6.674628 ms
[16:27:14,374] INFO  {BlockManagerInfo} Removed broadcast_12_piece0 on 192.168.0.103:45041 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:27:14,449] INFO  {Executor} Finished task 0.0 in stage 12.0 (TID 12). 2281 bytes result sent to driver
[16:27:14,451] INFO  {TaskSetManager} Finished task 0.0 in stage 12.0 (TID 12) in 300 ms on localhost (1/1)
[16:27:14,451] INFO  {TaskSchedulerImpl} Removed TaskSet 12.0, whose tasks have all completed, from pool 
[16:27:14,451] INFO  {DAGScheduler} ResultStage 12 (aggregate at RegressionMetrics.scala:57) finished in 0.301 s
[16:27:14,452] INFO  {DAGScheduler} Job 10 finished: aggregate at RegressionMetrics.scala:57, took 0.308305 s
[16:27:14,463] INFO  {SparkContext} Starting job: sum at RegressionMetrics.scala:71
[16:27:14,464] INFO  {DAGScheduler} Got job 11 (sum at RegressionMetrics.scala:71) with 1 output partitions
[16:27:14,464] INFO  {DAGScheduler} Final stage: ResultStage 13 (sum at RegressionMetrics.scala:71)
[16:27:14,464] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:14,464] INFO  {DAGScheduler} Missing parents: List()
[16:27:14,465] INFO  {DAGScheduler} Submitting ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69), which has no missing parents
[16:27:14,467] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 40.7 KB, free 1127.5 MB)
[16:27:14,468] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.4 MB)
[16:27:14,468] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 192.168.0.103:45041 (size: 14.4 KB, free: 1127.6 MB)
[16:27:14,469] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[16:27:14,469] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69)
[16:27:14,469] INFO  {TaskSchedulerImpl} Adding task set 13.0 with 1 tasks
[16:27:14,470] INFO  {TaskSetManager} Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[16:27:14,470] INFO  {Executor} Running task 0.0 in stage 13.0 (TID 13)
[16:27:14,474] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:14,660] INFO  {Executor} Finished task 0.0 in stage 13.0 (TID 13). 1786 bytes result sent to driver
[16:27:14,661] INFO  {TaskSetManager} Finished task 0.0 in stage 13.0 (TID 13) in 192 ms on localhost (1/1)
[16:27:14,661] INFO  {TaskSchedulerImpl} Removed TaskSet 13.0, whose tasks have all completed, from pool 
[16:27:14,662] INFO  {DAGScheduler} ResultStage 13 (sum at RegressionMetrics.scala:71) finished in 0.193 s
[16:27:14,662] INFO  {DAGScheduler} Job 11 finished: sum at RegressionMetrics.scala:71, took 0.198756 s
[16:27:14,700] INFO  {CodeGenerator} Code generated in 6.125008 ms
[16:27:14,708] INFO  {CodeGenerator} Code generated in 5.552147 ms
[16:27:14,720] INFO  {SparkContext} Starting job: count at LinearRegression.scala:643
[16:27:14,721] INFO  {DAGScheduler} Registering RDD 51 (count at LinearRegression.scala:643)
[16:27:14,721] INFO  {DAGScheduler} Got job 12 (count at LinearRegression.scala:643) with 1 output partitions
[16:27:14,721] INFO  {DAGScheduler} Final stage: ResultStage 15 (count at LinearRegression.scala:643)
[16:27:14,721] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 14)
[16:27:14,721] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 14)
[16:27:14,722] INFO  {DAGScheduler} Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643), which has no missing parents
[16:27:14,724] INFO  {MemoryStore} Block broadcast_15 stored as values in memory (estimated size 14.0 KB, free 1127.4 MB)
[16:27:14,726] INFO  {MemoryStore} Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1127.4 MB)
[16:27:14,726] INFO  {BlockManagerInfo} Added broadcast_15_piece0 in memory on 192.168.0.103:45041 (size: 6.8 KB, free: 1127.6 MB)
[16:27:14,726] INFO  {SparkContext} Created broadcast 15 from broadcast at DAGScheduler.scala:1012
[16:27:14,727] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643)
[16:27:14,727] INFO  {TaskSchedulerImpl} Adding task set 14.0 with 1 tasks
[16:27:14,728] INFO  {TaskSetManager} Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5979 bytes)
[16:27:14,728] INFO  {Executor} Running task 0.0 in stage 14.0 (TID 14)
[16:27:14,731] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:14,739] INFO  {CodeGenerator} Code generated in 7.800695 ms
[16:27:14,745] INFO  {Executor} Finished task 0.0 in stage 14.0 (TID 14). 2324 bytes result sent to driver
[16:27:14,745] INFO  {TaskSetManager} Finished task 0.0 in stage 14.0 (TID 14) in 18 ms on localhost (1/1)
[16:27:14,746] INFO  {TaskSchedulerImpl} Removed TaskSet 14.0, whose tasks have all completed, from pool 
[16:27:14,746] INFO  {DAGScheduler} ShuffleMapStage 14 (count at LinearRegression.scala:643) finished in 0.019 s
[16:27:14,746] INFO  {DAGScheduler} looking for newly runnable stages
[16:27:14,746] INFO  {DAGScheduler} running: Set()
[16:27:14,746] INFO  {DAGScheduler} waiting: Set(ResultStage 15)
[16:27:14,746] INFO  {DAGScheduler} failed: Set()
[16:27:14,746] INFO  {DAGScheduler} Submitting ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643), which has no missing parents
[16:27:14,748] INFO  {MemoryStore} Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 1127.4 MB)
[16:27:14,755] INFO  {MemoryStore} Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1127.4 MB)
[16:27:14,755] INFO  {BlockManagerInfo} Removed broadcast_13_piece0 on 192.168.0.103:45041 in memory (size: 14.5 KB, free: 1127.7 MB)
[16:27:14,756] INFO  {BlockManagerInfo} Added broadcast_16_piece0 in memory on 192.168.0.103:45041 (size: 3.7 KB, free: 1127.7 MB)
[16:27:14,756] INFO  {SparkContext} Created broadcast 16 from broadcast at DAGScheduler.scala:1012
[16:27:14,756] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643)
[16:27:14,757] INFO  {TaskSchedulerImpl} Adding task set 15.0 with 1 tasks
[16:27:14,757] INFO  {BlockManagerInfo} Removed broadcast_14_piece0 on 192.168.0.103:45041 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:27:14,759] INFO  {ContextCleaner} Cleaned accumulator 663
[16:27:14,759] INFO  {TaskSetManager} Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, ANY, 5318 bytes)
[16:27:14,759] INFO  {Executor} Running task 0.0 in stage 15.0 (TID 15)
[16:27:14,761] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:27:14,761] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:27:14,764] INFO  {Executor} Finished task 0.0 in stage 15.0 (TID 15). 1873 bytes result sent to driver
[16:27:14,765] INFO  {TaskSetManager} Finished task 0.0 in stage 15.0 (TID 15) in 8 ms on localhost (1/1)
[16:27:14,765] INFO  {TaskSchedulerImpl} Removed TaskSet 15.0, whose tasks have all completed, from pool 
[16:27:14,765] INFO  {DAGScheduler} ResultStage 15 (count at LinearRegression.scala:643) finished in 0.008 s
[16:27:14,766] INFO  {DAGScheduler} Job 12 finished: count at LinearRegression.scala:643, took 0.045302 s
[16:27:14,773] INFO  {CodeGenerator} Code generated in 5.515305 ms
[16:27:14,933] INFO  {CodeGenerator} Code generated in 7.578715 ms
[16:27:14,943] INFO  {CodeGenerator} Code generated in 4.64677 ms
[16:27:14,948] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:27:14,953] INFO  {ServerConnector} Stopped ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:27:14,955] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[16:27:14,955] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[16:27:14,955] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[16:27:14,955] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[16:27:14,955] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[16:27:14,955] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[16:27:14,955] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[16:27:14,955] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[16:27:14,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[16:27:14,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[16:27:14,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[16:27:14,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[16:27:14,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[16:27:14,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[16:27:14,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[16:27:14,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[16:27:14,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[16:27:14,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[16:27:14,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[16:27:14,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[16:27:14,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[16:27:14,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[16:27:14,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[16:27:14,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[16:27:14,959] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:27:14,972] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:27:14,984] INFO  {MemoryStore} MemoryStore cleared
[16:27:14,984] INFO  {BlockManager} BlockManager stopped
[16:27:14,986] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:27:14,989] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:27:15,001] INFO  {SparkContext} Successfully stopped SparkContext
[16:27:15,002] INFO  {ShutdownHookManager} Shutdown hook called
[16:27:15,003] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-5d3095db-4afb-4012-93dc-ec25579fbd10
[16:27:43,276] INFO  {SparkContext} Running Spark version 2.0.1
[16:27:43,536] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:27:43,665] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:27:43,666] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:27:43,753] INFO  {SecurityManager} Changing view acls to: victor
[16:27:43,754] INFO  {SecurityManager} Changing modify acls to: victor
[16:27:43,756] INFO  {SecurityManager} Changing view acls groups to: 
[16:27:43,757] INFO  {SecurityManager} Changing modify acls groups to: 
[16:27:43,758] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:27:44,073] INFO  {Utils} Successfully started service 'sparkDriver' on port 33941.
[16:27:44,089] INFO  {SparkEnv} Registering MapOutputTracker
[16:27:44,104] INFO  {SparkEnv} Registering BlockManagerMaster
[16:27:44,116] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-726cb2dc-bca0-438f-b3ba-a5d5ec5fc710
[16:27:44,129] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:27:44,173] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:27:44,244] INFO  {log} Logging initialized @1586ms
[16:27:44,346] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:27:44,362] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[16:27:44,362] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[16:27:44,362] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[16:27:44,363] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[16:27:44,363] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[16:27:44,363] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[16:27:44,363] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[16:27:44,364] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[16:27:44,364] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[16:27:44,364] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[16:27:44,364] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[16:27:44,364] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[16:27:44,364] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[16:27:44,365] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[16:27:44,365] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[16:27:44,365] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[16:27:44,365] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[16:27:44,366] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[16:27:44,366] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[16:27:44,366] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[16:27:44,375] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[16:27:44,375] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[16:27:44,377] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[16:27:44,377] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[16:27:44,386] INFO  {ServerConnector} Started ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:27:44,387] INFO  {Server} Started @1729ms
[16:27:44,387] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:27:44,389] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:27:44,497] INFO  {Executor} Starting executor ID driver on host localhost
[16:27:44,527] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42227.
[16:27:44,528] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:42227
[16:27:44,531] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 42227)
[16:27:44,535] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:42227 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 42227)
[16:27:44,540] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 42227)
[16:27:44,694] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[16:27:44,740] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL,null,AVAILABLE}
[16:27:44,741] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/json,null,AVAILABLE}
[16:27:44,742] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution,null,AVAILABLE}
[16:27:44,743] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b11ef33{/SQL/execution/json,null,AVAILABLE}
[16:27:44,745] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@21ec5d87{/static/sql,null,AVAILABLE}
[16:27:44,762] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:27:46,498] INFO  {FileSourceStrategy} Pruning directories with: 
[16:27:46,500] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:27:46,506] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:27:46,506] INFO  {FileSourceStrategy} Pushed Filters: 
[16:27:46,617] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:27:46,663] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:27:46,674] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:42227 (size: 14.6 KB, free: 1128.9 MB)
[16:27:46,679] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:27:46,684] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:27:47,133] INFO  {CodeGenerator} Code generated in 197.702699 ms
[16:27:47,341] INFO  {CodeGenerator} Code generated in 28.120771 ms
[16:27:47,396] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:27:47,414] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:27:47,414] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:27:47,415] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:47,418] INFO  {DAGScheduler} Missing parents: List()
[16:27:47,422] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:27:47,488] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:27:47,489] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:27:47,490] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:42227 (size: 8.4 KB, free: 1128.9 MB)
[16:27:47,491] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:27:47,495] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:27:47,497] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:27:47,529] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:47,538] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:27:47,584] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:27:47,597] INFO  {CodeGenerator} Code generated in 9.875715 ms
[16:27:47,720] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:27:47,721] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:42227 (size: 1239.2 KB, free: 1127.7 MB)
[16:27:47,730] INFO  {CodeGenerator} Code generated in 3.830452 ms
[16:27:47,755] INFO  {CodeGenerator} Code generated in 18.721922 ms
[16:27:47,775] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:27:47,781] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4550 bytes result sent to driver
[16:27:47,792] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 277 ms on localhost (1/1)
[16:27:47,793] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:27:47,798] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.292 s
[16:27:47,814] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.417037 s
[16:27:47,843] INFO  {CodeGenerator} Code generated in 16.243345 ms
[16:27:47,950] INFO  {CodeGenerator} Code generated in 34.495061 ms
[16:27:47,964] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:27:47,965] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:27:47,965] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:27:47,965] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:47,967] INFO  {DAGScheduler} Missing parents: List()
[16:27:47,967] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:27:47,972] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:27:47,973] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:27:47,974] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:42227 (size: 10.0 KB, free: 1127.7 MB)
[16:27:47,975] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:27:47,975] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:27:47,975] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:27:47,980] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:47,980] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:27:47,992] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:48,006] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:27:48,007] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:27:48,009] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on localhost (1/1)
[16:27:48,009] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:27:48,009] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.032 s
[16:27:48,010] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.046219 s
[16:27:48,032] INFO  {CodeGenerator} Code generated in 14.539633 ms
[16:27:48,191] INFO  {ContextCleaner} Cleaned accumulator 3
[16:27:48,191] INFO  {ContextCleaner} Cleaned accumulator 4
[16:27:48,206] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:42227 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:27:48,214] INFO  {ContextCleaner} Cleaned accumulator 49
[16:27:48,214] INFO  {ContextCleaner} Cleaned accumulator 50
[16:27:48,215] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:42227 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:27:48,283] INFO  {CodeGenerator} Code generated in 54.501268 ms
[16:27:48,298] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:27:48,299] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:27:48,300] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:27:48,300] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:48,301] INFO  {DAGScheduler} Missing parents: List()
[16:27:48,301] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:27:48,306] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:27:48,308] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:27:48,309] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:42227 (size: 11.7 KB, free: 1127.7 MB)
[16:27:48,309] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:27:48,309] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:27:48,310] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:27:48,312] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:48,312] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:27:48,321] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:48,332] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:27:48,333] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:27:48,335] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on localhost (1/1)
[16:27:48,335] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:27:48,335] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.025 s
[16:27:48,336] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.037491 s
[16:27:48,354] INFO  {CodeGenerator} Code generated in 15.056758 ms
[16:27:48,454] INFO  {CodeGenerator} Code generated in 45.298146 ms
[16:27:48,467] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:27:48,468] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:27:48,468] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:27:48,468] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:48,468] INFO  {DAGScheduler} Missing parents: List()
[16:27:48,469] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:27:48,472] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:27:48,474] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1127.5 MB)
[16:27:48,475] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:42227 (size: 13.2 KB, free: 1127.7 MB)
[16:27:48,475] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:27:48,475] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:27:48,475] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:27:48,477] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:48,477] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:27:48,485] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:48,493] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:27:48,494] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4099 bytes result sent to driver
[16:27:48,496] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on localhost (1/1)
[16:27:48,496] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:27:48,496] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.020 s
[16:27:48,497] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.029684 s
[16:27:48,513] INFO  {CodeGenerator} Code generated in 13.832207 ms
[16:27:48,618] INFO  {CodeGenerator} Code generated in 12.26956 ms
[16:27:48,640] INFO  {CodeGenerator} Code generated in 17.157989 ms
[16:27:48,673] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:27:48,676] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:27:48,678] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:27:48,678] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:27:48,678] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:27:48,678] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:27:48,680] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:27:48,687] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:27:48,689] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:27:48,690] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:42227 (size: 10.1 KB, free: 1127.6 MB)
[16:27:48,690] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:27:48,692] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:27:48,693] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:27:48,695] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:27:48,696] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:27:48,700] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:48,981] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:27:48,983] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 290 ms on localhost (1/1)
[16:27:48,983] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:27:48,984] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.291 s
[16:27:48,985] INFO  {DAGScheduler} looking for newly runnable stages
[16:27:48,985] INFO  {DAGScheduler} running: Set()
[16:27:48,986] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:27:48,986] INFO  {DAGScheduler} failed: Set()
[16:27:48,988] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:27:48,992] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:27:48,994] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:27:48,995] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:42227 (size: 3.9 KB, free: 1127.6 MB)
[16:27:48,995] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:27:48,996] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:27:48,996] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:27:48,999] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:27:48,999] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:27:49,013] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:27:49,014] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 3 ms
[16:27:49,026] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1955 bytes result sent to driver
[16:27:49,027] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 30 ms on localhost (1/1)
[16:27:49,027] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:27:49,028] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.032 s
[16:27:49,028] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.355432 s
[16:27:49,036] INFO  {CodeGenerator} Code generated in 5.212641 ms
[16:27:49,075] INFO  {CodeGenerator} Code generated in 8.696077 ms
[16:27:49,096] INFO  {CodeGenerator} Code generated in 17.299389 ms
[16:27:49,110] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:27:49,111] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:27:49,112] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:27:49,112] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:27:49,112] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:27:49,112] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:27:49,113] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:27:49,116] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:27:49,118] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:27:49,119] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:42227 (size: 10.1 KB, free: 1127.6 MB)
[16:27:49,119] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:27:49,120] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:27:49,120] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:27:49,122] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:27:49,122] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:27:49,126] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:49,200] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:42227 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:27:49,201] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:42227 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:27:49,201] INFO  {ContextCleaner} Cleaned accumulator 288
[16:27:49,202] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:42227 in memory (size: 13.2 KB, free: 1127.7 MB)
[16:27:49,202] INFO  {ContextCleaner} Cleaned accumulator 187
[16:27:49,203] INFO  {ContextCleaner} Cleaned accumulator 188
[16:27:49,203] INFO  {ContextCleaner} Cleaned accumulator 189
[16:27:49,203] INFO  {ContextCleaner} Cleaned accumulator 190
[16:27:49,203] INFO  {ContextCleaner} Cleaned accumulator 191
[16:27:49,203] INFO  {ContextCleaner} Cleaned accumulator 192
[16:27:49,203] INFO  {ContextCleaner} Cleaned accumulator 193
[16:27:49,203] INFO  {ContextCleaner} Cleaned accumulator 194
[16:27:49,203] INFO  {ContextCleaner} Cleaned accumulator 195
[16:27:49,203] INFO  {ContextCleaner} Cleaned accumulator 196
[16:27:49,203] INFO  {ContextCleaner} Cleaned accumulator 197
[16:27:49,203] INFO  {ContextCleaner} Cleaned accumulator 198
[16:27:49,204] INFO  {ContextCleaner} Cleaned accumulator 199
[16:27:49,206] INFO  {ContextCleaner} Cleaned shuffle 0
[16:27:49,207] INFO  {ContextCleaner} Cleaned accumulator 95
[16:27:49,207] INFO  {ContextCleaner} Cleaned accumulator 96
[16:27:49,208] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:42227 in memory (size: 11.7 KB, free: 1127.7 MB)
[16:27:49,208] INFO  {ContextCleaner} Cleaned accumulator 141
[16:27:49,208] INFO  {ContextCleaner} Cleaned accumulator 142
[16:27:49,233] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:27:49,234] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 114 ms on localhost (1/1)
[16:27:49,234] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:27:49,235] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.114 s
[16:27:49,235] INFO  {DAGScheduler} looking for newly runnable stages
[16:27:49,235] INFO  {DAGScheduler} running: Set()
[16:27:49,235] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:27:49,235] INFO  {DAGScheduler} failed: Set()
[16:27:49,236] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:27:49,238] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:27:49,239] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:27:49,240] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:42227 (size: 3.9 KB, free: 1127.7 MB)
[16:27:49,240] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:27:49,241] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:27:49,241] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:27:49,242] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:27:49,243] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:27:49,245] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:27:49,245] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:27:49,248] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:27:49,249] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (1/1)
[16:27:49,249] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:27:49,250] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.008 s
[16:27:49,250] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.139393 s
[16:27:49,342] INFO  {CodeGenerator} Code generated in 40.326575 ms
[16:27:49,351] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:27:49,352] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:27:49,352] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:27:49,352] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:49,353] INFO  {DAGScheduler} Missing parents: List()
[16:27:49,353] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:27:49,357] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:27:49,359] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:27:49,360] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:42227 (size: 15.0 KB, free: 1127.6 MB)
[16:27:49,360] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:27:49,361] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:27:49,361] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:27:49,363] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:49,363] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:27:49,368] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:49,373] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:27:49,374] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:27:49,375] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 14 ms on localhost (1/1)
[16:27:49,375] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:27:49,376] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.014 s
[16:27:49,376] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.024370 s
[16:27:49,391] INFO  {CodeGenerator} Code generated in 12.953515 ms
[16:27:49,489] INFO  {CodeGenerator} Code generated in 46.245409 ms
[16:27:49,497] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:27:49,499] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:27:49,500] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:27:49,500] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:49,501] INFO  {DAGScheduler} Missing parents: List()
[16:27:49,501] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:27:49,504] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:27:49,505] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:27:49,506] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:42227 (size: 16.4 KB, free: 1127.6 MB)
[16:27:49,506] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:27:49,507] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:27:49,507] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:27:49,508] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:49,509] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:27:49,513] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:49,522] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:27:49,522] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:27:49,523] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 16 ms on localhost (1/1)
[16:27:49,523] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:27:49,524] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.017 s
[16:27:49,524] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.026364 s
[16:27:49,539] INFO  {CodeGenerator} Code generated in 12.439553 ms
[16:27:49,669] INFO  {CodeGenerator} Code generated in 14.125195 ms
[16:27:49,677] INFO  {SparkContext} Starting job: first at LinearRegression.scala:163
[16:27:49,678] INFO  {DAGScheduler} Got job 8 (first at LinearRegression.scala:163) with 1 output partitions
[16:27:49,678] INFO  {DAGScheduler} Final stage: ResultStage 10 (first at LinearRegression.scala:163)
[16:27:49,678] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:49,678] INFO  {DAGScheduler} Missing parents: List()
[16:27:49,679] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163), which has no missing parents
[16:27:49,682] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 24.2 KB, free 1127.3 MB)
[16:27:49,684] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1127.3 MB)
[16:27:49,684] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:42227 (size: 9.7 KB, free: 1127.6 MB)
[16:27:49,685] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[16:27:49,685] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163)
[16:27:49,685] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[16:27:49,687] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:27:49,687] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[16:27:49,692] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:49,696] WARN  {Executor} 1 block locks were not released by TID = 10:
[rdd_2_0]
[16:27:49,696] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 1844 bytes result sent to driver
[16:27:49,697] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 11 ms on localhost (1/1)
[16:27:49,697] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[16:27:49,697] INFO  {DAGScheduler} ResultStage 10 (first at LinearRegression.scala:163) finished in 0.011 s
[16:27:49,698] INFO  {DAGScheduler} Job 8 finished: first at LinearRegression.scala:163, took 0.020773 s
[16:27:49,705] INFO  {CodeGenerator} Code generated in 5.293681 ms
[16:27:49,808] INFO  {CodeGenerator} Code generated in 28.953875 ms
[16:27:49,864] INFO  {SparkContext} Starting job: treeAggregate at WeightedLeastSquares.scala:81
[16:27:49,865] INFO  {DAGScheduler} Got job 9 (treeAggregate at WeightedLeastSquares.scala:81) with 1 output partitions
[16:27:49,865] INFO  {DAGScheduler} Final stage: ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81)
[16:27:49,865] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:49,866] INFO  {DAGScheduler} Missing parents: List()
[16:27:49,866] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81), which has no missing parents
[16:27:49,869] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 42.1 KB, free 1127.3 MB)
[16:27:49,870] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.3 MB)
[16:27:49,870] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:42227 (size: 14.4 KB, free: 1127.6 MB)
[16:27:49,871] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[16:27:49,871] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81)
[16:27:49,871] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[16:27:49,872] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5967 bytes)
[16:27:49,873] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[16:27:49,879] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:49,893] INFO  {CodeGenerator} Code generated in 7.574508 ms
[16:27:49,906] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
[16:27:49,906] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[16:27:50,024] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 192.168.0.103:42227 in memory (size: 9.7 KB, free: 1127.6 MB)
[16:27:50,025] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 192.168.0.103:42227 in memory (size: 15.0 KB, free: 1127.6 MB)
[16:27:50,026] INFO  {ContextCleaner} Cleaned accumulator 435
[16:27:50,026] INFO  {ContextCleaner} Cleaned accumulator 436
[16:27:50,027] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 192.168.0.103:42227 in memory (size: 16.4 KB, free: 1127.6 MB)
[16:27:50,028] INFO  {ContextCleaner} Cleaned accumulator 481
[16:27:50,028] INFO  {ContextCleaner} Cleaned accumulator 482
[16:27:50,028] INFO  {ContextCleaner} Cleaned accumulator 389
[16:27:50,028] INFO  {ContextCleaner} Cleaned accumulator 390
[16:27:50,030] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:42227 in memory (size: 3.9 KB, free: 1127.7 MB)
[16:27:50,030] INFO  {ContextCleaner} Cleaned accumulator 289
[16:27:50,031] INFO  {ContextCleaner} Cleaned accumulator 290
[16:27:50,031] INFO  {ContextCleaner} Cleaned accumulator 291
[16:27:50,031] INFO  {ContextCleaner} Cleaned accumulator 292
[16:27:50,031] INFO  {ContextCleaner} Cleaned accumulator 293
[16:27:50,031] INFO  {ContextCleaner} Cleaned accumulator 294
[16:27:50,031] INFO  {ContextCleaner} Cleaned accumulator 295
[16:27:50,031] INFO  {ContextCleaner} Cleaned accumulator 296
[16:27:50,031] INFO  {ContextCleaner} Cleaned accumulator 297
[16:27:50,031] INFO  {ContextCleaner} Cleaned accumulator 298
[16:27:50,031] INFO  {ContextCleaner} Cleaned accumulator 299
[16:27:50,031] INFO  {ContextCleaner} Cleaned accumulator 300
[16:27:50,032] INFO  {ContextCleaner} Cleaned shuffle 1
[16:27:50,033] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:42227 in memory (size: 10.1 KB, free: 1127.7 MB)
[16:27:50,196] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 2430 bytes result sent to driver
[16:27:50,198] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 326 ms on localhost (1/1)
[16:27:50,198] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[16:27:50,198] INFO  {DAGScheduler} ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81) finished in 0.327 s
[16:27:50,199] INFO  {DAGScheduler} Job 9 finished: treeAggregate at WeightedLeastSquares.scala:81, took 0.334193 s
[16:27:50,201] INFO  {WeightedLeastSquares} Number of instances: 6724.
[16:27:50,208] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
[16:27:50,208] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[16:27:50,512] INFO  {CodeGenerator} Code generated in 19.878098 ms
[16:27:50,540] INFO  {SparkContext} Starting job: aggregate at RegressionMetrics.scala:57
[16:27:50,541] INFO  {DAGScheduler} Got job 10 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
[16:27:50,541] INFO  {DAGScheduler} Final stage: ResultStage 12 (aggregate at RegressionMetrics.scala:57)
[16:27:50,541] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:50,542] INFO  {DAGScheduler} Missing parents: List()
[16:27:50,542] INFO  {DAGScheduler} Submitting ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55), which has no missing parents
[16:27:50,545] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 41.1 KB, free 1127.5 MB)
[16:27:50,546] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1127.4 MB)
[16:27:50,547] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 192.168.0.103:42227 (size: 14.5 KB, free: 1127.6 MB)
[16:27:50,547] INFO  {SparkContext} Created broadcast 13 from broadcast at DAGScheduler.scala:1012
[16:27:50,548] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55)
[16:27:50,548] INFO  {TaskSchedulerImpl} Adding task set 12.0 with 1 tasks
[16:27:50,549] INFO  {TaskSetManager} Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5963 bytes)
[16:27:50,550] INFO  {Executor} Running task 0.0 in stage 12.0 (TID 12)
[16:27:50,555] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:50,564] INFO  {CodeGenerator} Code generated in 5.010468 ms
[16:27:50,725] INFO  {BlockManagerInfo} Removed broadcast_12_piece0 on 192.168.0.103:42227 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:27:50,852] INFO  {Executor} Finished task 0.0 in stage 12.0 (TID 12). 2281 bytes result sent to driver
[16:27:50,853] INFO  {TaskSetManager} Finished task 0.0 in stage 12.0 (TID 12) in 305 ms on localhost (1/1)
[16:27:50,853] INFO  {TaskSchedulerImpl} Removed TaskSet 12.0, whose tasks have all completed, from pool 
[16:27:50,854] INFO  {DAGScheduler} ResultStage 12 (aggregate at RegressionMetrics.scala:57) finished in 0.306 s
[16:27:50,854] INFO  {DAGScheduler} Job 10 finished: aggregate at RegressionMetrics.scala:57, took 0.314259 s
[16:27:50,872] INFO  {SparkContext} Starting job: sum at RegressionMetrics.scala:71
[16:27:50,873] INFO  {DAGScheduler} Got job 11 (sum at RegressionMetrics.scala:71) with 1 output partitions
[16:27:50,873] INFO  {DAGScheduler} Final stage: ResultStage 13 (sum at RegressionMetrics.scala:71)
[16:27:50,873] INFO  {DAGScheduler} Parents of final stage: List()
[16:27:50,873] INFO  {DAGScheduler} Missing parents: List()
[16:27:50,873] INFO  {DAGScheduler} Submitting ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69), which has no missing parents
[16:27:50,875] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 40.7 KB, free 1127.5 MB)
[16:27:50,877] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.4 MB)
[16:27:50,877] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 192.168.0.103:42227 (size: 14.4 KB, free: 1127.6 MB)
[16:27:50,878] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[16:27:50,878] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69)
[16:27:50,878] INFO  {TaskSchedulerImpl} Adding task set 13.0 with 1 tasks
[16:27:50,879] INFO  {TaskSetManager} Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[16:27:50,880] INFO  {Executor} Running task 0.0 in stage 13.0 (TID 13)
[16:27:50,884] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:51,047] INFO  {BlockManagerInfo} Removed broadcast_13_piece0 on 192.168.0.103:42227 in memory (size: 14.5 KB, free: 1127.7 MB)
[16:27:51,096] INFO  {Executor} Finished task 0.0 in stage 13.0 (TID 13). 1859 bytes result sent to driver
[16:27:51,097] INFO  {TaskSetManager} Finished task 0.0 in stage 13.0 (TID 13) in 219 ms on localhost (1/1)
[16:27:51,097] INFO  {TaskSchedulerImpl} Removed TaskSet 13.0, whose tasks have all completed, from pool 
[16:27:51,097] INFO  {DAGScheduler} ResultStage 13 (sum at RegressionMetrics.scala:71) finished in 0.219 s
[16:27:51,098] INFO  {DAGScheduler} Job 11 finished: sum at RegressionMetrics.scala:71, took 0.225872 s
[16:27:51,157] INFO  {CodeGenerator} Code generated in 9.355178 ms
[16:27:51,168] INFO  {CodeGenerator} Code generated in 8.315557 ms
[16:27:51,186] INFO  {SparkContext} Starting job: count at LinearRegression.scala:643
[16:27:51,187] INFO  {DAGScheduler} Registering RDD 51 (count at LinearRegression.scala:643)
[16:27:51,187] INFO  {DAGScheduler} Got job 12 (count at LinearRegression.scala:643) with 1 output partitions
[16:27:51,187] INFO  {DAGScheduler} Final stage: ResultStage 15 (count at LinearRegression.scala:643)
[16:27:51,187] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 14)
[16:27:51,187] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 14)
[16:27:51,188] INFO  {DAGScheduler} Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643), which has no missing parents
[16:27:51,191] INFO  {MemoryStore} Block broadcast_15 stored as values in memory (estimated size 14.0 KB, free 1127.5 MB)
[16:27:51,193] INFO  {MemoryStore} Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1127.5 MB)
[16:27:51,194] INFO  {BlockManagerInfo} Added broadcast_15_piece0 in memory on 192.168.0.103:42227 (size: 6.8 KB, free: 1127.7 MB)
[16:27:51,195] INFO  {SparkContext} Created broadcast 15 from broadcast at DAGScheduler.scala:1012
[16:27:51,195] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643)
[16:27:51,195] INFO  {TaskSchedulerImpl} Adding task set 14.0 with 1 tasks
[16:27:51,197] INFO  {TaskSetManager} Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5979 bytes)
[16:27:51,197] INFO  {Executor} Running task 0.0 in stage 14.0 (TID 14)
[16:27:51,201] INFO  {BlockManager} Found block rdd_2_0 locally
[16:27:51,211] INFO  {CodeGenerator} Code generated in 9.282544 ms
[16:27:51,218] INFO  {Executor} Finished task 0.0 in stage 14.0 (TID 14). 2324 bytes result sent to driver
[16:27:51,220] INFO  {TaskSetManager} Finished task 0.0 in stage 14.0 (TID 14) in 23 ms on localhost (1/1)
[16:27:51,220] INFO  {TaskSchedulerImpl} Removed TaskSet 14.0, whose tasks have all completed, from pool 
[16:27:51,220] INFO  {DAGScheduler} ShuffleMapStage 14 (count at LinearRegression.scala:643) finished in 0.024 s
[16:27:51,220] INFO  {DAGScheduler} looking for newly runnable stages
[16:27:51,220] INFO  {DAGScheduler} running: Set()
[16:27:51,220] INFO  {DAGScheduler} waiting: Set(ResultStage 15)
[16:27:51,220] INFO  {DAGScheduler} failed: Set()
[16:27:51,221] INFO  {DAGScheduler} Submitting ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643), which has no missing parents
[16:27:51,222] INFO  {MemoryStore} Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 1127.5 MB)
[16:27:51,224] INFO  {MemoryStore} Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1127.5 MB)
[16:27:51,225] INFO  {BlockManagerInfo} Added broadcast_16_piece0 in memory on 192.168.0.103:42227 (size: 3.7 KB, free: 1127.7 MB)
[16:27:51,225] INFO  {SparkContext} Created broadcast 16 from broadcast at DAGScheduler.scala:1012
[16:27:51,226] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643)
[16:27:51,226] INFO  {TaskSchedulerImpl} Adding task set 15.0 with 1 tasks
[16:27:51,227] INFO  {TaskSetManager} Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, ANY, 5318 bytes)
[16:27:51,227] INFO  {Executor} Running task 0.0 in stage 15.0 (TID 15)
[16:27:51,230] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:27:51,230] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:27:51,233] INFO  {Executor} Finished task 0.0 in stage 15.0 (TID 15). 1873 bytes result sent to driver
[16:27:51,234] INFO  {TaskSetManager} Finished task 0.0 in stage 15.0 (TID 15) in 8 ms on localhost (1/1)
[16:27:51,235] INFO  {TaskSchedulerImpl} Removed TaskSet 15.0, whose tasks have all completed, from pool 
[16:27:51,235] INFO  {DAGScheduler} ResultStage 15 (count at LinearRegression.scala:643) finished in 0.009 s
[16:27:51,236] INFO  {DAGScheduler} Job 12 finished: count at LinearRegression.scala:643, took 0.049628 s
[16:27:51,243] INFO  {CodeGenerator} Code generated in 5.350968 ms
[16:27:51,425] INFO  {CodeGenerator} Code generated in 10.774534 ms
[16:27:51,440] INFO  {CodeGenerator} Code generated in 5.20116 ms
[16:27:51,446] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:27:51,451] INFO  {ServerConnector} Stopped ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:27:51,454] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[16:27:51,454] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[16:27:51,454] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[16:27:51,454] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[16:27:51,454] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[16:27:51,454] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[16:27:51,454] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[16:27:51,455] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[16:27:51,455] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[16:27:51,455] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[16:27:51,455] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[16:27:51,455] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[16:27:51,455] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[16:27:51,455] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[16:27:51,455] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[16:27:51,456] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[16:27:51,456] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[16:27:51,456] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[16:27:51,456] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[16:27:51,456] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[16:27:51,456] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[16:27:51,456] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[16:27:51,456] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[16:27:51,457] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[16:27:51,458] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:27:51,468] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:27:51,476] INFO  {MemoryStore} MemoryStore cleared
[16:27:51,477] INFO  {BlockManager} BlockManager stopped
[16:27:51,478] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:27:51,481] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:27:51,484] INFO  {SparkContext} Successfully stopped SparkContext
[16:27:51,485] INFO  {ShutdownHookManager} Shutdown hook called
[16:27:51,485] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-ec6c1487-9f2e-46fb-a6b5-0cd2a9d62f72
[16:28:40,351] INFO  {SparkContext} Running Spark version 2.0.1
[16:28:40,572] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:28:40,668] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:28:40,669] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:28:40,741] INFO  {SecurityManager} Changing view acls to: victor
[16:28:40,742] INFO  {SecurityManager} Changing modify acls to: victor
[16:28:40,742] INFO  {SecurityManager} Changing view acls groups to: 
[16:28:40,743] INFO  {SecurityManager} Changing modify acls groups to: 
[16:28:40,744] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:28:41,080] INFO  {Utils} Successfully started service 'sparkDriver' on port 39587.
[16:28:41,095] INFO  {SparkEnv} Registering MapOutputTracker
[16:28:41,110] INFO  {SparkEnv} Registering BlockManagerMaster
[16:28:41,121] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-fcdabf21-fa9e-44c4-88e0-f17ec98f017f
[16:28:41,135] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:28:41,185] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:28:41,253] INFO  {log} Logging initialized @1492ms
[16:28:41,353] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:28:41,369] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:28:41,369] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:28:41,369] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:28:41,370] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:28:41,370] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:28:41,370] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:28:41,370] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:28:41,371] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:28:41,371] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:28:41,371] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:28:41,371] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:28:41,372] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:28:41,372] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:28:41,372] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:28:41,372] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:28:41,373] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:28:41,373] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:28:41,373] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:28:41,373] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:28:41,374] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:28:41,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:28:41,383] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:28:41,384] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:28:41,384] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:28:41,393] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:28:41,393] INFO  {Server} Started @1632ms
[16:28:41,393] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:28:41,396] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:28:41,489] INFO  {Executor} Starting executor ID driver on host localhost
[16:28:41,517] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37391.
[16:28:41,518] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:37391
[16:28:41,520] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 37391)
[16:28:41,523] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:37391 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 37391)
[16:28:41,526] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 37391)
[16:28:41,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:28:41,688] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:28:41,689] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:28:41,690] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:28:41,691] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:28:41,693] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:28:41,707] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:28:43,433] INFO  {FileSourceStrategy} Pruning directories with: 
[16:28:43,436] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:28:43,440] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:28:43,441] INFO  {FileSourceStrategy} Pushed Filters: 
[16:28:43,547] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:28:43,589] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:28:43,591] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:37391 (size: 14.6 KB, free: 1128.9 MB)
[16:28:43,596] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:28:43,599] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:28:44,026] INFO  {CodeGenerator} Code generated in 189.385071 ms
[16:28:44,219] INFO  {CodeGenerator} Code generated in 27.003661 ms
[16:28:44,266] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:28:44,283] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:28:44,283] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:28:44,284] INFO  {DAGScheduler} Parents of final stage: List()
[16:28:44,289] INFO  {DAGScheduler} Missing parents: List()
[16:28:44,293] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:28:44,348] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:28:44,350] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:28:44,351] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:37391 (size: 8.5 KB, free: 1128.9 MB)
[16:28:44,351] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:28:44,354] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:28:44,356] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:28:44,390] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:28:44,399] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:28:44,443] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:28:44,456] INFO  {CodeGenerator} Code generated in 9.762918 ms
[16:28:44,595] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:28:44,596] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:37391 (size: 1239.2 KB, free: 1127.7 MB)
[16:28:44,606] INFO  {CodeGenerator} Code generated in 4.406886 ms
[16:28:44,631] INFO  {CodeGenerator} Code generated in 18.706728 ms
[16:28:44,651] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:28:44,657] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:28:44,667] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 292 ms on localhost (1/1)
[16:28:44,669] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:28:44,673] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.308 s
[16:28:44,677] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.411477 s
[16:28:44,710] INFO  {CodeGenerator} Code generated in 17.39564 ms
[16:28:44,819] INFO  {CodeGenerator} Code generated in 34.816302 ms
[16:28:44,833] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:28:44,834] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:28:44,834] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:28:44,834] INFO  {DAGScheduler} Parents of final stage: List()
[16:28:44,836] INFO  {DAGScheduler} Missing parents: List()
[16:28:44,837] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:28:44,841] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:28:44,843] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:28:44,843] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:37391 (size: 10.0 KB, free: 1127.7 MB)
[16:28:44,844] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:28:44,844] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:28:44,844] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:28:44,849] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:28:44,849] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:28:44,859] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:44,872] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:28:44,872] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:28:44,874] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 27 ms on localhost (1/1)
[16:28:44,874] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:28:44,875] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.027 s
[16:28:44,875] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.041969 s
[16:28:44,897] INFO  {CodeGenerator} Code generated in 14.679316 ms
[16:28:45,087] INFO  {ContextCleaner} Cleaned accumulator 3
[16:28:45,087] INFO  {ContextCleaner} Cleaned accumulator 4
[16:28:45,104] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:37391 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:28:45,109] INFO  {ContextCleaner} Cleaned accumulator 49
[16:28:45,109] INFO  {ContextCleaner} Cleaned accumulator 50
[16:28:45,110] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:37391 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:28:45,149] INFO  {CodeGenerator} Code generated in 44.212042 ms
[16:28:45,161] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:28:45,162] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:28:45,163] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:28:45,163] INFO  {DAGScheduler} Parents of final stage: List()
[16:28:45,164] INFO  {DAGScheduler} Missing parents: List()
[16:28:45,164] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:28:45,169] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:28:45,171] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:28:45,172] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:37391 (size: 11.7 KB, free: 1127.7 MB)
[16:28:45,173] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:28:45,173] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:28:45,173] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:28:45,176] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:28:45,176] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:28:45,185] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:45,199] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:28:45,200] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:28:45,202] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on localhost (1/1)
[16:28:45,202] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:28:45,203] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.028 s
[16:28:45,203] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.041425 s
[16:28:45,226] INFO  {CodeGenerator} Code generated in 19.277203 ms
[16:28:45,348] INFO  {CodeGenerator} Code generated in 49.921392 ms
[16:28:45,364] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:28:45,366] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:28:45,366] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:28:45,366] INFO  {DAGScheduler} Parents of final stage: List()
[16:28:45,366] INFO  {DAGScheduler} Missing parents: List()
[16:28:45,367] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:28:45,371] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:28:45,374] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:28:45,375] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:37391 (size: 13.3 KB, free: 1127.7 MB)
[16:28:45,375] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:28:45,375] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:28:45,376] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:28:45,378] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:28:45,378] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:28:45,388] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:45,400] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:28:45,401] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:28:45,403] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 27 ms on localhost (1/1)
[16:28:45,403] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:28:45,403] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.027 s
[16:28:45,404] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.039589 s
[16:28:45,422] INFO  {CodeGenerator} Code generated in 14.65084 ms
[16:28:45,531] INFO  {CodeGenerator} Code generated in 13.390428 ms
[16:28:45,553] INFO  {CodeGenerator} Code generated in 17.016341 ms
[16:28:45,583] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:28:45,586] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:28:45,587] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:28:45,587] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:28:45,587] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:28:45,588] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:28:45,589] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:28:45,596] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:28:45,598] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:28:45,598] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:37391 (size: 10.1 KB, free: 1127.6 MB)
[16:28:45,599] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:28:45,601] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:28:45,601] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:28:45,603] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:28:45,604] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:28:45,610] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:45,875] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:28:45,878] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 277 ms on localhost (1/1)
[16:28:45,878] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:28:45,879] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.278 s
[16:28:45,879] INFO  {DAGScheduler} looking for newly runnable stages
[16:28:45,880] INFO  {DAGScheduler} running: Set()
[16:28:45,880] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:28:45,880] INFO  {DAGScheduler} failed: Set()
[16:28:45,882] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:28:45,885] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:28:45,887] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:28:45,887] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:37391 (size: 3.9 KB, free: 1127.6 MB)
[16:28:45,888] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:28:45,888] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:28:45,888] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:28:45,891] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:28:45,891] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:28:45,903] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:28:45,905] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[16:28:45,918] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:28:45,919] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 30 ms on localhost (1/1)
[16:28:45,919] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:28:45,919] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.030 s
[16:28:45,920] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.336274 s
[16:28:45,931] INFO  {CodeGenerator} Code generated in 6.845965 ms
[16:28:45,975] INFO  {CodeGenerator} Code generated in 8.949498 ms
[16:28:45,997] INFO  {CodeGenerator} Code generated in 16.882264 ms
[16:28:46,010] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:28:46,011] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:28:46,012] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:28:46,012] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:28:46,012] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:28:46,012] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:28:46,013] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:28:46,017] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:28:46,018] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:28:46,019] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:37391 (size: 10.1 KB, free: 1127.6 MB)
[16:28:46,020] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:28:46,020] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:28:46,020] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:28:46,022] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:28:46,022] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:28:46,028] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:46,111] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:37391 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:28:46,112] INFO  {ContextCleaner} Cleaned accumulator 288
[16:28:46,113] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:37391 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:28:46,115] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:37391 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:28:46,116] INFO  {ContextCleaner} Cleaned accumulator 187
[16:28:46,116] INFO  {ContextCleaner} Cleaned accumulator 188
[16:28:46,116] INFO  {ContextCleaner} Cleaned accumulator 189
[16:28:46,116] INFO  {ContextCleaner} Cleaned accumulator 190
[16:28:46,117] INFO  {ContextCleaner} Cleaned accumulator 191
[16:28:46,117] INFO  {ContextCleaner} Cleaned accumulator 192
[16:28:46,117] INFO  {ContextCleaner} Cleaned accumulator 193
[16:28:46,117] INFO  {ContextCleaner} Cleaned accumulator 194
[16:28:46,117] INFO  {ContextCleaner} Cleaned accumulator 195
[16:28:46,117] INFO  {ContextCleaner} Cleaned accumulator 196
[16:28:46,117] INFO  {ContextCleaner} Cleaned accumulator 197
[16:28:46,117] INFO  {ContextCleaner} Cleaned accumulator 198
[16:28:46,117] INFO  {ContextCleaner} Cleaned accumulator 199
[16:28:46,121] INFO  {ContextCleaner} Cleaned shuffle 0
[16:28:46,122] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:37391 in memory (size: 11.7 KB, free: 1127.7 MB)
[16:28:46,123] INFO  {ContextCleaner} Cleaned accumulator 141
[16:28:46,123] INFO  {ContextCleaner} Cleaned accumulator 142
[16:28:46,161] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:28:46,162] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 141 ms on localhost (1/1)
[16:28:46,162] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:28:46,163] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.142 s
[16:28:46,163] INFO  {DAGScheduler} looking for newly runnable stages
[16:28:46,163] INFO  {DAGScheduler} running: Set()
[16:28:46,163] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:28:46,163] INFO  {DAGScheduler} failed: Set()
[16:28:46,164] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:28:46,166] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:28:46,168] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:28:46,168] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:37391 (size: 3.9 KB, free: 1127.7 MB)
[16:28:46,169] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:28:46,169] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:28:46,169] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:28:46,170] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:28:46,171] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:28:46,173] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:28:46,173] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:28:46,177] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:28:46,178] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (1/1)
[16:28:46,178] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:28:46,178] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.009 s
[16:28:46,179] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.168029 s
[16:28:46,314] INFO  {CodeGenerator} Code generated in 62.824157 ms
[16:28:46,327] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:28:46,327] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:28:46,328] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:28:46,328] INFO  {DAGScheduler} Parents of final stage: List()
[16:28:46,328] INFO  {DAGScheduler} Missing parents: List()
[16:28:46,329] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:28:46,332] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:28:46,334] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:28:46,335] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:37391 (size: 15.0 KB, free: 1127.6 MB)
[16:28:46,335] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:28:46,336] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:28:46,336] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:28:46,338] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:28:46,338] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:28:46,344] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:46,352] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:28:46,353] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4107 bytes result sent to driver
[16:28:46,354] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 18 ms on localhost (1/1)
[16:28:46,354] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:28:46,355] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.018 s
[16:28:46,356] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.029196 s
[16:28:46,376] INFO  {CodeGenerator} Code generated in 16.887692 ms
[16:28:46,513] INFO  {CodeGenerator} Code generated in 59.363456 ms
[16:28:46,525] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:28:46,526] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:28:46,526] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:28:46,526] INFO  {DAGScheduler} Parents of final stage: List()
[16:28:46,526] INFO  {DAGScheduler} Missing parents: List()
[16:28:46,527] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:28:46,531] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:28:46,532] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:28:46,533] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:37391 (size: 16.4 KB, free: 1127.6 MB)
[16:28:46,533] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:28:46,534] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:28:46,534] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:28:46,536] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:28:46,536] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:28:46,540] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:46,546] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:28:46,546] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:28:46,547] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 12 ms on localhost (1/1)
[16:28:46,548] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:28:46,548] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.014 s
[16:28:46,548] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.023553 s
[16:28:46,563] INFO  {CodeGenerator} Code generated in 12.003815 ms
[16:28:46,683] INFO  {CodeGenerator} Code generated in 13.851623 ms
[16:28:46,691] INFO  {SparkContext} Starting job: first at LinearRegression.scala:163
[16:28:46,692] INFO  {DAGScheduler} Got job 8 (first at LinearRegression.scala:163) with 1 output partitions
[16:28:46,692] INFO  {DAGScheduler} Final stage: ResultStage 10 (first at LinearRegression.scala:163)
[16:28:46,692] INFO  {DAGScheduler} Parents of final stage: List()
[16:28:46,692] INFO  {DAGScheduler} Missing parents: List()
[16:28:46,693] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163), which has no missing parents
[16:28:46,697] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 24.2 KB, free 1127.3 MB)
[16:28:46,699] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1127.3 MB)
[16:28:46,700] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:37391 (size: 9.7 KB, free: 1127.6 MB)
[16:28:46,701] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[16:28:46,701] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163)
[16:28:46,701] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[16:28:46,703] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:28:46,703] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[16:28:46,706] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:46,709] WARN  {Executor} 1 block locks were not released by TID = 10:
[rdd_2_0]
[16:28:46,710] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 1844 bytes result sent to driver
[16:28:46,711] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 8 ms on localhost (1/1)
[16:28:46,711] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[16:28:46,711] INFO  {DAGScheduler} ResultStage 10 (first at LinearRegression.scala:163) finished in 0.009 s
[16:28:46,711] INFO  {DAGScheduler} Job 8 finished: first at LinearRegression.scala:163, took 0.020424 s
[16:28:46,720] INFO  {CodeGenerator} Code generated in 6.710946 ms
[16:28:46,807] INFO  {CodeGenerator} Code generated in 24.199455 ms
[16:28:46,857] INFO  {SparkContext} Starting job: treeAggregate at WeightedLeastSquares.scala:81
[16:28:46,858] INFO  {DAGScheduler} Got job 9 (treeAggregate at WeightedLeastSquares.scala:81) with 1 output partitions
[16:28:46,858] INFO  {DAGScheduler} Final stage: ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81)
[16:28:46,858] INFO  {DAGScheduler} Parents of final stage: List()
[16:28:46,859] INFO  {DAGScheduler} Missing parents: List()
[16:28:46,859] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81), which has no missing parents
[16:28:46,862] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 42.1 KB, free 1127.3 MB)
[16:28:46,864] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.3 MB)
[16:28:46,865] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:37391 (size: 14.4 KB, free: 1127.6 MB)
[16:28:46,868] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[16:28:46,869] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81)
[16:28:46,869] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[16:28:46,870] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5967 bytes)
[16:28:46,871] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[16:28:46,877] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:46,887] INFO  {CodeGenerator} Code generated in 5.670804 ms
[16:28:46,897] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
[16:28:46,897] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[16:28:46,994] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 192.168.0.103:37391 in memory (size: 9.7 KB, free: 1127.6 MB)
[16:28:46,996] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 192.168.0.103:37391 in memory (size: 16.4 KB, free: 1127.6 MB)
[16:28:46,997] INFO  {ContextCleaner} Cleaned accumulator 481
[16:28:46,997] INFO  {ContextCleaner} Cleaned accumulator 482
[16:28:46,998] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:37391 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:28:46,999] INFO  {ContextCleaner} Cleaned accumulator 389
[16:28:46,999] INFO  {ContextCleaner} Cleaned accumulator 390
[16:28:47,000] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 192.168.0.103:37391 in memory (size: 15.0 KB, free: 1127.7 MB)
[16:28:47,001] INFO  {ContextCleaner} Cleaned accumulator 435
[16:28:47,001] INFO  {ContextCleaner} Cleaned accumulator 436
[16:28:47,001] INFO  {ContextCleaner} Cleaned accumulator 289
[16:28:47,001] INFO  {ContextCleaner} Cleaned accumulator 290
[16:28:47,001] INFO  {ContextCleaner} Cleaned accumulator 291
[16:28:47,001] INFO  {ContextCleaner} Cleaned accumulator 292
[16:28:47,001] INFO  {ContextCleaner} Cleaned accumulator 293
[16:28:47,001] INFO  {ContextCleaner} Cleaned accumulator 294
[16:28:47,001] INFO  {ContextCleaner} Cleaned accumulator 295
[16:28:47,002] INFO  {ContextCleaner} Cleaned accumulator 296
[16:28:47,002] INFO  {ContextCleaner} Cleaned accumulator 297
[16:28:47,002] INFO  {ContextCleaner} Cleaned accumulator 298
[16:28:47,002] INFO  {ContextCleaner} Cleaned accumulator 299
[16:28:47,002] INFO  {ContextCleaner} Cleaned accumulator 300
[16:28:47,002] INFO  {ContextCleaner} Cleaned shuffle 1
[16:28:47,004] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:37391 in memory (size: 10.1 KB, free: 1127.7 MB)
[16:28:47,146] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 2430 bytes result sent to driver
[16:28:47,147] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 278 ms on localhost (1/1)
[16:28:47,147] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[16:28:47,147] INFO  {DAGScheduler} ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81) finished in 0.278 s
[16:28:47,148] INFO  {DAGScheduler} Job 9 finished: treeAggregate at WeightedLeastSquares.scala:81, took 0.290436 s
[16:28:47,150] INFO  {WeightedLeastSquares} Number of instances: 6724.
[16:28:47,157] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
[16:28:47,157] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[16:28:47,442] INFO  {CodeGenerator} Code generated in 18.406351 ms
[16:28:47,472] INFO  {SparkContext} Starting job: aggregate at RegressionMetrics.scala:57
[16:28:47,473] INFO  {DAGScheduler} Got job 10 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
[16:28:47,473] INFO  {DAGScheduler} Final stage: ResultStage 12 (aggregate at RegressionMetrics.scala:57)
[16:28:47,473] INFO  {DAGScheduler} Parents of final stage: List()
[16:28:47,474] INFO  {DAGScheduler} Missing parents: List()
[16:28:47,474] INFO  {DAGScheduler} Submitting ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55), which has no missing parents
[16:28:47,477] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 41.1 KB, free 1127.5 MB)
[16:28:47,479] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1127.4 MB)
[16:28:47,480] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 192.168.0.103:37391 (size: 14.5 KB, free: 1127.6 MB)
[16:28:47,480] INFO  {SparkContext} Created broadcast 13 from broadcast at DAGScheduler.scala:1012
[16:28:47,481] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55)
[16:28:47,481] INFO  {TaskSchedulerImpl} Adding task set 12.0 with 1 tasks
[16:28:47,482] INFO  {TaskSetManager} Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5963 bytes)
[16:28:47,482] INFO  {Executor} Running task 0.0 in stage 12.0 (TID 12)
[16:28:47,487] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:47,495] INFO  {CodeGenerator} Code generated in 4.786569 ms
[16:28:47,652] INFO  {BlockManagerInfo} Removed broadcast_12_piece0 on 192.168.0.103:37391 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:28:47,774] INFO  {Executor} Finished task 0.0 in stage 12.0 (TID 12). 2281 bytes result sent to driver
[16:28:47,775] INFO  {TaskSetManager} Finished task 0.0 in stage 12.0 (TID 12) in 294 ms on localhost (1/1)
[16:28:47,775] INFO  {TaskSchedulerImpl} Removed TaskSet 12.0, whose tasks have all completed, from pool 
[16:28:47,775] INFO  {DAGScheduler} ResultStage 12 (aggregate at RegressionMetrics.scala:57) finished in 0.294 s
[16:28:47,776] INFO  {DAGScheduler} Job 10 finished: aggregate at RegressionMetrics.scala:57, took 0.303503 s
[16:28:47,789] INFO  {SparkContext} Starting job: sum at RegressionMetrics.scala:71
[16:28:47,790] INFO  {DAGScheduler} Got job 11 (sum at RegressionMetrics.scala:71) with 1 output partitions
[16:28:47,790] INFO  {DAGScheduler} Final stage: ResultStage 13 (sum at RegressionMetrics.scala:71)
[16:28:47,790] INFO  {DAGScheduler} Parents of final stage: List()
[16:28:47,791] INFO  {DAGScheduler} Missing parents: List()
[16:28:47,791] INFO  {DAGScheduler} Submitting ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69), which has no missing parents
[16:28:47,794] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 40.7 KB, free 1127.5 MB)
[16:28:47,795] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.4 MB)
[16:28:47,796] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 192.168.0.103:37391 (size: 14.4 KB, free: 1127.6 MB)
[16:28:47,796] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[16:28:47,796] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69)
[16:28:47,797] INFO  {TaskSchedulerImpl} Adding task set 13.0 with 1 tasks
[16:28:47,798] INFO  {TaskSetManager} Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[16:28:47,798] INFO  {Executor} Running task 0.0 in stage 13.0 (TID 13)
[16:28:47,802] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:47,973] INFO  {BlockManagerInfo} Removed broadcast_13_piece0 on 192.168.0.103:37391 in memory (size: 14.5 KB, free: 1127.7 MB)
[16:28:48,001] INFO  {Executor} Finished task 0.0 in stage 13.0 (TID 13). 1859 bytes result sent to driver
[16:28:48,002] INFO  {TaskSetManager} Finished task 0.0 in stage 13.0 (TID 13) in 205 ms on localhost (1/1)
[16:28:48,002] INFO  {TaskSchedulerImpl} Removed TaskSet 13.0, whose tasks have all completed, from pool 
[16:28:48,003] INFO  {DAGScheduler} ResultStage 13 (sum at RegressionMetrics.scala:71) finished in 0.206 s
[16:28:48,003] INFO  {DAGScheduler} Job 11 finished: sum at RegressionMetrics.scala:71, took 0.213787 s
[16:28:48,059] INFO  {CodeGenerator} Code generated in 8.751505 ms
[16:28:48,070] INFO  {CodeGenerator} Code generated in 7.628913 ms
[16:28:48,084] INFO  {SparkContext} Starting job: count at LinearRegression.scala:643
[16:28:48,085] INFO  {DAGScheduler} Registering RDD 51 (count at LinearRegression.scala:643)
[16:28:48,085] INFO  {DAGScheduler} Got job 12 (count at LinearRegression.scala:643) with 1 output partitions
[16:28:48,085] INFO  {DAGScheduler} Final stage: ResultStage 15 (count at LinearRegression.scala:643)
[16:28:48,085] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 14)
[16:28:48,085] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 14)
[16:28:48,086] INFO  {DAGScheduler} Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643), which has no missing parents
[16:28:48,089] INFO  {MemoryStore} Block broadcast_15 stored as values in memory (estimated size 14.0 KB, free 1127.5 MB)
[16:28:48,090] INFO  {MemoryStore} Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1127.5 MB)
[16:28:48,091] INFO  {BlockManagerInfo} Added broadcast_15_piece0 in memory on 192.168.0.103:37391 (size: 6.8 KB, free: 1127.7 MB)
[16:28:48,092] INFO  {SparkContext} Created broadcast 15 from broadcast at DAGScheduler.scala:1012
[16:28:48,092] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643)
[16:28:48,092] INFO  {TaskSchedulerImpl} Adding task set 14.0 with 1 tasks
[16:28:48,093] INFO  {TaskSetManager} Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5979 bytes)
[16:28:48,094] INFO  {Executor} Running task 0.0 in stage 14.0 (TID 14)
[16:28:48,096] INFO  {BlockManager} Found block rdd_2_0 locally
[16:28:48,106] INFO  {CodeGenerator} Code generated in 9.162711 ms
[16:28:48,114] INFO  {Executor} Finished task 0.0 in stage 14.0 (TID 14). 2324 bytes result sent to driver
[16:28:48,115] INFO  {TaskSetManager} Finished task 0.0 in stage 14.0 (TID 14) in 23 ms on localhost (1/1)
[16:28:48,115] INFO  {TaskSchedulerImpl} Removed TaskSet 14.0, whose tasks have all completed, from pool 
[16:28:48,116] INFO  {DAGScheduler} ShuffleMapStage 14 (count at LinearRegression.scala:643) finished in 0.023 s
[16:28:48,116] INFO  {DAGScheduler} looking for newly runnable stages
[16:28:48,116] INFO  {DAGScheduler} running: Set()
[16:28:48,116] INFO  {DAGScheduler} waiting: Set(ResultStage 15)
[16:28:48,116] INFO  {DAGScheduler} failed: Set()
[16:28:48,116] INFO  {DAGScheduler} Submitting ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643), which has no missing parents
[16:28:48,118] INFO  {MemoryStore} Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 1127.5 MB)
[16:28:48,120] INFO  {MemoryStore} Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1127.5 MB)
[16:28:48,121] INFO  {BlockManagerInfo} Added broadcast_16_piece0 in memory on 192.168.0.103:37391 (size: 3.7 KB, free: 1127.7 MB)
[16:28:48,121] INFO  {SparkContext} Created broadcast 16 from broadcast at DAGScheduler.scala:1012
[16:28:48,121] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643)
[16:28:48,121] INFO  {TaskSchedulerImpl} Adding task set 15.0 with 1 tasks
[16:28:48,122] INFO  {TaskSetManager} Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, ANY, 5318 bytes)
[16:28:48,123] INFO  {Executor} Running task 0.0 in stage 15.0 (TID 15)
[16:28:48,125] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:28:48,126] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[16:28:48,128] INFO  {Executor} Finished task 0.0 in stage 15.0 (TID 15). 1873 bytes result sent to driver
[16:28:48,130] INFO  {TaskSetManager} Finished task 0.0 in stage 15.0 (TID 15) in 8 ms on localhost (1/1)
[16:28:48,130] INFO  {TaskSchedulerImpl} Removed TaskSet 15.0, whose tasks have all completed, from pool 
[16:28:48,130] INFO  {DAGScheduler} ResultStage 15 (count at LinearRegression.scala:643) finished in 0.008 s
[16:28:48,131] INFO  {DAGScheduler} Job 12 finished: count at LinearRegression.scala:643, took 0.046599 s
[16:28:48,139] INFO  {CodeGenerator} Code generated in 6.682832 ms
[16:28:48,262] INFO  {CodeGenerator} Code generated in 7.834079 ms
[16:28:48,273] INFO  {CodeGenerator} Code generated in 4.677932 ms
[16:28:48,277] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:28:48,282] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:28:48,284] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:28:48,284] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:28:48,285] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:28:48,285] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:28:48,285] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:28:48,285] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:28:48,285] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:28:48,285] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:28:48,285] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:28:48,285] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:28:48,285] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:28:48,286] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:28:48,286] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:28:48,286] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:28:48,286] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:28:48,286] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:28:48,286] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:28:48,286] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:28:48,286] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:28:48,287] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:28:48,287] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:28:48,287] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:28:48,287] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:28:48,287] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:28:48,289] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:28:48,302] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:28:48,316] INFO  {MemoryStore} MemoryStore cleared
[16:28:48,316] INFO  {BlockManager} BlockManager stopped
[16:28:48,318] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:28:48,323] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:28:48,334] INFO  {SparkContext} Successfully stopped SparkContext
[16:28:48,334] INFO  {ShutdownHookManager} Shutdown hook called
[16:28:48,335] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-e1fc8485-39e1-436d-ab4a-71a215c3fdcc
[16:29:14,355] INFO  {SparkContext} Running Spark version 2.0.1
[16:29:14,571] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:29:14,674] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:29:14,674] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:29:14,745] INFO  {SecurityManager} Changing view acls to: victor
[16:29:14,745] INFO  {SecurityManager} Changing modify acls to: victor
[16:29:14,746] INFO  {SecurityManager} Changing view acls groups to: 
[16:29:14,747] INFO  {SecurityManager} Changing modify acls groups to: 
[16:29:14,747] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:29:15,084] INFO  {Utils} Successfully started service 'sparkDriver' on port 45047.
[16:29:15,100] INFO  {SparkEnv} Registering MapOutputTracker
[16:29:15,114] INFO  {SparkEnv} Registering BlockManagerMaster
[16:29:15,126] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-77223428-42af-4cf3-ad0f-a5a17932f9d2
[16:29:15,140] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:29:15,191] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:29:15,261] INFO  {log} Logging initialized @1457ms
[16:29:15,365] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:29:15,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[16:29:15,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[16:29:15,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[16:29:15,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[16:29:15,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[16:29:15,381] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[16:29:15,381] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[16:29:15,381] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[16:29:15,381] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[16:29:15,381] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[16:29:15,381] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[16:29:15,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[16:29:15,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[16:29:15,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[16:29:15,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[16:29:15,382] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[16:29:15,383] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[16:29:15,383] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[16:29:15,383] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[16:29:15,383] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[16:29:15,389] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[16:29:15,389] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[16:29:15,390] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[16:29:15,390] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[16:29:15,396] INFO  {ServerConnector} Started ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:29:15,397] INFO  {Server} Started @1593ms
[16:29:15,397] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:29:15,399] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:29:15,475] INFO  {Executor} Starting executor ID driver on host localhost
[16:29:15,501] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33041.
[16:29:15,502] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:33041
[16:29:15,504] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 33041)
[16:29:15,507] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:33041 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 33041)
[16:29:15,510] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 33041)
[16:29:15,629] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[16:29:15,681] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL,null,AVAILABLE}
[16:29:15,681] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/json,null,AVAILABLE}
[16:29:15,682] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution,null,AVAILABLE}
[16:29:15,682] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b11ef33{/SQL/execution/json,null,AVAILABLE}
[16:29:15,684] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@21ec5d87{/static/sql,null,AVAILABLE}
[16:29:15,697] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:29:17,460] INFO  {FileSourceStrategy} Pruning directories with: 
[16:29:17,463] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:29:17,468] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:29:17,469] INFO  {FileSourceStrategy} Pushed Filters: 
[16:29:17,584] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:29:17,634] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:29:17,646] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:33041 (size: 14.6 KB, free: 1128.9 MB)
[16:29:17,653] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:29:17,656] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:29:18,117] INFO  {CodeGenerator} Code generated in 189.068632 ms
[16:29:18,309] INFO  {CodeGenerator} Code generated in 26.035119 ms
[16:29:18,355] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:29:18,373] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:29:18,373] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:29:18,374] INFO  {DAGScheduler} Parents of final stage: List()
[16:29:18,377] INFO  {DAGScheduler} Missing parents: List()
[16:29:18,381] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:29:18,444] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:29:18,446] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:29:18,446] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:33041 (size: 8.4 KB, free: 1128.9 MB)
[16:29:18,447] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:29:18,451] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:29:18,453] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:29:18,486] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:29:18,493] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:29:18,529] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:29:18,540] INFO  {CodeGenerator} Code generated in 7.972847 ms
[16:29:18,662] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:29:18,662] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:33041 (size: 1239.2 KB, free: 1127.7 MB)
[16:29:18,672] INFO  {CodeGenerator} Code generated in 4.021328 ms
[16:29:18,697] INFO  {CodeGenerator} Code generated in 19.212566 ms
[16:29:18,734] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:29:18,742] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:29:18,751] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 279 ms on localhost (1/1)
[16:29:18,752] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:29:18,755] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.294 s
[16:29:18,760] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.404214 s
[16:29:18,795] INFO  {CodeGenerator} Code generated in 21.641513 ms
[16:29:18,887] INFO  {CodeGenerator} Code generated in 27.737856 ms
[16:29:18,898] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:29:18,899] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:29:18,900] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:29:18,900] INFO  {DAGScheduler} Parents of final stage: List()
[16:29:18,902] INFO  {DAGScheduler} Missing parents: List()
[16:29:18,902] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:29:18,906] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:29:18,908] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:29:18,908] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:33041 (size: 10.0 KB, free: 1127.7 MB)
[16:29:18,909] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:29:18,909] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:29:18,909] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:29:18,915] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:29:18,916] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:29:18,929] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:18,947] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:29:18,948] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:29:18,950] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (1/1)
[16:29:18,950] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:29:18,951] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.037 s
[16:29:18,951] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.052572 s
[16:29:18,973] INFO  {CodeGenerator} Code generated in 14.887608 ms
[16:29:19,133] INFO  {ContextCleaner} Cleaned accumulator 3
[16:29:19,133] INFO  {ContextCleaner} Cleaned accumulator 4
[16:29:19,153] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:33041 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:29:19,156] INFO  {ContextCleaner} Cleaned accumulator 49
[16:29:19,156] INFO  {ContextCleaner} Cleaned accumulator 50
[16:29:19,159] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:33041 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:29:19,216] INFO  {CodeGenerator} Code generated in 42.346146 ms
[16:29:19,226] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:29:19,227] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:29:19,227] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:29:19,227] INFO  {DAGScheduler} Parents of final stage: List()
[16:29:19,228] INFO  {DAGScheduler} Missing parents: List()
[16:29:19,229] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:29:19,233] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:29:19,235] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:29:19,235] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:33041 (size: 11.7 KB, free: 1127.7 MB)
[16:29:19,236] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:29:19,236] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:29:19,236] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:29:19,238] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:29:19,238] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:29:19,245] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:19,254] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:29:19,255] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:29:19,257] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 19 ms on localhost (1/1)
[16:29:19,257] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:29:19,257] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.021 s
[16:29:19,258] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.031506 s
[16:29:19,274] INFO  {CodeGenerator} Code generated in 13.803799 ms
[16:29:19,368] INFO  {CodeGenerator} Code generated in 41.644929 ms
[16:29:19,379] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:29:19,380] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:29:19,380] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:29:19,380] INFO  {DAGScheduler} Parents of final stage: List()
[16:29:19,380] INFO  {DAGScheduler} Missing parents: List()
[16:29:19,381] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:29:19,384] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:29:19,386] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:29:19,386] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:33041 (size: 13.3 KB, free: 1127.7 MB)
[16:29:19,387] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:29:19,387] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:29:19,387] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:29:19,389] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:29:19,389] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:29:19,396] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:19,404] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:29:19,405] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:29:19,407] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 19 ms on localhost (1/1)
[16:29:19,407] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:29:19,407] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.020 s
[16:29:19,408] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.028498 s
[16:29:19,424] INFO  {CodeGenerator} Code generated in 13.881621 ms
[16:29:19,531] INFO  {CodeGenerator} Code generated in 12.129735 ms
[16:29:19,557] INFO  {CodeGenerator} Code generated in 19.350682 ms
[16:29:19,594] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:29:19,597] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:29:19,597] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:29:19,597] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:29:19,597] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:29:19,598] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:29:19,599] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:29:19,605] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:29:19,607] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:29:19,608] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:33041 (size: 10.1 KB, free: 1127.6 MB)
[16:29:19,608] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:29:19,610] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:29:19,610] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:29:19,612] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:29:19,613] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:29:19,619] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:19,880] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:29:19,884] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 272 ms on localhost (1/1)
[16:29:19,884] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:29:19,885] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.275 s
[16:29:19,886] INFO  {DAGScheduler} looking for newly runnable stages
[16:29:19,887] INFO  {DAGScheduler} running: Set()
[16:29:19,887] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:29:19,888] INFO  {DAGScheduler} failed: Set()
[16:29:19,889] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:29:19,894] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:29:19,896] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:29:19,897] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:33041 (size: 3.9 KB, free: 1127.6 MB)
[16:29:19,897] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:29:19,898] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:29:19,898] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:29:19,901] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:29:19,902] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:29:19,913] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:29:19,914] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[16:29:19,927] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:29:19,928] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 29 ms on localhost (1/1)
[16:29:19,928] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:29:19,928] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.029 s
[16:29:19,929] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.334793 s
[16:29:19,939] INFO  {CodeGenerator} Code generated in 7.05523 ms
[16:29:19,978] INFO  {CodeGenerator} Code generated in 8.212662 ms
[16:29:19,998] INFO  {CodeGenerator} Code generated in 15.4447 ms
[16:29:20,011] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:29:20,012] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:29:20,012] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:29:20,013] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:29:20,013] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:29:20,013] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:29:20,014] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:29:20,018] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:29:20,020] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:29:20,021] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:33041 (size: 10.1 KB, free: 1127.6 MB)
[16:29:20,021] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:29:20,022] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:29:20,022] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:29:20,024] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:29:20,025] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:29:20,030] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:20,100] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:33041 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:29:20,101] INFO  {ContextCleaner} Cleaned accumulator 288
[16:29:20,102] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:33041 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:29:20,103] INFO  {ContextCleaner} Cleaned accumulator 191
[16:29:20,103] INFO  {ContextCleaner} Cleaned accumulator 192
[16:29:20,103] INFO  {ContextCleaner} Cleaned accumulator 193
[16:29:20,103] INFO  {ContextCleaner} Cleaned accumulator 194
[16:29:20,103] INFO  {ContextCleaner} Cleaned accumulator 195
[16:29:20,103] INFO  {ContextCleaner} Cleaned accumulator 196
[16:29:20,103] INFO  {ContextCleaner} Cleaned accumulator 197
[16:29:20,103] INFO  {ContextCleaner} Cleaned accumulator 198
[16:29:20,103] INFO  {ContextCleaner} Cleaned accumulator 199
[16:29:20,107] INFO  {ContextCleaner} Cleaned shuffle 0
[16:29:20,107] INFO  {ContextCleaner} Cleaned accumulator 96
[16:29:20,107] INFO  {ContextCleaner} Cleaned accumulator 95
[16:29:20,109] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:33041 in memory (size: 11.7 KB, free: 1127.7 MB)
[16:29:20,109] INFO  {ContextCleaner} Cleaned accumulator 141
[16:29:20,109] INFO  {ContextCleaner} Cleaned accumulator 142
[16:29:20,110] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:33041 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:29:20,111] INFO  {ContextCleaner} Cleaned accumulator 187
[16:29:20,111] INFO  {ContextCleaner} Cleaned accumulator 188
[16:29:20,111] INFO  {ContextCleaner} Cleaned accumulator 189
[16:29:20,111] INFO  {ContextCleaner} Cleaned accumulator 190
[16:29:20,174] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2484 bytes result sent to driver
[16:29:20,175] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 152 ms on localhost (1/1)
[16:29:20,175] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:29:20,176] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.154 s
[16:29:20,176] INFO  {DAGScheduler} looking for newly runnable stages
[16:29:20,176] INFO  {DAGScheduler} running: Set()
[16:29:20,176] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:29:20,176] INFO  {DAGScheduler} failed: Set()
[16:29:20,177] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:29:20,179] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:29:20,181] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:29:20,181] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:33041 (size: 3.9 KB, free: 1127.7 MB)
[16:29:20,182] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:29:20,182] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:29:20,182] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:29:20,183] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:29:20,184] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:29:20,186] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:29:20,186] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:29:20,189] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:29:20,189] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 7 ms on localhost (1/1)
[16:29:20,190] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:29:20,190] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.008 s
[16:29:20,190] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.178741 s
[16:29:20,318] INFO  {CodeGenerator} Code generated in 57.671475 ms
[16:29:20,327] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:29:20,327] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:29:20,327] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:29:20,328] INFO  {DAGScheduler} Parents of final stage: List()
[16:29:20,328] INFO  {DAGScheduler} Missing parents: List()
[16:29:20,328] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:29:20,332] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:29:20,334] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:29:20,334] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:33041 (size: 15.0 KB, free: 1127.6 MB)
[16:29:20,335] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:29:20,335] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:29:20,335] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:29:20,338] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:29:20,338] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:29:20,344] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:20,350] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:29:20,350] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:29:20,352] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 16 ms on localhost (1/1)
[16:29:20,352] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:29:20,353] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.016 s
[16:29:20,353] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.026212 s
[16:29:20,373] INFO  {CodeGenerator} Code generated in 17.3116 ms
[16:29:20,515] INFO  {CodeGenerator} Code generated in 62.531478 ms
[16:29:20,525] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:29:20,526] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:29:20,526] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:29:20,526] INFO  {DAGScheduler} Parents of final stage: List()
[16:29:20,526] INFO  {DAGScheduler} Missing parents: List()
[16:29:20,527] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:29:20,529] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:29:20,531] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:29:20,532] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:33041 (size: 16.4 KB, free: 1127.6 MB)
[16:29:20,532] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:29:20,533] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:29:20,533] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:29:20,534] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:29:20,535] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:29:20,541] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:20,549] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:29:20,549] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:29:20,550] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 17 ms on localhost (1/1)
[16:29:20,551] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:29:20,551] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.018 s
[16:29:20,551] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.025945 s
[16:29:20,565] INFO  {CodeGenerator} Code generated in 11.371534 ms
[16:29:20,691] INFO  {CodeGenerator} Code generated in 13.39697 ms
[16:29:20,699] INFO  {SparkContext} Starting job: first at LinearRegression.scala:163
[16:29:20,699] INFO  {DAGScheduler} Got job 8 (first at LinearRegression.scala:163) with 1 output partitions
[16:29:20,699] INFO  {DAGScheduler} Final stage: ResultStage 10 (first at LinearRegression.scala:163)
[16:29:20,700] INFO  {DAGScheduler} Parents of final stage: List()
[16:29:20,700] INFO  {DAGScheduler} Missing parents: List()
[16:29:20,700] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163), which has no missing parents
[16:29:20,703] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 24.2 KB, free 1127.3 MB)
[16:29:20,705] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1127.3 MB)
[16:29:20,706] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:33041 (size: 9.7 KB, free: 1127.6 MB)
[16:29:20,706] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[16:29:20,706] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163)
[16:29:20,706] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[16:29:20,708] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:29:20,708] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[16:29:20,713] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:20,716] WARN  {Executor} 1 block locks were not released by TID = 10:
[rdd_2_0]
[16:29:20,717] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 1844 bytes result sent to driver
[16:29:20,718] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 11 ms on localhost (1/1)
[16:29:20,718] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[16:29:20,718] INFO  {DAGScheduler} ResultStage 10 (first at LinearRegression.scala:163) finished in 0.011 s
[16:29:20,719] INFO  {DAGScheduler} Job 8 finished: first at LinearRegression.scala:163, took 0.019991 s
[16:29:20,725] INFO  {CodeGenerator} Code generated in 4.861715 ms
[16:29:20,824] INFO  {CodeGenerator} Code generated in 26.403943 ms
[16:29:20,881] INFO  {SparkContext} Starting job: treeAggregate at WeightedLeastSquares.scala:81
[16:29:20,882] INFO  {DAGScheduler} Got job 9 (treeAggregate at WeightedLeastSquares.scala:81) with 1 output partitions
[16:29:20,882] INFO  {DAGScheduler} Final stage: ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81)
[16:29:20,882] INFO  {DAGScheduler} Parents of final stage: List()
[16:29:20,883] INFO  {DAGScheduler} Missing parents: List()
[16:29:20,883] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81), which has no missing parents
[16:29:20,886] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 42.1 KB, free 1127.3 MB)
[16:29:20,887] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.3 MB)
[16:29:20,888] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:33041 (size: 14.4 KB, free: 1127.6 MB)
[16:29:20,888] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[16:29:20,889] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81)
[16:29:20,889] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[16:29:20,890] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5967 bytes)
[16:29:20,891] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[16:29:20,898] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:20,914] INFO  {CodeGenerator} Code generated in 10.325009 ms
[16:29:20,927] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
[16:29:20,928] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[16:29:21,005] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 192.168.0.103:33041 in memory (size: 15.0 KB, free: 1127.6 MB)
[16:29:21,006] INFO  {ContextCleaner} Cleaned accumulator 435
[16:29:21,006] INFO  {ContextCleaner} Cleaned accumulator 436
[16:29:21,007] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 192.168.0.103:33041 in memory (size: 16.4 KB, free: 1127.6 MB)
[16:29:21,008] INFO  {ContextCleaner} Cleaned accumulator 481
[16:29:21,008] INFO  {ContextCleaner} Cleaned accumulator 482
[16:29:21,009] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 192.168.0.103:33041 in memory (size: 9.7 KB, free: 1127.6 MB)
[16:29:21,010] INFO  {ContextCleaner} Cleaned accumulator 293
[16:29:21,010] INFO  {ContextCleaner} Cleaned accumulator 294
[16:29:21,010] INFO  {ContextCleaner} Cleaned accumulator 295
[16:29:21,010] INFO  {ContextCleaner} Cleaned accumulator 296
[16:29:21,010] INFO  {ContextCleaner} Cleaned accumulator 297
[16:29:21,010] INFO  {ContextCleaner} Cleaned accumulator 298
[16:29:21,010] INFO  {ContextCleaner} Cleaned accumulator 299
[16:29:21,010] INFO  {ContextCleaner} Cleaned accumulator 300
[16:29:21,011] INFO  {ContextCleaner} Cleaned shuffle 1
[16:29:21,012] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:33041 in memory (size: 10.1 KB, free: 1127.7 MB)
[16:29:21,013] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:33041 in memory (size: 3.9 KB, free: 1127.7 MB)
[16:29:21,014] INFO  {ContextCleaner} Cleaned accumulator 389
[16:29:21,014] INFO  {ContextCleaner} Cleaned accumulator 390
[16:29:21,014] INFO  {ContextCleaner} Cleaned accumulator 289
[16:29:21,014] INFO  {ContextCleaner} Cleaned accumulator 290
[16:29:21,014] INFO  {ContextCleaner} Cleaned accumulator 291
[16:29:21,014] INFO  {ContextCleaner} Cleaned accumulator 292
[16:29:21,206] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 2430 bytes result sent to driver
[16:29:21,208] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 318 ms on localhost (1/1)
[16:29:21,208] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[16:29:21,208] INFO  {DAGScheduler} ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81) finished in 0.319 s
[16:29:21,209] INFO  {DAGScheduler} Job 9 finished: treeAggregate at WeightedLeastSquares.scala:81, took 0.327066 s
[16:29:21,211] INFO  {WeightedLeastSquares} Number of instances: 6724.
[16:29:21,217] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
[16:29:21,217] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[16:29:21,510] INFO  {CodeGenerator} Code generated in 19.917045 ms
[16:29:21,541] INFO  {SparkContext} Starting job: aggregate at RegressionMetrics.scala:57
[16:29:21,541] INFO  {DAGScheduler} Got job 10 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
[16:29:21,541] INFO  {DAGScheduler} Final stage: ResultStage 12 (aggregate at RegressionMetrics.scala:57)
[16:29:21,541] INFO  {DAGScheduler} Parents of final stage: List()
[16:29:21,542] INFO  {DAGScheduler} Missing parents: List()
[16:29:21,542] INFO  {DAGScheduler} Submitting ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55), which has no missing parents
[16:29:21,545] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 41.1 KB, free 1127.5 MB)
[16:29:21,546] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1127.4 MB)
[16:29:21,546] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 192.168.0.103:33041 (size: 14.5 KB, free: 1127.6 MB)
[16:29:21,547] INFO  {SparkContext} Created broadcast 13 from broadcast at DAGScheduler.scala:1012
[16:29:21,547] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55)
[16:29:21,547] INFO  {TaskSchedulerImpl} Adding task set 12.0 with 1 tasks
[16:29:21,548] INFO  {TaskSetManager} Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5963 bytes)
[16:29:21,549] INFO  {Executor} Running task 0.0 in stage 12.0 (TID 12)
[16:29:21,553] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:21,561] INFO  {CodeGenerator} Code generated in 4.619281 ms
[16:29:21,659] INFO  {BlockManagerInfo} Removed broadcast_12_piece0 on 192.168.0.103:33041 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:29:21,834] INFO  {Executor} Finished task 0.0 in stage 12.0 (TID 12). 2281 bytes result sent to driver
[16:29:21,835] INFO  {TaskSetManager} Finished task 0.0 in stage 12.0 (TID 12) in 287 ms on localhost (1/1)
[16:29:21,835] INFO  {TaskSchedulerImpl} Removed TaskSet 12.0, whose tasks have all completed, from pool 
[16:29:21,835] INFO  {DAGScheduler} ResultStage 12 (aggregate at RegressionMetrics.scala:57) finished in 0.288 s
[16:29:21,836] INFO  {DAGScheduler} Job 10 finished: aggregate at RegressionMetrics.scala:57, took 0.295159 s
[16:29:21,848] INFO  {SparkContext} Starting job: sum at RegressionMetrics.scala:71
[16:29:21,849] INFO  {DAGScheduler} Got job 11 (sum at RegressionMetrics.scala:71) with 1 output partitions
[16:29:21,849] INFO  {DAGScheduler} Final stage: ResultStage 13 (sum at RegressionMetrics.scala:71)
[16:29:21,849] INFO  {DAGScheduler} Parents of final stage: List()
[16:29:21,850] INFO  {DAGScheduler} Missing parents: List()
[16:29:21,850] INFO  {DAGScheduler} Submitting ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69), which has no missing parents
[16:29:21,852] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 40.7 KB, free 1127.5 MB)
[16:29:21,854] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.4 MB)
[16:29:21,854] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 192.168.0.103:33041 (size: 14.4 KB, free: 1127.6 MB)
[16:29:21,855] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[16:29:21,855] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69)
[16:29:21,855] INFO  {TaskSchedulerImpl} Adding task set 13.0 with 1 tasks
[16:29:21,856] INFO  {TaskSetManager} Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[16:29:21,856] INFO  {Executor} Running task 0.0 in stage 13.0 (TID 13)
[16:29:21,861] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:21,963] INFO  {BlockManagerInfo} Removed broadcast_13_piece0 on 192.168.0.103:33041 in memory (size: 14.5 KB, free: 1127.7 MB)
[16:29:22,059] INFO  {Executor} Finished task 0.0 in stage 13.0 (TID 13). 1859 bytes result sent to driver
[16:29:22,060] INFO  {TaskSetManager} Finished task 0.0 in stage 13.0 (TID 13) in 205 ms on localhost (1/1)
[16:29:22,060] INFO  {TaskSchedulerImpl} Removed TaskSet 13.0, whose tasks have all completed, from pool 
[16:29:22,061] INFO  {DAGScheduler} ResultStage 13 (sum at RegressionMetrics.scala:71) finished in 0.206 s
[16:29:22,061] INFO  {DAGScheduler} Job 11 finished: sum at RegressionMetrics.scala:71, took 0.212580 s
[16:29:22,103] INFO  {CodeGenerator} Code generated in 6.289322 ms
[16:29:22,111] INFO  {CodeGenerator} Code generated in 5.566858 ms
[16:29:22,124] INFO  {SparkContext} Starting job: count at LinearRegression.scala:643
[16:29:22,125] INFO  {DAGScheduler} Registering RDD 51 (count at LinearRegression.scala:643)
[16:29:22,125] INFO  {DAGScheduler} Got job 12 (count at LinearRegression.scala:643) with 1 output partitions
[16:29:22,125] INFO  {DAGScheduler} Final stage: ResultStage 15 (count at LinearRegression.scala:643)
[16:29:22,126] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 14)
[16:29:22,126] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 14)
[16:29:22,126] INFO  {DAGScheduler} Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643), which has no missing parents
[16:29:22,128] INFO  {MemoryStore} Block broadcast_15 stored as values in memory (estimated size 14.0 KB, free 1127.5 MB)
[16:29:22,130] INFO  {MemoryStore} Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1127.5 MB)
[16:29:22,130] INFO  {BlockManagerInfo} Added broadcast_15_piece0 in memory on 192.168.0.103:33041 (size: 6.8 KB, free: 1127.7 MB)
[16:29:22,131] INFO  {SparkContext} Created broadcast 15 from broadcast at DAGScheduler.scala:1012
[16:29:22,131] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643)
[16:29:22,131] INFO  {TaskSchedulerImpl} Adding task set 14.0 with 1 tasks
[16:29:22,132] INFO  {TaskSetManager} Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5979 bytes)
[16:29:22,132] INFO  {Executor} Running task 0.0 in stage 14.0 (TID 14)
[16:29:22,135] INFO  {BlockManager} Found block rdd_2_0 locally
[16:29:22,145] INFO  {CodeGenerator} Code generated in 8.889669 ms
[16:29:22,151] INFO  {Executor} Finished task 0.0 in stage 14.0 (TID 14). 2324 bytes result sent to driver
[16:29:22,152] INFO  {TaskSetManager} Finished task 0.0 in stage 14.0 (TID 14) in 21 ms on localhost (1/1)
[16:29:22,152] INFO  {TaskSchedulerImpl} Removed TaskSet 14.0, whose tasks have all completed, from pool 
[16:29:22,152] INFO  {DAGScheduler} ShuffleMapStage 14 (count at LinearRegression.scala:643) finished in 0.021 s
[16:29:22,153] INFO  {DAGScheduler} looking for newly runnable stages
[16:29:22,153] INFO  {DAGScheduler} running: Set()
[16:29:22,153] INFO  {DAGScheduler} waiting: Set(ResultStage 15)
[16:29:22,153] INFO  {DAGScheduler} failed: Set()
[16:29:22,153] INFO  {DAGScheduler} Submitting ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643), which has no missing parents
[16:29:22,155] INFO  {MemoryStore} Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 1127.5 MB)
[16:29:22,157] INFO  {MemoryStore} Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1127.5 MB)
[16:29:22,157] INFO  {BlockManagerInfo} Added broadcast_16_piece0 in memory on 192.168.0.103:33041 (size: 3.7 KB, free: 1127.7 MB)
[16:29:22,158] INFO  {SparkContext} Created broadcast 16 from broadcast at DAGScheduler.scala:1012
[16:29:22,158] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643)
[16:29:22,158] INFO  {TaskSchedulerImpl} Adding task set 15.0 with 1 tasks
[16:29:22,159] INFO  {TaskSetManager} Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, ANY, 5318 bytes)
[16:29:22,159] INFO  {Executor} Running task 0.0 in stage 15.0 (TID 15)
[16:29:22,162] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:29:22,162] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:29:22,165] INFO  {Executor} Finished task 0.0 in stage 15.0 (TID 15). 1873 bytes result sent to driver
[16:29:22,166] INFO  {TaskSetManager} Finished task 0.0 in stage 15.0 (TID 15) in 8 ms on localhost (1/1)
[16:29:22,166] INFO  {TaskSchedulerImpl} Removed TaskSet 15.0, whose tasks have all completed, from pool 
[16:29:22,166] INFO  {DAGScheduler} ResultStage 15 (count at LinearRegression.scala:643) finished in 0.008 s
[16:29:22,167] INFO  {DAGScheduler} Job 12 finished: count at LinearRegression.scala:643, took 0.041873 s
[16:29:22,173] INFO  {CodeGenerator} Code generated in 4.604921 ms
[16:29:22,323] INFO  {CodeGenerator} Code generated in 9.68283 ms
[16:29:22,335] INFO  {CodeGenerator} Code generated in 4.94586 ms
[16:29:22,339] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:29:22,343] INFO  {ServerConnector} Stopped ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:29:22,345] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[16:29:22,345] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[16:29:22,345] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[16:29:22,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[16:29:22,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[16:29:22,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[16:29:22,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[16:29:22,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[16:29:22,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[16:29:22,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[16:29:22,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[16:29:22,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[16:29:22,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[16:29:22,349] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:29:22,359] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:29:22,368] INFO  {MemoryStore} MemoryStore cleared
[16:29:22,369] INFO  {BlockManager} BlockManager stopped
[16:29:22,371] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:29:22,374] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:29:22,377] INFO  {SparkContext} Successfully stopped SparkContext
[16:29:22,378] INFO  {ShutdownHookManager} Shutdown hook called
[16:29:22,379] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-3c74e3d5-96dd-400b-abbc-18d3ded9a48f
[16:29:59,202] INFO  {SparkContext} Running Spark version 2.0.1
[16:29:59,452] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:29:59,545] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:29:59,545] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:29:59,613] INFO  {SecurityManager} Changing view acls to: victor
[16:29:59,614] INFO  {SecurityManager} Changing modify acls to: victor
[16:29:59,615] INFO  {SecurityManager} Changing view acls groups to: 
[16:29:59,616] INFO  {SecurityManager} Changing modify acls groups to: 
[16:29:59,616] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:29:59,962] INFO  {Utils} Successfully started service 'sparkDriver' on port 35645.
[16:29:59,982] INFO  {SparkEnv} Registering MapOutputTracker
[16:29:59,996] INFO  {SparkEnv} Registering BlockManagerMaster
[16:30:00,008] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e36adcd9-b0cb-45e1-b729-221d1313aecf
[16:30:00,022] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:30:00,071] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:30:00,141] INFO  {log} Logging initialized @1582ms
[16:30:00,246] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:30:00,262] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:30:00,262] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:30:00,263] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:30:00,263] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:30:00,263] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:30:00,263] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:30:00,264] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:30:00,264] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:30:00,264] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:30:00,264] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:30:00,265] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:30:00,265] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:30:00,265] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:30:00,266] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:30:00,266] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:30:00,266] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:30:00,266] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:30:00,267] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:30:00,267] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:30:00,267] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:30:00,276] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:30:00,276] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:30:00,277] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:30:00,278] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:30:00,286] INFO  {ServerConnector} Started ServerConnector@372d0aa1{HTTP/1.1}{0.0.0.0:4040}
[16:30:00,286] INFO  {Server} Started @1728ms
[16:30:00,286] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:30:00,289] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:30:00,384] INFO  {Executor} Starting executor ID driver on host localhost
[16:30:00,406] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33945.
[16:30:00,407] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:33945
[16:30:00,409] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 33945)
[16:30:00,412] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:33945 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 33945)
[16:30:00,415] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 33945)
[16:30:00,533] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:30:00,587] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:30:00,587] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:30:00,588] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:30:00,588] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:30:00,590] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:30:00,602] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:30:02,372] INFO  {FileSourceStrategy} Pruning directories with: 
[16:30:02,375] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:30:02,380] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:30:02,381] INFO  {FileSourceStrategy} Pushed Filters: 
[16:30:02,490] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:30:02,538] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:30:02,540] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:33945 (size: 14.6 KB, free: 1128.9 MB)
[16:30:02,546] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:30:02,550] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:30:02,993] INFO  {CodeGenerator} Code generated in 193.54525 ms
[16:30:03,192] INFO  {CodeGenerator} Code generated in 26.789555 ms
[16:30:03,238] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:30:03,254] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:30:03,254] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:30:03,255] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:03,259] INFO  {DAGScheduler} Missing parents: List()
[16:30:03,263] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:30:03,321] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:30:03,323] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:30:03,324] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:33945 (size: 8.4 KB, free: 1128.9 MB)
[16:30:03,324] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:30:03,327] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:30:03,329] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:30:03,366] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:03,376] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:30:03,427] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:30:03,441] INFO  {CodeGenerator} Code generated in 10.991515 ms
[16:30:03,573] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:30:03,575] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:33945 (size: 1239.2 KB, free: 1127.7 MB)
[16:30:03,585] INFO  {CodeGenerator} Code generated in 4.255793 ms
[16:30:03,610] INFO  {CodeGenerator} Code generated in 18.974075 ms
[16:30:03,629] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:30:03,635] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:30:03,649] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 298 ms on localhost (1/1)
[16:30:03,650] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:30:03,653] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.312 s
[16:30:03,658] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.420158 s
[16:30:03,698] INFO  {CodeGenerator} Code generated in 20.858561 ms
[16:30:03,787] INFO  {CodeGenerator} Code generated in 28.253531 ms
[16:30:03,799] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:30:03,800] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:30:03,800] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:30:03,800] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:03,803] INFO  {DAGScheduler} Missing parents: List()
[16:30:03,804] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:30:03,809] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:30:03,811] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:30:03,812] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:33945 (size: 10.0 KB, free: 1127.7 MB)
[16:30:03,812] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:30:03,813] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:30:03,813] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:30:03,818] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:03,819] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:30:03,828] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:03,841] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:30:03,842] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:30:03,844] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[16:30:03,844] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:30:03,844] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.028 s
[16:30:03,845] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.045641 s
[16:30:03,867] INFO  {CodeGenerator} Code generated in 14.586842 ms
[16:30:04,069] INFO  {ContextCleaner} Cleaned accumulator 3
[16:30:04,069] INFO  {ContextCleaner} Cleaned accumulator 4
[16:30:04,084] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:33945 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:30:04,086] INFO  {ContextCleaner} Cleaned accumulator 49
[16:30:04,087] INFO  {ContextCleaner} Cleaned accumulator 50
[16:30:04,088] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:33945 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:30:04,142] INFO  {CodeGenerator} Code generated in 52.440855 ms
[16:30:04,158] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:30:04,159] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:30:04,160] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:30:04,160] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:04,161] INFO  {DAGScheduler} Missing parents: List()
[16:30:04,161] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:30:04,166] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:30:04,168] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:30:04,169] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:33945 (size: 11.7 KB, free: 1127.7 MB)
[16:30:04,169] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:30:04,169] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:30:04,170] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:30:04,172] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:04,173] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:30:04,180] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:04,193] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:30:04,194] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:30:04,196] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on localhost (1/1)
[16:30:04,196] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:30:04,196] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.026 s
[16:30:04,197] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.038828 s
[16:30:04,223] INFO  {CodeGenerator} Code generated in 22.044616 ms
[16:30:04,359] INFO  {CodeGenerator} Code generated in 59.51365 ms
[16:30:04,375] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:30:04,376] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:30:04,377] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:30:04,377] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:04,377] INFO  {DAGScheduler} Missing parents: List()
[16:30:04,378] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:30:04,382] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:30:04,384] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:30:04,385] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:33945 (size: 13.3 KB, free: 1127.7 MB)
[16:30:04,386] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:30:04,386] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:30:04,386] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:30:04,388] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:04,388] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:30:04,395] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:04,403] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:30:04,404] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4099 bytes result sent to driver
[16:30:04,406] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 18 ms on localhost (1/1)
[16:30:04,406] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:30:04,406] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.018 s
[16:30:04,407] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.031356 s
[16:30:04,425] INFO  {CodeGenerator} Code generated in 14.574307 ms
[16:30:04,540] INFO  {CodeGenerator} Code generated in 12.676159 ms
[16:30:04,562] INFO  {CodeGenerator} Code generated in 16.19334 ms
[16:30:04,596] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:30:04,599] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:30:04,600] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:30:04,601] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:30:04,601] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:30:04,601] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:30:04,603] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:30:04,610] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:30:04,612] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:30:04,613] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:33945 (size: 10.1 KB, free: 1127.6 MB)
[16:30:04,613] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:30:04,616] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:30:04,616] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:30:04,618] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:30:04,619] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:30:04,625] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:04,888] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2324 bytes result sent to driver
[16:30:04,890] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 273 ms on localhost (1/1)
[16:30:04,890] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:30:04,891] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.275 s
[16:30:04,892] INFO  {DAGScheduler} looking for newly runnable stages
[16:30:04,892] INFO  {DAGScheduler} running: Set()
[16:30:04,893] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:30:04,893] INFO  {DAGScheduler} failed: Set()
[16:30:04,895] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:30:04,899] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:30:04,901] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:30:04,902] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:33945 (size: 3.9 KB, free: 1127.6 MB)
[16:30:04,902] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:30:04,903] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:30:04,903] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:30:04,906] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:30:04,906] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:30:04,919] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:30:04,920] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[16:30:04,933] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:30:04,934] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 30 ms on localhost (1/1)
[16:30:04,934] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:30:04,934] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.030 s
[16:30:04,934] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.338465 s
[16:30:04,945] INFO  {CodeGenerator} Code generated in 6.739013 ms
[16:30:04,985] INFO  {CodeGenerator} Code generated in 8.563592 ms
[16:30:05,004] INFO  {CodeGenerator} Code generated in 14.925523 ms
[16:30:05,018] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:30:05,019] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:30:05,019] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:30:05,019] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:30:05,019] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:30:05,019] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:30:05,020] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:30:05,023] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:30:05,025] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:30:05,025] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:33945 (size: 10.1 KB, free: 1127.6 MB)
[16:30:05,026] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:30:05,026] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:30:05,026] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:30:05,028] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:30:05,028] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:30:05,034] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:05,094] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:33945 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:30:05,095] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:33945 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:30:05,096] INFO  {ContextCleaner} Cleaned accumulator 187
[16:30:05,096] INFO  {ContextCleaner} Cleaned accumulator 188
[16:30:05,096] INFO  {ContextCleaner} Cleaned accumulator 189
[16:30:05,096] INFO  {ContextCleaner} Cleaned accumulator 190
[16:30:05,096] INFO  {ContextCleaner} Cleaned accumulator 191
[16:30:05,097] INFO  {ContextCleaner} Cleaned accumulator 192
[16:30:05,097] INFO  {ContextCleaner} Cleaned accumulator 193
[16:30:05,097] INFO  {ContextCleaner} Cleaned accumulator 194
[16:30:05,097] INFO  {ContextCleaner} Cleaned accumulator 195
[16:30:05,097] INFO  {ContextCleaner} Cleaned accumulator 196
[16:30:05,097] INFO  {ContextCleaner} Cleaned accumulator 197
[16:30:05,098] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:33945 in memory (size: 3.9 KB, free: 1127.7 MB)
[16:30:05,099] INFO  {ContextCleaner} Cleaned accumulator 288
[16:30:05,099] INFO  {ContextCleaner} Cleaned accumulator 198
[16:30:05,099] INFO  {ContextCleaner} Cleaned accumulator 199
[16:30:05,104] INFO  {ContextCleaner} Cleaned shuffle 0
[16:30:05,105] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:33945 in memory (size: 11.7 KB, free: 1127.7 MB)
[16:30:05,105] INFO  {ContextCleaner} Cleaned accumulator 141
[16:30:05,106] INFO  {ContextCleaner} Cleaned accumulator 142
[16:30:05,165] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:30:05,166] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 140 ms on localhost (1/1)
[16:30:05,166] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:30:05,167] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.141 s
[16:30:05,167] INFO  {DAGScheduler} looking for newly runnable stages
[16:30:05,167] INFO  {DAGScheduler} running: Set()
[16:30:05,167] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:30:05,167] INFO  {DAGScheduler} failed: Set()
[16:30:05,168] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:30:05,170] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:30:05,171] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:30:05,172] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:33945 (size: 3.9 KB, free: 1127.7 MB)
[16:30:05,172] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:30:05,173] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:30:05,173] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:30:05,174] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:30:05,175] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:30:05,177] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:30:05,177] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:30:05,180] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:30:05,181] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (1/1)
[16:30:05,181] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:30:05,181] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.007 s
[16:30:05,181] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.163260 s
[16:30:05,277] INFO  {CodeGenerator} Code generated in 40.995318 ms
[16:30:05,286] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:30:05,286] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:30:05,287] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:30:05,287] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:05,287] INFO  {DAGScheduler} Missing parents: List()
[16:30:05,287] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:30:05,290] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:30:05,292] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:30:05,292] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:33945 (size: 15.0 KB, free: 1127.6 MB)
[16:30:05,292] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:30:05,293] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:30:05,293] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:30:05,295] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:05,295] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:30:05,300] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:05,306] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:30:05,306] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:30:05,307] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 14 ms on localhost (1/1)
[16:30:05,308] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:30:05,308] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.015 s
[16:30:05,309] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.022591 s
[16:30:05,322] INFO  {CodeGenerator} Code generated in 11.610502 ms
[16:30:05,423] INFO  {CodeGenerator} Code generated in 49.086801 ms
[16:30:05,432] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:30:05,433] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:30:05,433] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:30:05,433] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:05,433] INFO  {DAGScheduler} Missing parents: List()
[16:30:05,434] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:30:05,437] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:30:05,438] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:30:05,440] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:33945 (size: 16.4 KB, free: 1127.6 MB)
[16:30:05,440] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:30:05,440] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:30:05,440] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:30:05,442] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:05,442] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:30:05,447] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:05,453] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:30:05,454] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4170 bytes result sent to driver
[16:30:05,455] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 14 ms on localhost (1/1)
[16:30:05,455] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:30:05,456] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.015 s
[16:30:05,456] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.024382 s
[16:30:05,471] INFO  {CodeGenerator} Code generated in 12.709013 ms
[16:30:05,601] INFO  {CodeGenerator} Code generated in 14.611935 ms
[16:30:05,609] INFO  {SparkContext} Starting job: first at LinearRegression.scala:163
[16:30:05,609] INFO  {DAGScheduler} Got job 8 (first at LinearRegression.scala:163) with 1 output partitions
[16:30:05,610] INFO  {DAGScheduler} Final stage: ResultStage 10 (first at LinearRegression.scala:163)
[16:30:05,610] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:05,610] INFO  {DAGScheduler} Missing parents: List()
[16:30:05,611] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163), which has no missing parents
[16:30:05,613] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 24.2 KB, free 1127.3 MB)
[16:30:05,615] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1127.3 MB)
[16:30:05,616] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:33945 (size: 9.7 KB, free: 1127.6 MB)
[16:30:05,616] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[16:30:05,616] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163)
[16:30:05,617] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[16:30:05,618] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:05,619] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[16:30:05,622] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:05,625] WARN  {Executor} 1 block locks were not released by TID = 10:
[rdd_2_0]
[16:30:05,625] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 1844 bytes result sent to driver
[16:30:05,626] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 9 ms on localhost (1/1)
[16:30:05,626] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[16:30:05,627] INFO  {DAGScheduler} ResultStage 10 (first at LinearRegression.scala:163) finished in 0.010 s
[16:30:05,627] INFO  {DAGScheduler} Job 8 finished: first at LinearRegression.scala:163, took 0.018441 s
[16:30:05,633] INFO  {CodeGenerator} Code generated in 4.698492 ms
[16:30:05,731] INFO  {CodeGenerator} Code generated in 27.34038 ms
[16:30:05,789] INFO  {SparkContext} Starting job: treeAggregate at WeightedLeastSquares.scala:81
[16:30:05,790] INFO  {DAGScheduler} Got job 9 (treeAggregate at WeightedLeastSquares.scala:81) with 1 output partitions
[16:30:05,790] INFO  {DAGScheduler} Final stage: ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81)
[16:30:05,790] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:05,791] INFO  {DAGScheduler} Missing parents: List()
[16:30:05,791] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81), which has no missing parents
[16:30:05,794] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 42.1 KB, free 1127.3 MB)
[16:30:05,796] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.3 MB)
[16:30:05,797] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:33945 (size: 14.4 KB, free: 1127.6 MB)
[16:30:05,797] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[16:30:05,797] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81)
[16:30:05,797] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[16:30:05,799] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5967 bytes)
[16:30:05,799] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[16:30:05,804] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:05,814] INFO  {CodeGenerator} Code generated in 5.430319 ms
[16:30:05,823] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
[16:30:05,823] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[16:30:05,890] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 192.168.0.103:33945 in memory (size: 9.7 KB, free: 1127.6 MB)
[16:30:05,891] INFO  {ContextCleaner} Cleaned accumulator 389
[16:30:05,891] INFO  {ContextCleaner} Cleaned accumulator 390
[16:30:05,892] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 192.168.0.103:33945 in memory (size: 15.0 KB, free: 1127.6 MB)
[16:30:05,893] INFO  {ContextCleaner} Cleaned accumulator 435
[16:30:05,893] INFO  {ContextCleaner} Cleaned accumulator 436
[16:30:05,894] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 192.168.0.103:33945 in memory (size: 16.4 KB, free: 1127.6 MB)
[16:30:05,895] INFO  {ContextCleaner} Cleaned accumulator 481
[16:30:05,895] INFO  {ContextCleaner} Cleaned accumulator 482
[16:30:05,895] INFO  {ContextCleaner} Cleaned accumulator 291
[16:30:05,895] INFO  {ContextCleaner} Cleaned accumulator 292
[16:30:05,895] INFO  {ContextCleaner} Cleaned accumulator 293
[16:30:05,895] INFO  {ContextCleaner} Cleaned accumulator 294
[16:30:05,896] INFO  {ContextCleaner} Cleaned accumulator 295
[16:30:05,896] INFO  {ContextCleaner} Cleaned accumulator 296
[16:30:05,896] INFO  {ContextCleaner} Cleaned accumulator 297
[16:30:05,896] INFO  {ContextCleaner} Cleaned accumulator 298
[16:30:05,896] INFO  {ContextCleaner} Cleaned accumulator 299
[16:30:05,896] INFO  {ContextCleaner} Cleaned accumulator 300
[16:30:05,897] INFO  {ContextCleaner} Cleaned shuffle 1
[16:30:05,897] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:33945 in memory (size: 10.1 KB, free: 1127.7 MB)
[16:30:05,898] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:33945 in memory (size: 3.9 KB, free: 1127.7 MB)
[16:30:05,899] INFO  {ContextCleaner} Cleaned accumulator 289
[16:30:05,899] INFO  {ContextCleaner} Cleaned accumulator 290
[16:30:06,100] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 2430 bytes result sent to driver
[16:30:06,101] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 303 ms on localhost (1/1)
[16:30:06,101] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[16:30:06,101] INFO  {DAGScheduler} ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81) finished in 0.303 s
[16:30:06,102] INFO  {DAGScheduler} Job 9 finished: treeAggregate at WeightedLeastSquares.scala:81, took 0.312265 s
[16:30:06,105] INFO  {WeightedLeastSquares} Number of instances: 6724.
[16:30:06,113] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
[16:30:06,114] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[16:30:06,431] INFO  {CodeGenerator} Code generated in 18.943912 ms
[16:30:06,463] INFO  {SparkContext} Starting job: aggregate at RegressionMetrics.scala:57
[16:30:06,464] INFO  {DAGScheduler} Got job 10 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
[16:30:06,464] INFO  {DAGScheduler} Final stage: ResultStage 12 (aggregate at RegressionMetrics.scala:57)
[16:30:06,464] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:06,464] INFO  {DAGScheduler} Missing parents: List()
[16:30:06,465] INFO  {DAGScheduler} Submitting ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55), which has no missing parents
[16:30:06,468] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 41.1 KB, free 1127.5 MB)
[16:30:06,470] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1127.4 MB)
[16:30:06,470] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 192.168.0.103:33945 (size: 14.5 KB, free: 1127.6 MB)
[16:30:06,471] INFO  {SparkContext} Created broadcast 13 from broadcast at DAGScheduler.scala:1012
[16:30:06,471] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55)
[16:30:06,471] INFO  {TaskSchedulerImpl} Adding task set 12.0 with 1 tasks
[16:30:06,473] INFO  {TaskSetManager} Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5963 bytes)
[16:30:06,473] INFO  {Executor} Running task 0.0 in stage 12.0 (TID 12)
[16:30:06,479] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:06,487] INFO  {CodeGenerator} Code generated in 5.250972 ms
[16:30:06,583] INFO  {BlockManagerInfo} Removed broadcast_12_piece0 on 192.168.0.103:33945 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:30:06,776] INFO  {Executor} Finished task 0.0 in stage 12.0 (TID 12). 2281 bytes result sent to driver
[16:30:06,778] INFO  {TaskSetManager} Finished task 0.0 in stage 12.0 (TID 12) in 305 ms on localhost (1/1)
[16:30:06,778] INFO  {TaskSchedulerImpl} Removed TaskSet 12.0, whose tasks have all completed, from pool 
[16:30:06,778] INFO  {DAGScheduler} ResultStage 12 (aggregate at RegressionMetrics.scala:57) finished in 0.306 s
[16:30:06,779] INFO  {DAGScheduler} Job 10 finished: aggregate at RegressionMetrics.scala:57, took 0.315812 s
[16:30:06,795] INFO  {SparkContext} Starting job: sum at RegressionMetrics.scala:71
[16:30:06,796] INFO  {DAGScheduler} Got job 11 (sum at RegressionMetrics.scala:71) with 1 output partitions
[16:30:06,796] INFO  {DAGScheduler} Final stage: ResultStage 13 (sum at RegressionMetrics.scala:71)
[16:30:06,796] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:06,796] INFO  {DAGScheduler} Missing parents: List()
[16:30:06,797] INFO  {DAGScheduler} Submitting ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69), which has no missing parents
[16:30:06,799] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 40.7 KB, free 1127.5 MB)
[16:30:06,801] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.4 MB)
[16:30:06,801] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 192.168.0.103:33945 (size: 14.4 KB, free: 1127.6 MB)
[16:30:06,802] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[16:30:06,802] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69)
[16:30:06,802] INFO  {TaskSchedulerImpl} Adding task set 13.0 with 1 tasks
[16:30:06,803] INFO  {TaskSetManager} Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[16:30:06,804] INFO  {Executor} Running task 0.0 in stage 13.0 (TID 13)
[16:30:06,809] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:06,916] INFO  {BlockManagerInfo} Removed broadcast_13_piece0 on 192.168.0.103:33945 in memory (size: 14.5 KB, free: 1127.7 MB)
[16:30:07,022] INFO  {Executor} Finished task 0.0 in stage 13.0 (TID 13). 1859 bytes result sent to driver
[16:30:07,024] INFO  {TaskSetManager} Finished task 0.0 in stage 13.0 (TID 13) in 221 ms on localhost (1/1)
[16:30:07,024] INFO  {TaskSchedulerImpl} Removed TaskSet 13.0, whose tasks have all completed, from pool 
[16:30:07,024] INFO  {DAGScheduler} ResultStage 13 (sum at RegressionMetrics.scala:71) finished in 0.222 s
[16:30:07,024] INFO  {DAGScheduler} Job 11 finished: sum at RegressionMetrics.scala:71, took 0.229450 s
[16:30:07,078] INFO  {CodeGenerator} Code generated in 6.3673 ms
[16:30:07,088] INFO  {CodeGenerator} Code generated in 6.84923 ms
[16:30:07,107] INFO  {SparkContext} Starting job: count at LinearRegression.scala:643
[16:30:07,108] INFO  {DAGScheduler} Registering RDD 51 (count at LinearRegression.scala:643)
[16:30:07,108] INFO  {DAGScheduler} Got job 12 (count at LinearRegression.scala:643) with 1 output partitions
[16:30:07,108] INFO  {DAGScheduler} Final stage: ResultStage 15 (count at LinearRegression.scala:643)
[16:30:07,109] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 14)
[16:30:07,109] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 14)
[16:30:07,110] INFO  {DAGScheduler} Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643), which has no missing parents
[16:30:07,112] INFO  {MemoryStore} Block broadcast_15 stored as values in memory (estimated size 14.0 KB, free 1127.5 MB)
[16:30:07,113] INFO  {MemoryStore} Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1127.5 MB)
[16:30:07,114] INFO  {BlockManagerInfo} Added broadcast_15_piece0 in memory on 192.168.0.103:33945 (size: 6.8 KB, free: 1127.7 MB)
[16:30:07,114] INFO  {SparkContext} Created broadcast 15 from broadcast at DAGScheduler.scala:1012
[16:30:07,114] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643)
[16:30:07,114] INFO  {TaskSchedulerImpl} Adding task set 14.0 with 1 tasks
[16:30:07,116] INFO  {TaskSetManager} Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5979 bytes)
[16:30:07,116] INFO  {Executor} Running task 0.0 in stage 14.0 (TID 14)
[16:30:07,120] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:07,134] INFO  {CodeGenerator} Code generated in 12.922194 ms
[16:30:07,142] INFO  {Executor} Finished task 0.0 in stage 14.0 (TID 14). 2324 bytes result sent to driver
[16:30:07,143] INFO  {TaskSetManager} Finished task 0.0 in stage 14.0 (TID 14) in 28 ms on localhost (1/1)
[16:30:07,143] INFO  {TaskSchedulerImpl} Removed TaskSet 14.0, whose tasks have all completed, from pool 
[16:30:07,144] INFO  {DAGScheduler} ShuffleMapStage 14 (count at LinearRegression.scala:643) finished in 0.029 s
[16:30:07,144] INFO  {DAGScheduler} looking for newly runnable stages
[16:30:07,144] INFO  {DAGScheduler} running: Set()
[16:30:07,144] INFO  {DAGScheduler} waiting: Set(ResultStage 15)
[16:30:07,144] INFO  {DAGScheduler} failed: Set()
[16:30:07,144] INFO  {DAGScheduler} Submitting ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643), which has no missing parents
[16:30:07,146] INFO  {MemoryStore} Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 1127.5 MB)
[16:30:07,147] INFO  {MemoryStore} Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1127.5 MB)
[16:30:07,148] INFO  {BlockManagerInfo} Added broadcast_16_piece0 in memory on 192.168.0.103:33945 (size: 3.7 KB, free: 1127.7 MB)
[16:30:07,148] INFO  {SparkContext} Created broadcast 16 from broadcast at DAGScheduler.scala:1012
[16:30:07,148] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643)
[16:30:07,148] INFO  {TaskSchedulerImpl} Adding task set 15.0 with 1 tasks
[16:30:07,150] INFO  {TaskSetManager} Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, ANY, 5318 bytes)
[16:30:07,150] INFO  {Executor} Running task 0.0 in stage 15.0 (TID 15)
[16:30:07,153] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:30:07,154] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[16:30:07,157] INFO  {Executor} Finished task 0.0 in stage 15.0 (TID 15). 1873 bytes result sent to driver
[16:30:07,159] INFO  {TaskSetManager} Finished task 0.0 in stage 15.0 (TID 15) in 10 ms on localhost (1/1)
[16:30:07,159] INFO  {TaskSchedulerImpl} Removed TaskSet 15.0, whose tasks have all completed, from pool 
[16:30:07,160] INFO  {DAGScheduler} ResultStage 15 (count at LinearRegression.scala:643) finished in 0.011 s
[16:30:07,160] INFO  {DAGScheduler} Job 12 finished: count at LinearRegression.scala:643, took 0.052800 s
[16:30:07,168] INFO  {CodeGenerator} Code generated in 5.909635 ms
[16:30:07,349] INFO  {CodeGenerator} Code generated in 11.342655 ms
[16:30:07,364] INFO  {CodeGenerator} Code generated in 6.472731 ms
[16:30:07,370] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:30:07,376] INFO  {ServerConnector} Stopped ServerConnector@372d0aa1{HTTP/1.1}{0.0.0.0:4040}
[16:30:07,379] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:30:07,379] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:30:07,379] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:30:07,380] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:30:07,380] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:30:07,380] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:30:07,380] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:30:07,380] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:30:07,380] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:30:07,380] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:30:07,380] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:30:07,381] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:30:07,381] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:30:07,381] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:30:07,381] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:30:07,381] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:30:07,381] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:30:07,381] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:30:07,381] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:30:07,382] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:30:07,382] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:30:07,382] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:30:07,382] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:30:07,383] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:30:07,384] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:30:07,397] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:30:07,408] INFO  {MemoryStore} MemoryStore cleared
[16:30:07,408] INFO  {BlockManager} BlockManager stopped
[16:30:07,410] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:30:07,416] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:30:07,428] INFO  {SparkContext} Successfully stopped SparkContext
[16:30:07,428] INFO  {ShutdownHookManager} Shutdown hook called
[16:30:07,429] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-d2413366-0ed5-495c-8294-c3389866dd5f
[16:30:53,557] INFO  {SparkContext} Running Spark version 2.0.1
[16:30:53,759] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:30:53,843] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:30:53,844] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:30:53,922] INFO  {SecurityManager} Changing view acls to: victor
[16:30:53,923] INFO  {SecurityManager} Changing modify acls to: victor
[16:30:53,924] INFO  {SecurityManager} Changing view acls groups to: 
[16:30:53,924] INFO  {SecurityManager} Changing modify acls groups to: 
[16:30:53,925] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:30:54,264] INFO  {Utils} Successfully started service 'sparkDriver' on port 46791.
[16:30:54,284] INFO  {SparkEnv} Registering MapOutputTracker
[16:30:54,300] INFO  {SparkEnv} Registering BlockManagerMaster
[16:30:54,312] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-61016b09-958e-4fa2-b620-68e65405c2da
[16:30:54,325] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:30:54,381] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:30:54,450] INFO  {log} Logging initialized @1462ms
[16:30:54,551] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:30:54,567] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:30:54,567] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:30:54,568] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:30:54,568] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:30:54,568] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:30:54,568] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:30:54,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:30:54,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:30:54,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:30:54,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:30:54,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:30:54,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:30:54,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:30:54,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:30:54,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:30:54,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:30:54,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:30:54,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:30:54,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:30:54,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:30:54,577] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:30:54,578] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:30:54,578] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:30:54,579] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:30:54,585] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:30:54,585] INFO  {Server} Started @1598ms
[16:30:54,585] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:30:54,587] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:30:54,665] INFO  {Executor} Starting executor ID driver on host localhost
[16:30:54,688] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35653.
[16:30:54,688] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:35653
[16:30:54,690] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 35653)
[16:30:54,693] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:35653 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 35653)
[16:30:54,697] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 35653)
[16:30:54,815] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:30:54,865] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:30:54,866] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:30:54,866] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:30:54,867] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:30:54,869] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:30:54,884] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:30:56,620] INFO  {FileSourceStrategy} Pruning directories with: 
[16:30:56,622] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:30:56,628] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:30:56,629] INFO  {FileSourceStrategy} Pushed Filters: 
[16:30:56,737] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:30:56,781] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:30:56,783] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:35653 (size: 14.6 KB, free: 1128.9 MB)
[16:30:56,788] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:30:56,792] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:30:57,233] INFO  {CodeGenerator} Code generated in 186.974884 ms
[16:30:57,432] INFO  {CodeGenerator} Code generated in 27.601839 ms
[16:30:57,477] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:30:57,492] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:30:57,492] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:30:57,493] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:57,497] INFO  {DAGScheduler} Missing parents: List()
[16:30:57,501] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:30:57,571] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:30:57,574] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:30:57,575] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:35653 (size: 8.4 KB, free: 1128.9 MB)
[16:30:57,576] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:30:57,580] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:30:57,583] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:30:57,618] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:57,625] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:30:57,667] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:30:57,694] INFO  {CodeGenerator} Code generated in 24.862554 ms
[16:30:57,818] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:30:57,819] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:35653 (size: 1239.2 KB, free: 1127.7 MB)
[16:30:57,831] INFO  {CodeGenerator} Code generated in 4.235022 ms
[16:30:57,856] INFO  {CodeGenerator} Code generated in 19.339829 ms
[16:30:57,876] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:30:57,882] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:30:57,892] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 291 ms on localhost (1/1)
[16:30:57,894] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:30:57,897] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.305 s
[16:30:57,902] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.425156 s
[16:30:57,939] INFO  {CodeGenerator} Code generated in 17.255199 ms
[16:30:58,032] INFO  {CodeGenerator} Code generated in 29.333884 ms
[16:30:58,044] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:30:58,046] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:30:58,046] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:30:58,046] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:58,048] INFO  {DAGScheduler} Missing parents: List()
[16:30:58,049] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:30:58,055] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:30:58,057] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:30:58,058] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:35653 (size: 10.0 KB, free: 1127.7 MB)
[16:30:58,058] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:30:58,059] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:30:58,059] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:30:58,064] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:58,065] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:30:58,075] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:58,089] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:30:58,091] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:30:58,092] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on localhost (1/1)
[16:30:58,093] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:30:58,093] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.031 s
[16:30:58,094] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.049080 s
[16:30:58,116] INFO  {CodeGenerator} Code generated in 14.572094 ms
[16:30:58,300] INFO  {ContextCleaner} Cleaned accumulator 3
[16:30:58,300] INFO  {ContextCleaner} Cleaned accumulator 4
[16:30:58,316] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:35653 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:30:58,320] INFO  {ContextCleaner} Cleaned accumulator 49
[16:30:58,320] INFO  {ContextCleaner} Cleaned accumulator 50
[16:30:58,322] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:35653 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:30:58,379] INFO  {CodeGenerator} Code generated in 47.633402 ms
[16:30:58,392] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:30:58,393] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:30:58,394] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:30:58,394] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:58,394] INFO  {DAGScheduler} Missing parents: List()
[16:30:58,395] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:30:58,398] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:30:58,400] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:30:58,401] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:35653 (size: 11.7 KB, free: 1127.7 MB)
[16:30:58,402] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:30:58,402] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:30:58,402] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:30:58,404] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:58,404] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:30:58,415] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:58,426] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:30:58,427] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:30:58,429] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 26 ms on localhost (1/1)
[16:30:58,429] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:30:58,430] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.028 s
[16:30:58,431] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.038444 s
[16:30:58,455] INFO  {CodeGenerator} Code generated in 20.50231 ms
[16:30:58,593] INFO  {CodeGenerator} Code generated in 58.709278 ms
[16:30:58,608] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:30:58,609] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:30:58,609] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:30:58,609] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:58,610] INFO  {DAGScheduler} Missing parents: List()
[16:30:58,611] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:30:58,616] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:30:58,618] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1127.5 MB)
[16:30:58,618] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:35653 (size: 13.2 KB, free: 1127.7 MB)
[16:30:58,619] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:30:58,619] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:30:58,619] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:30:58,621] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:58,622] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:30:58,631] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:58,642] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:30:58,643] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:30:58,645] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on localhost (1/1)
[16:30:58,645] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:30:58,646] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.025 s
[16:30:58,646] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.037797 s
[16:30:58,667] INFO  {CodeGenerator} Code generated in 18.089746 ms
[16:30:58,786] INFO  {CodeGenerator} Code generated in 11.609538 ms
[16:30:58,807] INFO  {CodeGenerator} Code generated in 16.872529 ms
[16:30:58,837] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:30:58,841] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:30:58,842] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:30:58,842] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:30:58,842] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:30:58,843] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:30:58,846] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:30:58,853] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:30:58,855] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:30:58,856] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:35653 (size: 10.1 KB, free: 1127.6 MB)
[16:30:58,856] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:30:58,858] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:30:58,858] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:30:58,862] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:30:58,862] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:30:58,871] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:59,199] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:30:59,201] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 342 ms on localhost (1/1)
[16:30:59,201] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:30:59,202] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.343 s
[16:30:59,203] INFO  {DAGScheduler} looking for newly runnable stages
[16:30:59,203] INFO  {DAGScheduler} running: Set()
[16:30:59,204] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:30:59,204] INFO  {DAGScheduler} failed: Set()
[16:30:59,206] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:30:59,210] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:30:59,212] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:30:59,213] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:35653 (size: 3.9 KB, free: 1127.6 MB)
[16:30:59,214] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:30:59,214] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:30:59,214] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:30:59,217] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:30:59,218] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:30:59,231] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:30:59,232] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[16:30:59,248] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:30:59,249] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 34 ms on localhost (1/1)
[16:30:59,249] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:30:59,250] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.035 s
[16:30:59,250] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.412595 s
[16:30:59,259] INFO  {CodeGenerator} Code generated in 6.007288 ms
[16:30:59,319] INFO  {CodeGenerator} Code generated in 13.699531 ms
[16:30:59,346] INFO  {CodeGenerator} Code generated in 20.193391 ms
[16:30:59,366] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:30:59,367] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:30:59,368] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:30:59,368] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:30:59,368] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:30:59,368] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:30:59,369] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:30:59,373] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:30:59,375] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:30:59,376] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:35653 (size: 10.2 KB, free: 1127.6 MB)
[16:30:59,377] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:30:59,377] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:30:59,377] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:30:59,383] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:30:59,384] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:30:59,390] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:59,469] INFO  {ContextCleaner} Cleaned accumulator 95
[16:30:59,470] INFO  {ContextCleaner} Cleaned accumulator 96
[16:30:59,471] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:35653 in memory (size: 11.7 KB, free: 1127.6 MB)
[16:30:59,472] INFO  {ContextCleaner} Cleaned accumulator 141
[16:30:59,472] INFO  {ContextCleaner} Cleaned accumulator 142
[16:30:59,473] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:35653 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:30:59,475] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:35653 in memory (size: 3.9 KB, free: 1127.7 MB)
[16:30:59,476] INFO  {ContextCleaner} Cleaned accumulator 288
[16:30:59,477] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:35653 in memory (size: 13.2 KB, free: 1127.7 MB)
[16:30:59,478] INFO  {ContextCleaner} Cleaned accumulator 187
[16:30:59,478] INFO  {ContextCleaner} Cleaned accumulator 188
[16:30:59,478] INFO  {ContextCleaner} Cleaned accumulator 189
[16:30:59,478] INFO  {ContextCleaner} Cleaned accumulator 190
[16:30:59,478] INFO  {ContextCleaner} Cleaned accumulator 191
[16:30:59,478] INFO  {ContextCleaner} Cleaned accumulator 192
[16:30:59,478] INFO  {ContextCleaner} Cleaned accumulator 193
[16:30:59,478] INFO  {ContextCleaner} Cleaned accumulator 194
[16:30:59,478] INFO  {ContextCleaner} Cleaned accumulator 195
[16:30:59,479] INFO  {ContextCleaner} Cleaned accumulator 196
[16:30:59,479] INFO  {ContextCleaner} Cleaned accumulator 197
[16:30:59,479] INFO  {ContextCleaner} Cleaned accumulator 198
[16:30:59,479] INFO  {ContextCleaner} Cleaned accumulator 199
[16:30:59,483] INFO  {ContextCleaner} Cleaned shuffle 0
[16:30:59,528] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:30:59,529] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 151 ms on localhost (1/1)
[16:30:59,529] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:30:59,530] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.152 s
[16:30:59,530] INFO  {DAGScheduler} looking for newly runnable stages
[16:30:59,530] INFO  {DAGScheduler} running: Set()
[16:30:59,530] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:30:59,530] INFO  {DAGScheduler} failed: Set()
[16:30:59,531] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:30:59,532] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:30:59,534] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:30:59,535] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:35653 (size: 3.9 KB, free: 1127.7 MB)
[16:30:59,535] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:30:59,536] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:30:59,536] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:30:59,537] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:30:59,538] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:30:59,540] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:30:59,540] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:30:59,543] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:30:59,544] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 7 ms on localhost (1/1)
[16:30:59,544] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:30:59,544] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.008 s
[16:30:59,545] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.177823 s
[16:30:59,675] INFO  {CodeGenerator} Code generated in 59.912815 ms
[16:30:59,688] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:30:59,688] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:30:59,688] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:30:59,689] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:59,689] INFO  {DAGScheduler} Missing parents: List()
[16:30:59,689] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:30:59,693] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:30:59,694] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:30:59,695] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:35653 (size: 15.0 KB, free: 1127.6 MB)
[16:30:59,696] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:30:59,696] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:30:59,696] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:30:59,699] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:59,699] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:30:59,704] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:59,711] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:30:59,712] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:30:59,713] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 16 ms on localhost (1/1)
[16:30:59,713] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:30:59,714] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.017 s
[16:30:59,715] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.027272 s
[16:30:59,733] INFO  {CodeGenerator} Code generated in 15.010874 ms
[16:30:59,870] INFO  {CodeGenerator} Code generated in 58.528869 ms
[16:30:59,881] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:30:59,882] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:30:59,882] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:30:59,882] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:59,882] INFO  {DAGScheduler} Missing parents: List()
[16:30:59,883] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:30:59,887] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:30:59,890] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:30:59,891] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:35653 (size: 16.4 KB, free: 1127.6 MB)
[16:30:59,892] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:30:59,892] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:30:59,892] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:30:59,894] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:30:59,895] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:30:59,900] INFO  {BlockManager} Found block rdd_2_0 locally
[16:30:59,908] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:30:59,909] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:30:59,910] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 17 ms on localhost (1/1)
[16:30:59,910] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:30:59,911] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.018 s
[16:30:59,912] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.030575 s
[16:30:59,929] INFO  {CodeGenerator} Code generated in 14.872604 ms
[16:31:00,083] INFO  {CodeGenerator} Code generated in 16.389609 ms
[16:31:00,094] INFO  {SparkContext} Starting job: first at LinearRegression.scala:163
[16:31:00,095] INFO  {DAGScheduler} Got job 8 (first at LinearRegression.scala:163) with 1 output partitions
[16:31:00,095] INFO  {DAGScheduler} Final stage: ResultStage 10 (first at LinearRegression.scala:163)
[16:31:00,095] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:00,095] INFO  {DAGScheduler} Missing parents: List()
[16:31:00,096] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163), which has no missing parents
[16:31:00,100] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 24.2 KB, free 1127.3 MB)
[16:31:00,102] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1127.3 MB)
[16:31:00,102] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:35653 (size: 9.7 KB, free: 1127.6 MB)
[16:31:00,103] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[16:31:00,103] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163)
[16:31:00,103] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[16:31:00,106] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:31:00,106] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[16:31:00,110] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:00,115] WARN  {Executor} 1 block locks were not released by TID = 10:
[rdd_2_0]
[16:31:00,116] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 1844 bytes result sent to driver
[16:31:00,117] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 12 ms on localhost (1/1)
[16:31:00,117] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[16:31:00,117] INFO  {DAGScheduler} ResultStage 10 (first at LinearRegression.scala:163) finished in 0.013 s
[16:31:00,118] INFO  {DAGScheduler} Job 8 finished: first at LinearRegression.scala:163, took 0.023773 s
[16:31:00,125] INFO  {CodeGenerator} Code generated in 5.9754 ms
[16:31:00,250] INFO  {CodeGenerator} Code generated in 36.090594 ms
[16:31:00,304] INFO  {SparkContext} Starting job: treeAggregate at WeightedLeastSquares.scala:81
[16:31:00,305] INFO  {DAGScheduler} Got job 9 (treeAggregate at WeightedLeastSquares.scala:81) with 1 output partitions
[16:31:00,305] INFO  {DAGScheduler} Final stage: ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81)
[16:31:00,306] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:00,306] INFO  {DAGScheduler} Missing parents: List()
[16:31:00,306] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81), which has no missing parents
[16:31:00,310] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 42.1 KB, free 1127.3 MB)
[16:31:00,312] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.3 MB)
[16:31:00,312] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:35653 (size: 14.4 KB, free: 1127.6 MB)
[16:31:00,313] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[16:31:00,313] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81)
[16:31:00,313] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[16:31:00,315] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5967 bytes)
[16:31:00,316] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[16:31:00,322] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:00,337] INFO  {CodeGenerator} Code generated in 8.335405 ms
[16:31:00,348] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
[16:31:00,349] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[16:31:00,460] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 192.168.0.103:35653 in memory (size: 9.7 KB, free: 1127.6 MB)
[16:31:00,461] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:35653 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:31:00,462] INFO  {ContextCleaner} Cleaned accumulator 389
[16:31:00,462] INFO  {ContextCleaner} Cleaned accumulator 390
[16:31:00,463] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 192.168.0.103:35653 in memory (size: 15.0 KB, free: 1127.6 MB)
[16:31:00,464] INFO  {ContextCleaner} Cleaned accumulator 435
[16:31:00,464] INFO  {ContextCleaner} Cleaned accumulator 436
[16:31:00,465] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 192.168.0.103:35653 in memory (size: 16.4 KB, free: 1127.7 MB)
[16:31:00,466] INFO  {ContextCleaner} Cleaned accumulator 481
[16:31:00,466] INFO  {ContextCleaner} Cleaned accumulator 482
[16:31:00,466] INFO  {ContextCleaner} Cleaned accumulator 289
[16:31:00,466] INFO  {ContextCleaner} Cleaned accumulator 290
[16:31:00,466] INFO  {ContextCleaner} Cleaned accumulator 291
[16:31:00,466] INFO  {ContextCleaner} Cleaned accumulator 292
[16:31:00,466] INFO  {ContextCleaner} Cleaned accumulator 293
[16:31:00,466] INFO  {ContextCleaner} Cleaned accumulator 294
[16:31:00,466] INFO  {ContextCleaner} Cleaned accumulator 295
[16:31:00,466] INFO  {ContextCleaner} Cleaned accumulator 296
[16:31:00,466] INFO  {ContextCleaner} Cleaned accumulator 297
[16:31:00,467] INFO  {ContextCleaner} Cleaned accumulator 298
[16:31:00,467] INFO  {ContextCleaner} Cleaned accumulator 299
[16:31:00,467] INFO  {ContextCleaner} Cleaned accumulator 300
[16:31:00,468] INFO  {ContextCleaner} Cleaned shuffle 1
[16:31:00,469] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:35653 in memory (size: 10.2 KB, free: 1127.7 MB)
[16:31:00,626] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 2430 bytes result sent to driver
[16:31:00,627] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 313 ms on localhost (1/1)
[16:31:00,627] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[16:31:00,627] INFO  {DAGScheduler} ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81) finished in 0.313 s
[16:31:00,628] INFO  {DAGScheduler} Job 9 finished: treeAggregate at WeightedLeastSquares.scala:81, took 0.323166 s
[16:31:00,630] INFO  {WeightedLeastSquares} Number of instances: 6724.
[16:31:00,638] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
[16:31:00,638] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[16:31:00,944] INFO  {CodeGenerator} Code generated in 18.180105 ms
[16:31:00,977] INFO  {SparkContext} Starting job: aggregate at RegressionMetrics.scala:57
[16:31:00,978] INFO  {DAGScheduler} Got job 10 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
[16:31:00,978] INFO  {DAGScheduler} Final stage: ResultStage 12 (aggregate at RegressionMetrics.scala:57)
[16:31:00,978] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:00,978] INFO  {DAGScheduler} Missing parents: List()
[16:31:00,979] INFO  {DAGScheduler} Submitting ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55), which has no missing parents
[16:31:00,981] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 41.1 KB, free 1127.5 MB)
[16:31:00,983] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1127.4 MB)
[16:31:00,983] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 192.168.0.103:35653 (size: 14.5 KB, free: 1127.6 MB)
[16:31:00,984] INFO  {SparkContext} Created broadcast 13 from broadcast at DAGScheduler.scala:1012
[16:31:00,984] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55)
[16:31:00,984] INFO  {TaskSchedulerImpl} Adding task set 12.0 with 1 tasks
[16:31:00,986] INFO  {TaskSetManager} Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5963 bytes)
[16:31:00,986] INFO  {Executor} Running task 0.0 in stage 12.0 (TID 12)
[16:31:00,993] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:01,005] INFO  {CodeGenerator} Code generated in 7.386342 ms
[16:31:01,175] INFO  {BlockManagerInfo} Removed broadcast_12_piece0 on 192.168.0.103:35653 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:31:01,307] INFO  {Executor} Finished task 0.0 in stage 12.0 (TID 12). 2368 bytes result sent to driver
[16:31:01,309] INFO  {TaskSetManager} Finished task 0.0 in stage 12.0 (TID 12) in 324 ms on localhost (1/1)
[16:31:01,309] INFO  {TaskSchedulerImpl} Removed TaskSet 12.0, whose tasks have all completed, from pool 
[16:31:01,310] INFO  {DAGScheduler} ResultStage 12 (aggregate at RegressionMetrics.scala:57) finished in 0.325 s
[16:31:01,310] INFO  {DAGScheduler} Job 10 finished: aggregate at RegressionMetrics.scala:57, took 0.333271 s
[16:31:01,324] INFO  {SparkContext} Starting job: sum at RegressionMetrics.scala:71
[16:31:01,325] INFO  {DAGScheduler} Got job 11 (sum at RegressionMetrics.scala:71) with 1 output partitions
[16:31:01,325] INFO  {DAGScheduler} Final stage: ResultStage 13 (sum at RegressionMetrics.scala:71)
[16:31:01,325] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:01,326] INFO  {DAGScheduler} Missing parents: List()
[16:31:01,326] INFO  {DAGScheduler} Submitting ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69), which has no missing parents
[16:31:01,328] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 40.7 KB, free 1127.5 MB)
[16:31:01,330] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.4 MB)
[16:31:01,330] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 192.168.0.103:35653 (size: 14.4 KB, free: 1127.6 MB)
[16:31:01,331] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[16:31:01,331] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69)
[16:31:01,331] INFO  {TaskSchedulerImpl} Adding task set 13.0 with 1 tasks
[16:31:01,332] INFO  {TaskSetManager} Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[16:31:01,333] INFO  {Executor} Running task 0.0 in stage 13.0 (TID 13)
[16:31:01,336] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:01,469] INFO  {BlockManagerInfo} Removed broadcast_13_piece0 on 192.168.0.103:35653 in memory (size: 14.5 KB, free: 1127.7 MB)
[16:31:01,522] INFO  {Executor} Finished task 0.0 in stage 13.0 (TID 13). 1859 bytes result sent to driver
[16:31:01,523] INFO  {TaskSetManager} Finished task 0.0 in stage 13.0 (TID 13) in 192 ms on localhost (1/1)
[16:31:01,523] INFO  {TaskSchedulerImpl} Removed TaskSet 13.0, whose tasks have all completed, from pool 
[16:31:01,523] INFO  {DAGScheduler} ResultStage 13 (sum at RegressionMetrics.scala:71) finished in 0.192 s
[16:31:01,524] INFO  {DAGScheduler} Job 11 finished: sum at RegressionMetrics.scala:71, took 0.199243 s
[16:31:01,580] INFO  {CodeGenerator} Code generated in 9.561238 ms
[16:31:01,591] INFO  {CodeGenerator} Code generated in 7.793659 ms
[16:31:01,606] INFO  {SparkContext} Starting job: count at LinearRegression.scala:643
[16:31:01,606] INFO  {DAGScheduler} Registering RDD 51 (count at LinearRegression.scala:643)
[16:31:01,607] INFO  {DAGScheduler} Got job 12 (count at LinearRegression.scala:643) with 1 output partitions
[16:31:01,607] INFO  {DAGScheduler} Final stage: ResultStage 15 (count at LinearRegression.scala:643)
[16:31:01,607] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 14)
[16:31:01,607] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 14)
[16:31:01,607] INFO  {DAGScheduler} Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643), which has no missing parents
[16:31:01,610] INFO  {MemoryStore} Block broadcast_15 stored as values in memory (estimated size 14.0 KB, free 1127.5 MB)
[16:31:01,611] INFO  {MemoryStore} Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1127.5 MB)
[16:31:01,612] INFO  {BlockManagerInfo} Added broadcast_15_piece0 in memory on 192.168.0.103:35653 (size: 6.8 KB, free: 1127.7 MB)
[16:31:01,612] INFO  {SparkContext} Created broadcast 15 from broadcast at DAGScheduler.scala:1012
[16:31:01,612] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643)
[16:31:01,612] INFO  {TaskSchedulerImpl} Adding task set 14.0 with 1 tasks
[16:31:01,613] INFO  {TaskSetManager} Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5979 bytes)
[16:31:01,614] INFO  {Executor} Running task 0.0 in stage 14.0 (TID 14)
[16:31:01,617] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:01,630] INFO  {CodeGenerator} Code generated in 11.995488 ms
[16:31:01,638] INFO  {Executor} Finished task 0.0 in stage 14.0 (TID 14). 2324 bytes result sent to driver
[16:31:01,640] INFO  {TaskSetManager} Finished task 0.0 in stage 14.0 (TID 14) in 26 ms on localhost (1/1)
[16:31:01,640] INFO  {TaskSchedulerImpl} Removed TaskSet 14.0, whose tasks have all completed, from pool 
[16:31:01,640] INFO  {DAGScheduler} ShuffleMapStage 14 (count at LinearRegression.scala:643) finished in 0.028 s
[16:31:01,641] INFO  {DAGScheduler} looking for newly runnable stages
[16:31:01,641] INFO  {DAGScheduler} running: Set()
[16:31:01,641] INFO  {DAGScheduler} waiting: Set(ResultStage 15)
[16:31:01,641] INFO  {DAGScheduler} failed: Set()
[16:31:01,641] INFO  {DAGScheduler} Submitting ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643), which has no missing parents
[16:31:01,643] INFO  {MemoryStore} Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 1127.5 MB)
[16:31:01,645] INFO  {MemoryStore} Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1127.5 MB)
[16:31:01,645] INFO  {BlockManagerInfo} Added broadcast_16_piece0 in memory on 192.168.0.103:35653 (size: 3.7 KB, free: 1127.7 MB)
[16:31:01,646] INFO  {SparkContext} Created broadcast 16 from broadcast at DAGScheduler.scala:1012
[16:31:01,646] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643)
[16:31:01,646] INFO  {TaskSchedulerImpl} Adding task set 15.0 with 1 tasks
[16:31:01,647] INFO  {TaskSetManager} Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, ANY, 5318 bytes)
[16:31:01,648] INFO  {Executor} Running task 0.0 in stage 15.0 (TID 15)
[16:31:01,650] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:31:01,650] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:31:01,653] INFO  {Executor} Finished task 0.0 in stage 15.0 (TID 15). 1873 bytes result sent to driver
[16:31:01,654] INFO  {TaskSetManager} Finished task 0.0 in stage 15.0 (TID 15) in 7 ms on localhost (1/1)
[16:31:01,654] INFO  {TaskSchedulerImpl} Removed TaskSet 15.0, whose tasks have all completed, from pool 
[16:31:01,654] INFO  {DAGScheduler} ResultStage 15 (count at LinearRegression.scala:643) finished in 0.008 s
[16:31:01,655] INFO  {DAGScheduler} Job 12 finished: count at LinearRegression.scala:643, took 0.048659 s
[16:31:01,662] INFO  {CodeGenerator} Code generated in 5.588695 ms
[16:31:01,781] INFO  {CodeGenerator} Code generated in 7.648774 ms
[16:31:01,791] INFO  {CodeGenerator} Code generated in 4.615477 ms
[16:31:01,796] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:31:01,801] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:31:01,804] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:31:01,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:31:01,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:31:01,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:31:01,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:31:01,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:31:01,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:31:01,806] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:31:01,806] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:31:01,806] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:31:01,806] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:31:01,806] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:31:01,806] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:31:01,806] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:31:01,806] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:31:01,806] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:31:01,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:31:01,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:31:01,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:31:01,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:31:01,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:31:01,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:31:01,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:31:01,808] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:31:01,809] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:31:01,823] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:31:01,838] INFO  {MemoryStore} MemoryStore cleared
[16:31:01,839] INFO  {BlockManager} BlockManager stopped
[16:31:01,841] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:31:01,844] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:31:01,860] INFO  {SparkContext} Successfully stopped SparkContext
[16:31:01,860] INFO  {ShutdownHookManager} Shutdown hook called
[16:31:01,861] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-dbdad852-e43c-4aab-8311-8363241dcef9
[16:31:50,928] INFO  {SparkContext} Running Spark version 2.0.1
[16:31:51,159] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:31:51,233] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:31:51,234] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:31:51,306] INFO  {SecurityManager} Changing view acls to: victor
[16:31:51,306] INFO  {SecurityManager} Changing modify acls to: victor
[16:31:51,307] INFO  {SecurityManager} Changing view acls groups to: 
[16:31:51,308] INFO  {SecurityManager} Changing modify acls groups to: 
[16:31:51,308] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:31:51,688] INFO  {Utils} Successfully started service 'sparkDriver' on port 46099.
[16:31:51,705] INFO  {SparkEnv} Registering MapOutputTracker
[16:31:51,727] INFO  {SparkEnv} Registering BlockManagerMaster
[16:31:51,739] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-ebd121eb-c0bb-4dca-86c5-67b1018ab915
[16:31:51,753] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:31:51,810] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:31:51,878] INFO  {log} Logging initialized @1518ms
[16:31:51,975] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:31:51,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:31:51,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:31:51,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:31:51,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:31:51,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:31:51,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:31:51,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:31:51,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:31:51,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:31:51,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:31:51,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:31:51,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:31:51,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:31:51,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:31:51,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:31:51,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:31:51,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:31:51,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:31:51,994] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:31:51,994] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:31:52,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:31:52,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:31:52,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:31:52,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:31:52,007] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:31:52,007] INFO  {Server} Started @1648ms
[16:31:52,007] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:31:52,009] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:31:52,098] INFO  {Executor} Starting executor ID driver on host localhost
[16:31:52,125] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45419.
[16:31:52,126] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:45419
[16:31:52,128] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 45419)
[16:31:52,130] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:45419 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 45419)
[16:31:52,135] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 45419)
[16:31:52,264] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:31:52,309] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:31:52,309] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:31:52,310] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:31:52,310] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:31:52,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:31:52,325] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:31:54,067] INFO  {FileSourceStrategy} Pruning directories with: 
[16:31:54,069] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:31:54,074] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:31:54,075] INFO  {FileSourceStrategy} Pushed Filters: 
[16:31:54,186] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:31:54,231] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:31:54,233] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:45419 (size: 14.6 KB, free: 1128.9 MB)
[16:31:54,239] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:31:54,242] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:31:54,674] INFO  {CodeGenerator} Code generated in 189.811981 ms
[16:31:54,871] INFO  {CodeGenerator} Code generated in 27.92617 ms
[16:31:54,917] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:31:54,936] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:31:54,936] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:31:54,937] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:54,941] INFO  {DAGScheduler} Missing parents: List()
[16:31:54,947] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:31:55,007] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:31:55,010] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:31:55,010] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:45419 (size: 8.5 KB, free: 1128.9 MB)
[16:31:55,011] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:31:55,014] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:31:55,015] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:31:55,055] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:31:55,063] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:31:55,106] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:31:55,118] INFO  {CodeGenerator} Code generated in 8.780781 ms
[16:31:55,265] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:31:55,266] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:45419 (size: 1239.2 KB, free: 1127.7 MB)
[16:31:55,276] INFO  {CodeGenerator} Code generated in 4.08143 ms
[16:31:55,300] INFO  {CodeGenerator} Code generated in 18.711098 ms
[16:31:55,320] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:31:55,327] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:31:55,337] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 299 ms on localhost (1/1)
[16:31:55,339] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:31:55,342] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.317 s
[16:31:55,347] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.429832 s
[16:31:55,391] INFO  {CodeGenerator} Code generated in 23.974607 ms
[16:31:55,507] INFO  {CodeGenerator} Code generated in 38.614537 ms
[16:31:55,519] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:31:55,520] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:31:55,520] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:31:55,520] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:55,522] INFO  {DAGScheduler} Missing parents: List()
[16:31:55,523] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:31:55,529] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:31:55,531] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:31:55,531] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:45419 (size: 10.0 KB, free: 1127.7 MB)
[16:31:55,532] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:31:55,532] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:31:55,532] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:31:55,537] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:31:55,538] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:31:55,551] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:55,564] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:31:55,565] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:31:55,568] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on localhost (1/1)
[16:31:55,568] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:31:55,568] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.033 s
[16:31:55,569] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.050017 s
[16:31:55,591] INFO  {CodeGenerator} Code generated in 15.246813 ms
[16:31:55,779] INFO  {ContextCleaner} Cleaned accumulator 3
[16:31:55,779] INFO  {ContextCleaner} Cleaned accumulator 4
[16:31:55,797] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:45419 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:31:55,800] INFO  {ContextCleaner} Cleaned accumulator 49
[16:31:55,800] INFO  {ContextCleaner} Cleaned accumulator 50
[16:31:55,802] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:45419 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:31:55,858] INFO  {CodeGenerator} Code generated in 47.684847 ms
[16:31:55,873] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:31:55,874] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:31:55,875] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:31:55,875] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:55,876] INFO  {DAGScheduler} Missing parents: List()
[16:31:55,877] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:31:55,881] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:31:55,884] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:31:55,885] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:45419 (size: 11.7 KB, free: 1127.7 MB)
[16:31:55,885] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:31:55,886] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:31:55,886] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:31:55,888] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:31:55,889] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:31:55,898] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:55,911] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:31:55,912] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:31:55,914] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on localhost (1/1)
[16:31:55,914] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:31:55,915] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.028 s
[16:31:55,916] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.043056 s
[16:31:55,939] INFO  {CodeGenerator} Code generated in 18.56475 ms
[16:31:56,064] INFO  {CodeGenerator} Code generated in 48.029107 ms
[16:31:56,082] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:31:56,083] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:31:56,083] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:31:56,083] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:56,084] INFO  {DAGScheduler} Missing parents: List()
[16:31:56,085] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:31:56,090] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:31:56,092] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:31:56,093] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:45419 (size: 13.3 KB, free: 1127.7 MB)
[16:31:56,094] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:31:56,094] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:31:56,094] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:31:56,096] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:31:56,096] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:31:56,105] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:56,115] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:31:56,115] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:31:56,117] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 22 ms on localhost (1/1)
[16:31:56,117] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:31:56,117] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.022 s
[16:31:56,118] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.035817 s
[16:31:56,133] INFO  {CodeGenerator} Code generated in 12.866316 ms
[16:31:56,236] INFO  {CodeGenerator} Code generated in 11.91992 ms
[16:31:56,258] INFO  {CodeGenerator} Code generated in 17.002149 ms
[16:31:56,289] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:31:56,293] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:31:56,294] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:31:56,294] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:31:56,294] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:31:56,294] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:31:56,296] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:31:56,304] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:31:56,306] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:31:56,307] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:45419 (size: 10.2 KB, free: 1127.6 MB)
[16:31:56,307] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:31:56,310] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:31:56,310] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:31:56,312] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:31:56,313] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:31:56,318] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:56,589] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:31:56,592] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 281 ms on localhost (1/1)
[16:31:56,593] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:31:56,594] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.284 s
[16:31:56,594] INFO  {DAGScheduler} looking for newly runnable stages
[16:31:56,594] INFO  {DAGScheduler} running: Set()
[16:31:56,595] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:31:56,595] INFO  {DAGScheduler} failed: Set()
[16:31:56,596] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:31:56,600] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:31:56,601] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:31:56,602] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:45419 (size: 3.9 KB, free: 1127.6 MB)
[16:31:56,602] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:31:56,603] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:31:56,603] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:31:56,606] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:31:56,606] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:31:56,620] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:31:56,622] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 6 ms
[16:31:56,634] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:31:56,635] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 31 ms on localhost (1/1)
[16:31:56,635] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:31:56,635] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.031 s
[16:31:56,636] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.346609 s
[16:31:56,644] INFO  {CodeGenerator} Code generated in 5.265944 ms
[16:31:56,682] INFO  {CodeGenerator} Code generated in 8.915894 ms
[16:31:56,704] INFO  {CodeGenerator} Code generated in 16.870275 ms
[16:31:56,719] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:31:56,720] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:31:56,720] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:31:56,720] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:31:56,720] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:31:56,720] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:31:56,722] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:31:56,725] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:31:56,727] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:31:56,728] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:45419 (size: 10.2 KB, free: 1127.6 MB)
[16:31:56,728] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:31:56,729] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:31:56,729] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:31:56,731] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:31:56,731] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:31:56,734] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:56,824] INFO  {ContextCleaner} Cleaned accumulator 288
[16:31:56,824] INFO  {ContextCleaner} Cleaned accumulator 95
[16:31:56,824] INFO  {ContextCleaner} Cleaned accumulator 96
[16:31:56,825] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:45419 in memory (size: 11.7 KB, free: 1127.6 MB)
[16:31:56,826] INFO  {ContextCleaner} Cleaned accumulator 141
[16:31:56,826] INFO  {ContextCleaner} Cleaned accumulator 142
[16:31:56,827] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:45419 in memory (size: 10.2 KB, free: 1127.6 MB)
[16:31:56,828] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:45419 in memory (size: 3.9 KB, free: 1127.7 MB)
[16:31:56,829] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:45419 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:31:56,830] INFO  {ContextCleaner} Cleaned accumulator 187
[16:31:56,830] INFO  {ContextCleaner} Cleaned accumulator 188
[16:31:56,830] INFO  {ContextCleaner} Cleaned accumulator 189
[16:31:56,830] INFO  {ContextCleaner} Cleaned accumulator 190
[16:31:56,830] INFO  {ContextCleaner} Cleaned accumulator 191
[16:31:56,830] INFO  {ContextCleaner} Cleaned accumulator 192
[16:31:56,830] INFO  {ContextCleaner} Cleaned accumulator 193
[16:31:56,830] INFO  {ContextCleaner} Cleaned accumulator 194
[16:31:56,830] INFO  {ContextCleaner} Cleaned accumulator 195
[16:31:56,830] INFO  {ContextCleaner} Cleaned accumulator 196
[16:31:56,830] INFO  {ContextCleaner} Cleaned accumulator 197
[16:31:56,831] INFO  {ContextCleaner} Cleaned accumulator 198
[16:31:56,831] INFO  {ContextCleaner} Cleaned accumulator 199
[16:31:56,834] INFO  {ContextCleaner} Cleaned shuffle 0
[16:31:56,872] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:31:56,873] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 144 ms on localhost (1/1)
[16:31:56,873] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:31:56,874] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.145 s
[16:31:56,874] INFO  {DAGScheduler} looking for newly runnable stages
[16:31:56,874] INFO  {DAGScheduler} running: Set()
[16:31:56,874] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:31:56,874] INFO  {DAGScheduler} failed: Set()
[16:31:56,874] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:31:56,876] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:31:56,878] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:31:56,878] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:45419 (size: 3.9 KB, free: 1127.7 MB)
[16:31:56,879] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:31:56,879] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:31:56,879] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:31:56,880] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:31:56,880] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:31:56,882] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:31:56,883] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[16:31:56,885] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:31:56,886] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 6 ms on localhost (1/1)
[16:31:56,887] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:31:56,887] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.008 s
[16:31:56,887] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.168178 s
[16:31:56,979] INFO  {CodeGenerator} Code generated in 40.335165 ms
[16:31:56,988] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:31:56,988] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:31:56,988] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:31:56,988] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:56,989] INFO  {DAGScheduler} Missing parents: List()
[16:31:56,989] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:31:56,992] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:31:56,994] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:31:56,994] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:45419 (size: 15.1 KB, free: 1127.6 MB)
[16:31:56,995] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:31:56,995] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:31:56,995] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:31:56,997] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:31:56,998] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:31:57,003] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:57,009] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:31:57,009] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:31:57,010] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 14 ms on localhost (1/1)
[16:31:57,010] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:31:57,011] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.014 s
[16:31:57,011] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.023253 s
[16:31:57,025] INFO  {CodeGenerator} Code generated in 11.961517 ms
[16:31:57,126] INFO  {CodeGenerator} Code generated in 50.750144 ms
[16:31:57,137] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:31:57,138] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:31:57,138] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:31:57,138] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:57,138] INFO  {DAGScheduler} Missing parents: List()
[16:31:57,138] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:31:57,141] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:31:57,143] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:31:57,143] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:45419 (size: 16.4 KB, free: 1127.6 MB)
[16:31:57,144] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:31:57,145] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:31:57,145] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:31:57,147] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:31:57,147] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:31:57,153] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:57,158] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:31:57,159] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4170 bytes result sent to driver
[16:31:57,160] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 14 ms on localhost (1/1)
[16:31:57,160] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:31:57,160] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.015 s
[16:31:57,162] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.025343 s
[16:31:57,177] INFO  {CodeGenerator} Code generated in 11.693288 ms
[16:31:57,307] INFO  {CodeGenerator} Code generated in 13.650731 ms
[16:31:57,314] INFO  {SparkContext} Starting job: first at LinearRegression.scala:163
[16:31:57,315] INFO  {DAGScheduler} Got job 8 (first at LinearRegression.scala:163) with 1 output partitions
[16:31:57,315] INFO  {DAGScheduler} Final stage: ResultStage 10 (first at LinearRegression.scala:163)
[16:31:57,315] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:57,315] INFO  {DAGScheduler} Missing parents: List()
[16:31:57,316] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163), which has no missing parents
[16:31:57,319] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 24.2 KB, free 1127.3 MB)
[16:31:57,321] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1127.3 MB)
[16:31:57,322] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:45419 (size: 9.7 KB, free: 1127.6 MB)
[16:31:57,322] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[16:31:57,322] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at first at LinearRegression.scala:163)
[16:31:57,322] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[16:31:57,324] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:31:57,325] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[16:31:57,328] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:57,331] WARN  {Executor} 1 block locks were not released by TID = 10:
[rdd_2_0]
[16:31:57,332] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 1844 bytes result sent to driver
[16:31:57,332] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 9 ms on localhost (1/1)
[16:31:57,333] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[16:31:57,333] INFO  {DAGScheduler} ResultStage 10 (first at LinearRegression.scala:163) finished in 0.010 s
[16:31:57,334] INFO  {DAGScheduler} Job 8 finished: first at LinearRegression.scala:163, took 0.019611 s
[16:31:57,341] INFO  {CodeGenerator} Code generated in 5.510119 ms
[16:31:57,438] INFO  {CodeGenerator} Code generated in 26.521599 ms
[16:31:57,492] INFO  {SparkContext} Starting job: treeAggregate at WeightedLeastSquares.scala:81
[16:31:57,493] INFO  {DAGScheduler} Got job 9 (treeAggregate at WeightedLeastSquares.scala:81) with 1 output partitions
[16:31:57,493] INFO  {DAGScheduler} Final stage: ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81)
[16:31:57,493] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:57,493] INFO  {DAGScheduler} Missing parents: List()
[16:31:57,494] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81), which has no missing parents
[16:31:57,496] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 42.1 KB, free 1127.3 MB)
[16:31:57,498] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.3 MB)
[16:31:57,499] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:45419 (size: 14.4 KB, free: 1127.6 MB)
[16:31:57,499] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[16:31:57,500] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at treeAggregate at WeightedLeastSquares.scala:81)
[16:31:57,500] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[16:31:57,502] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5967 bytes)
[16:31:57,502] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[16:31:57,508] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:57,518] INFO  {CodeGenerator} Code generated in 5.622284 ms
[16:31:57,527] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
[16:31:57,527] WARN  {BLAS} Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[16:31:57,653] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 192.168.0.103:45419 in memory (size: 16.4 KB, free: 1127.6 MB)
[16:31:57,654] INFO  {ContextCleaner} Cleaned accumulator 481
[16:31:57,654] INFO  {ContextCleaner} Cleaned accumulator 482
[16:31:57,654] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 192.168.0.103:45419 in memory (size: 9.7 KB, free: 1127.6 MB)
[16:31:57,655] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:45419 in memory (size: 10.2 KB, free: 1127.6 MB)
[16:31:57,656] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:45419 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:31:57,657] INFO  {ContextCleaner} Cleaned accumulator 389
[16:31:57,657] INFO  {ContextCleaner} Cleaned accumulator 390
[16:31:57,657] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 192.168.0.103:45419 in memory (size: 15.1 KB, free: 1127.7 MB)
[16:31:57,658] INFO  {ContextCleaner} Cleaned accumulator 435
[16:31:57,658] INFO  {ContextCleaner} Cleaned accumulator 436
[16:31:57,658] INFO  {ContextCleaner} Cleaned accumulator 289
[16:31:57,658] INFO  {ContextCleaner} Cleaned accumulator 290
[16:31:57,658] INFO  {ContextCleaner} Cleaned accumulator 291
[16:31:57,658] INFO  {ContextCleaner} Cleaned accumulator 292
[16:31:57,658] INFO  {ContextCleaner} Cleaned accumulator 293
[16:31:57,659] INFO  {ContextCleaner} Cleaned accumulator 294
[16:31:57,659] INFO  {ContextCleaner} Cleaned accumulator 295
[16:31:57,659] INFO  {ContextCleaner} Cleaned accumulator 296
[16:31:57,659] INFO  {ContextCleaner} Cleaned accumulator 297
[16:31:57,659] INFO  {ContextCleaner} Cleaned accumulator 298
[16:31:57,659] INFO  {ContextCleaner} Cleaned accumulator 299
[16:31:57,659] INFO  {ContextCleaner} Cleaned accumulator 300
[16:31:57,660] INFO  {ContextCleaner} Cleaned shuffle 1
[16:31:57,809] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 2430 bytes result sent to driver
[16:31:57,810] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 309 ms on localhost (1/1)
[16:31:57,810] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[16:31:57,810] INFO  {DAGScheduler} ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:81) finished in 0.309 s
[16:31:57,811] INFO  {DAGScheduler} Job 9 finished: treeAggregate at WeightedLeastSquares.scala:81, took 0.318760 s
[16:31:57,813] INFO  {WeightedLeastSquares} Number of instances: 6724.
[16:31:57,820] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
[16:31:57,820] WARN  {LAPACK} Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[16:31:58,135] INFO  {CodeGenerator} Code generated in 21.353579 ms
[16:31:58,172] INFO  {SparkContext} Starting job: aggregate at RegressionMetrics.scala:57
[16:31:58,173] INFO  {DAGScheduler} Got job 10 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
[16:31:58,173] INFO  {DAGScheduler} Final stage: ResultStage 12 (aggregate at RegressionMetrics.scala:57)
[16:31:58,173] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:58,174] INFO  {DAGScheduler} Missing parents: List()
[16:31:58,174] INFO  {DAGScheduler} Submitting ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55), which has no missing parents
[16:31:58,177] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 41.1 KB, free 1127.5 MB)
[16:31:58,179] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.5 KB, free 1127.4 MB)
[16:31:58,179] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 192.168.0.103:45419 (size: 14.5 KB, free: 1127.6 MB)
[16:31:58,180] INFO  {SparkContext} Created broadcast 13 from broadcast at DAGScheduler.scala:1012
[16:31:58,180] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at map at RegressionMetrics.scala:55)
[16:31:58,180] INFO  {TaskSchedulerImpl} Adding task set 12.0 with 1 tasks
[16:31:58,182] INFO  {TaskSetManager} Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5963 bytes)
[16:31:58,182] INFO  {Executor} Running task 0.0 in stage 12.0 (TID 12)
[16:31:58,189] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:58,199] INFO  {CodeGenerator} Code generated in 6.392509 ms
[16:31:58,450] INFO  {BlockManagerInfo} Removed broadcast_12_piece0 on 192.168.0.103:45419 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:31:58,537] INFO  {Executor} Finished task 0.0 in stage 12.0 (TID 12). 2281 bytes result sent to driver
[16:31:58,538] INFO  {TaskSetManager} Finished task 0.0 in stage 12.0 (TID 12) in 357 ms on localhost (1/1)
[16:31:58,538] INFO  {TaskSchedulerImpl} Removed TaskSet 12.0, whose tasks have all completed, from pool 
[16:31:58,539] INFO  {DAGScheduler} ResultStage 12 (aggregate at RegressionMetrics.scala:57) finished in 0.358 s
[16:31:58,540] INFO  {DAGScheduler} Job 10 finished: aggregate at RegressionMetrics.scala:57, took 0.367089 s
[16:31:58,556] INFO  {SparkContext} Starting job: sum at RegressionMetrics.scala:71
[16:31:58,557] INFO  {DAGScheduler} Got job 11 (sum at RegressionMetrics.scala:71) with 1 output partitions
[16:31:58,558] INFO  {DAGScheduler} Final stage: ResultStage 13 (sum at RegressionMetrics.scala:71)
[16:31:58,558] INFO  {DAGScheduler} Parents of final stage: List()
[16:31:58,558] INFO  {DAGScheduler} Missing parents: List()
[16:31:58,559] INFO  {DAGScheduler} Submitting ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69), which has no missing parents
[16:31:58,562] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 40.7 KB, free 1127.5 MB)
[16:31:58,564] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1127.4 MB)
[16:31:58,565] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 192.168.0.103:45419 (size: 14.4 KB, free: 1127.6 MB)
[16:31:58,565] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[16:31:58,566] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:69)
[16:31:58,566] INFO  {TaskSchedulerImpl} Adding task set 13.0 with 1 tasks
[16:31:58,568] INFO  {TaskSetManager} Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[16:31:58,568] INFO  {Executor} Running task 0.0 in stage 13.0 (TID 13)
[16:31:58,573] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:58,781] INFO  {Executor} Finished task 0.0 in stage 13.0 (TID 13). 1786 bytes result sent to driver
[16:31:58,782] INFO  {TaskSetManager} Finished task 0.0 in stage 13.0 (TID 13) in 216 ms on localhost (1/1)
[16:31:58,783] INFO  {TaskSchedulerImpl} Removed TaskSet 13.0, whose tasks have all completed, from pool 
[16:31:58,783] INFO  {DAGScheduler} ResultStage 13 (sum at RegressionMetrics.scala:71) finished in 0.216 s
[16:31:58,783] INFO  {DAGScheduler} Job 11 finished: sum at RegressionMetrics.scala:71, took 0.226552 s
[16:31:58,836] INFO  {CodeGenerator} Code generated in 9.279353 ms
[16:31:58,849] INFO  {BlockManagerInfo} Removed broadcast_13_piece0 on 192.168.0.103:45419 in memory (size: 14.5 KB, free: 1127.7 MB)
[16:31:58,850] INFO  {BlockManagerInfo} Removed broadcast_14_piece0 on 192.168.0.103:45419 in memory (size: 14.4 KB, free: 1127.7 MB)
[16:31:58,851] INFO  {ContextCleaner} Cleaned accumulator 663
[16:31:58,853] INFO  {CodeGenerator} Code generated in 14.268308 ms
[16:31:58,869] INFO  {SparkContext} Starting job: count at LinearRegression.scala:643
[16:31:58,870] INFO  {DAGScheduler} Registering RDD 51 (count at LinearRegression.scala:643)
[16:31:58,870] INFO  {DAGScheduler} Got job 12 (count at LinearRegression.scala:643) with 1 output partitions
[16:31:58,870] INFO  {DAGScheduler} Final stage: ResultStage 15 (count at LinearRegression.scala:643)
[16:31:58,871] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 14)
[16:31:58,871] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 14)
[16:31:58,871] INFO  {DAGScheduler} Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643), which has no missing parents
[16:31:58,873] INFO  {MemoryStore} Block broadcast_15 stored as values in memory (estimated size 14.0 KB, free 1127.5 MB)
[16:31:58,875] INFO  {MemoryStore} Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1127.5 MB)
[16:31:58,875] INFO  {BlockManagerInfo} Added broadcast_15_piece0 in memory on 192.168.0.103:45419 (size: 6.8 KB, free: 1127.7 MB)
[16:31:58,876] INFO  {SparkContext} Created broadcast 15 from broadcast at DAGScheduler.scala:1012
[16:31:58,876] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at count at LinearRegression.scala:643)
[16:31:58,876] INFO  {TaskSchedulerImpl} Adding task set 14.0 with 1 tasks
[16:31:58,877] INFO  {TaskSetManager} Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5979 bytes)
[16:31:58,878] INFO  {Executor} Running task 0.0 in stage 14.0 (TID 14)
[16:31:58,882] INFO  {BlockManager} Found block rdd_2_0 locally
[16:31:58,895] INFO  {CodeGenerator} Code generated in 12.036912 ms
[16:31:58,903] INFO  {Executor} Finished task 0.0 in stage 14.0 (TID 14). 2324 bytes result sent to driver
[16:31:58,904] INFO  {TaskSetManager} Finished task 0.0 in stage 14.0 (TID 14) in 27 ms on localhost (1/1)
[16:31:58,904] INFO  {TaskSchedulerImpl} Removed TaskSet 14.0, whose tasks have all completed, from pool 
[16:31:58,905] INFO  {DAGScheduler} ShuffleMapStage 14 (count at LinearRegression.scala:643) finished in 0.029 s
[16:31:58,905] INFO  {DAGScheduler} looking for newly runnable stages
[16:31:58,905] INFO  {DAGScheduler} running: Set()
[16:31:58,905] INFO  {DAGScheduler} waiting: Set(ResultStage 15)
[16:31:58,905] INFO  {DAGScheduler} failed: Set()
[16:31:58,905] INFO  {DAGScheduler} Submitting ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643), which has no missing parents
[16:31:58,907] INFO  {MemoryStore} Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 1127.5 MB)
[16:31:58,909] INFO  {MemoryStore} Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1127.5 MB)
[16:31:58,909] INFO  {BlockManagerInfo} Added broadcast_16_piece0 in memory on 192.168.0.103:45419 (size: 3.7 KB, free: 1127.7 MB)
[16:31:58,910] INFO  {SparkContext} Created broadcast 16 from broadcast at DAGScheduler.scala:1012
[16:31:58,910] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at count at LinearRegression.scala:643)
[16:31:58,910] INFO  {TaskSchedulerImpl} Adding task set 15.0 with 1 tasks
[16:31:58,912] INFO  {TaskSetManager} Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, ANY, 5318 bytes)
[16:31:58,912] INFO  {Executor} Running task 0.0 in stage 15.0 (TID 15)
[16:31:58,915] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:31:58,916] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[16:31:58,919] INFO  {Executor} Finished task 0.0 in stage 15.0 (TID 15). 1960 bytes result sent to driver
[16:31:58,921] INFO  {TaskSetManager} Finished task 0.0 in stage 15.0 (TID 15) in 9 ms on localhost (1/1)
[16:31:58,921] INFO  {TaskSchedulerImpl} Removed TaskSet 15.0, whose tasks have all completed, from pool 
[16:31:58,921] INFO  {DAGScheduler} ResultStage 15 (count at LinearRegression.scala:643) finished in 0.010 s
[16:31:58,922] INFO  {DAGScheduler} Job 12 finished: count at LinearRegression.scala:643, took 0.052107 s
[16:31:58,929] INFO  {CodeGenerator} Code generated in 5.618679 ms
[16:31:59,099] INFO  {CodeGenerator} Code generated in 11.94247 ms
[16:31:59,115] INFO  {CodeGenerator} Code generated in 7.06555 ms
[16:31:59,121] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:31:59,126] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:31:59,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:31:59,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:31:59,129] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:31:59,129] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:31:59,129] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:31:59,129] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:31:59,129] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:31:59,129] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:31:59,129] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:31:59,129] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:31:59,130] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:31:59,130] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:31:59,130] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:31:59,130] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:31:59,130] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:31:59,130] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:31:59,130] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:31:59,130] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:31:59,131] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:31:59,131] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:31:59,131] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:31:59,131] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:31:59,131] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:31:59,131] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:31:59,133] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:31:59,146] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:31:59,160] INFO  {MemoryStore} MemoryStore cleared
[16:31:59,161] INFO  {BlockManager} BlockManager stopped
[16:31:59,162] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:31:59,167] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:31:59,172] INFO  {SparkContext} Successfully stopped SparkContext
[16:31:59,172] INFO  {ShutdownHookManager} Shutdown hook called
[16:31:59,173] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-e725aecd-052b-4fdb-af58-6f2951a5536c
[16:32:38,874] INFO  {SparkContext} Running Spark version 2.0.1
[16:32:39,107] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:32:39,208] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:32:39,209] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:32:39,299] INFO  {SecurityManager} Changing view acls to: victor
[16:32:39,300] INFO  {SecurityManager} Changing modify acls to: victor
[16:32:39,301] INFO  {SecurityManager} Changing view acls groups to: 
[16:32:39,302] INFO  {SecurityManager} Changing modify acls groups to: 
[16:32:39,302] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:32:39,612] INFO  {Utils} Successfully started service 'sparkDriver' on port 34943.
[16:32:39,630] INFO  {SparkEnv} Registering MapOutputTracker
[16:32:39,645] INFO  {SparkEnv} Registering BlockManagerMaster
[16:32:39,656] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-23e87536-e1eb-45d5-bead-34b9ea51d078
[16:32:39,670] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:32:39,725] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:32:39,801] INFO  {log} Logging initialized @1559ms
[16:32:39,902] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:32:39,918] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:32:39,918] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:32:39,918] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:32:39,919] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:32:39,919] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:32:39,919] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:32:39,919] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:32:39,919] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:32:39,920] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:32:39,920] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:32:39,920] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:32:39,920] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:32:39,920] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:32:39,921] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:32:39,921] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:32:39,921] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:32:39,921] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:32:39,921] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:32:39,921] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:32:39,921] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:32:39,927] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:32:39,928] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:32:39,928] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:32:39,928] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:32:39,935] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:32:39,935] INFO  {Server} Started @1694ms
[16:32:39,935] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:32:39,937] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:32:40,009] INFO  {Executor} Starting executor ID driver on host localhost
[16:32:40,029] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34759.
[16:32:40,030] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:34759
[16:32:40,032] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 34759)
[16:32:40,034] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:34759 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 34759)
[16:32:40,037] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 34759)
[16:32:40,155] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:32:40,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:32:40,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:32:40,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:32:40,199] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:32:40,200] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:32:40,213] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:32:42,012] INFO  {FileSourceStrategy} Pruning directories with: 
[16:32:42,015] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:32:42,019] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:32:42,020] INFO  {FileSourceStrategy} Pushed Filters: 
[16:32:42,126] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:32:42,171] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:32:42,172] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:34759 (size: 14.6 KB, free: 1128.9 MB)
[16:32:42,178] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:32:42,181] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:32:42,606] INFO  {CodeGenerator} Code generated in 186.347031 ms
[16:32:42,797] INFO  {CodeGenerator} Code generated in 25.86939 ms
[16:32:42,842] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:32:42,859] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:32:42,860] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:32:42,860] INFO  {DAGScheduler} Parents of final stage: List()
[16:32:42,864] INFO  {DAGScheduler} Missing parents: List()
[16:32:42,868] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:32:42,924] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:32:42,926] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:32:42,927] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:34759 (size: 8.5 KB, free: 1128.9 MB)
[16:32:42,927] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:32:42,931] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:32:42,932] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:32:42,970] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:32:42,978] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:32:43,020] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:32:43,032] INFO  {CodeGenerator} Code generated in 8.934014 ms
[16:32:43,181] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:32:43,182] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:34759 (size: 1239.2 KB, free: 1127.7 MB)
[16:32:43,194] INFO  {CodeGenerator} Code generated in 4.523205 ms
[16:32:43,221] INFO  {CodeGenerator} Code generated in 20.568285 ms
[16:32:43,241] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:32:43,248] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:32:43,256] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 302 ms on localhost (1/1)
[16:32:43,257] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:32:43,260] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.319 s
[16:32:43,265] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.422973 s
[16:32:43,303] INFO  {CodeGenerator} Code generated in 22.713569 ms
[16:32:43,411] INFO  {CodeGenerator} Code generated in 34.935729 ms
[16:32:43,427] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:32:43,428] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:32:43,428] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:32:43,428] INFO  {DAGScheduler} Parents of final stage: List()
[16:32:43,431] INFO  {DAGScheduler} Missing parents: List()
[16:32:43,431] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:32:43,437] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:32:43,439] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:32:43,440] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:34759 (size: 10.0 KB, free: 1127.7 MB)
[16:32:43,441] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:32:43,441] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:32:43,441] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:32:43,447] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:32:43,447] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:32:43,457] INFO  {BlockManager} Found block rdd_2_0 locally
[16:32:43,470] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:32:43,471] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:32:43,473] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[16:32:43,474] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:32:43,474] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.029 s
[16:32:43,476] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.049083 s
[16:32:43,505] INFO  {CodeGenerator} Code generated in 19.41709 ms
[16:32:43,707] INFO  {ContextCleaner} Cleaned accumulator 3
[16:32:43,707] INFO  {ContextCleaner} Cleaned accumulator 4
[16:32:43,731] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:34759 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:32:43,735] INFO  {ContextCleaner} Cleaned accumulator 49
[16:32:43,735] INFO  {ContextCleaner} Cleaned accumulator 50
[16:32:43,736] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:34759 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:32:43,783] INFO  {CodeGenerator} Code generated in 46.758675 ms
[16:32:43,798] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:32:43,799] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:32:43,799] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:32:43,799] INFO  {DAGScheduler} Parents of final stage: List()
[16:32:43,800] INFO  {DAGScheduler} Missing parents: List()
[16:32:43,801] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:32:43,806] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:32:43,808] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:32:43,809] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:34759 (size: 11.7 KB, free: 1127.7 MB)
[16:32:43,809] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:32:43,810] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:32:43,810] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:32:43,812] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:32:43,812] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:32:43,821] INFO  {BlockManager} Found block rdd_2_0 locally
[16:32:43,833] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:32:43,834] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:32:43,835] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on localhost (1/1)
[16:32:43,836] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:32:43,836] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.025 s
[16:32:43,837] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.038676 s
[16:32:43,859] INFO  {CodeGenerator} Code generated in 18.48879 ms
[16:32:43,953] INFO  {CodeGenerator} Code generated in 42.654502 ms
[16:32:43,966] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:32:43,966] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:32:43,967] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:32:43,967] INFO  {DAGScheduler} Parents of final stage: List()
[16:32:43,967] INFO  {DAGScheduler} Missing parents: List()
[16:32:43,967] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:32:43,970] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:32:43,972] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:32:43,973] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:34759 (size: 13.3 KB, free: 1127.7 MB)
[16:32:43,974] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:32:43,974] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:32:43,974] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:32:43,975] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:32:43,976] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:32:43,985] INFO  {BlockManager} Found block rdd_2_0 locally
[16:32:43,996] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:32:43,997] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:32:43,999] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on localhost (1/1)
[16:32:43,999] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:32:43,999] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.025 s
[16:32:44,000] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.033898 s
[16:32:44,014] INFO  {CodeGenerator} Code generated in 12.410458 ms
[16:32:44,113] INFO  {CodeGenerator} Code generated in 12.262707 ms
[16:32:44,134] INFO  {CodeGenerator} Code generated in 16.428046 ms
[16:32:44,167] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:32:44,172] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:32:44,172] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:32:44,173] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:32:44,173] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:32:44,173] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:32:44,174] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:32:44,180] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:32:44,182] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:32:44,182] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:34759 (size: 10.2 KB, free: 1127.6 MB)
[16:32:44,183] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:32:44,185] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:32:44,185] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:32:44,187] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:32:44,188] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:32:44,193] INFO  {BlockManager} Found block rdd_2_0 locally
[16:32:44,491] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:32:44,493] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 308 ms on localhost (1/1)
[16:32:44,493] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:32:44,495] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.310 s
[16:32:44,495] INFO  {DAGScheduler} looking for newly runnable stages
[16:32:44,496] INFO  {DAGScheduler} running: Set()
[16:32:44,496] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:32:44,496] INFO  {DAGScheduler} failed: Set()
[16:32:44,497] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:32:44,501] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:32:44,503] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:32:44,503] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:34759 (size: 3.9 KB, free: 1127.6 MB)
[16:32:44,504] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:32:44,504] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:32:44,504] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:32:44,507] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:32:44,508] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:32:44,521] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:32:44,522] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 3 ms
[16:32:44,535] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1955 bytes result sent to driver
[16:32:44,536] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 30 ms on localhost (1/1)
[16:32:44,536] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:32:44,536] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.031 s
[16:32:44,537] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.369094 s
[16:32:44,546] INFO  {CodeGenerator} Code generated in 6.199733 ms
[16:32:44,585] INFO  {CodeGenerator} Code generated in 8.456202 ms
[16:32:44,605] INFO  {CodeGenerator} Code generated in 16.035045 ms
[16:32:44,621] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:32:44,622] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:32:44,622] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:32:44,622] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:32:44,622] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:32:44,622] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:32:44,623] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:32:44,626] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:32:44,628] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:32:44,629] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:34759 (size: 10.2 KB, free: 1127.6 MB)
[16:32:44,629] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:32:44,629] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:32:44,629] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:32:44,631] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:32:44,631] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:32:44,637] INFO  {BlockManager} Found block rdd_2_0 locally
[16:32:44,731] INFO  {ContextCleaner} Cleaned accumulator 95
[16:32:44,731] INFO  {ContextCleaner} Cleaned accumulator 96
[16:32:44,732] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:34759 in memory (size: 11.7 KB, free: 1127.6 MB)
[16:32:44,733] INFO  {ContextCleaner} Cleaned accumulator 141
[16:32:44,733] INFO  {ContextCleaner} Cleaned accumulator 142
[16:32:44,734] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:34759 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:32:44,735] INFO  {ContextCleaner} Cleaned accumulator 288
[16:32:44,739] INFO  {ContextCleaner} Cleaned shuffle 0
[16:32:44,740] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:34759 in memory (size: 10.2 KB, free: 1127.7 MB)
[16:32:44,741] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:34759 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:32:44,742] INFO  {ContextCleaner} Cleaned accumulator 187
[16:32:44,742] INFO  {ContextCleaner} Cleaned accumulator 188
[16:32:44,742] INFO  {ContextCleaner} Cleaned accumulator 189
[16:32:44,742] INFO  {ContextCleaner} Cleaned accumulator 190
[16:32:44,742] INFO  {ContextCleaner} Cleaned accumulator 191
[16:32:44,742] INFO  {ContextCleaner} Cleaned accumulator 192
[16:32:44,742] INFO  {ContextCleaner} Cleaned accumulator 193
[16:32:44,743] INFO  {ContextCleaner} Cleaned accumulator 194
[16:32:44,743] INFO  {ContextCleaner} Cleaned accumulator 195
[16:32:44,743] INFO  {ContextCleaner} Cleaned accumulator 196
[16:32:44,743] INFO  {ContextCleaner} Cleaned accumulator 197
[16:32:44,743] INFO  {ContextCleaner} Cleaned accumulator 198
[16:32:44,743] INFO  {ContextCleaner} Cleaned accumulator 199
[16:32:44,774] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:32:44,775] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 145 ms on localhost (1/1)
[16:32:44,775] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:32:44,776] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.146 s
[16:32:44,776] INFO  {DAGScheduler} looking for newly runnable stages
[16:32:44,776] INFO  {DAGScheduler} running: Set()
[16:32:44,776] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:32:44,776] INFO  {DAGScheduler} failed: Set()
[16:32:44,777] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:32:44,779] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:32:44,781] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:32:44,781] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:34759 (size: 3.9 KB, free: 1127.7 MB)
[16:32:44,782] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:32:44,782] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:32:44,782] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:32:44,784] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:32:44,784] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:32:44,787] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:32:44,787] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:32:44,790] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:32:44,791] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (1/1)
[16:32:44,791] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:32:44,792] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.009 s
[16:32:44,793] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.171669 s
[16:32:44,923] INFO  {CodeGenerator} Code generated in 56.411312 ms
[16:32:44,937] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:32:44,937] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:32:44,937] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:32:44,938] INFO  {DAGScheduler} Parents of final stage: List()
[16:32:44,938] INFO  {DAGScheduler} Missing parents: List()
[16:32:44,939] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:32:44,943] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:32:44,946] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:32:44,946] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:34759 (size: 15.1 KB, free: 1127.6 MB)
[16:32:44,947] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:32:44,947] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:32:44,948] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:32:44,950] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:32:44,951] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:32:44,958] INFO  {BlockManager} Found block rdd_2_0 locally
[16:32:44,967] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:32:44,968] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:32:44,969] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 21 ms on localhost (1/1)
[16:32:44,969] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:32:44,970] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.022 s
[16:32:44,971] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.033852 s
[16:32:44,989] INFO  {CodeGenerator} Code generated in 15.512429 ms
[16:32:45,133] INFO  {CodeGenerator} Code generated in 59.844099 ms
[16:32:45,143] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:32:45,143] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:32:45,144] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:32:45,144] INFO  {DAGScheduler} Parents of final stage: List()
[16:32:45,144] INFO  {DAGScheduler} Missing parents: List()
[16:32:45,144] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:32:45,147] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:32:45,149] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:32:45,150] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:34759 (size: 16.4 KB, free: 1127.6 MB)
[16:32:45,150] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:32:45,151] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:32:45,151] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:32:45,152] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:32:45,153] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:32:45,158] INFO  {BlockManager} Found block rdd_2_0 locally
[16:32:45,164] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:32:45,164] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:32:45,165] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 14 ms on localhost (1/1)
[16:32:45,165] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:32:45,166] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.015 s
[16:32:45,166] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.023566 s
[16:32:45,180] INFO  {CodeGenerator} Code generated in 11.888806 ms
[16:32:45,582] INFO  {CodeGenerator} Code generated in 7.789641 ms
[16:32:45,594] INFO  {CodeGenerator} Code generated in 4.98157 ms
[16:32:45,601] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:32:45,606] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:32:45,608] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:32:45,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:32:45,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:32:45,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:32:45,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:32:45,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:32:45,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:32:45,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:32:45,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:32:45,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:32:45,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:32:45,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:32:45,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:32:45,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:32:45,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:32:45,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:32:45,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:32:45,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:32:45,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:32:45,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:32:45,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:32:45,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:32:45,611] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:32:45,611] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:32:45,612] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:32:45,628] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:32:45,637] INFO  {MemoryStore} MemoryStore cleared
[16:32:45,637] INFO  {BlockManager} BlockManager stopped
[16:32:45,639] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:32:45,642] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:32:45,644] INFO  {SparkContext} Successfully stopped SparkContext
[16:32:45,645] INFO  {ShutdownHookManager} Shutdown hook called
[16:32:45,646] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-282066b2-7c44-48ec-b07f-0be265b456a7
[16:33:08,450] INFO  {SparkContext} Running Spark version 2.0.1
[16:33:08,662] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:33:08,780] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:33:08,780] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:33:08,864] INFO  {SecurityManager} Changing view acls to: victor
[16:33:08,865] INFO  {SecurityManager} Changing modify acls to: victor
[16:33:08,866] INFO  {SecurityManager} Changing view acls groups to: 
[16:33:08,867] INFO  {SecurityManager} Changing modify acls groups to: 
[16:33:08,868] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:33:09,249] INFO  {Utils} Successfully started service 'sparkDriver' on port 32977.
[16:33:09,265] INFO  {SparkEnv} Registering MapOutputTracker
[16:33:09,280] INFO  {SparkEnv} Registering BlockManagerMaster
[16:33:09,292] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-9fccccb7-8d2d-4b37-bf53-f13ba4627f99
[16:33:09,306] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:33:09,355] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:33:09,423] INFO  {log} Logging initialized @1581ms
[16:33:09,520] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:33:09,537] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:33:09,537] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:33:09,537] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:33:09,538] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:33:09,538] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:33:09,538] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:33:09,539] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:33:09,539] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:33:09,539] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:33:09,539] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:33:09,540] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:33:09,540] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:33:09,540] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:33:09,541] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:33:09,541] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:33:09,541] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:33:09,541] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:33:09,542] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:33:09,542] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:33:09,542] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:33:09,551] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:33:09,551] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:33:09,552] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:33:09,553] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:33:09,561] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:33:09,561] INFO  {Server} Started @1720ms
[16:33:09,561] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:33:09,564] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:33:09,651] INFO  {Executor} Starting executor ID driver on host localhost
[16:33:09,677] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39637.
[16:33:09,678] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:39637
[16:33:09,679] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 39637)
[16:33:09,682] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:39637 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 39637)
[16:33:09,688] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 39637)
[16:33:09,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:33:09,864] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:33:09,865] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:33:09,866] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:33:09,866] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:33:09,868] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:33:09,880] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:33:11,603] INFO  {FileSourceStrategy} Pruning directories with: 
[16:33:11,606] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:33:11,610] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:33:11,611] INFO  {FileSourceStrategy} Pushed Filters: 
[16:33:11,721] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:33:11,765] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:33:11,767] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:39637 (size: 14.6 KB, free: 1128.9 MB)
[16:33:11,773] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:33:11,777] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:33:12,203] INFO  {CodeGenerator} Code generated in 192.130204 ms
[16:33:12,394] INFO  {CodeGenerator} Code generated in 25.595057 ms
[16:33:12,442] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:33:12,458] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:33:12,458] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:33:12,459] INFO  {DAGScheduler} Parents of final stage: List()
[16:33:12,462] INFO  {DAGScheduler} Missing parents: List()
[16:33:12,466] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:33:12,527] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:33:12,529] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:33:12,530] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:39637 (size: 8.5 KB, free: 1128.9 MB)
[16:33:12,530] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:33:12,534] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:33:12,535] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:33:12,568] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:33:12,575] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:33:12,613] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:33:12,624] INFO  {CodeGenerator} Code generated in 8.742146 ms
[16:33:12,767] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:33:12,768] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:39637 (size: 1239.2 KB, free: 1127.7 MB)
[16:33:12,778] INFO  {CodeGenerator} Code generated in 4.20383 ms
[16:33:12,803] INFO  {CodeGenerator} Code generated in 18.714277 ms
[16:33:12,822] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:33:12,828] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:33:12,838] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 284 ms on localhost (1/1)
[16:33:12,839] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:33:12,843] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.299 s
[16:33:12,850] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.407636 s
[16:33:12,885] INFO  {CodeGenerator} Code generated in 16.630138 ms
[16:33:12,975] INFO  {CodeGenerator} Code generated in 28.547524 ms
[16:33:12,987] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:33:12,988] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:33:12,988] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:33:12,988] INFO  {DAGScheduler} Parents of final stage: List()
[16:33:12,989] INFO  {DAGScheduler} Missing parents: List()
[16:33:12,990] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:33:12,994] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:33:12,996] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:33:12,996] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:39637 (size: 10.0 KB, free: 1127.7 MB)
[16:33:12,997] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:33:12,997] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:33:12,997] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:33:13,002] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:33:13,003] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:33:13,012] INFO  {BlockManager} Found block rdd_2_0 locally
[16:33:13,025] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:33:13,026] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:33:13,028] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 27 ms on localhost (1/1)
[16:33:13,028] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:33:13,028] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.028 s
[16:33:13,029] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.042020 s
[16:33:13,051] INFO  {CodeGenerator} Code generated in 14.747367 ms
[16:33:13,245] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:39637 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:33:13,252] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:39637 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:33:13,254] INFO  {ContextCleaner} Cleaned accumulator 49
[16:33:13,254] INFO  {ContextCleaner} Cleaned accumulator 50
[16:33:13,254] INFO  {ContextCleaner} Cleaned accumulator 3
[16:33:13,254] INFO  {ContextCleaner} Cleaned accumulator 4
[16:33:13,303] INFO  {CodeGenerator} Code generated in 39.551309 ms
[16:33:13,314] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:33:13,314] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:33:13,315] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:33:13,315] INFO  {DAGScheduler} Parents of final stage: List()
[16:33:13,315] INFO  {DAGScheduler} Missing parents: List()
[16:33:13,316] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:33:13,320] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:33:13,322] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:33:13,322] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:39637 (size: 11.7 KB, free: 1127.7 MB)
[16:33:13,323] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:33:13,323] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:33:13,323] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:33:13,325] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:33:13,326] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:33:13,333] INFO  {BlockManager} Found block rdd_2_0 locally
[16:33:13,345] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:33:13,346] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:33:13,348] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 24 ms on localhost (1/1)
[16:33:13,348] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:33:13,349] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.025 s
[16:33:13,350] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.035832 s
[16:33:13,373] INFO  {CodeGenerator} Code generated in 19.595455 ms
[16:33:13,475] INFO  {CodeGenerator} Code generated in 44.637688 ms
[16:33:13,490] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:33:13,491] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:33:13,491] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:33:13,491] INFO  {DAGScheduler} Parents of final stage: List()
[16:33:13,491] INFO  {DAGScheduler} Missing parents: List()
[16:33:13,492] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:33:13,496] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:33:13,498] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:33:13,498] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:39637 (size: 13.3 KB, free: 1127.7 MB)
[16:33:13,499] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:33:13,499] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:33:13,499] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:33:13,501] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:33:13,501] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:33:13,508] INFO  {BlockManager} Found block rdd_2_0 locally
[16:33:13,517] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:33:13,518] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:33:13,519] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 19 ms on localhost (1/1)
[16:33:13,519] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:33:13,524] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.020 s
[16:33:13,524] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.034510 s
[16:33:13,541] INFO  {CodeGenerator} Code generated in 14.45756 ms
[16:33:13,658] INFO  {CodeGenerator} Code generated in 13.00567 ms
[16:33:13,681] INFO  {CodeGenerator} Code generated in 17.972282 ms
[16:33:13,713] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:33:13,716] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:33:13,716] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:33:13,717] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:33:13,717] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:33:13,717] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:33:13,718] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:33:13,724] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:33:13,726] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:33:13,727] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:39637 (size: 10.2 KB, free: 1127.6 MB)
[16:33:13,727] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:33:13,729] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:33:13,729] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:33:13,732] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:33:13,732] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:33:13,740] INFO  {BlockManager} Found block rdd_2_0 locally
[16:33:14,028] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:33:14,031] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 300 ms on localhost (1/1)
[16:33:14,031] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:33:14,032] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.303 s
[16:33:14,032] INFO  {DAGScheduler} looking for newly runnable stages
[16:33:14,033] INFO  {DAGScheduler} running: Set()
[16:33:14,033] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:33:14,034] INFO  {DAGScheduler} failed: Set()
[16:33:14,035] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:33:14,040] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:33:14,042] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:33:14,042] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:39637 (size: 3.9 KB, free: 1127.6 MB)
[16:33:14,043] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:33:14,043] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:33:14,043] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:33:14,046] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:33:14,046] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:33:14,060] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:33:14,061] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[16:33:14,072] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:33:14,074] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 29 ms on localhost (1/1)
[16:33:14,074] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:33:14,074] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.030 s
[16:33:14,075] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.362110 s
[16:33:14,087] INFO  {CodeGenerator} Code generated in 7.272567 ms
[16:33:14,129] INFO  {CodeGenerator} Code generated in 10.595286 ms
[16:33:14,159] INFO  {CodeGenerator} Code generated in 23.912626 ms
[16:33:14,176] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:33:14,176] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:33:14,177] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:33:14,177] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:33:14,177] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:33:14,177] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:33:14,178] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:33:14,181] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:33:14,183] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:33:14,183] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:39637 (size: 10.2 KB, free: 1127.6 MB)
[16:33:14,184] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:33:14,184] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:33:14,184] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:33:14,186] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:33:14,186] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:33:14,190] INFO  {BlockManager} Found block rdd_2_0 locally
[16:33:14,263] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:39637 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:33:14,263] INFO  {ContextCleaner} Cleaned accumulator 288
[16:33:14,264] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:39637 in memory (size: 10.2 KB, free: 1127.6 MB)
[16:33:14,265] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:39637 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 187
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 188
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 189
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 190
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 191
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 192
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 193
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 194
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 195
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 196
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 197
[16:33:14,266] INFO  {ContextCleaner} Cleaned accumulator 198
[16:33:14,267] INFO  {ContextCleaner} Cleaned accumulator 199
[16:33:14,269] INFO  {ContextCleaner} Cleaned shuffle 0
[16:33:14,270] INFO  {ContextCleaner} Cleaned accumulator 95
[16:33:14,270] INFO  {ContextCleaner} Cleaned accumulator 96
[16:33:14,271] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:39637 in memory (size: 11.7 KB, free: 1127.7 MB)
[16:33:14,271] INFO  {ContextCleaner} Cleaned accumulator 141
[16:33:14,271] INFO  {ContextCleaner} Cleaned accumulator 142
[16:33:14,288] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:33:14,289] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 104 ms on localhost (1/1)
[16:33:14,289] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:33:14,290] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.106 s
[16:33:14,290] INFO  {DAGScheduler} looking for newly runnable stages
[16:33:14,290] INFO  {DAGScheduler} running: Set()
[16:33:14,290] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:33:14,290] INFO  {DAGScheduler} failed: Set()
[16:33:14,291] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:33:14,292] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:33:14,294] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:33:14,294] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:39637 (size: 3.9 KB, free: 1127.7 MB)
[16:33:14,295] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:33:14,295] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:33:14,295] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:33:14,297] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:33:14,297] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:33:14,299] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:33:14,300] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[16:33:14,302] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:33:14,303] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 7 ms on localhost (1/1)
[16:33:14,303] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:33:14,304] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.009 s
[16:33:14,304] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.128517 s
[16:33:14,402] INFO  {CodeGenerator} Code generated in 42.588376 ms
[16:33:14,411] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:33:14,412] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:33:14,412] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:33:14,412] INFO  {DAGScheduler} Parents of final stage: List()
[16:33:14,412] INFO  {DAGScheduler} Missing parents: List()
[16:33:14,413] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:33:14,416] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:33:14,418] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:33:14,419] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:39637 (size: 15.0 KB, free: 1127.6 MB)
[16:33:14,419] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:33:14,420] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:33:14,420] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:33:14,422] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:33:14,422] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:33:14,427] INFO  {BlockManager} Found block rdd_2_0 locally
[16:33:14,434] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:33:14,435] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:33:14,436] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 15 ms on localhost (1/1)
[16:33:14,436] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:33:14,436] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.016 s
[16:33:14,437] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.025368 s
[16:33:14,451] INFO  {CodeGenerator} Code generated in 12.401118 ms
[16:33:14,564] INFO  {CodeGenerator} Code generated in 58.248189 ms
[16:33:14,574] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:33:14,576] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:33:14,576] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:33:14,576] INFO  {DAGScheduler} Parents of final stage: List()
[16:33:14,577] INFO  {DAGScheduler} Missing parents: List()
[16:33:14,577] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:33:14,580] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:33:14,582] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:33:14,583] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:39637 (size: 16.4 KB, free: 1127.6 MB)
[16:33:14,583] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:33:14,584] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:33:14,584] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:33:14,586] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:33:14,587] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:33:14,590] INFO  {BlockManager} Found block rdd_2_0 locally
[16:33:14,597] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:33:14,598] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4086 bytes result sent to driver
[16:33:14,599] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 15 ms on localhost (1/1)
[16:33:14,599] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:33:14,600] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.015 s
[16:33:14,601] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.026240 s
[16:33:14,619] INFO  {CodeGenerator} Code generated in 14.093294 ms
[16:33:14,986] INFO  {CodeGenerator} Code generated in 8.73588 ms
[16:33:15,000] INFO  {CodeGenerator} Code generated in 6.518364 ms
[16:33:15,004] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:33:15,008] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:33:15,010] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:33:15,010] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:33:15,010] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:33:15,010] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:33:15,010] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:33:15,010] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:33:15,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:33:15,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:33:15,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:33:15,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:33:15,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:33:15,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:33:15,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:33:15,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:33:15,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:33:15,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:33:15,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:33:15,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:33:15,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:33:15,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:33:15,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:33:15,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:33:15,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:33:15,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:33:15,014] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:33:15,023] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:33:15,031] INFO  {MemoryStore} MemoryStore cleared
[16:33:15,032] INFO  {BlockManager} BlockManager stopped
[16:33:15,033] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:33:15,035] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:33:15,039] INFO  {SparkContext} Successfully stopped SparkContext
[16:33:15,040] INFO  {ShutdownHookManager} Shutdown hook called
[16:33:15,040] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-248ba6d1-be86-4ffc-8d20-0d213d9b30d9
[16:34:30,445] INFO  {SparkContext} Running Spark version 2.0.1
[16:34:30,655] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:34:30,747] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:34:30,748] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:34:30,817] INFO  {SecurityManager} Changing view acls to: victor
[16:34:30,818] INFO  {SecurityManager} Changing modify acls to: victor
[16:34:30,818] INFO  {SecurityManager} Changing view acls groups to: 
[16:34:30,819] INFO  {SecurityManager} Changing modify acls groups to: 
[16:34:30,820] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:34:31,173] INFO  {Utils} Successfully started service 'sparkDriver' on port 33423.
[16:34:31,191] INFO  {SparkEnv} Registering MapOutputTracker
[16:34:31,206] INFO  {SparkEnv} Registering BlockManagerMaster
[16:34:31,218] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-783bf5a7-1dc1-4937-85f9-541bc9c02546
[16:34:31,232] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:34:31,274] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:34:31,348] INFO  {log} Logging initialized @1467ms
[16:34:31,452] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:34:31,468] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[16:34:31,469] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[16:34:31,469] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[16:34:31,469] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[16:34:31,469] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[16:34:31,470] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[16:34:31,470] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[16:34:31,470] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[16:34:31,470] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[16:34:31,471] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[16:34:31,471] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[16:34:31,471] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[16:34:31,472] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[16:34:31,472] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[16:34:31,472] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[16:34:31,472] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[16:34:31,473] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[16:34:31,473] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[16:34:31,473] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[16:34:31,473] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[16:34:31,482] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[16:34:31,482] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[16:34:31,483] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[16:34:31,484] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[16:34:31,492] INFO  {ServerConnector} Started ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:34:31,492] INFO  {Server} Started @1613ms
[16:34:31,492] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:34:31,495] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:34:31,579] INFO  {Executor} Starting executor ID driver on host localhost
[16:34:31,604] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46245.
[16:34:31,605] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:46245
[16:34:31,607] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 46245)
[16:34:31,610] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:46245 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 46245)
[16:34:31,614] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 46245)
[16:34:31,735] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[16:34:31,782] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL,null,AVAILABLE}
[16:34:31,782] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/json,null,AVAILABLE}
[16:34:31,783] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution,null,AVAILABLE}
[16:34:31,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b11ef33{/SQL/execution/json,null,AVAILABLE}
[16:34:31,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@21ec5d87{/static/sql,null,AVAILABLE}
[16:34:31,799] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:34:33,536] INFO  {FileSourceStrategy} Pruning directories with: 
[16:34:33,539] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:34:33,544] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:34:33,545] INFO  {FileSourceStrategy} Pushed Filters: 
[16:34:33,656] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:34:33,703] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:34:33,715] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:46245 (size: 14.6 KB, free: 1128.9 MB)
[16:34:33,722] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:34:33,727] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:34:34,161] INFO  {CodeGenerator} Code generated in 192.457977 ms
[16:34:34,354] INFO  {CodeGenerator} Code generated in 25.977286 ms
[16:34:34,399] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:34:34,417] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:34:34,418] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:34:34,418] INFO  {DAGScheduler} Parents of final stage: List()
[16:34:34,422] INFO  {DAGScheduler} Missing parents: List()
[16:34:34,426] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:34:34,488] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:34:34,489] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:34:34,490] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:46245 (size: 8.5 KB, free: 1128.9 MB)
[16:34:34,490] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:34:34,493] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:34:34,495] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:34:34,530] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:34:34,538] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:34:34,578] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:34:34,589] INFO  {CodeGenerator} Code generated in 8.789364 ms
[16:34:34,727] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:34:34,728] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:46245 (size: 1239.2 KB, free: 1127.7 MB)
[16:34:34,753] INFO  {CodeGenerator} Code generated in 16.186025 ms
[16:34:34,779] INFO  {CodeGenerator} Code generated in 19.914149 ms
[16:34:34,799] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:34:34,806] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:34:34,817] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 304 ms on localhost (1/1)
[16:34:34,818] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:34:34,821] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.318 s
[16:34:34,828] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.428588 s
[16:34:34,866] INFO  {CodeGenerator} Code generated in 21.192525 ms
[16:34:34,960] INFO  {CodeGenerator} Code generated in 29.084642 ms
[16:34:34,973] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:34:34,974] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:34:34,974] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:34:34,974] INFO  {DAGScheduler} Parents of final stage: List()
[16:34:34,976] INFO  {DAGScheduler} Missing parents: List()
[16:34:34,976] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:34:34,980] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:34:34,982] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:34:34,982] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:46245 (size: 10.0 KB, free: 1127.7 MB)
[16:34:34,983] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:34:34,983] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:34:34,983] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:34:34,988] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:34:34,989] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:34:34,998] INFO  {BlockManager} Found block rdd_2_0 locally
[16:34:35,012] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:34:35,013] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:34:35,015] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 29 ms on localhost (1/1)
[16:34:35,016] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:34:35,016] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.030 s
[16:34:35,017] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.043975 s
[16:34:35,047] INFO  {CodeGenerator} Code generated in 20.916072 ms
[16:34:35,252] INFO  {ContextCleaner} Cleaned accumulator 3
[16:34:35,252] INFO  {ContextCleaner} Cleaned accumulator 4
[16:34:35,268] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:46245 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:34:35,271] INFO  {ContextCleaner} Cleaned accumulator 49
[16:34:35,272] INFO  {ContextCleaner} Cleaned accumulator 50
[16:34:35,272] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:46245 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:34:35,329] INFO  {CodeGenerator} Code generated in 53.919323 ms
[16:34:35,346] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:34:35,347] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:34:35,347] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:34:35,347] INFO  {DAGScheduler} Parents of final stage: List()
[16:34:35,348] INFO  {DAGScheduler} Missing parents: List()
[16:34:35,349] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:34:35,355] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:34:35,357] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:34:35,358] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:46245 (size: 11.7 KB, free: 1127.7 MB)
[16:34:35,359] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:34:35,359] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:34:35,359] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:34:35,362] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:34:35,363] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:34:35,372] INFO  {BlockManager} Found block rdd_2_0 locally
[16:34:35,385] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:34:35,386] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:34:35,388] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on localhost (1/1)
[16:34:35,388] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:34:35,390] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.029 s
[16:34:35,390] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.044332 s
[16:34:35,416] INFO  {CodeGenerator} Code generated in 21.418869 ms
[16:34:35,538] INFO  {CodeGenerator} Code generated in 52.272214 ms
[16:34:35,552] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:34:35,553] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:34:35,553] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:34:35,553] INFO  {DAGScheduler} Parents of final stage: List()
[16:34:35,553] INFO  {DAGScheduler} Missing parents: List()
[16:34:35,554] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:34:35,558] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:34:35,560] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:34:35,560] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:46245 (size: 13.3 KB, free: 1127.7 MB)
[16:34:35,561] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:34:35,561] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:34:35,561] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:34:35,563] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:34:35,564] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:34:35,572] INFO  {BlockManager} Found block rdd_2_0 locally
[16:34:35,582] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:34:35,583] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:34:35,585] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 22 ms on localhost (1/1)
[16:34:35,585] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:34:35,585] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.023 s
[16:34:35,586] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.033294 s
[16:34:35,603] INFO  {CodeGenerator} Code generated in 15.237184 ms
[16:34:35,715] INFO  {CodeGenerator} Code generated in 11.864716 ms
[16:34:35,739] INFO  {CodeGenerator} Code generated in 18.971827 ms
[16:34:35,778] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:34:35,782] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:34:35,784] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:34:35,784] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:34:35,784] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:34:35,784] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:34:35,786] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:34:35,795] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:34:35,797] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:34:35,798] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:46245 (size: 10.1 KB, free: 1127.6 MB)
[16:34:35,798] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:34:35,801] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:34:35,801] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:34:35,804] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:34:35,804] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:34:35,810] INFO  {BlockManager} Found block rdd_2_0 locally
[16:34:36,115] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:34:36,117] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 315 ms on localhost (1/1)
[16:34:36,118] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:34:36,119] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.316 s
[16:34:36,119] INFO  {DAGScheduler} looking for newly runnable stages
[16:34:36,119] INFO  {DAGScheduler} running: Set()
[16:34:36,120] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:34:36,120] INFO  {DAGScheduler} failed: Set()
[16:34:36,122] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:34:36,126] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:34:36,128] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:34:36,128] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:46245 (size: 3.9 KB, free: 1127.6 MB)
[16:34:36,129] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:34:36,129] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:34:36,129] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:34:36,132] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:34:36,132] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:34:36,146] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:34:36,148] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[16:34:36,160] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:34:36,161] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 31 ms on localhost (1/1)
[16:34:36,161] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:34:36,162] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.031 s
[16:34:36,162] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.383504 s
[16:34:36,170] INFO  {CodeGenerator} Code generated in 5.302215 ms
[16:34:36,209] INFO  {CodeGenerator} Code generated in 8.585657 ms
[16:34:36,228] INFO  {CodeGenerator} Code generated in 14.843422 ms
[16:34:36,242] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:34:36,243] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:34:36,243] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:34:36,243] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:34:36,243] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:34:36,244] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:34:36,244] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:34:36,248] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:34:36,251] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:34:36,252] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:46245 (size: 10.1 KB, free: 1127.6 MB)
[16:34:36,252] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:34:36,252] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:34:36,253] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:34:36,254] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:34:36,255] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:34:36,258] INFO  {BlockManager} Found block rdd_2_0 locally
[16:34:36,311] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:46245 in memory (size: 11.7 KB, free: 1127.6 MB)
[16:34:36,312] INFO  {ContextCleaner} Cleaned accumulator 141
[16:34:36,312] INFO  {ContextCleaner} Cleaned accumulator 142
[16:34:36,315] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:46245 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:34:36,317] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:46245 in memory (size: 3.9 KB, free: 1127.7 MB)
[16:34:36,318] INFO  {ContextCleaner} Cleaned accumulator 288
[16:34:36,319] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:46245 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:34:36,319] INFO  {ContextCleaner} Cleaned accumulator 187
[16:34:36,319] INFO  {ContextCleaner} Cleaned accumulator 188
[16:34:36,319] INFO  {ContextCleaner} Cleaned accumulator 189
[16:34:36,319] INFO  {ContextCleaner} Cleaned accumulator 190
[16:34:36,320] INFO  {ContextCleaner} Cleaned accumulator 191
[16:34:36,320] INFO  {ContextCleaner} Cleaned accumulator 192
[16:34:36,320] INFO  {ContextCleaner} Cleaned accumulator 193
[16:34:36,320] INFO  {ContextCleaner} Cleaned accumulator 194
[16:34:36,320] INFO  {ContextCleaner} Cleaned accumulator 195
[16:34:36,320] INFO  {ContextCleaner} Cleaned accumulator 196
[16:34:36,320] INFO  {ContextCleaner} Cleaned accumulator 197
[16:34:36,320] INFO  {ContextCleaner} Cleaned accumulator 198
[16:34:36,320] INFO  {ContextCleaner} Cleaned accumulator 199
[16:34:36,324] INFO  {ContextCleaner} Cleaned shuffle 0
[16:34:36,390] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:34:36,391] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 138 ms on localhost (1/1)
[16:34:36,391] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:34:36,392] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.139 s
[16:34:36,392] INFO  {DAGScheduler} looking for newly runnable stages
[16:34:36,392] INFO  {DAGScheduler} running: Set()
[16:34:36,392] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:34:36,392] INFO  {DAGScheduler} failed: Set()
[16:34:36,393] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:34:36,395] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:34:36,397] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:34:36,397] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:46245 (size: 3.9 KB, free: 1127.7 MB)
[16:34:36,398] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:34:36,398] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:34:36,398] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:34:36,400] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:34:36,400] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:34:36,403] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:34:36,403] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:34:36,407] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:34:36,408] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 9 ms on localhost (1/1)
[16:34:36,408] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:34:36,409] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.009 s
[16:34:36,409] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.166991 s
[16:34:36,542] INFO  {CodeGenerator} Code generated in 59.082525 ms
[16:34:36,553] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:34:36,554] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:34:36,554] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:34:36,554] INFO  {DAGScheduler} Parents of final stage: List()
[16:34:36,555] INFO  {DAGScheduler} Missing parents: List()
[16:34:36,555] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:34:36,559] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:34:36,561] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:34:36,562] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:46245 (size: 15.1 KB, free: 1127.6 MB)
[16:34:36,563] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:34:36,563] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:34:36,563] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:34:36,566] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:34:36,566] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:34:36,573] INFO  {BlockManager} Found block rdd_2_0 locally
[16:34:36,582] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:34:36,583] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:34:36,584] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 20 ms on localhost (1/1)
[16:34:36,584] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:34:36,585] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.021 s
[16:34:36,585] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.031914 s
[16:34:36,603] INFO  {CodeGenerator} Code generated in 14.723966 ms
[16:34:36,741] INFO  {CodeGenerator} Code generated in 59.90228 ms
[16:34:36,751] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:34:36,751] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:34:36,752] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:34:36,752] INFO  {DAGScheduler} Parents of final stage: List()
[16:34:36,752] INFO  {DAGScheduler} Missing parents: List()
[16:34:36,753] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:34:36,756] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:34:36,758] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:34:36,759] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:46245 (size: 16.4 KB, free: 1127.6 MB)
[16:34:36,759] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:34:36,760] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:34:36,760] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:34:36,765] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:34:36,766] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:34:36,771] INFO  {BlockManager} Found block rdd_2_0 locally
[16:34:36,779] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:34:36,780] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4086 bytes result sent to driver
[16:34:36,781] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 21 ms on localhost (1/1)
[16:34:36,781] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:34:36,781] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.021 s
[16:34:36,782] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.031316 s
[16:34:36,800] INFO  {CodeGenerator} Code generated in 14.804898 ms
[16:34:37,281] INFO  {CodeGenerator} Code generated in 11.816954 ms
[16:34:37,297] INFO  {CodeGenerator} Code generated in 6.393438 ms
[16:34:37,303] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:34:37,308] INFO  {ServerConnector} Stopped ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:34:37,310] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[16:34:37,310] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[16:34:37,310] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[16:34:37,310] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[16:34:37,311] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[16:34:37,311] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[16:34:37,311] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[16:34:37,311] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[16:34:37,311] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[16:34:37,311] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[16:34:37,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[16:34:37,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[16:34:37,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[16:34:37,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[16:34:37,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[16:34:37,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[16:34:37,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[16:34:37,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[16:34:37,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[16:34:37,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[16:34:37,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[16:34:37,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[16:34:37,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[16:34:37,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[16:34:37,315] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:34:37,327] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:34:37,342] INFO  {MemoryStore} MemoryStore cleared
[16:34:37,342] INFO  {BlockManager} BlockManager stopped
[16:34:37,345] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:34:37,347] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:34:37,352] INFO  {SparkContext} Successfully stopped SparkContext
[16:34:37,352] INFO  {ShutdownHookManager} Shutdown hook called
[16:34:37,353] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-3ed99b6c-ad1f-46bf-b969-7d078a134368
[16:35:34,456] INFO  {SparkContext} Running Spark version 2.0.1
[16:35:34,678] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:35:34,778] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:35:34,778] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:35:34,853] INFO  {SecurityManager} Changing view acls to: victor
[16:35:34,854] INFO  {SecurityManager} Changing modify acls to: victor
[16:35:34,855] INFO  {SecurityManager} Changing view acls groups to: 
[16:35:34,856] INFO  {SecurityManager} Changing modify acls groups to: 
[16:35:34,857] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:35:35,192] INFO  {Utils} Successfully started service 'sparkDriver' on port 33293.
[16:35:35,213] INFO  {SparkEnv} Registering MapOutputTracker
[16:35:35,228] INFO  {SparkEnv} Registering BlockManagerMaster
[16:35:35,240] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-f7ebc8ca-acaf-4f5c-b773-ca790c74eb0b
[16:35:35,255] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:35:35,309] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:35:35,386] INFO  {log} Logging initialized @1559ms
[16:35:35,487] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:35:35,503] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:35:35,504] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:35:35,504] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:35:35,504] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:35:35,504] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:35:35,505] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:35:35,505] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:35:35,505] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:35:35,506] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:35:35,506] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:35:35,506] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:35:35,506] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:35:35,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:35:35,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:35:35,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:35:35,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:35:35,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:35:35,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:35:35,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:35:35,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:35:35,515] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:35:35,515] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:35:35,516] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:35:35,516] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:35:35,524] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:35:35,525] INFO  {Server} Started @1699ms
[16:35:35,525] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:35:35,528] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:35:35,619] INFO  {Executor} Starting executor ID driver on host localhost
[16:35:35,644] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39525.
[16:35:35,645] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:39525
[16:35:35,647] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 39525)
[16:35:35,650] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:39525 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 39525)
[16:35:35,653] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 39525)
[16:35:35,774] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:35:35,820] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:35:35,821] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:35:35,821] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:35:35,822] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:35:35,824] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:35:35,838] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:35:37,680] INFO  {FileSourceStrategy} Pruning directories with: 
[16:35:37,683] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:35:37,687] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:35:37,688] INFO  {FileSourceStrategy} Pushed Filters: 
[16:35:37,804] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:35:37,851] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:35:37,853] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:39525 (size: 14.6 KB, free: 1128.9 MB)
[16:35:37,859] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:35:37,862] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:35:38,322] INFO  {CodeGenerator} Code generated in 199.578533 ms
[16:35:38,543] INFO  {CodeGenerator} Code generated in 33.449613 ms
[16:35:38,599] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:35:38,614] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:35:38,615] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:35:38,615] INFO  {DAGScheduler} Parents of final stage: List()
[16:35:38,619] INFO  {DAGScheduler} Missing parents: List()
[16:35:38,622] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:35:38,678] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:35:38,681] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:35:38,682] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:39525 (size: 8.5 KB, free: 1128.9 MB)
[16:35:38,682] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:35:38,685] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:35:38,687] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:35:38,723] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:35:38,732] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:35:38,774] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:35:38,786] INFO  {CodeGenerator} Code generated in 8.677436 ms
[16:35:38,934] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:35:38,934] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:39525 (size: 1239.2 KB, free: 1127.7 MB)
[16:35:38,946] INFO  {CodeGenerator} Code generated in 4.069546 ms
[16:35:38,971] INFO  {CodeGenerator} Code generated in 19.376563 ms
[16:35:38,991] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:35:38,997] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:35:39,005] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 297 ms on localhost (1/1)
[16:35:39,007] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:35:39,011] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.315 s
[16:35:39,018] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.418431 s
[16:35:39,057] INFO  {CodeGenerator} Code generated in 20.087065 ms
[16:35:39,156] INFO  {CodeGenerator} Code generated in 30.614219 ms
[16:35:39,168] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:35:39,170] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:35:39,170] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:35:39,170] INFO  {DAGScheduler} Parents of final stage: List()
[16:35:39,172] INFO  {DAGScheduler} Missing parents: List()
[16:35:39,172] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:35:39,177] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:35:39,179] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:35:39,179] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:39525 (size: 10.0 KB, free: 1127.7 MB)
[16:35:39,180] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:35:39,180] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:35:39,180] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:35:39,185] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:35:39,186] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:35:39,199] INFO  {BlockManager} Found block rdd_2_0 locally
[16:35:39,214] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:35:39,215] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:35:39,217] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on localhost (1/1)
[16:35:39,217] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:35:39,218] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.035 s
[16:35:39,218] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.049874 s
[16:35:39,241] INFO  {CodeGenerator} Code generated in 15.49263 ms
[16:35:39,428] INFO  {ContextCleaner} Cleaned accumulator 3
[16:35:39,428] INFO  {ContextCleaner} Cleaned accumulator 4
[16:35:39,442] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:39525 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:35:39,449] INFO  {ContextCleaner} Cleaned accumulator 49
[16:35:39,449] INFO  {ContextCleaner} Cleaned accumulator 50
[16:35:39,450] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:39525 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:35:39,505] INFO  {CodeGenerator} Code generated in 39.841019 ms
[16:35:39,516] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:35:39,517] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:35:39,517] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:35:39,517] INFO  {DAGScheduler} Parents of final stage: List()
[16:35:39,518] INFO  {DAGScheduler} Missing parents: List()
[16:35:39,519] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:35:39,523] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:35:39,525] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:35:39,525] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:39525 (size: 11.7 KB, free: 1127.7 MB)
[16:35:39,526] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:35:39,526] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:35:39,526] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:35:39,528] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:35:39,529] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:35:39,538] INFO  {BlockManager} Found block rdd_2_0 locally
[16:35:39,551] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:35:39,553] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:35:39,555] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on localhost (1/1)
[16:35:39,555] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:35:39,557] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.028 s
[16:35:39,557] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.041013 s
[16:35:39,575] INFO  {CodeGenerator} Code generated in 15.154606 ms
[16:35:39,672] INFO  {CodeGenerator} Code generated in 42.500515 ms
[16:35:39,684] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:35:39,685] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:35:39,685] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:35:39,685] INFO  {DAGScheduler} Parents of final stage: List()
[16:35:39,685] INFO  {DAGScheduler} Missing parents: List()
[16:35:39,685] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:35:39,688] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:35:39,691] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:35:39,691] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:39525 (size: 13.3 KB, free: 1127.7 MB)
[16:35:39,692] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:35:39,692] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:35:39,693] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:35:39,694] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:35:39,695] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:35:39,703] INFO  {BlockManager} Found block rdd_2_0 locally
[16:35:39,716] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:35:39,717] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:35:39,718] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on localhost (1/1)
[16:35:39,719] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:35:39,719] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.026 s
[16:35:39,719] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.035603 s
[16:35:39,735] INFO  {CodeGenerator} Code generated in 13.141349 ms
[16:35:39,841] INFO  {CodeGenerator} Code generated in 15.855645 ms
[16:35:39,867] INFO  {CodeGenerator} Code generated in 19.690402 ms
[16:35:39,902] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:35:39,906] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:35:39,906] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:35:39,906] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:35:39,907] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:35:39,907] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:35:39,908] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:35:39,914] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:35:39,915] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:35:39,916] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:39525 (size: 10.2 KB, free: 1127.6 MB)
[16:35:39,917] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:35:39,918] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:35:39,919] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:35:39,921] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:35:39,922] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:35:39,928] INFO  {BlockManager} Found block rdd_2_0 locally
[16:35:40,200] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:35:40,202] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 283 ms on localhost (1/1)
[16:35:40,202] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:35:40,203] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.284 s
[16:35:40,204] INFO  {DAGScheduler} looking for newly runnable stages
[16:35:40,205] INFO  {DAGScheduler} running: Set()
[16:35:40,205] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:35:40,206] INFO  {DAGScheduler} failed: Set()
[16:35:40,207] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:35:40,211] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:35:40,213] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:35:40,213] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:39525 (size: 3.9 KB, free: 1127.6 MB)
[16:35:40,214] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:35:40,214] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:35:40,214] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:35:40,218] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:35:40,219] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:35:40,230] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:35:40,232] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[16:35:40,244] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:35:40,245] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 29 ms on localhost (1/1)
[16:35:40,245] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:35:40,246] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.030 s
[16:35:40,246] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.344510 s
[16:35:40,258] INFO  {CodeGenerator} Code generated in 7.569956 ms
[16:35:40,297] INFO  {CodeGenerator} Code generated in 9.477395 ms
[16:35:40,322] INFO  {CodeGenerator} Code generated in 20.639073 ms
[16:35:40,339] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:35:40,340] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:35:40,340] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:35:40,341] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:35:40,341] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:35:40,341] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:35:40,342] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:35:40,345] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:35:40,348] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:35:40,349] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:39525 (size: 10.2 KB, free: 1127.6 MB)
[16:35:40,349] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:35:40,350] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:35:40,350] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:35:40,352] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:35:40,352] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:35:40,358] INFO  {BlockManager} Found block rdd_2_0 locally
[16:35:40,451] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:39525 in memory (size: 10.2 KB, free: 1127.6 MB)
[16:35:40,453] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:39525 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:35:40,454] INFO  {ContextCleaner} Cleaned accumulator 288
[16:35:40,455] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:39525 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:35:40,455] INFO  {ContextCleaner} Cleaned accumulator 187
[16:35:40,455] INFO  {ContextCleaner} Cleaned accumulator 188
[16:35:40,456] INFO  {ContextCleaner} Cleaned accumulator 189
[16:35:40,456] INFO  {ContextCleaner} Cleaned accumulator 190
[16:35:40,456] INFO  {ContextCleaner} Cleaned accumulator 191
[16:35:40,456] INFO  {ContextCleaner} Cleaned accumulator 192
[16:35:40,456] INFO  {ContextCleaner} Cleaned accumulator 193
[16:35:40,456] INFO  {ContextCleaner} Cleaned accumulator 194
[16:35:40,456] INFO  {ContextCleaner} Cleaned accumulator 195
[16:35:40,456] INFO  {ContextCleaner} Cleaned accumulator 196
[16:35:40,456] INFO  {ContextCleaner} Cleaned accumulator 197
[16:35:40,456] INFO  {ContextCleaner} Cleaned accumulator 198
[16:35:40,456] INFO  {ContextCleaner} Cleaned accumulator 199
[16:35:40,461] INFO  {ContextCleaner} Cleaned shuffle 0
[16:35:40,462] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:39525 in memory (size: 11.7 KB, free: 1127.7 MB)
[16:35:40,463] INFO  {ContextCleaner} Cleaned accumulator 141
[16:35:40,463] INFO  {ContextCleaner} Cleaned accumulator 142
[16:35:40,463] INFO  {ContextCleaner} Cleaned accumulator 95
[16:35:40,463] INFO  {ContextCleaner} Cleaned accumulator 96
[16:35:40,499] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:35:40,500] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 150 ms on localhost (1/1)
[16:35:40,501] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:35:40,501] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.151 s
[16:35:40,501] INFO  {DAGScheduler} looking for newly runnable stages
[16:35:40,502] INFO  {DAGScheduler} running: Set()
[16:35:40,502] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:35:40,502] INFO  {DAGScheduler} failed: Set()
[16:35:40,502] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:35:40,504] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:35:40,505] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:35:40,506] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:39525 (size: 3.9 KB, free: 1127.7 MB)
[16:35:40,507] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:35:40,507] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:35:40,507] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:35:40,508] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:35:40,509] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:35:40,512] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:35:40,512] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:35:40,516] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:35:40,517] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 10 ms on localhost (1/1)
[16:35:40,517] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:35:40,517] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.010 s
[16:35:40,518] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.178032 s
[16:35:40,641] INFO  {CodeGenerator} Code generated in 45.442002 ms
[16:35:40,651] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:35:40,652] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:35:40,652] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:35:40,652] INFO  {DAGScheduler} Parents of final stage: List()
[16:35:40,653] INFO  {DAGScheduler} Missing parents: List()
[16:35:40,653] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:35:40,657] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:35:40,659] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:35:40,660] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:39525 (size: 15.1 KB, free: 1127.6 MB)
[16:35:40,660] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:35:40,661] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:35:40,661] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:35:40,664] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:35:40,664] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:35:40,671] INFO  {BlockManager} Found block rdd_2_0 locally
[16:35:40,680] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:35:40,681] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:35:40,682] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 21 ms on localhost (1/1)
[16:35:40,682] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:35:40,683] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.022 s
[16:35:40,684] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.032551 s
[16:35:40,699] INFO  {CodeGenerator} Code generated in 13.601666 ms
[16:35:40,810] INFO  {CodeGenerator} Code generated in 49.246619 ms
[16:35:40,821] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:35:40,822] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:35:40,822] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:35:40,822] INFO  {DAGScheduler} Parents of final stage: List()
[16:35:40,823] INFO  {DAGScheduler} Missing parents: List()
[16:35:40,824] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:35:40,828] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:35:40,831] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:35:40,833] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:39525 (size: 16.4 KB, free: 1127.6 MB)
[16:35:40,834] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:35:40,834] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:35:40,834] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:35:40,836] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:35:40,836] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:35:40,842] INFO  {BlockManager} Found block rdd_2_0 locally
[16:35:40,850] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:35:40,851] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4086 bytes result sent to driver
[16:35:40,853] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 18 ms on localhost (1/1)
[16:35:40,853] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:35:40,854] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.019 s
[16:35:40,854] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.033533 s
[16:35:40,874] INFO  {CodeGenerator} Code generated in 16.685665 ms
[16:35:41,329] INFO  {CodeGenerator} Code generated in 17.085825 ms
[16:35:41,350] INFO  {CodeGenerator} Code generated in 11.282682 ms
[16:35:41,379] INFO  {CodeGenerator} Code generated in 8.189884 ms
[16:35:41,390] INFO  {CodeGenerator} Code generated in 4.857763 ms
[16:35:41,394] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:35:41,399] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:35:41,401] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:35:41,401] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:35:41,401] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:35:41,401] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:35:41,401] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:35:41,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:35:41,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:35:41,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:35:41,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:35:41,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:35:41,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:35:41,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:35:41,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:35:41,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:35:41,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:35:41,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:35:41,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:35:41,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:35:41,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:35:41,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:35:41,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:35:41,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:35:41,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:35:41,404] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:35:41,405] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:35:41,417] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:35:41,424] INFO  {MemoryStore} MemoryStore cleared
[16:35:41,425] INFO  {BlockManager} BlockManager stopped
[16:35:41,426] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:35:41,429] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:35:41,432] INFO  {SparkContext} Successfully stopped SparkContext
[16:35:41,433] INFO  {ShutdownHookManager} Shutdown hook called
[16:35:41,433] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f7997625-9ed6-4c04-9bdc-9f1828a5ef67
[16:37:25,444] INFO  {SparkContext} Running Spark version 2.0.1
[16:37:25,671] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:37:25,766] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:37:25,767] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:37:25,840] INFO  {SecurityManager} Changing view acls to: victor
[16:37:25,841] INFO  {SecurityManager} Changing modify acls to: victor
[16:37:25,842] INFO  {SecurityManager} Changing view acls groups to: 
[16:37:25,842] INFO  {SecurityManager} Changing modify acls groups to: 
[16:37:25,843] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:37:26,186] INFO  {Utils} Successfully started service 'sparkDriver' on port 37385.
[16:37:26,202] INFO  {SparkEnv} Registering MapOutputTracker
[16:37:26,217] INFO  {SparkEnv} Registering BlockManagerMaster
[16:37:26,229] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-239a308d-336c-4132-b747-05941d287fa0
[16:37:26,243] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:37:26,291] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:37:26,360] INFO  {log} Logging initialized @1520ms
[16:37:26,465] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:37:26,480] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:37:26,480] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:37:26,480] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:37:26,480] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:37:26,481] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:37:26,481] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:37:26,481] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:37:26,481] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:37:26,481] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:37:26,482] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:37:26,482] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:37:26,482] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:37:26,482] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:37:26,482] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:37:26,482] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:37:26,483] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:37:26,483] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:37:26,483] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:37:26,483] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:37:26,483] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:37:26,489] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:37:26,489] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:37:26,490] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:37:26,490] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:37:26,497] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:37:26,497] INFO  {Server} Started @1658ms
[16:37:26,497] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:37:26,499] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:37:26,575] INFO  {Executor} Starting executor ID driver on host localhost
[16:37:26,600] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36941.
[16:37:26,601] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:36941
[16:37:26,603] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 36941)
[16:37:26,606] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:36941 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 36941)
[16:37:26,609] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 36941)
[16:37:26,736] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:37:26,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:37:26,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:37:26,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:37:26,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:37:26,796] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:37:26,808] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:37:28,587] INFO  {FileSourceStrategy} Pruning directories with: 
[16:37:28,589] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:37:28,594] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:37:28,595] INFO  {FileSourceStrategy} Pushed Filters: 
[16:37:28,700] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:37:28,744] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:37:28,746] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:36941 (size: 14.6 KB, free: 1128.9 MB)
[16:37:28,752] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:37:28,755] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:37:29,199] INFO  {CodeGenerator} Code generated in 193.458051 ms
[16:37:29,396] INFO  {CodeGenerator} Code generated in 26.77077 ms
[16:37:29,447] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:37:29,465] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:37:29,466] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:37:29,466] INFO  {DAGScheduler} Parents of final stage: List()
[16:37:29,470] INFO  {DAGScheduler} Missing parents: List()
[16:37:29,474] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:37:29,536] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:37:29,539] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:37:29,539] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:36941 (size: 8.4 KB, free: 1128.9 MB)
[16:37:29,540] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:37:29,544] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:37:29,545] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:37:29,583] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:37:29,590] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:37:29,641] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:37:29,653] INFO  {CodeGenerator} Code generated in 8.563611 ms
[16:37:29,778] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:37:29,779] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:36941 (size: 1239.2 KB, free: 1127.7 MB)
[16:37:29,789] INFO  {CodeGenerator} Code generated in 3.903675 ms
[16:37:29,814] INFO  {CodeGenerator} Code generated in 18.655304 ms
[16:37:29,832] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:37:29,839] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:37:29,849] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 281 ms on localhost (1/1)
[16:37:29,851] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:37:29,855] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.301 s
[16:37:29,860] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.412034 s
[16:37:29,889] INFO  {CodeGenerator} Code generated in 15.534101 ms
[16:37:29,980] INFO  {CodeGenerator} Code generated in 28.710168 ms
[16:37:29,991] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:37:29,992] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:37:29,992] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:37:29,992] INFO  {DAGScheduler} Parents of final stage: List()
[16:37:29,994] INFO  {DAGScheduler} Missing parents: List()
[16:37:29,995] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:37:30,002] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:37:30,004] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:37:30,005] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:36941 (size: 10.0 KB, free: 1127.7 MB)
[16:37:30,005] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:37:30,006] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:37:30,006] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:37:30,011] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:37:30,012] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:37:30,025] INFO  {BlockManager} Found block rdd_2_0 locally
[16:37:30,041] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:37:30,041] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:37:30,043] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on localhost (1/1)
[16:37:30,043] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:37:30,044] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.035 s
[16:37:30,044] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.052919 s
[16:37:30,074] INFO  {CodeGenerator} Code generated in 20.309069 ms
[16:37:30,266] INFO  {ContextCleaner} Cleaned accumulator 3
[16:37:30,267] INFO  {ContextCleaner} Cleaned accumulator 4
[16:37:30,280] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:36941 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:37:30,283] INFO  {ContextCleaner} Cleaned accumulator 49
[16:37:30,283] INFO  {ContextCleaner} Cleaned accumulator 50
[16:37:30,284] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:36941 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:37:30,334] INFO  {CodeGenerator} Code generated in 38.053356 ms
[16:37:30,346] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:37:30,348] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:37:30,348] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:37:30,348] INFO  {DAGScheduler} Parents of final stage: List()
[16:37:30,349] INFO  {DAGScheduler} Missing parents: List()
[16:37:30,349] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:37:30,352] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:37:30,354] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:37:30,355] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:36941 (size: 11.7 KB, free: 1127.7 MB)
[16:37:30,355] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:37:30,355] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:37:30,356] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:37:30,358] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:37:30,359] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:37:30,367] INFO  {BlockManager} Found block rdd_2_0 locally
[16:37:30,376] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:37:30,377] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:37:30,379] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 22 ms on localhost (1/1)
[16:37:30,379] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:37:30,379] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.023 s
[16:37:30,380] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.033129 s
[16:37:30,397] INFO  {CodeGenerator} Code generated in 14.601342 ms
[16:37:30,493] INFO  {CodeGenerator} Code generated in 42.045936 ms
[16:37:30,508] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:37:30,509] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:37:30,509] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:37:30,509] INFO  {DAGScheduler} Parents of final stage: List()
[16:37:30,509] INFO  {DAGScheduler} Missing parents: List()
[16:37:30,510] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:37:30,513] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:37:30,515] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1127.5 MB)
[16:37:30,516] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:36941 (size: 13.2 KB, free: 1127.7 MB)
[16:37:30,517] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:37:30,517] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:37:30,517] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:37:30,519] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:37:30,519] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:37:30,530] INFO  {BlockManager} Found block rdd_2_0 locally
[16:37:30,542] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:37:30,543] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:37:30,545] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 26 ms on localhost (1/1)
[16:37:30,545] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:37:30,545] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.027 s
[16:37:30,546] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.037286 s
[16:37:30,562] INFO  {CodeGenerator} Code generated in 13.908759 ms
[16:37:30,677] INFO  {CodeGenerator} Code generated in 12.446034 ms
[16:37:30,700] INFO  {CodeGenerator} Code generated in 17.819245 ms
[16:37:30,731] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:37:30,734] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:37:30,735] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:37:30,735] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:37:30,735] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:37:30,736] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:37:30,737] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:37:30,743] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:37:30,744] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:37:30,745] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:36941 (size: 10.1 KB, free: 1127.6 MB)
[16:37:30,745] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:37:30,747] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:37:30,747] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:37:30,751] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:37:30,751] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:37:30,757] INFO  {BlockManager} Found block rdd_2_0 locally
[16:37:31,024] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:37:31,026] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 278 ms on localhost (1/1)
[16:37:31,026] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:37:31,027] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.279 s
[16:37:31,028] INFO  {DAGScheduler} looking for newly runnable stages
[16:37:31,028] INFO  {DAGScheduler} running: Set()
[16:37:31,029] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:37:31,029] INFO  {DAGScheduler} failed: Set()
[16:37:31,030] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:37:31,035] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:37:31,037] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:37:31,037] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:36941 (size: 3.9 KB, free: 1127.6 MB)
[16:37:31,038] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:37:31,038] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:37:31,038] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:37:31,041] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:37:31,042] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:37:31,057] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:37:31,059] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 6 ms
[16:37:31,071] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:37:31,072] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 33 ms on localhost (1/1)
[16:37:31,073] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:37:31,073] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.034 s
[16:37:31,073] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.341883 s
[16:37:31,086] INFO  {CodeGenerator} Code generated in 7.913424 ms
[16:37:31,133] INFO  {CodeGenerator} Code generated in 10.398241 ms
[16:37:31,162] INFO  {CodeGenerator} Code generated in 22.67326 ms
[16:37:31,183] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:37:31,184] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:37:31,185] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:37:31,185] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:37:31,185] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:37:31,185] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:37:31,186] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:37:31,190] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:37:31,192] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:37:31,193] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:36941 (size: 10.1 KB, free: 1127.6 MB)
[16:37:31,194] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:37:31,194] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:37:31,194] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:37:31,196] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:37:31,196] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:37:31,202] INFO  {BlockManager} Found block rdd_2_0 locally
[16:37:31,271] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:36941 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:37:31,271] INFO  {ContextCleaner} Cleaned accumulator 288
[16:37:31,273] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:36941 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:37:31,273] INFO  {ContextCleaner} Cleaned accumulator 95
[16:37:31,273] INFO  {ContextCleaner} Cleaned accumulator 96
[16:37:31,274] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:36941 in memory (size: 11.7 KB, free: 1127.7 MB)
[16:37:31,275] INFO  {ContextCleaner} Cleaned accumulator 141
[16:37:31,275] INFO  {ContextCleaner} Cleaned accumulator 142
[16:37:31,276] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:36941 in memory (size: 13.2 KB, free: 1127.7 MB)
[16:37:31,277] INFO  {ContextCleaner} Cleaned accumulator 187
[16:37:31,277] INFO  {ContextCleaner} Cleaned accumulator 188
[16:37:31,277] INFO  {ContextCleaner} Cleaned accumulator 189
[16:37:31,277] INFO  {ContextCleaner} Cleaned accumulator 190
[16:37:31,277] INFO  {ContextCleaner} Cleaned accumulator 191
[16:37:31,277] INFO  {ContextCleaner} Cleaned accumulator 192
[16:37:31,277] INFO  {ContextCleaner} Cleaned accumulator 193
[16:37:31,277] INFO  {ContextCleaner} Cleaned accumulator 194
[16:37:31,277] INFO  {ContextCleaner} Cleaned accumulator 195
[16:37:31,277] INFO  {ContextCleaner} Cleaned accumulator 196
[16:37:31,278] INFO  {ContextCleaner} Cleaned accumulator 197
[16:37:31,278] INFO  {ContextCleaner} Cleaned accumulator 198
[16:37:31,278] INFO  {ContextCleaner} Cleaned accumulator 199
[16:37:31,283] INFO  {ContextCleaner} Cleaned shuffle 0
[16:37:31,361] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:37:31,363] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 168 ms on localhost (1/1)
[16:37:31,363] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:37:31,366] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.170 s
[16:37:31,366] INFO  {DAGScheduler} looking for newly runnable stages
[16:37:31,366] INFO  {DAGScheduler} running: Set()
[16:37:31,366] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:37:31,366] INFO  {DAGScheduler} failed: Set()
[16:37:31,366] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:37:31,368] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:37:31,370] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:37:31,371] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:36941 (size: 3.9 KB, free: 1127.7 MB)
[16:37:31,372] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:37:31,372] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:37:31,372] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:37:31,374] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:37:31,374] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:37:31,377] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:37:31,377] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:37:31,381] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:37:31,382] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 9 ms on localhost (1/1)
[16:37:31,382] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:37:31,383] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.010 s
[16:37:31,384] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.200119 s
[16:37:31,495] INFO  {CodeGenerator} Code generated in 41.984413 ms
[16:37:31,506] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:37:31,507] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:37:31,507] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:37:31,507] INFO  {DAGScheduler} Parents of final stage: List()
[16:37:31,508] INFO  {DAGScheduler} Missing parents: List()
[16:37:31,508] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:37:31,511] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:37:31,514] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:37:31,514] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:36941 (size: 15.0 KB, free: 1127.6 MB)
[16:37:31,515] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:37:31,515] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:37:31,515] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:37:31,518] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:37:31,518] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:37:31,524] INFO  {BlockManager} Found block rdd_2_0 locally
[16:37:31,530] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:37:31,530] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:37:31,531] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 15 ms on localhost (1/1)
[16:37:31,532] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:37:31,532] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.017 s
[16:37:31,533] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.026405 s
[16:37:31,548] INFO  {CodeGenerator} Code generated in 13.004055 ms
[16:37:31,659] INFO  {CodeGenerator} Code generated in 51.924379 ms
[16:37:31,669] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:37:31,670] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:37:31,670] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:37:31,670] INFO  {DAGScheduler} Parents of final stage: List()
[16:37:31,671] INFO  {DAGScheduler} Missing parents: List()
[16:37:31,671] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:37:31,674] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:37:31,677] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:37:31,678] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:36941 (size: 16.4 KB, free: 1127.6 MB)
[16:37:31,678] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:37:31,679] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:37:31,679] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:37:31,681] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:37:31,681] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:37:31,690] INFO  {BlockManager} Found block rdd_2_0 locally
[16:37:31,698] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:37:31,700] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4086 bytes result sent to driver
[16:37:31,701] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 22 ms on localhost (1/1)
[16:37:31,701] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:37:31,701] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.022 s
[16:37:31,702] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.032818 s
[16:37:31,717] INFO  {CodeGenerator} Code generated in 12.194876 ms
[16:37:32,106] INFO  {CodeGenerator} Code generated in 14.914549 ms
[16:37:32,129] INFO  {CodeGenerator} Code generated in 10.776884 ms
[16:37:32,162] INFO  {CodeGenerator} Code generated in 9.23166 ms
[16:37:32,173] INFO  {CodeGenerator} Code generated in 5.254481 ms
[16:37:32,179] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:37:32,184] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:37:32,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:37:32,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:37:32,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:37:32,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:37:32,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:37:32,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:37:32,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:37:32,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:37:32,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:37:32,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:37:32,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:37:32,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:37:32,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:37:32,189] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:37:32,189] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:37:32,189] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:37:32,189] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:37:32,189] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:37:32,189] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:37:32,189] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:37:32,190] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:37:32,190] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:37:32,190] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:37:32,190] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:37:32,192] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:37:32,205] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:37:32,216] INFO  {MemoryStore} MemoryStore cleared
[16:37:32,216] INFO  {BlockManager} BlockManager stopped
[16:37:32,218] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:37:32,220] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:37:32,222] INFO  {SparkContext} Successfully stopped SparkContext
[16:37:32,223] INFO  {ShutdownHookManager} Shutdown hook called
[16:37:32,224] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-650a8fa2-d592-4f38-860b-b5912b12720c
[16:40:56,031] INFO  {SparkContext} Running Spark version 2.0.1
[16:40:56,312] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:40:56,431] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:40:56,432] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:40:56,547] INFO  {SecurityManager} Changing view acls to: victor
[16:40:56,547] INFO  {SecurityManager} Changing modify acls to: victor
[16:40:56,548] INFO  {SecurityManager} Changing view acls groups to: 
[16:40:56,548] INFO  {SecurityManager} Changing modify acls groups to: 
[16:40:56,549] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:40:56,952] INFO  {Utils} Successfully started service 'sparkDriver' on port 38753.
[16:40:56,971] INFO  {SparkEnv} Registering MapOutputTracker
[16:40:56,993] INFO  {SparkEnv} Registering BlockManagerMaster
[16:40:57,005] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-dcd02763-1e83-45d5-af06-d48e5c76654a
[16:40:57,022] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:40:57,090] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:40:57,175] INFO  {log} Logging initialized @1878ms
[16:40:57,298] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:40:57,316] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:40:57,316] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:40:57,316] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:40:57,316] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:40:57,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:40:57,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:40:57,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:40:57,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:40:57,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:40:57,318] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:40:57,318] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:40:57,318] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:40:57,318] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:40:57,318] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:40:57,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:40:57,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:40:57,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:40:57,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:40:57,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:40:57,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:40:57,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:40:57,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:40:57,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:40:57,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:40:57,338] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:40:57,338] INFO  {Server} Started @2043ms
[16:40:57,338] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:40:57,344] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:40:57,456] INFO  {Executor} Starting executor ID driver on host localhost
[16:40:57,489] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39191.
[16:40:57,490] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:39191
[16:40:57,494] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 39191)
[16:40:57,497] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:39191 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 39191)
[16:40:57,500] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 39191)
[16:40:57,650] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:40:57,703] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:40:57,704] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:40:57,706] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:40:57,706] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:40:57,710] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:40:57,728] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:41:00,143] INFO  {FileSourceStrategy} Pruning directories with: 
[16:41:00,147] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:41:00,154] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:41:00,154] INFO  {FileSourceStrategy} Pushed Filters: 
[16:41:00,277] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:41:00,337] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:41:00,339] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:39191 (size: 14.6 KB, free: 1128.9 MB)
[16:41:00,360] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:41:00,365] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:41:00,882] INFO  {CodeGenerator} Code generated in 229.753397 ms
[16:41:01,124] INFO  {CodeGenerator} Code generated in 34.447478 ms
[16:41:01,188] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:41:01,214] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:41:01,216] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:41:01,217] INFO  {DAGScheduler} Parents of final stage: List()
[16:41:01,223] INFO  {DAGScheduler} Missing parents: List()
[16:41:01,227] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:41:01,298] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:41:01,300] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:41:01,301] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:39191 (size: 8.4 KB, free: 1128.9 MB)
[16:41:01,302] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:41:01,305] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:41:01,308] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:41:01,351] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:41:01,362] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:41:01,414] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:41:01,426] INFO  {CodeGenerator} Code generated in 8.858856 ms
[16:41:01,573] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:41:01,573] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:39191 (size: 1239.2 KB, free: 1127.7 MB)
[16:41:01,596] INFO  {CodeGenerator} Code generated in 7.133435 ms
[16:41:01,626] INFO  {CodeGenerator} Code generated in 23.419426 ms
[16:41:01,663] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:41:01,671] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:41:01,685] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 354 ms on localhost (1/1)
[16:41:01,687] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:41:01,692] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.375 s
[16:41:01,698] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.509926 s
[16:41:01,742] INFO  {CodeGenerator} Code generated in 20.696779 ms
[16:41:01,856] INFO  {CodeGenerator} Code generated in 34.110943 ms
[16:41:01,875] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:41:01,876] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:41:01,876] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:41:01,876] INFO  {DAGScheduler} Parents of final stage: List()
[16:41:01,879] INFO  {DAGScheduler} Missing parents: List()
[16:41:01,879] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:41:01,887] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:41:01,890] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:41:01,891] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:39191 (size: 10.0 KB, free: 1127.7 MB)
[16:41:01,892] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:41:01,892] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:41:01,892] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:41:01,898] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:41:01,899] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:41:01,912] INFO  {BlockManager} Found block rdd_2_0 locally
[16:41:01,930] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:41:01,931] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:41:01,933] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on localhost (1/1)
[16:41:01,933] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:41:01,934] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.038 s
[16:41:01,936] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.060495 s
[16:41:01,969] INFO  {CodeGenerator} Code generated in 22.919848 ms
[16:41:02,194] INFO  {ContextCleaner} Cleaned accumulator 3
[16:41:02,194] INFO  {ContextCleaner} Cleaned accumulator 4
[16:41:02,220] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:39191 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:41:02,223] INFO  {ContextCleaner} Cleaned accumulator 49
[16:41:02,223] INFO  {ContextCleaner} Cleaned accumulator 50
[16:41:02,224] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:39191 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:41:02,303] INFO  {CodeGenerator} Code generated in 58.257954 ms
[16:41:02,318] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:41:02,321] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:41:02,322] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:41:02,322] INFO  {DAGScheduler} Parents of final stage: List()
[16:41:02,323] INFO  {DAGScheduler} Missing parents: List()
[16:41:02,323] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:41:02,328] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:41:02,331] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:41:02,331] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:39191 (size: 11.7 KB, free: 1127.7 MB)
[16:41:02,332] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:41:02,332] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:41:02,332] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:41:02,334] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:41:02,335] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:41:02,348] INFO  {BlockManager} Found block rdd_2_0 locally
[16:41:02,365] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:41:02,366] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:41:02,368] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 34 ms on localhost (1/1)
[16:41:02,368] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:41:02,368] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.035 s
[16:41:02,369] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.049760 s
[16:41:02,393] INFO  {CodeGenerator} Code generated in 21.838446 ms
[16:41:02,511] INFO  {CodeGenerator} Code generated in 53.33968 ms
[16:41:02,524] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:41:02,526] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:41:02,526] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:41:02,526] INFO  {DAGScheduler} Parents of final stage: List()
[16:41:02,527] INFO  {DAGScheduler} Missing parents: List()
[16:41:02,527] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:41:02,531] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:41:02,535] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1127.5 MB)
[16:41:02,536] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:39191 (size: 13.2 KB, free: 1127.7 MB)
[16:41:02,537] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:41:02,538] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:41:02,538] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:41:02,541] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:41:02,541] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:41:02,549] INFO  {BlockManager} Found block rdd_2_0 locally
[16:41:02,558] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:41:02,559] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:41:02,560] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 21 ms on localhost (1/1)
[16:41:02,560] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:41:02,561] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.023 s
[16:41:02,562] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.036879 s
[16:41:02,585] INFO  {CodeGenerator} Code generated in 19.419225 ms
[16:41:02,725] INFO  {CodeGenerator} Code generated in 18.532112 ms
[16:41:02,750] INFO  {CodeGenerator} Code generated in 19.916026 ms
[16:41:02,789] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:41:02,795] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:41:02,795] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:41:02,796] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:41:02,796] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:41:02,796] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:41:02,797] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:41:02,803] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:41:02,805] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:41:02,806] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:39191 (size: 10.1 KB, free: 1127.6 MB)
[16:41:02,807] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:41:02,809] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:41:02,809] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:41:02,812] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:41:02,812] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:41:02,817] INFO  {BlockManager} Found block rdd_2_0 locally
[16:41:03,118] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:41:03,120] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 310 ms on localhost (1/1)
[16:41:03,120] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:41:03,123] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.313 s
[16:41:03,124] INFO  {DAGScheduler} looking for newly runnable stages
[16:41:03,125] INFO  {DAGScheduler} running: Set()
[16:41:03,126] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:41:03,127] INFO  {DAGScheduler} failed: Set()
[16:41:03,128] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:41:03,132] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:41:03,134] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:41:03,135] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:39191 (size: 3.9 KB, free: 1127.6 MB)
[16:41:03,136] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:41:03,136] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:41:03,136] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:41:03,139] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:41:03,140] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:41:03,154] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:41:03,158] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 6 ms
[16:41:03,175] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:41:03,177] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 40 ms on localhost (1/1)
[16:41:03,177] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:41:03,178] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.040 s
[16:41:03,179] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.389385 s
[16:41:03,188] INFO  {CodeGenerator} Code generated in 5.894786 ms
[16:41:03,237] INFO  {CodeGenerator} Code generated in 10.714375 ms
[16:41:03,261] INFO  {CodeGenerator} Code generated in 16.361126 ms
[16:41:03,280] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:41:03,280] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:41:03,281] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:41:03,281] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:41:03,281] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:41:03,281] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:41:03,282] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:41:03,285] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:41:03,286] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:41:03,287] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:39191 (size: 10.1 KB, free: 1127.6 MB)
[16:41:03,287] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:41:03,287] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:41:03,287] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:41:03,289] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:41:03,290] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:41:03,296] INFO  {BlockManager} Found block rdd_2_0 locally
[16:41:03,378] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:39191 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:41:03,379] INFO  {ContextCleaner} Cleaned accumulator 288
[16:41:03,379] INFO  {ContextCleaner} Cleaned accumulator 95
[16:41:03,379] INFO  {ContextCleaner} Cleaned accumulator 96
[16:41:03,380] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:39191 in memory (size: 11.7 KB, free: 1127.6 MB)
[16:41:03,381] INFO  {ContextCleaner} Cleaned accumulator 141
[16:41:03,381] INFO  {ContextCleaner} Cleaned accumulator 142
[16:41:03,382] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:39191 in memory (size: 10.1 KB, free: 1127.7 MB)
[16:41:03,383] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:39191 in memory (size: 13.2 KB, free: 1127.7 MB)
[16:41:03,384] INFO  {ContextCleaner} Cleaned accumulator 187
[16:41:03,385] INFO  {ContextCleaner} Cleaned accumulator 188
[16:41:03,385] INFO  {ContextCleaner} Cleaned accumulator 189
[16:41:03,385] INFO  {ContextCleaner} Cleaned accumulator 190
[16:41:03,385] INFO  {ContextCleaner} Cleaned accumulator 191
[16:41:03,385] INFO  {ContextCleaner} Cleaned accumulator 192
[16:41:03,385] INFO  {ContextCleaner} Cleaned accumulator 193
[16:41:03,385] INFO  {ContextCleaner} Cleaned accumulator 194
[16:41:03,386] INFO  {ContextCleaner} Cleaned accumulator 195
[16:41:03,386] INFO  {ContextCleaner} Cleaned accumulator 196
[16:41:03,386] INFO  {ContextCleaner} Cleaned accumulator 197
[16:41:03,386] INFO  {ContextCleaner} Cleaned accumulator 198
[16:41:03,386] INFO  {ContextCleaner} Cleaned accumulator 199
[16:41:03,396] INFO  {ContextCleaner} Cleaned shuffle 0
[16:41:03,447] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:41:03,450] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 162 ms on localhost (1/1)
[16:41:03,450] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:41:03,451] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.163 s
[16:41:03,451] INFO  {DAGScheduler} looking for newly runnable stages
[16:41:03,451] INFO  {DAGScheduler} running: Set()
[16:41:03,451] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:41:03,451] INFO  {DAGScheduler} failed: Set()
[16:41:03,452] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:41:03,454] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:41:03,458] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:41:03,460] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:39191 (size: 3.9 KB, free: 1127.7 MB)
[16:41:03,462] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:41:03,463] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:41:03,463] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:41:03,465] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:41:03,465] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:41:03,468] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:41:03,468] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:41:03,471] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:41:03,472] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (1/1)
[16:41:03,473] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:41:03,474] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.010 s
[16:41:03,475] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.195409 s
[16:41:03,634] INFO  {CodeGenerator} Code generated in 73.352415 ms
[16:41:03,651] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:41:03,652] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:41:03,652] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:41:03,652] INFO  {DAGScheduler} Parents of final stage: List()
[16:41:03,652] INFO  {DAGScheduler} Missing parents: List()
[16:41:03,653] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:41:03,658] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:41:03,662] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:41:03,663] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:39191 (size: 15.0 KB, free: 1127.6 MB)
[16:41:03,664] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:41:03,664] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:41:03,665] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:41:03,668] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:41:03,668] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:41:03,676] INFO  {BlockManager} Found block rdd_2_0 locally
[16:41:03,687] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:41:03,689] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:41:03,690] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 25 ms on localhost (1/1)
[16:41:03,691] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:41:03,694] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.028 s
[16:41:03,694] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.043668 s
[16:41:03,723] INFO  {CodeGenerator} Code generated in 23.795455 ms
[16:41:03,881] INFO  {CodeGenerator} Code generated in 78.795707 ms
[16:41:03,893] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:41:03,893] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:41:03,894] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:41:03,894] INFO  {DAGScheduler} Parents of final stage: List()
[16:41:03,894] INFO  {DAGScheduler} Missing parents: List()
[16:41:03,895] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:41:03,899] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:41:03,901] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:41:03,902] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:39191 (size: 16.4 KB, free: 1127.6 MB)
[16:41:03,902] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:41:03,903] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:41:03,903] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:41:03,906] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:41:03,907] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:41:03,917] INFO  {BlockManager} Found block rdd_2_0 locally
[16:41:03,925] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:41:03,926] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4170 bytes result sent to driver
[16:41:03,927] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 22 ms on localhost (1/1)
[16:41:03,928] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:41:03,928] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.024 s
[16:41:03,929] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.036242 s
[16:41:03,955] INFO  {CodeGenerator} Code generated in 22.998883 ms
[16:41:04,395] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:41:04,400] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:41:04,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:41:04,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:41:04,402] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:41:04,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:41:04,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:41:04,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:41:04,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:41:04,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:41:04,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:41:04,403] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:41:04,404] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:41:04,404] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:41:04,404] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:41:04,404] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:41:04,404] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:41:04,404] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:41:04,404] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:41:04,404] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:41:04,404] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:41:04,404] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:41:04,405] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:41:04,405] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:41:04,405] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:41:04,405] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:41:04,406] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:41:04,422] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:41:04,436] INFO  {MemoryStore} MemoryStore cleared
[16:41:04,437] INFO  {BlockManager} BlockManager stopped
[16:41:04,439] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:41:04,441] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:41:04,456] INFO  {SparkContext} Successfully stopped SparkContext
[16:41:04,457] INFO  {ShutdownHookManager} Shutdown hook called
[16:41:04,458] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-97ca1472-6203-4c70-b354-8c7de17b83b7
[16:45:04,283] INFO  {SparkContext} Running Spark version 2.0.1
[16:45:04,489] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:45:04,578] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:45:04,578] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:45:04,656] INFO  {SecurityManager} Changing view acls to: victor
[16:45:04,657] INFO  {SecurityManager} Changing modify acls to: victor
[16:45:04,658] INFO  {SecurityManager} Changing view acls groups to: 
[16:45:04,659] INFO  {SecurityManager} Changing modify acls groups to: 
[16:45:04,659] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:45:05,032] INFO  {Utils} Successfully started service 'sparkDriver' on port 38257.
[16:45:05,048] INFO  {SparkEnv} Registering MapOutputTracker
[16:45:05,063] INFO  {SparkEnv} Registering BlockManagerMaster
[16:45:05,075] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-16381dd0-1606-4db0-a465-52c8a9f64bc4
[16:45:05,088] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:45:05,131] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:45:05,204] INFO  {log} Logging initialized @1491ms
[16:45:05,310] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:45:05,326] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[16:45:05,326] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[16:45:05,326] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[16:45:05,326] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[16:45:05,326] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[16:45:05,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[16:45:05,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[16:45:05,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[16:45:05,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[16:45:05,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[16:45:05,327] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[16:45:05,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[16:45:05,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[16:45:05,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[16:45:05,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[16:45:05,328] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[16:45:05,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[16:45:05,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[16:45:05,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[16:45:05,329] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[16:45:05,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[16:45:05,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[16:45:05,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[16:45:05,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[16:45:05,342] INFO  {ServerConnector} Started ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:45:05,342] INFO  {Server} Started @1630ms
[16:45:05,342] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:45:05,344] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:45:05,419] INFO  {Executor} Starting executor ID driver on host localhost
[16:45:05,445] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44551.
[16:45:05,446] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:44551
[16:45:05,448] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 44551)
[16:45:05,451] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:44551 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 44551)
[16:45:05,454] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 44551)
[16:45:05,580] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[16:45:05,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL,null,AVAILABLE}
[16:45:05,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/json,null,AVAILABLE}
[16:45:05,628] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution,null,AVAILABLE}
[16:45:05,628] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b11ef33{/SQL/execution/json,null,AVAILABLE}
[16:45:05,630] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@21ec5d87{/static/sql,null,AVAILABLE}
[16:45:05,643] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:45:07,363] INFO  {FileSourceStrategy} Pruning directories with: 
[16:45:07,366] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:45:07,372] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:45:07,372] INFO  {FileSourceStrategy} Pushed Filters: 
[16:45:07,491] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:45:07,546] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:45:07,556] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:44551 (size: 14.6 KB, free: 1128.9 MB)
[16:45:07,563] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:45:07,567] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:45:07,999] INFO  {CodeGenerator} Code generated in 196.43569 ms
[16:45:08,195] INFO  {CodeGenerator} Code generated in 25.890101 ms
[16:45:08,239] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:45:08,255] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:45:08,255] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:45:08,256] INFO  {DAGScheduler} Parents of final stage: List()
[16:45:08,259] INFO  {DAGScheduler} Missing parents: List()
[16:45:08,263] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:45:08,315] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:45:08,317] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[16:45:08,318] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:44551 (size: 8.5 KB, free: 1128.9 MB)
[16:45:08,318] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:45:08,321] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:45:08,323] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:45:08,362] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:45:08,369] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:45:08,410] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:45:08,420] INFO  {CodeGenerator} Code generated in 8.000044 ms
[16:45:08,544] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:45:08,545] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:44551 (size: 1239.2 KB, free: 1127.7 MB)
[16:45:08,555] INFO  {CodeGenerator} Code generated in 4.166579 ms
[16:45:08,581] INFO  {CodeGenerator} Code generated in 19.540686 ms
[16:45:08,600] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:45:08,607] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4550 bytes result sent to driver
[16:45:08,632] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 289 ms on localhost (1/1)
[16:45:08,634] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:45:08,636] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.306 s
[16:45:08,641] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.401502 s
[16:45:08,675] INFO  {CodeGenerator} Code generated in 16.132711 ms
[16:45:08,765] INFO  {CodeGenerator} Code generated in 28.800795 ms
[16:45:08,777] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:45:08,778] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:45:08,778] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:45:08,779] INFO  {DAGScheduler} Parents of final stage: List()
[16:45:08,780] INFO  {DAGScheduler} Missing parents: List()
[16:45:08,781] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:45:08,787] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:45:08,789] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:45:08,790] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:44551 (size: 10.0 KB, free: 1127.7 MB)
[16:45:08,790] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:45:08,790] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:45:08,791] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:45:08,796] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:45:08,796] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:45:08,805] INFO  {BlockManager} Found block rdd_2_0 locally
[16:45:08,819] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:45:08,820] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:45:08,822] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on localhost (1/1)
[16:45:08,822] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:45:08,822] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.029 s
[16:45:08,823] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.045508 s
[16:45:08,846] INFO  {CodeGenerator} Code generated in 15.41128 ms
[16:45:09,040] INFO  {ContextCleaner} Cleaned accumulator 3
[16:45:09,041] INFO  {ContextCleaner} Cleaned accumulator 4
[16:45:09,056] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:44551 in memory (size: 8.5 KB, free: 1127.7 MB)
[16:45:09,060] INFO  {ContextCleaner} Cleaned accumulator 49
[16:45:09,060] INFO  {ContextCleaner} Cleaned accumulator 50
[16:45:09,062] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:44551 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:45:09,127] INFO  {CodeGenerator} Code generated in 51.413116 ms
[16:45:09,143] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:45:09,145] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:45:09,145] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:45:09,145] INFO  {DAGScheduler} Parents of final stage: List()
[16:45:09,146] INFO  {DAGScheduler} Missing parents: List()
[16:45:09,147] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:45:09,151] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:45:09,154] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:45:09,155] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:44551 (size: 11.7 KB, free: 1127.7 MB)
[16:45:09,156] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:45:09,157] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:45:09,157] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:45:09,159] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:45:09,160] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:45:09,169] INFO  {BlockManager} Found block rdd_2_0 locally
[16:45:09,186] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:45:09,187] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:45:09,189] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 31 ms on localhost (1/1)
[16:45:09,189] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:45:09,189] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.032 s
[16:45:09,190] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.046341 s
[16:45:09,207] INFO  {CodeGenerator} Code generated in 14.736313 ms
[16:45:09,308] INFO  {CodeGenerator} Code generated in 44.265631 ms
[16:45:09,322] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:45:09,323] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:45:09,323] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:45:09,323] INFO  {DAGScheduler} Parents of final stage: List()
[16:45:09,324] INFO  {DAGScheduler} Missing parents: List()
[16:45:09,324] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:45:09,328] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:45:09,330] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:45:09,331] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:44551 (size: 13.3 KB, free: 1127.7 MB)
[16:45:09,332] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:45:09,332] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:45:09,332] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:45:09,334] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:45:09,334] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:45:09,341] INFO  {BlockManager} Found block rdd_2_0 locally
[16:45:09,349] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:45:09,350] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:45:09,352] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 19 ms on localhost (1/1)
[16:45:09,352] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:45:09,353] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.019 s
[16:45:09,353] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.030737 s
[16:45:09,369] INFO  {CodeGenerator} Code generated in 13.670594 ms
[16:45:09,481] INFO  {CodeGenerator} Code generated in 13.224467 ms
[16:45:09,509] INFO  {CodeGenerator} Code generated in 20.550212 ms
[16:45:09,544] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:45:09,548] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:45:09,549] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:45:09,549] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:45:09,550] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:45:09,550] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:45:09,551] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:45:09,558] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:45:09,559] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:45:09,560] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:44551 (size: 10.2 KB, free: 1127.6 MB)
[16:45:09,560] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:45:09,563] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:45:09,563] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:45:09,565] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:45:09,566] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:45:09,572] INFO  {BlockManager} Found block rdd_2_0 locally
[16:45:09,835] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:45:09,838] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 274 ms on localhost (1/1)
[16:45:09,838] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:45:09,839] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.276 s
[16:45:09,840] INFO  {DAGScheduler} looking for newly runnable stages
[16:45:09,840] INFO  {DAGScheduler} running: Set()
[16:45:09,841] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:45:09,841] INFO  {DAGScheduler} failed: Set()
[16:45:09,842] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:45:09,846] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:45:09,848] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:45:09,848] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:44551 (size: 3.9 KB, free: 1127.6 MB)
[16:45:09,849] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:45:09,849] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:45:09,849] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:45:09,853] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:45:09,853] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:45:09,864] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:45:09,865] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[16:45:09,876] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:45:09,877] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 26 ms on localhost (1/1)
[16:45:09,877] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:45:09,878] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.028 s
[16:45:09,878] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.333551 s
[16:45:09,887] INFO  {CodeGenerator} Code generated in 5.598877 ms
[16:45:09,925] INFO  {CodeGenerator} Code generated in 8.895289 ms
[16:45:09,945] INFO  {CodeGenerator} Code generated in 16.030479 ms
[16:45:09,958] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:45:09,959] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:45:09,960] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:45:09,960] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:45:09,960] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:45:09,960] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:45:09,961] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:45:09,964] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:45:09,966] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[16:45:09,967] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:44551 (size: 10.2 KB, free: 1127.6 MB)
[16:45:09,967] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:45:09,967] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:45:09,968] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:45:09,969] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:45:09,970] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:45:09,975] INFO  {BlockManager} Found block rdd_2_0 locally
[16:45:10,051] INFO  {ContextCleaner} Cleaned accumulator 95
[16:45:10,051] INFO  {ContextCleaner} Cleaned accumulator 96
[16:45:10,053] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:44551 in memory (size: 11.7 KB, free: 1127.6 MB)
[16:45:10,054] INFO  {ContextCleaner} Cleaned accumulator 141
[16:45:10,054] INFO  {ContextCleaner} Cleaned accumulator 142
[16:45:10,056] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:44551 in memory (size: 10.2 KB, free: 1127.6 MB)
[16:45:10,057] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:44551 in memory (size: 3.9 KB, free: 1127.7 MB)
[16:45:10,058] INFO  {ContextCleaner} Cleaned accumulator 288
[16:45:10,059] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:44551 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:45:10,059] INFO  {ContextCleaner} Cleaned accumulator 187
[16:45:10,060] INFO  {ContextCleaner} Cleaned accumulator 188
[16:45:10,060] INFO  {ContextCleaner} Cleaned accumulator 189
[16:45:10,060] INFO  {ContextCleaner} Cleaned accumulator 190
[16:45:10,060] INFO  {ContextCleaner} Cleaned accumulator 191
[16:45:10,060] INFO  {ContextCleaner} Cleaned accumulator 192
[16:45:10,060] INFO  {ContextCleaner} Cleaned accumulator 193
[16:45:10,060] INFO  {ContextCleaner} Cleaned accumulator 194
[16:45:10,060] INFO  {ContextCleaner} Cleaned accumulator 195
[16:45:10,060] INFO  {ContextCleaner} Cleaned accumulator 196
[16:45:10,060] INFO  {ContextCleaner} Cleaned accumulator 197
[16:45:10,060] INFO  {ContextCleaner} Cleaned accumulator 198
[16:45:10,061] INFO  {ContextCleaner} Cleaned accumulator 199
[16:45:10,064] INFO  {ContextCleaner} Cleaned shuffle 0
[16:45:10,119] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:45:10,120] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 152 ms on localhost (1/1)
[16:45:10,120] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:45:10,121] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.153 s
[16:45:10,121] INFO  {DAGScheduler} looking for newly runnable stages
[16:45:10,121] INFO  {DAGScheduler} running: Set()
[16:45:10,121] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:45:10,121] INFO  {DAGScheduler} failed: Set()
[16:45:10,122] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:45:10,124] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:45:10,126] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:45:10,126] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:44551 (size: 3.9 KB, free: 1127.7 MB)
[16:45:10,127] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:45:10,127] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:45:10,128] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:45:10,129] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:45:10,129] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:45:10,132] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:45:10,132] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[16:45:10,135] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:45:10,136] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (1/1)
[16:45:10,136] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:45:10,137] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.009 s
[16:45:10,137] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.178380 s
[16:45:10,242] INFO  {CodeGenerator} Code generated in 43.066404 ms
[16:45:10,252] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:45:10,252] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:45:10,252] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:45:10,253] INFO  {DAGScheduler} Parents of final stage: List()
[16:45:10,253] INFO  {DAGScheduler} Missing parents: List()
[16:45:10,253] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:45:10,256] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:45:10,257] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.4 MB)
[16:45:10,258] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:44551 (size: 15.1 KB, free: 1127.6 MB)
[16:45:10,258] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:45:10,259] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:45:10,259] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:45:10,261] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:45:10,261] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:45:10,266] INFO  {BlockManager} Found block rdd_2_0 locally
[16:45:10,271] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:45:10,272] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:45:10,273] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 14 ms on localhost (1/1)
[16:45:10,273] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:45:10,273] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.014 s
[16:45:10,274] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.021602 s
[16:45:10,287] INFO  {CodeGenerator} Code generated in 11.670645 ms
[16:45:10,412] INFO  {CodeGenerator} Code generated in 70.447643 ms
[16:45:10,423] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:45:10,424] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:45:10,424] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:45:10,424] INFO  {DAGScheduler} Parents of final stage: List()
[16:45:10,425] INFO  {DAGScheduler} Missing parents: List()
[16:45:10,425] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:45:10,429] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:45:10,433] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:45:10,434] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:44551 (size: 16.4 KB, free: 1127.6 MB)
[16:45:10,434] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:45:10,435] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:45:10,435] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:45:10,437] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:45:10,437] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:45:10,444] INFO  {BlockManager} Found block rdd_2_0 locally
[16:45:10,452] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:45:10,453] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:45:10,455] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 18 ms on localhost (1/1)
[16:45:10,455] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:45:10,457] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.021 s
[16:45:10,458] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.034874 s
[16:45:10,478] INFO  {CodeGenerator} Code generated in 16.744342 ms
[16:45:10,817] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:45:10,822] INFO  {ServerConnector} Stopped ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:45:10,824] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[16:45:10,824] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[16:45:10,825] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[16:45:10,825] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[16:45:10,825] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[16:45:10,825] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[16:45:10,825] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[16:45:10,825] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[16:45:10,825] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[16:45:10,825] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[16:45:10,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[16:45:10,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[16:45:10,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[16:45:10,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[16:45:10,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[16:45:10,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[16:45:10,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[16:45:10,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[16:45:10,827] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[16:45:10,827] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[16:45:10,827] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[16:45:10,827] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[16:45:10,827] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[16:45:10,827] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[16:45:10,829] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:45:10,842] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:45:10,850] INFO  {MemoryStore} MemoryStore cleared
[16:45:10,850] INFO  {BlockManager} BlockManager stopped
[16:45:10,852] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:45:10,855] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:45:10,858] INFO  {SparkContext} Successfully stopped SparkContext
[16:45:10,859] INFO  {ShutdownHookManager} Shutdown hook called
[16:45:10,860] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-bdcab23f-7184-44fb-9705-2660ac7f99c3
[16:46:30,893] INFO  {SparkContext} Running Spark version 2.0.1
[16:46:31,094] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:46:31,189] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:46:31,190] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:46:31,262] INFO  {SecurityManager} Changing view acls to: victor
[16:46:31,262] INFO  {SecurityManager} Changing modify acls to: victor
[16:46:31,263] INFO  {SecurityManager} Changing view acls groups to: 
[16:46:31,263] INFO  {SecurityManager} Changing modify acls groups to: 
[16:46:31,264] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:46:31,629] INFO  {Utils} Successfully started service 'sparkDriver' on port 42393.
[16:46:31,652] INFO  {SparkEnv} Registering MapOutputTracker
[16:46:31,668] INFO  {SparkEnv} Registering BlockManagerMaster
[16:46:31,681] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-5495c96b-220f-43e9-a874-a424caa02f18
[16:46:31,695] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:46:31,741] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:46:31,810] INFO  {log} Logging initialized @1506ms
[16:46:31,913] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:46:31,928] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:46:31,928] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:46:31,928] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:46:31,928] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:46:31,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:46:31,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:46:31,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:46:31,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:46:31,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:46:31,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:46:31,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:46:31,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:46:31,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:46:31,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:46:31,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:46:31,931] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:46:31,931] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:46:31,931] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:46:31,931] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:46:31,931] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:46:31,937] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:46:31,937] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:46:31,938] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:46:31,938] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:46:31,944] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:46:31,945] INFO  {Server} Started @1641ms
[16:46:31,945] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:46:31,947] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:46:32,025] INFO  {Executor} Starting executor ID driver on host localhost
[16:46:32,048] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38901.
[16:46:32,049] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:38901
[16:46:32,051] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 38901)
[16:46:32,055] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:38901 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 38901)
[16:46:32,058] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 38901)
[16:46:32,188] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:46:32,239] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:46:32,240] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:46:32,241] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:46:32,241] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:46:32,243] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:46:32,256] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:46:34,019] INFO  {FileSourceStrategy} Pruning directories with: 
[16:46:34,022] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:46:34,028] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:46:34,029] INFO  {FileSourceStrategy} Pushed Filters: 
[16:46:34,152] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:46:34,198] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:46:34,200] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:38901 (size: 14.6 KB, free: 1128.9 MB)
[16:46:34,206] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:46:34,210] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:46:34,638] INFO  {CodeGenerator} Code generated in 187.783224 ms
[16:46:34,835] INFO  {CodeGenerator} Code generated in 27.39378 ms
[16:46:34,885] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:46:34,903] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:46:34,904] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:46:34,904] INFO  {DAGScheduler} Parents of final stage: List()
[16:46:34,908] INFO  {DAGScheduler} Missing parents: List()
[16:46:34,913] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:46:34,976] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:46:34,979] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:46:34,979] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:38901 (size: 8.4 KB, free: 1128.9 MB)
[16:46:34,980] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:46:34,983] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:46:34,984] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:46:35,020] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:46:35,028] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:46:35,068] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:46:35,079] INFO  {CodeGenerator} Code generated in 8.86266 ms
[16:46:35,231] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:46:35,231] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:38901 (size: 1239.2 KB, free: 1127.7 MB)
[16:46:35,244] INFO  {CodeGenerator} Code generated in 4.935777 ms
[16:46:35,275] INFO  {CodeGenerator} Code generated in 24.160615 ms
[16:46:35,294] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:46:35,300] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:46:35,311] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 305 ms on localhost (1/1)
[16:46:35,313] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:46:35,316] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.322 s
[16:46:35,322] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.436346 s
[16:46:35,364] INFO  {CodeGenerator} Code generated in 21.555918 ms
[16:46:35,479] INFO  {CodeGenerator} Code generated in 41.024314 ms
[16:46:35,492] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:46:35,493] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:46:35,493] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:46:35,494] INFO  {DAGScheduler} Parents of final stage: List()
[16:46:35,496] INFO  {DAGScheduler} Missing parents: List()
[16:46:35,497] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:46:35,502] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:46:35,504] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:46:35,505] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:38901 (size: 10.0 KB, free: 1127.7 MB)
[16:46:35,505] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:46:35,506] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:46:35,506] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:46:35,511] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:46:35,511] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:46:35,520] INFO  {BlockManager} Found block rdd_2_0 locally
[16:46:35,534] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:46:35,535] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:46:35,537] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 27 ms on localhost (1/1)
[16:46:35,537] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:46:35,537] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.028 s
[16:46:35,538] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.045097 s
[16:46:35,559] INFO  {CodeGenerator} Code generated in 14.458432 ms
[16:46:35,748] INFO  {ContextCleaner} Cleaned accumulator 3
[16:46:35,748] INFO  {ContextCleaner} Cleaned accumulator 4
[16:46:35,765] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:38901 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:46:35,768] INFO  {ContextCleaner} Cleaned accumulator 49
[16:46:35,768] INFO  {ContextCleaner} Cleaned accumulator 50
[16:46:35,770] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:38901 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:46:35,825] INFO  {CodeGenerator} Code generated in 53.664104 ms
[16:46:35,840] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:46:35,841] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:46:35,841] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:46:35,841] INFO  {DAGScheduler} Parents of final stage: List()
[16:46:35,842] INFO  {DAGScheduler} Missing parents: List()
[16:46:35,842] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:46:35,846] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:46:35,850] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:46:35,851] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:38901 (size: 11.7 KB, free: 1127.7 MB)
[16:46:35,851] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:46:35,852] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:46:35,852] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:46:35,853] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:46:35,854] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:46:35,864] INFO  {BlockManager} Found block rdd_2_0 locally
[16:46:35,878] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:46:35,879] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:46:35,881] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.029 s
[16:46:35,881] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on localhost (1/1)
[16:46:35,881] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:46:35,882] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.041391 s
[16:46:35,898] INFO  {CodeGenerator} Code generated in 14.169689 ms
[16:46:35,996] INFO  {CodeGenerator} Code generated in 42.135494 ms
[16:46:36,008] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:46:36,009] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:46:36,009] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:46:36,009] INFO  {DAGScheduler} Parents of final stage: List()
[16:46:36,009] INFO  {DAGScheduler} Missing parents: List()
[16:46:36,010] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:46:36,013] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:46:36,016] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:46:36,017] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:38901 (size: 13.3 KB, free: 1127.7 MB)
[16:46:36,017] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:46:36,018] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:46:36,018] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:46:36,019] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:46:36,020] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:46:36,030] INFO  {BlockManager} Found block rdd_2_0 locally
[16:46:36,042] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:46:36,044] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4099 bytes result sent to driver
[16:46:36,045] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 27 ms on localhost (1/1)
[16:46:36,046] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:46:36,046] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.028 s
[16:46:36,047] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.038252 s
[16:46:36,066] INFO  {CodeGenerator} Code generated in 16.412648 ms
[16:46:36,189] INFO  {CodeGenerator} Code generated in 15.339736 ms
[16:46:36,216] INFO  {CodeGenerator} Code generated in 19.725275 ms
[16:46:36,252] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:46:36,256] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:46:36,257] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:46:36,257] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:46:36,257] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:46:36,257] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:46:36,258] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:46:36,265] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:46:36,266] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:46:36,267] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:38901 (size: 10.1 KB, free: 1127.6 MB)
[16:46:36,267] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:46:36,269] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:46:36,269] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:46:36,271] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:46:36,272] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:46:36,277] INFO  {BlockManager} Found block rdd_2_0 locally
[16:46:36,507] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:46:36,510] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 240 ms on localhost (1/1)
[16:46:36,510] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:46:36,511] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.242 s
[16:46:36,511] INFO  {DAGScheduler} looking for newly runnable stages
[16:46:36,512] INFO  {DAGScheduler} running: Set()
[16:46:36,512] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:46:36,513] INFO  {DAGScheduler} failed: Set()
[16:46:36,514] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:46:36,519] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:46:36,520] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:46:36,521] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:38901 (size: 3.9 KB, free: 1127.6 MB)
[16:46:36,521] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:46:36,522] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:46:36,522] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:46:36,525] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:46:36,525] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:46:36,539] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:46:36,540] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[16:46:36,553] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:46:36,555] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 31 ms on localhost (1/1)
[16:46:36,555] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:46:36,555] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.032 s
[16:46:36,555] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.303404 s
[16:46:36,566] INFO  {CodeGenerator} Code generated in 7.801056 ms
[16:46:36,608] INFO  {CodeGenerator} Code generated in 9.183941 ms
[16:46:36,628] INFO  {CodeGenerator} Code generated in 16.297121 ms
[16:46:36,653] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:46:36,654] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:46:36,654] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:46:36,654] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:46:36,654] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:46:36,655] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:46:36,655] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:46:36,659] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:46:36,662] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:46:36,663] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:38901 (size: 10.1 KB, free: 1127.6 MB)
[16:46:36,664] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:46:36,664] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:46:36,665] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:46:36,667] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:46:36,668] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:46:36,673] INFO  {BlockManager} Found block rdd_2_0 locally
[16:46:36,782] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:38901 in memory (size: 11.7 KB, free: 1127.6 MB)
[16:46:36,782] INFO  {ContextCleaner} Cleaned accumulator 141
[16:46:36,783] INFO  {ContextCleaner} Cleaned accumulator 142
[16:46:36,784] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:38901 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:46:36,784] INFO  {ContextCleaner} Cleaned accumulator 288
[16:46:36,786] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:38901 in memory (size: 10.1 KB, free: 1127.7 MB)
[16:46:36,787] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:38901 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:46:36,788] INFO  {ContextCleaner} Cleaned accumulator 187
[16:46:36,788] INFO  {ContextCleaner} Cleaned accumulator 188
[16:46:36,788] INFO  {ContextCleaner} Cleaned accumulator 189
[16:46:36,788] INFO  {ContextCleaner} Cleaned accumulator 190
[16:46:36,788] INFO  {ContextCleaner} Cleaned accumulator 191
[16:46:36,788] INFO  {ContextCleaner} Cleaned accumulator 192
[16:46:36,789] INFO  {ContextCleaner} Cleaned accumulator 193
[16:46:36,789] INFO  {ContextCleaner} Cleaned accumulator 194
[16:46:36,789] INFO  {ContextCleaner} Cleaned accumulator 195
[16:46:36,789] INFO  {ContextCleaner} Cleaned accumulator 196
[16:46:36,789] INFO  {ContextCleaner} Cleaned accumulator 197
[16:46:36,789] INFO  {ContextCleaner} Cleaned accumulator 198
[16:46:36,789] INFO  {ContextCleaner} Cleaned accumulator 199
[16:46:36,793] INFO  {ContextCleaner} Cleaned shuffle 0
[16:46:36,812] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:46:36,813] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 148 ms on localhost (1/1)
[16:46:36,813] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:46:36,814] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.149 s
[16:46:36,814] INFO  {DAGScheduler} looking for newly runnable stages
[16:46:36,814] INFO  {DAGScheduler} running: Set()
[16:46:36,814] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:46:36,814] INFO  {DAGScheduler} failed: Set()
[16:46:36,815] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:46:36,817] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:46:36,820] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:46:36,820] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:38901 (size: 3.9 KB, free: 1127.7 MB)
[16:46:36,821] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:46:36,821] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:46:36,821] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:46:36,822] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:46:36,823] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:46:36,825] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:46:36,825] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:46:36,828] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:46:36,828] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 6 ms on localhost (1/1)
[16:46:36,829] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:46:36,829] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.008 s
[16:46:36,830] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.176481 s
[16:46:36,971] INFO  {CodeGenerator} Code generated in 62.973973 ms
[16:46:36,980] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:46:36,981] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:46:36,981] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:46:36,981] INFO  {DAGScheduler} Parents of final stage: List()
[16:46:36,982] INFO  {DAGScheduler} Missing parents: List()
[16:46:36,982] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:46:36,985] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:46:36,987] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:46:36,987] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:38901 (size: 15.0 KB, free: 1127.6 MB)
[16:46:36,988] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:46:36,988] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:46:36,988] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:46:36,990] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:46:36,991] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:46:36,997] INFO  {BlockManager} Found block rdd_2_0 locally
[16:46:37,006] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:46:37,007] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:46:37,008] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 19 ms on localhost (1/1)
[16:46:37,009] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.020 s
[16:46:37,010] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:46:37,010] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.029949 s
[16:46:37,025] INFO  {CodeGenerator} Code generated in 12.217121 ms
[16:46:37,142] INFO  {CodeGenerator} Code generated in 51.459415 ms
[16:46:37,152] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:46:37,153] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:46:37,153] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:46:37,153] INFO  {DAGScheduler} Parents of final stage: List()
[16:46:37,153] INFO  {DAGScheduler} Missing parents: List()
[16:46:37,154] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:46:37,156] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:46:37,158] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:46:37,159] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:38901 (size: 16.4 KB, free: 1127.6 MB)
[16:46:37,160] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:46:37,160] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:46:37,160] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:46:37,162] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:46:37,163] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:46:37,166] INFO  {BlockManager} Found block rdd_2_0 locally
[16:46:37,172] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:46:37,173] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:46:37,174] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 14 ms on localhost (1/1)
[16:46:37,174] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:46:37,174] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.014 s
[16:46:37,175] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.022804 s
[16:46:37,189] INFO  {CodeGenerator} Code generated in 12.077404 ms
[16:46:37,558] INFO  {CodeGenerator} Code generated in 16.065777 ms
[16:46:37,578] INFO  {CodeGenerator} Code generated in 10.618209 ms
[16:46:37,608] INFO  {CodeGenerator} Code generated in 7.668288 ms
[16:46:37,618] INFO  {CodeGenerator} Code generated in 4.884105 ms
[16:46:37,623] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:46:37,627] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:46:37,629] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:46:37,630] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:46:37,630] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:46:37,630] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:46:37,630] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:46:37,630] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:46:37,630] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:46:37,630] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:46:37,630] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:46:37,630] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:46:37,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:46:37,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:46:37,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:46:37,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:46:37,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:46:37,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:46:37,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:46:37,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:46:37,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:46:37,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:46:37,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:46:37,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:46:37,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:46:37,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:46:37,633] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:46:37,644] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:46:37,651] INFO  {MemoryStore} MemoryStore cleared
[16:46:37,652] INFO  {BlockManager} BlockManager stopped
[16:46:37,653] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:46:37,657] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:46:37,659] INFO  {SparkContext} Successfully stopped SparkContext
[16:46:37,660] INFO  {ShutdownHookManager} Shutdown hook called
[16:46:37,661] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-5f00474b-b3c6-4a7b-9592-88b76f304e16
[16:47:10,803] INFO  {SparkContext} Running Spark version 2.0.1
[16:47:11,006] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:47:11,111] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:47:11,112] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:47:11,185] INFO  {SecurityManager} Changing view acls to: victor
[16:47:11,186] INFO  {SecurityManager} Changing modify acls to: victor
[16:47:11,187] INFO  {SecurityManager} Changing view acls groups to: 
[16:47:11,187] INFO  {SecurityManager} Changing modify acls groups to: 
[16:47:11,188] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:47:11,542] INFO  {Utils} Successfully started service 'sparkDriver' on port 37603.
[16:47:11,557] INFO  {SparkEnv} Registering MapOutputTracker
[16:47:11,572] INFO  {SparkEnv} Registering BlockManagerMaster
[16:47:11,584] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-48e79071-3691-4bcd-8ae1-bed7b8693ac1
[16:47:11,597] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:47:11,645] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:47:11,713] INFO  {log} Logging initialized @1509ms
[16:47:11,810] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:47:11,825] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:47:11,826] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:47:11,826] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:47:11,826] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:47:11,826] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:47:11,826] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:47:11,826] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:47:11,827] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:47:11,827] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:47:11,827] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:47:11,827] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:47:11,827] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:47:11,828] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:47:11,828] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:47:11,828] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:47:11,828] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:47:11,828] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:47:11,828] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:47:11,829] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:47:11,829] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:47:11,835] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:47:11,835] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:47:11,836] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:47:11,836] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:47:11,843] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:47:11,843] INFO  {Server} Started @1640ms
[16:47:11,843] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:47:11,846] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:47:11,932] INFO  {Executor} Starting executor ID driver on host localhost
[16:47:11,958] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46265.
[16:47:11,959] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:46265
[16:47:11,960] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 46265)
[16:47:11,964] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:46265 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 46265)
[16:47:11,966] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 46265)
[16:47:12,087] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:47:12,137] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:47:12,138] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:47:12,139] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:47:12,140] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:47:12,143] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:47:12,161] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:47:13,936] INFO  {FileSourceStrategy} Pruning directories with: 
[16:47:13,939] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:47:13,944] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:47:13,945] INFO  {FileSourceStrategy} Pushed Filters: 
[16:47:14,046] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:47:14,089] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:47:14,091] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:46265 (size: 14.6 KB, free: 1128.9 MB)
[16:47:14,097] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:47:14,100] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:47:14,533] INFO  {CodeGenerator} Code generated in 187.421917 ms
[16:47:14,726] INFO  {CodeGenerator} Code generated in 26.276308 ms
[16:47:14,774] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:47:14,791] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:47:14,791] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:47:14,792] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:14,795] INFO  {DAGScheduler} Missing parents: List()
[16:47:14,799] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:47:14,856] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:47:14,858] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:47:14,859] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:46265 (size: 8.4 KB, free: 1128.9 MB)
[16:47:14,859] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:47:14,862] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:47:14,864] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:47:14,903] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:14,912] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:47:14,964] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:47:14,976] INFO  {CodeGenerator} Code generated in 9.076908 ms
[16:47:15,119] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:47:15,120] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:46265 (size: 1239.2 KB, free: 1127.7 MB)
[16:47:15,130] INFO  {CodeGenerator} Code generated in 4.507939 ms
[16:47:15,157] INFO  {CodeGenerator} Code generated in 20.778864 ms
[16:47:15,177] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:47:15,183] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:47:15,191] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 306 ms on localhost (1/1)
[16:47:15,192] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:47:15,195] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.323 s
[16:47:15,200] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.425889 s
[16:47:15,229] INFO  {CodeGenerator} Code generated in 15.907206 ms
[16:47:15,326] INFO  {CodeGenerator} Code generated in 29.318307 ms
[16:47:15,339] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:47:15,340] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:47:15,340] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:47:15,341] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:15,343] INFO  {DAGScheduler} Missing parents: List()
[16:47:15,344] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:47:15,350] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:47:15,352] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:47:15,353] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:46265 (size: 10.0 KB, free: 1127.7 MB)
[16:47:15,353] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:47:15,354] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:47:15,354] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:47:15,359] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:15,359] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:47:15,372] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:15,389] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:47:15,390] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:47:15,392] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on localhost (1/1)
[16:47:15,392] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:47:15,393] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.036 s
[16:47:15,393] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.053795 s
[16:47:15,424] INFO  {CodeGenerator} Code generated in 20.976954 ms
[16:47:15,660] INFO  {ContextCleaner} Cleaned accumulator 3
[16:47:15,660] INFO  {ContextCleaner} Cleaned accumulator 4
[16:47:15,674] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:46265 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:47:15,683] INFO  {ContextCleaner} Cleaned accumulator 49
[16:47:15,683] INFO  {ContextCleaner} Cleaned accumulator 50
[16:47:15,684] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:46265 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:47:15,743] INFO  {CodeGenerator} Code generated in 44.341896 ms
[16:47:15,760] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:47:15,761] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:47:15,761] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:47:15,761] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:15,762] INFO  {DAGScheduler} Missing parents: List()
[16:47:15,763] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:47:15,767] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:47:15,770] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:47:15,771] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:46265 (size: 11.7 KB, free: 1127.7 MB)
[16:47:15,773] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:47:15,773] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:47:15,773] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:47:15,775] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:15,776] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:47:15,783] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:15,792] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:47:15,793] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:47:15,795] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 21 ms on localhost (1/1)
[16:47:15,795] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:47:15,796] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.022 s
[16:47:15,796] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.036248 s
[16:47:15,819] INFO  {CodeGenerator} Code generated in 19.444781 ms
[16:47:15,947] INFO  {CodeGenerator} Code generated in 55.745904 ms
[16:47:15,962] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:47:15,963] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:47:15,963] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:47:15,963] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:15,963] INFO  {DAGScheduler} Missing parents: List()
[16:47:15,964] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:47:15,967] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:47:15,969] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:47:15,970] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:46265 (size: 13.3 KB, free: 1127.7 MB)
[16:47:15,970] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:47:15,970] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:47:15,971] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:47:15,972] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:15,972] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:47:15,979] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:15,989] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:47:15,990] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:47:15,991] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on localhost (1/1)
[16:47:15,991] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:47:15,992] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.020 s
[16:47:15,992] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.030183 s
[16:47:16,008] INFO  {CodeGenerator} Code generated in 14.04846 ms
[16:47:16,126] INFO  {CodeGenerator} Code generated in 12.948058 ms
[16:47:16,148] INFO  {CodeGenerator} Code generated in 16.193278 ms
[16:47:16,178] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:47:16,181] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:47:16,182] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:47:16,182] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:47:16,182] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:47:16,182] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:47:16,184] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:47:16,190] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:47:16,192] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:47:16,192] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:46265 (size: 10.1 KB, free: 1127.6 MB)
[16:47:16,193] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:47:16,195] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:47:16,195] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:47:16,198] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:47:16,198] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:47:16,205] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:16,475] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:47:16,478] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 282 ms on localhost (1/1)
[16:47:16,478] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:47:16,479] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.283 s
[16:47:16,480] INFO  {DAGScheduler} looking for newly runnable stages
[16:47:16,480] INFO  {DAGScheduler} running: Set()
[16:47:16,480] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:47:16,481] INFO  {DAGScheduler} failed: Set()
[16:47:16,482] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:47:16,486] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:47:16,489] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:47:16,490] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:46265 (size: 3.9 KB, free: 1127.6 MB)
[16:47:16,490] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:47:16,490] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:47:16,490] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:47:16,494] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:47:16,495] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:47:16,508] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:47:16,510] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[16:47:16,521] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:47:16,522] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 31 ms on localhost (1/1)
[16:47:16,523] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:47:16,523] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.032 s
[16:47:16,523] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.344923 s
[16:47:16,535] INFO  {CodeGenerator} Code generated in 7.292611 ms
[16:47:16,574] INFO  {CodeGenerator} Code generated in 8.822297 ms
[16:47:16,594] INFO  {CodeGenerator} Code generated in 16.366002 ms
[16:47:16,610] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:47:16,611] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:47:16,611] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:47:16,611] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:47:16,611] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:47:16,612] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:47:16,613] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:47:16,616] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:47:16,619] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:47:16,620] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:46265 (size: 10.1 KB, free: 1127.6 MB)
[16:47:16,620] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:47:16,620] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:47:16,620] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:47:16,622] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:47:16,623] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:47:16,628] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:16,717] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:46265 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:47:16,718] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:46265 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:47:16,719] INFO  {ContextCleaner} Cleaned accumulator 288
[16:47:16,719] INFO  {ContextCleaner} Cleaned accumulator 95
[16:47:16,719] INFO  {ContextCleaner} Cleaned accumulator 96
[16:47:16,720] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:46265 in memory (size: 11.7 KB, free: 1127.7 MB)
[16:47:16,721] INFO  {ContextCleaner} Cleaned accumulator 141
[16:47:16,721] INFO  {ContextCleaner} Cleaned accumulator 142
[16:47:16,722] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:46265 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:47:16,724] INFO  {ContextCleaner} Cleaned accumulator 187
[16:47:16,725] INFO  {ContextCleaner} Cleaned accumulator 188
[16:47:16,725] INFO  {ContextCleaner} Cleaned accumulator 189
[16:47:16,725] INFO  {ContextCleaner} Cleaned accumulator 190
[16:47:16,725] INFO  {ContextCleaner} Cleaned accumulator 191
[16:47:16,725] INFO  {ContextCleaner} Cleaned accumulator 192
[16:47:16,725] INFO  {ContextCleaner} Cleaned accumulator 193
[16:47:16,725] INFO  {ContextCleaner} Cleaned accumulator 194
[16:47:16,725] INFO  {ContextCleaner} Cleaned accumulator 195
[16:47:16,725] INFO  {ContextCleaner} Cleaned accumulator 196
[16:47:16,726] INFO  {ContextCleaner} Cleaned accumulator 197
[16:47:16,726] INFO  {ContextCleaner} Cleaned accumulator 198
[16:47:16,726] INFO  {ContextCleaner} Cleaned accumulator 199
[16:47:16,729] INFO  {ContextCleaner} Cleaned shuffle 0
[16:47:16,748] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:47:16,749] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 128 ms on localhost (1/1)
[16:47:16,750] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:47:16,750] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.129 s
[16:47:16,750] INFO  {DAGScheduler} looking for newly runnable stages
[16:47:16,750] INFO  {DAGScheduler} running: Set()
[16:47:16,750] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:47:16,750] INFO  {DAGScheduler} failed: Set()
[16:47:16,751] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:47:16,753] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:47:16,755] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:47:16,755] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:46265 (size: 3.9 KB, free: 1127.7 MB)
[16:47:16,756] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:47:16,756] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:47:16,756] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:47:16,758] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:47:16,758] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:47:16,760] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:47:16,761] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[16:47:16,764] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:47:16,765] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (1/1)
[16:47:16,765] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:47:16,766] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.009 s
[16:47:16,766] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.156022 s
[16:47:16,873] INFO  {CodeGenerator} Code generated in 42.713825 ms
[16:47:16,883] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:47:16,884] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:47:16,884] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:47:16,884] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:16,885] INFO  {DAGScheduler} Missing parents: List()
[16:47:16,885] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:47:16,889] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:47:16,891] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:47:16,892] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:46265 (size: 15.0 KB, free: 1127.6 MB)
[16:47:16,892] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:47:16,893] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:47:16,893] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:47:16,895] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:16,896] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:47:16,901] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:16,907] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:47:16,908] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:47:16,909] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 16 ms on localhost (1/1)
[16:47:16,909] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:47:16,910] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.017 s
[16:47:16,910] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.026558 s
[16:47:16,928] INFO  {CodeGenerator} Code generated in 15.187421 ms
[16:47:17,079] INFO  {CodeGenerator} Code generated in 67.438142 ms
[16:47:17,091] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:47:17,092] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:47:17,092] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:47:17,093] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:17,093] INFO  {DAGScheduler} Missing parents: List()
[16:47:17,094] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:47:17,098] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:47:17,100] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:47:17,100] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:46265 (size: 16.4 KB, free: 1127.6 MB)
[16:47:17,101] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:47:17,101] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:47:17,101] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:47:17,103] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:17,103] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:47:17,109] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:17,119] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:47:17,120] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:47:17,121] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 19 ms on localhost (1/1)
[16:47:17,122] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:47:17,122] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.020 s
[16:47:17,123] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.030871 s
[16:47:17,143] INFO  {CodeGenerator} Code generated in 17.661754 ms
[16:47:17,542] INFO  {CodeGenerator} Code generated in 16.261019 ms
[16:47:17,564] INFO  {CodeGenerator} Code generated in 12.065138 ms
[16:47:17,595] INFO  {CodeGenerator} Code generated in 7.944174 ms
[16:47:17,606] INFO  {CodeGenerator} Code generated in 5.378312 ms
[16:47:17,611] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:47:17,616] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:47:17,618] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:47:17,618] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:47:17,618] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:47:17,618] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:47:17,618] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:47:17,618] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:47:17,618] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:47:17,619] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:47:17,619] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:47:17,619] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:47:17,619] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:47:17,619] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:47:17,619] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:47:17,619] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:47:17,619] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:47:17,620] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:47:17,620] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:47:17,620] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:47:17,620] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:47:17,620] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:47:17,620] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:47:17,620] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:47:17,620] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:47:17,620] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:47:17,622] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:47:17,632] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:47:17,641] INFO  {MemoryStore} MemoryStore cleared
[16:47:17,642] INFO  {BlockManager} BlockManager stopped
[16:47:17,643] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:47:17,646] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:47:17,651] INFO  {SparkContext} Successfully stopped SparkContext
[16:47:17,652] INFO  {ShutdownHookManager} Shutdown hook called
[16:47:17,652] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-950fa532-8555-4df9-a248-6319f091b13b
[16:47:43,851] INFO  {SparkContext} Running Spark version 2.0.1
[16:47:44,062] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:47:44,166] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:47:44,166] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:47:44,247] INFO  {SecurityManager} Changing view acls to: victor
[16:47:44,248] INFO  {SecurityManager} Changing modify acls to: victor
[16:47:44,248] INFO  {SecurityManager} Changing view acls groups to: 
[16:47:44,249] INFO  {SecurityManager} Changing modify acls groups to: 
[16:47:44,250] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:47:44,610] INFO  {Utils} Successfully started service 'sparkDriver' on port 40907.
[16:47:44,630] INFO  {SparkEnv} Registering MapOutputTracker
[16:47:44,645] INFO  {SparkEnv} Registering BlockManagerMaster
[16:47:44,657] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-54231874-47ad-4daf-be37-807c521ea8fe
[16:47:44,671] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:47:44,721] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:47:44,796] INFO  {log} Logging initialized @1517ms
[16:47:44,897] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:47:44,912] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:47:44,913] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:47:44,913] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:47:44,913] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:47:44,913] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:47:44,913] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:47:44,914] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:47:44,914] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:47:44,914] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:47:44,914] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:47:44,914] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:47:44,915] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:47:44,915] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:47:44,915] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:47:44,915] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:47:44,915] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:47:44,916] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:47:44,916] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:47:44,916] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:47:44,916] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:47:44,927] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:47:44,927] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:47:44,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:47:44,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:47:44,939] INFO  {ServerConnector} Started ServerConnector@9f7ef58{HTTP/1.1}{0.0.0.0:4040}
[16:47:44,940] INFO  {Server} Started @1662ms
[16:47:44,940] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:47:44,942] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:47:45,051] INFO  {Executor} Starting executor ID driver on host localhost
[16:47:45,085] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39103.
[16:47:45,086] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:39103
[16:47:45,088] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 39103)
[16:47:45,092] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:39103 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 39103)
[16:47:45,095] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 39103)
[16:47:45,234] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:47:45,281] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[16:47:45,281] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[16:47:45,282] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[16:47:45,283] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[16:47:45,285] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[16:47:45,301] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:47:47,073] INFO  {FileSourceStrategy} Pruning directories with: 
[16:47:47,075] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:47:47,080] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:47:47,080] INFO  {FileSourceStrategy} Pushed Filters: 
[16:47:47,185] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:47:47,231] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:47:47,233] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:39103 (size: 14.6 KB, free: 1128.9 MB)
[16:47:47,238] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:47:47,242] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:47:47,684] INFO  {CodeGenerator} Code generated in 198.557525 ms
[16:47:47,880] INFO  {CodeGenerator} Code generated in 26.587131 ms
[16:47:47,931] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:47:47,948] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:47:47,948] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:47:47,949] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:47,953] INFO  {DAGScheduler} Missing parents: List()
[16:47:47,956] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:47:48,016] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:47:48,018] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:47:48,019] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:39103 (size: 8.4 KB, free: 1128.9 MB)
[16:47:48,020] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:47:48,023] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:47:48,024] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:47:48,065] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:48,073] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:47:48,112] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:47:48,124] INFO  {CodeGenerator} Code generated in 8.709407 ms
[16:47:48,267] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:47:48,270] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:39103 (size: 1239.2 KB, free: 1127.7 MB)
[16:47:48,281] INFO  {CodeGenerator} Code generated in 4.281048 ms
[16:47:48,308] INFO  {CodeGenerator} Code generated in 19.638178 ms
[16:47:48,327] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:47:48,334] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[16:47:48,343] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 296 ms on localhost (1/1)
[16:47:48,345] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:47:48,349] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.314 s
[16:47:48,356] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.424897 s
[16:47:48,390] INFO  {CodeGenerator} Code generated in 17.639397 ms
[16:47:48,488] INFO  {CodeGenerator} Code generated in 29.915247 ms
[16:47:48,499] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:47:48,500] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:47:48,501] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:47:48,501] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:48,503] INFO  {DAGScheduler} Missing parents: List()
[16:47:48,503] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:47:48,507] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:47:48,509] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:47:48,510] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:39103 (size: 10.0 KB, free: 1127.7 MB)
[16:47:48,510] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:47:48,511] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:47:48,511] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:47:48,516] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:48,516] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:47:48,526] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:48,540] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:47:48,541] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:47:48,543] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 29 ms on localhost (1/1)
[16:47:48,544] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:47:48,544] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.031 s
[16:47:48,545] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.045026 s
[16:47:48,567] INFO  {CodeGenerator} Code generated in 14.821697 ms
[16:47:48,746] INFO  {ContextCleaner} Cleaned accumulator 3
[16:47:48,746] INFO  {ContextCleaner} Cleaned accumulator 4
[16:47:48,763] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:39103 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:47:48,768] INFO  {ContextCleaner} Cleaned accumulator 49
[16:47:48,768] INFO  {ContextCleaner} Cleaned accumulator 50
[16:47:48,769] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:39103 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:47:48,819] INFO  {CodeGenerator} Code generated in 40.017837 ms
[16:47:48,829] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:47:48,830] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:47:48,831] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:47:48,831] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:48,832] INFO  {DAGScheduler} Missing parents: List()
[16:47:48,832] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:47:48,837] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:47:48,839] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:47:48,840] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:39103 (size: 11.7 KB, free: 1127.7 MB)
[16:47:48,840] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:47:48,841] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:47:48,841] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:47:48,843] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:48,844] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:47:48,853] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:48,866] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:47:48,867] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:47:48,869] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 26 ms on localhost (1/1)
[16:47:48,869] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:47:48,869] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.028 s
[16:47:48,870] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.040075 s
[16:47:48,895] INFO  {CodeGenerator} Code generated in 21.390483 ms
[16:47:49,007] INFO  {CodeGenerator} Code generated in 47.007129 ms
[16:47:49,019] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:47:49,020] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:47:49,020] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:47:49,020] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:49,020] INFO  {DAGScheduler} Missing parents: List()
[16:47:49,021] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:47:49,024] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:47:49,026] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[16:47:49,027] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:39103 (size: 13.3 KB, free: 1127.7 MB)
[16:47:49,027] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:47:49,027] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:47:49,028] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:47:49,029] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:49,030] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:47:49,038] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:49,050] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:47:49,051] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:47:49,053] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on localhost (1/1)
[16:47:49,053] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:47:49,054] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.025 s
[16:47:49,054] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.035379 s
[16:47:49,071] INFO  {CodeGenerator} Code generated in 14.439439 ms
[16:47:49,180] INFO  {CodeGenerator} Code generated in 16.043288 ms
[16:47:49,210] INFO  {CodeGenerator} Code generated in 23.970161 ms
[16:47:49,254] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:47:49,259] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:47:49,260] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:47:49,260] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:47:49,260] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:47:49,261] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:47:49,262] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:47:49,270] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:47:49,273] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:47:49,274] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:39103 (size: 10.1 KB, free: 1127.6 MB)
[16:47:49,274] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:47:49,276] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:47:49,276] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:47:49,279] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:47:49,279] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:47:49,288] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:49,540] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:47:49,542] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 265 ms on localhost (1/1)
[16:47:49,542] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:47:49,543] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.266 s
[16:47:49,544] INFO  {DAGScheduler} looking for newly runnable stages
[16:47:49,544] INFO  {DAGScheduler} running: Set()
[16:47:49,544] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:47:49,545] INFO  {DAGScheduler} failed: Set()
[16:47:49,546] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:47:49,550] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:47:49,551] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:47:49,552] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:39103 (size: 3.9 KB, free: 1127.6 MB)
[16:47:49,552] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:47:49,552] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:47:49,553] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:47:49,555] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:47:49,556] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:47:49,566] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:47:49,568] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[16:47:49,579] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:47:49,580] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 26 ms on localhost (1/1)
[16:47:49,580] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:47:49,581] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.028 s
[16:47:49,581] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.327523 s
[16:47:49,590] INFO  {CodeGenerator} Code generated in 5.67308 ms
[16:47:49,630] INFO  {CodeGenerator} Code generated in 10.145625 ms
[16:47:49,652] INFO  {CodeGenerator} Code generated in 17.193944 ms
[16:47:49,668] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:47:49,669] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:47:49,669] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:47:49,669] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:47:49,669] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:47:49,669] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:47:49,670] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:47:49,674] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:47:49,675] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:47:49,676] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:39103 (size: 10.1 KB, free: 1127.6 MB)
[16:47:49,677] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:47:49,677] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:47:49,677] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:47:49,679] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:47:49,679] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:47:49,683] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:49,758] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:39103 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:47:49,758] INFO  {ContextCleaner} Cleaned accumulator 288
[16:47:49,760] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:39103 in memory (size: 10.1 KB, free: 1127.6 MB)
[16:47:49,762] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:39103 in memory (size: 13.3 KB, free: 1127.7 MB)
[16:47:49,763] INFO  {ContextCleaner} Cleaned accumulator 187
[16:47:49,763] INFO  {ContextCleaner} Cleaned accumulator 188
[16:47:49,763] INFO  {ContextCleaner} Cleaned accumulator 189
[16:47:49,763] INFO  {ContextCleaner} Cleaned accumulator 190
[16:47:49,763] INFO  {ContextCleaner} Cleaned accumulator 191
[16:47:49,763] INFO  {ContextCleaner} Cleaned accumulator 192
[16:47:49,763] INFO  {ContextCleaner} Cleaned accumulator 193
[16:47:49,763] INFO  {ContextCleaner} Cleaned accumulator 194
[16:47:49,763] INFO  {ContextCleaner} Cleaned accumulator 195
[16:47:49,763] INFO  {ContextCleaner} Cleaned accumulator 196
[16:47:49,763] INFO  {ContextCleaner} Cleaned accumulator 197
[16:47:49,764] INFO  {ContextCleaner} Cleaned accumulator 198
[16:47:49,764] INFO  {ContextCleaner} Cleaned accumulator 199
[16:47:49,769] INFO  {ContextCleaner} Cleaned shuffle 0
[16:47:49,769] INFO  {ContextCleaner} Cleaned accumulator 95
[16:47:49,769] INFO  {ContextCleaner} Cleaned accumulator 96
[16:47:49,770] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:39103 in memory (size: 11.7 KB, free: 1127.7 MB)
[16:47:49,775] INFO  {ContextCleaner} Cleaned accumulator 141
[16:47:49,776] INFO  {ContextCleaner} Cleaned accumulator 142
[16:47:49,807] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:47:49,808] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 130 ms on localhost (1/1)
[16:47:49,809] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:47:49,809] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.131 s
[16:47:49,810] INFO  {DAGScheduler} looking for newly runnable stages
[16:47:49,810] INFO  {DAGScheduler} running: Set()
[16:47:49,810] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:47:49,810] INFO  {DAGScheduler} failed: Set()
[16:47:49,810] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:47:49,812] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:47:49,814] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:47:49,814] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:39103 (size: 3.9 KB, free: 1127.7 MB)
[16:47:49,815] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:47:49,815] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:47:49,815] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:47:49,817] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:47:49,817] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:47:49,819] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:47:49,820] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[16:47:49,823] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:47:49,823] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 7 ms on localhost (1/1)
[16:47:49,824] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:47:49,824] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.007 s
[16:47:49,824] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.156391 s
[16:47:49,947] INFO  {CodeGenerator} Code generated in 61.421223 ms
[16:47:49,961] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:47:49,961] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:47:49,962] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:47:49,962] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:49,962] INFO  {DAGScheduler} Missing parents: List()
[16:47:49,962] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:47:49,966] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:47:49,968] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:47:49,969] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:39103 (size: 15.0 KB, free: 1127.6 MB)
[16:47:49,969] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:47:49,969] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:47:49,970] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:47:49,972] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:49,973] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:47:49,980] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:49,988] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:47:49,989] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:47:49,990] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 20 ms on localhost (1/1)
[16:47:49,990] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:47:49,991] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.020 s
[16:47:49,991] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.030315 s
[16:47:50,010] INFO  {CodeGenerator} Code generated in 15.836281 ms
[16:47:50,150] INFO  {CodeGenerator} Code generated in 59.285668 ms
[16:47:50,159] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:47:50,159] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:47:50,159] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:47:50,159] INFO  {DAGScheduler} Parents of final stage: List()
[16:47:50,160] INFO  {DAGScheduler} Missing parents: List()
[16:47:50,160] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:47:50,163] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:47:50,164] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:47:50,165] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:39103 (size: 16.4 KB, free: 1127.6 MB)
[16:47:50,166] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:47:50,166] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:47:50,166] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:47:50,169] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:47:50,169] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:47:50,175] INFO  {BlockManager} Found block rdd_2_0 locally
[16:47:50,184] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:47:50,185] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:47:50,186] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 18 ms on localhost (1/1)
[16:47:50,186] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:47:50,186] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.018 s
[16:47:50,187] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.028152 s
[16:47:50,201] INFO  {CodeGenerator} Code generated in 11.494498 ms
[16:47:50,568] INFO  {CodeGenerator} Code generated in 15.602977 ms
[16:47:50,589] INFO  {CodeGenerator} Code generated in 10.791119 ms
[16:47:50,618] INFO  {CodeGenerator} Code generated in 8.550774 ms
[16:47:50,630] INFO  {CodeGenerator} Code generated in 5.773363 ms
[16:47:50,635] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:47:50,641] INFO  {ServerConnector} Stopped ServerConnector@9f7ef58{HTTP/1.1}{0.0.0.0:4040}
[16:47:50,645] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:47:50,645] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:47:50,645] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:47:50,646] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:47:50,646] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:47:50,646] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:47:50,646] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:47:50,646] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:47:50,646] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:47:50,646] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:47:50,647] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:47:50,647] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:47:50,647] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:47:50,647] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:47:50,647] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:47:50,647] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:47:50,647] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:47:50,648] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:47:50,648] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:47:50,648] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:47:50,648] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:47:50,648] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:47:50,648] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:47:50,648] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:47:50,650] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:47:50,663] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:47:50,677] INFO  {MemoryStore} MemoryStore cleared
[16:47:50,677] INFO  {BlockManager} BlockManager stopped
[16:47:50,679] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:47:50,682] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:47:50,690] INFO  {SparkContext} Successfully stopped SparkContext
[16:47:50,691] INFO  {ShutdownHookManager} Shutdown hook called
[16:47:50,692] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-13e9c928-568c-45f2-8747-3359a20dc64f
[16:48:16,683] INFO  {SparkContext} Running Spark version 2.0.1
[16:48:16,889] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:48:16,988] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:48:16,989] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:48:17,065] INFO  {SecurityManager} Changing view acls to: victor
[16:48:17,065] INFO  {SecurityManager} Changing modify acls to: victor
[16:48:17,066] INFO  {SecurityManager} Changing view acls groups to: 
[16:48:17,067] INFO  {SecurityManager} Changing modify acls groups to: 
[16:48:17,067] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:48:17,422] INFO  {Utils} Successfully started service 'sparkDriver' on port 43899.
[16:48:17,439] INFO  {SparkEnv} Registering MapOutputTracker
[16:48:17,454] INFO  {SparkEnv} Registering BlockManagerMaster
[16:48:17,466] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e0230057-1377-478d-8bbd-1aee4c71ea44
[16:48:17,480] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:48:17,522] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:48:17,596] INFO  {log} Logging initialized @1502ms
[16:48:17,704] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:48:17,721] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[16:48:17,721] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[16:48:17,722] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[16:48:17,722] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[16:48:17,722] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[16:48:17,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[16:48:17,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[16:48:17,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[16:48:17,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[16:48:17,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[16:48:17,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[16:48:17,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[16:48:17,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[16:48:17,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[16:48:17,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[16:48:17,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[16:48:17,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[16:48:17,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[16:48:17,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[16:48:17,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[16:48:17,735] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[16:48:17,736] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[16:48:17,737] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[16:48:17,737] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[16:48:17,746] INFO  {ServerConnector} Started ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:48:17,746] INFO  {Server} Started @1654ms
[16:48:17,747] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:48:17,749] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:48:17,854] INFO  {Executor} Starting executor ID driver on host localhost
[16:48:17,876] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33707.
[16:48:17,877] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:33707
[16:48:17,878] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 33707)
[16:48:17,881] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:33707 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 33707)
[16:48:17,884] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 33707)
[16:48:18,006] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[16:48:18,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL,null,AVAILABLE}
[16:48:18,052] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/json,null,AVAILABLE}
[16:48:18,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution,null,AVAILABLE}
[16:48:18,054] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b11ef33{/SQL/execution/json,null,AVAILABLE}
[16:48:18,056] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@21ec5d87{/static/sql,null,AVAILABLE}
[16:48:18,069] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:48:19,818] INFO  {FileSourceStrategy} Pruning directories with: 
[16:48:19,821] INFO  {FileSourceStrategy} Post-Scan Filters: 
[16:48:19,826] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[16:48:19,827] INFO  {FileSourceStrategy} Pushed Filters: 
[16:48:19,945] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[16:48:19,999] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[16:48:20,010] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:33707 (size: 14.6 KB, free: 1128.9 MB)
[16:48:20,018] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[16:48:20,021] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[16:48:20,458] INFO  {CodeGenerator} Code generated in 189.452383 ms
[16:48:20,662] INFO  {CodeGenerator} Code generated in 27.884644 ms
[16:48:20,709] INFO  {SparkContext} Starting job: show at Main.scala:34
[16:48:20,724] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[16:48:20,724] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[16:48:20,725] INFO  {DAGScheduler} Parents of final stage: List()
[16:48:20,728] INFO  {DAGScheduler} Missing parents: List()
[16:48:20,732] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[16:48:20,786] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[16:48:20,788] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1128.7 MB)
[16:48:20,789] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:33707 (size: 8.4 KB, free: 1128.9 MB)
[16:48:20,789] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[16:48:20,792] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[16:48:20,794] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:48:20,829] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:48:20,838] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:48:20,882] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[16:48:20,893] INFO  {CodeGenerator} Code generated in 8.162884 ms
[16:48:21,036] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[16:48:21,036] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:33707 (size: 1239.2 KB, free: 1127.7 MB)
[16:48:21,048] INFO  {CodeGenerator} Code generated in 4.327532 ms
[16:48:21,074] INFO  {CodeGenerator} Code generated in 19.222478 ms
[16:48:21,096] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[16:48:21,104] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4550 bytes result sent to driver
[16:48:21,116] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 304 ms on localhost (1/1)
[16:48:21,129] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:48:21,132] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.330 s
[16:48:21,138] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.428892 s
[16:48:21,171] INFO  {CodeGenerator} Code generated in 18.746405 ms
[16:48:21,262] INFO  {CodeGenerator} Code generated in 28.295534 ms
[16:48:21,274] INFO  {SparkContext} Starting job: show at Main.scala:43
[16:48:21,275] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[16:48:21,275] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[16:48:21,275] INFO  {DAGScheduler} Parents of final stage: List()
[16:48:21,277] INFO  {DAGScheduler} Missing parents: List()
[16:48:21,278] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[16:48:21,282] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[16:48:21,284] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[16:48:21,285] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:33707 (size: 10.0 KB, free: 1127.7 MB)
[16:48:21,285] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[16:48:21,286] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[16:48:21,286] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[16:48:21,291] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:48:21,291] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[16:48:21,301] INFO  {BlockManager} Found block rdd_2_0 locally
[16:48:21,315] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[16:48:21,316] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[16:48:21,318] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 29 ms on localhost (1/1)
[16:48:21,318] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[16:48:21,318] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.030 s
[16:48:21,319] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.044529 s
[16:48:21,341] INFO  {CodeGenerator} Code generated in 14.551436 ms
[16:48:21,548] INFO  {ContextCleaner} Cleaned accumulator 3
[16:48:21,548] INFO  {ContextCleaner} Cleaned accumulator 4
[16:48:21,566] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:33707 in memory (size: 8.4 KB, free: 1127.7 MB)
[16:48:21,569] INFO  {ContextCleaner} Cleaned accumulator 49
[16:48:21,569] INFO  {ContextCleaner} Cleaned accumulator 50
[16:48:21,570] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:33707 in memory (size: 10.0 KB, free: 1127.7 MB)
[16:48:21,610] INFO  {CodeGenerator} Code generated in 57.37568 ms
[16:48:21,625] INFO  {SparkContext} Starting job: show at Main.scala:52
[16:48:21,627] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[16:48:21,627] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[16:48:21,628] INFO  {DAGScheduler} Parents of final stage: List()
[16:48:21,628] INFO  {DAGScheduler} Missing parents: List()
[16:48:21,629] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[16:48:21,634] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[16:48:21,636] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[16:48:21,637] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:33707 (size: 11.7 KB, free: 1127.7 MB)
[16:48:21,638] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[16:48:21,638] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[16:48:21,638] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[16:48:21,641] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:48:21,641] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[16:48:21,651] INFO  {BlockManager} Found block rdd_2_0 locally
[16:48:21,666] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[16:48:21,667] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[16:48:21,669] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on localhost (1/1)
[16:48:21,669] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[16:48:21,672] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.033 s
[16:48:21,674] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.047880 s
[16:48:21,698] INFO  {CodeGenerator} Code generated in 20.58378 ms
[16:48:21,826] INFO  {CodeGenerator} Code generated in 48.347588 ms
[16:48:21,841] INFO  {SparkContext} Starting job: show at Main.scala:62
[16:48:21,842] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[16:48:21,842] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[16:48:21,842] INFO  {DAGScheduler} Parents of final stage: List()
[16:48:21,843] INFO  {DAGScheduler} Missing parents: List()
[16:48:21,843] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[16:48:21,847] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[16:48:21,849] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1127.5 MB)
[16:48:21,850] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:33707 (size: 13.2 KB, free: 1127.7 MB)
[16:48:21,851] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[16:48:21,851] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[16:48:21,851] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[16:48:21,853] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:48:21,854] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[16:48:21,862] INFO  {BlockManager} Found block rdd_2_0 locally
[16:48:21,874] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[16:48:21,875] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[16:48:21,876] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 24 ms on localhost (1/1)
[16:48:21,876] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[16:48:21,877] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.024 s
[16:48:21,877] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.035771 s
[16:48:21,894] INFO  {CodeGenerator} Code generated in 13.871393 ms
[16:48:22,024] INFO  {CodeGenerator} Code generated in 13.952419 ms
[16:48:22,045] INFO  {CodeGenerator} Code generated in 16.267743 ms
[16:48:22,076] INFO  {SparkContext} Starting job: collect at Main.scala:67
[16:48:22,078] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[16:48:22,079] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[16:48:22,079] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[16:48:22,079] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[16:48:22,080] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[16:48:22,081] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[16:48:22,088] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:48:22,090] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:48:22,090] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:33707 (size: 10.1 KB, free: 1127.6 MB)
[16:48:22,091] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[16:48:22,093] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[16:48:22,093] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[16:48:22,095] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:48:22,096] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[16:48:22,101] INFO  {BlockManager} Found block rdd_2_0 locally
[16:48:22,354] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[16:48:22,356] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 262 ms on localhost (1/1)
[16:48:22,357] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[16:48:22,358] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.264 s
[16:48:22,358] INFO  {DAGScheduler} looking for newly runnable stages
[16:48:22,358] INFO  {DAGScheduler} running: Set()
[16:48:22,359] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[16:48:22,359] INFO  {DAGScheduler} failed: Set()
[16:48:22,360] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[16:48:22,364] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[16:48:22,366] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[16:48:22,367] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:33707 (size: 3.9 KB, free: 1127.6 MB)
[16:48:22,367] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[16:48:22,367] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[16:48:22,367] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[16:48:22,370] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[16:48:22,371] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[16:48:22,382] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:48:22,383] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[16:48:22,396] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[16:48:22,396] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 27 ms on localhost (1/1)
[16:48:22,397] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[16:48:22,397] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.029 s
[16:48:22,397] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.321531 s
[16:48:22,407] INFO  {CodeGenerator} Code generated in 6.378141 ms
[16:48:22,458] INFO  {CodeGenerator} Code generated in 10.103424 ms
[16:48:22,485] INFO  {CodeGenerator} Code generated in 22.078975 ms
[16:48:22,506] INFO  {SparkContext} Starting job: collect at Main.scala:68
[16:48:22,507] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[16:48:22,507] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[16:48:22,507] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[16:48:22,507] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[16:48:22,507] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[16:48:22,508] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[16:48:22,511] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[16:48:22,512] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[16:48:22,513] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:33707 (size: 10.1 KB, free: 1127.6 MB)
[16:48:22,513] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[16:48:22,513] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[16:48:22,514] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[16:48:22,515] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[16:48:22,516] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[16:48:22,519] INFO  {BlockManager} Found block rdd_2_0 locally
[16:48:22,610] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:33707 in memory (size: 11.7 KB, free: 1127.6 MB)
[16:48:22,611] INFO  {ContextCleaner} Cleaned accumulator 141
[16:48:22,611] INFO  {ContextCleaner} Cleaned accumulator 142
[16:48:22,612] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:33707 in memory (size: 3.9 KB, free: 1127.6 MB)
[16:48:22,613] INFO  {ContextCleaner} Cleaned accumulator 288
[16:48:22,614] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:33707 in memory (size: 10.1 KB, free: 1127.7 MB)
[16:48:22,615] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:33707 in memory (size: 13.2 KB, free: 1127.7 MB)
[16:48:22,616] INFO  {ContextCleaner} Cleaned accumulator 187
[16:48:22,616] INFO  {ContextCleaner} Cleaned accumulator 188
[16:48:22,616] INFO  {ContextCleaner} Cleaned accumulator 189
[16:48:22,616] INFO  {ContextCleaner} Cleaned accumulator 190
[16:48:22,616] INFO  {ContextCleaner} Cleaned accumulator 191
[16:48:22,616] INFO  {ContextCleaner} Cleaned accumulator 192
[16:48:22,617] INFO  {ContextCleaner} Cleaned accumulator 193
[16:48:22,617] INFO  {ContextCleaner} Cleaned accumulator 194
[16:48:22,617] INFO  {ContextCleaner} Cleaned accumulator 195
[16:48:22,617] INFO  {ContextCleaner} Cleaned accumulator 196
[16:48:22,617] INFO  {ContextCleaner} Cleaned accumulator 197
[16:48:22,617] INFO  {ContextCleaner} Cleaned accumulator 198
[16:48:22,617] INFO  {ContextCleaner} Cleaned accumulator 199
[16:48:22,621] INFO  {ContextCleaner} Cleaned shuffle 0
[16:48:22,660] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[16:48:22,661] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 147 ms on localhost (1/1)
[16:48:22,662] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[16:48:22,662] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.148 s
[16:48:22,662] INFO  {DAGScheduler} looking for newly runnable stages
[16:48:22,662] INFO  {DAGScheduler} running: Set()
[16:48:22,662] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[16:48:22,662] INFO  {DAGScheduler} failed: Set()
[16:48:22,663] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[16:48:22,665] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[16:48:22,667] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[16:48:22,667] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:33707 (size: 3.9 KB, free: 1127.7 MB)
[16:48:22,668] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[16:48:22,668] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[16:48:22,668] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[16:48:22,669] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[16:48:22,670] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[16:48:22,673] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[16:48:22,673] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[16:48:22,677] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[16:48:22,678] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 9 ms on localhost (1/1)
[16:48:22,678] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[16:48:22,678] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.009 s
[16:48:22,679] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.172680 s
[16:48:22,798] INFO  {CodeGenerator} Code generated in 44.422333 ms
[16:48:22,808] INFO  {SparkContext} Starting job: show at Main.scala:83
[16:48:22,808] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[16:48:22,809] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[16:48:22,809] INFO  {DAGScheduler} Parents of final stage: List()
[16:48:22,809] INFO  {DAGScheduler} Missing parents: List()
[16:48:22,809] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[16:48:22,812] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[16:48:22,814] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[16:48:22,814] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:33707 (size: 15.0 KB, free: 1127.6 MB)
[16:48:22,815] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[16:48:22,815] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[16:48:22,815] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[16:48:22,817] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:48:22,818] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[16:48:22,824] INFO  {BlockManager} Found block rdd_2_0 locally
[16:48:22,833] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[16:48:22,834] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[16:48:22,834] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 19 ms on localhost (1/1)
[16:48:22,835] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[16:48:22,835] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.020 s
[16:48:22,836] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.027726 s
[16:48:22,851] INFO  {CodeGenerator} Code generated in 13.008625 ms
[16:48:22,966] INFO  {CodeGenerator} Code generated in 53.708202 ms
[16:48:22,976] INFO  {SparkContext} Starting job: show at Main.scala:92
[16:48:22,977] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[16:48:22,977] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[16:48:22,977] INFO  {DAGScheduler} Parents of final stage: List()
[16:48:22,978] INFO  {DAGScheduler} Missing parents: List()
[16:48:22,978] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[16:48:22,982] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[16:48:22,983] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[16:48:22,984] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:33707 (size: 16.4 KB, free: 1127.6 MB)
[16:48:22,984] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[16:48:22,985] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[16:48:22,985] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[16:48:22,986] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[16:48:22,987] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[16:48:22,993] INFO  {BlockManager} Found block rdd_2_0 locally
[16:48:23,000] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[16:48:23,001] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[16:48:23,002] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 17 ms on localhost (1/1)
[16:48:23,002] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[16:48:23,003] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.017 s
[16:48:23,003] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.027098 s
[16:48:23,019] INFO  {CodeGenerator} Code generated in 13.604791 ms
[16:48:23,400] INFO  {CodeGenerator} Code generated in 17.955638 ms
[16:48:23,420] INFO  {CodeGenerator} Code generated in 11.215626 ms
[16:48:23,451] INFO  {CodeGenerator} Code generated in 8.804214 ms
[16:48:23,462] INFO  {CodeGenerator} Code generated in 5.772674 ms
[16:48:23,467] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:48:23,471] INFO  {ServerConnector} Stopped ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[16:48:23,473] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[16:48:23,473] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[16:48:23,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[16:48:23,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[16:48:23,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[16:48:23,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[16:48:23,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[16:48:23,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[16:48:23,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[16:48:23,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[16:48:23,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[16:48:23,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[16:48:23,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[16:48:23,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[16:48:23,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[16:48:23,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[16:48:23,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[16:48:23,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[16:48:23,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[16:48:23,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[16:48:23,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[16:48:23,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[16:48:23,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[16:48:23,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[16:48:23,478] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:48:23,490] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:48:23,505] INFO  {MemoryStore} MemoryStore cleared
[16:48:23,505] INFO  {BlockManager} BlockManager stopped
[16:48:23,507] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:48:23,509] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:48:23,517] INFO  {SparkContext} Successfully stopped SparkContext
[16:48:23,518] INFO  {ShutdownHookManager} Shutdown hook called
[16:48:23,519] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-60b09376-158a-4fd2-a955-fdec8bd7dfaf
[17:52:52,634] INFO  {SparkContext} Running Spark version 2.0.1
[17:52:53,268] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[17:52:53,538] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[17:52:53,539] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[17:52:53,708] INFO  {SecurityManager} Changing view acls to: victor
[17:52:53,713] INFO  {SecurityManager} Changing modify acls to: victor
[17:52:53,714] INFO  {SecurityManager} Changing view acls groups to: 
[17:52:53,715] INFO  {SecurityManager} Changing modify acls groups to: 
[17:52:53,715] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[17:52:54,299] INFO  {Utils} Successfully started service 'sparkDriver' on port 43803.
[17:52:54,402] INFO  {SparkEnv} Registering MapOutputTracker
[17:52:54,490] INFO  {SparkEnv} Registering BlockManagerMaster
[17:52:54,519] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e692adad-3dd8-48e3-a92a-679da2ef135d
[17:52:54,579] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[17:52:54,682] INFO  {SparkEnv} Registering OutputCommitCoordinator
[17:52:54,945] INFO  {log} Logging initialized @4069ms
[17:52:55,207] INFO  {Server} jetty-9.2.z-SNAPSHOT
[17:52:55,230] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[17:52:55,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[17:52:55,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[17:52:55,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[17:52:55,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[17:52:55,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[17:52:55,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[17:52:55,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[17:52:55,233] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[17:52:55,233] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[17:52:55,234] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[17:52:55,234] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[17:52:55,235] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[17:52:55,236] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[17:52:55,237] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[17:52:55,238] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[17:52:55,238] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[17:52:55,238] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[17:52:55,239] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[17:52:55,239] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[17:52:55,255] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[17:52:55,256] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[17:52:55,259] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[17:52:55,259] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[17:52:55,278] INFO  {ServerConnector} Started ServerConnector@c0c8e73{HTTP/1.1}{0.0.0.0:4040}
[17:52:55,279] INFO  {Server} Started @4406ms
[17:52:55,280] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[17:52:55,283] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[17:52:55,544] INFO  {Executor} Starting executor ID driver on host localhost
[17:52:55,688] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35565.
[17:52:55,689] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:35565
[17:52:55,702] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 35565)
[17:52:55,713] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:35565 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 35565)
[17:52:55,730] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 35565)
[17:52:55,922] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@72ccd81a{/metrics/json,null,AVAILABLE}
[17:52:56,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL,null,AVAILABLE}
[17:52:56,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1133ec6e{/SQL/json,null,AVAILABLE}
[17:52:56,158] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/SQL/execution,null,AVAILABLE}
[17:52:56,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/SQL/execution/json,null,AVAILABLE}
[17:52:56,161] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bd7f8dc{/static/sql,null,AVAILABLE}
[17:52:56,196] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[17:53:00,323] INFO  {FileSourceStrategy} Pruning directories with: 
[17:53:00,345] INFO  {FileSourceStrategy} Post-Scan Filters: 
[17:53:00,357] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[17:53:00,358] INFO  {FileSourceStrategy} Pushed Filters: 
[17:53:00,705] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[17:53:00,850] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[17:53:00,854] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:35565 (size: 14.6 KB, free: 1128.9 MB)
[17:53:00,877] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:24
[17:53:00,885] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[17:53:01,909] INFO  {CodeGenerator} Code generated in 433.035619 ms
[17:53:02,364] INFO  {CodeGenerator} Code generated in 29.372618 ms
[17:53:02,435] INFO  {SparkContext} Starting job: show at Main.scala:34
[17:53:02,496] INFO  {DAGScheduler} Got job 0 (show at Main.scala:34) with 1 output partitions
[17:53:02,497] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:34)
[17:53:02,497] INFO  {DAGScheduler} Parents of final stage: List()
[17:53:02,502] INFO  {DAGScheduler} Missing parents: List()
[17:53:02,545] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34), which has no missing parents
[17:53:02,681] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[17:53:02,684] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[17:53:02,684] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:35565 (size: 8.5 KB, free: 1128.9 MB)
[17:53:02,685] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[17:53:02,688] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:34)
[17:53:02,690] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[17:53:02,743] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:53:02,752] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[17:53:02,811] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[17:53:02,825] INFO  {CodeGenerator} Code generated in 10.062726 ms
[17:53:03,049] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[17:53:03,050] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:35565 (size: 1239.2 KB, free: 1127.7 MB)
[17:53:03,073] INFO  {CodeGenerator} Code generated in 5.792949 ms
[17:53:03,103] INFO  {CodeGenerator} Code generated in 23.460946 ms
[17:53:03,157] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[17:53:03,165] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4550 bytes result sent to driver
[17:53:03,185] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 456 ms on localhost (1/1)
[17:53:03,187] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[17:53:03,189] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:34) finished in 0.491 s
[17:53:03,194] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:34, took 0.758633 s
[17:53:03,255] INFO  {CodeGenerator} Code generated in 18.320273 ms
[17:53:03,388] INFO  {CodeGenerator} Code generated in 41.736633 ms
[17:53:03,407] INFO  {SparkContext} Starting job: show at Main.scala:43
[17:53:03,408] INFO  {DAGScheduler} Got job 1 (show at Main.scala:43) with 1 output partitions
[17:53:03,408] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:43)
[17:53:03,408] INFO  {DAGScheduler} Parents of final stage: List()
[17:53:03,411] INFO  {DAGScheduler} Missing parents: List()
[17:53:03,411] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43), which has no missing parents
[17:53:03,416] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[17:53:03,418] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[17:53:03,419] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:35565 (size: 10.0 KB, free: 1127.7 MB)
[17:53:03,419] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[17:53:03,419] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:43)
[17:53:03,419] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[17:53:03,425] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:53:03,425] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[17:53:03,436] INFO  {BlockManager} Found block rdd_2_0 locally
[17:53:03,619] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[17:53:03,621] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[17:53:03,623] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 201 ms on localhost (1/1)
[17:53:03,623] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[17:53:03,624] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:43) finished in 0.202 s
[17:53:03,624] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:43, took 0.216919 s
[17:53:03,651] INFO  {CodeGenerator} Code generated in 15.934345 ms
[17:53:03,765] INFO  {ContextCleaner} Cleaned accumulator 3
[17:53:03,766] INFO  {ContextCleaner} Cleaned accumulator 4
[17:53:03,923] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:35565 in memory (size: 8.5 KB, free: 1127.7 MB)
[17:53:03,975] INFO  {ContextCleaner} Cleaned accumulator 49
[17:53:03,975] INFO  {ContextCleaner} Cleaned accumulator 50
[17:53:03,977] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:35565 in memory (size: 10.0 KB, free: 1127.7 MB)
[17:53:04,082] INFO  {CodeGenerator} Code generated in 100.74347 ms
[17:53:04,108] INFO  {SparkContext} Starting job: show at Main.scala:52
[17:53:04,112] INFO  {DAGScheduler} Got job 2 (show at Main.scala:52) with 1 output partitions
[17:53:04,112] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:52)
[17:53:04,112] INFO  {DAGScheduler} Parents of final stage: List()
[17:53:04,114] INFO  {DAGScheduler} Missing parents: List()
[17:53:04,115] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52), which has no missing parents
[17:53:04,142] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[17:53:04,154] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[17:53:04,166] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:35565 (size: 11.7 KB, free: 1127.7 MB)
[17:53:04,168] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[17:53:04,169] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:52)
[17:53:04,169] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[17:53:04,175] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:53:04,176] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[17:53:04,189] INFO  {BlockManager} Found block rdd_2_0 locally
[17:53:04,234] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[17:53:04,237] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[17:53:04,250] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 75 ms on localhost (1/1)
[17:53:04,250] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[17:53:04,255] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:52) finished in 0.084 s
[17:53:04,257] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:52, took 0.147275 s
[17:53:04,352] INFO  {CodeGenerator} Code generated in 90.588803 ms
[17:53:04,500] INFO  {CodeGenerator} Code generated in 44.171372 ms
[17:53:04,511] INFO  {SparkContext} Starting job: show at Main.scala:62
[17:53:04,512] INFO  {DAGScheduler} Got job 3 (show at Main.scala:62) with 1 output partitions
[17:53:04,512] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:62)
[17:53:04,512] INFO  {DAGScheduler} Parents of final stage: List()
[17:53:04,513] INFO  {DAGScheduler} Missing parents: List()
[17:53:04,513] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62), which has no missing parents
[17:53:04,517] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[17:53:04,520] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[17:53:04,521] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:35565 (size: 13.3 KB, free: 1127.7 MB)
[17:53:04,521] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[17:53:04,522] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:62)
[17:53:04,522] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[17:53:04,524] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:53:04,524] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[17:53:04,531] INFO  {BlockManager} Found block rdd_2_0 locally
[17:53:04,539] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[17:53:04,540] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4099 bytes result sent to driver
[17:53:04,541] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 18 ms on localhost (1/1)
[17:53:04,541] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[17:53:04,542] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:62) finished in 0.020 s
[17:53:04,542] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:62, took 0.030782 s
[17:53:04,560] INFO  {CodeGenerator} Code generated in 14.896049 ms
[17:53:04,743] INFO  {CodeGenerator} Code generated in 22.398898 ms
[17:53:04,768] INFO  {CodeGenerator} Code generated in 18.963978 ms
[17:53:04,842] INFO  {SparkContext} Starting job: collect at Main.scala:67
[17:53:04,844] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:67)
[17:53:04,845] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:67) with 1 output partitions
[17:53:04,845] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:67)
[17:53:04,845] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[17:53:04,846] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[17:53:04,847] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67), which has no missing parents
[17:53:04,858] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[17:53:04,861] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[17:53:04,862] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:35565 (size: 10.2 KB, free: 1127.6 MB)
[17:53:04,862] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[17:53:04,865] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:67)
[17:53:04,865] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[17:53:04,868] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[17:53:04,869] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[17:53:04,877] INFO  {BlockManager} Found block rdd_2_0 locally
[17:53:05,119] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:35565 in memory (size: 13.3 KB, free: 1127.7 MB)
[17:53:05,121] INFO  {ContextCleaner} Cleaned accumulator 187
[17:53:05,121] INFO  {ContextCleaner} Cleaned accumulator 95
[17:53:05,121] INFO  {ContextCleaner} Cleaned accumulator 96
[17:53:05,122] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:35565 in memory (size: 11.7 KB, free: 1127.7 MB)
[17:53:05,124] INFO  {ContextCleaner} Cleaned accumulator 141
[17:53:05,124] INFO  {ContextCleaner} Cleaned accumulator 142
[17:53:05,218] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2484 bytes result sent to driver
[17:53:05,221] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 355 ms on localhost (1/1)
[17:53:05,221] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[17:53:05,222] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:67) finished in 0.357 s
[17:53:05,223] INFO  {DAGScheduler} looking for newly runnable stages
[17:53:05,223] INFO  {DAGScheduler} running: Set()
[17:53:05,224] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[17:53:05,224] INFO  {DAGScheduler} failed: Set()
[17:53:05,225] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67), which has no missing parents
[17:53:05,229] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[17:53:05,231] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[17:53:05,232] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:35565 (size: 3.9 KB, free: 1127.7 MB)
[17:53:05,232] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[17:53:05,233] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:67)
[17:53:05,233] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[17:53:05,236] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[17:53:05,237] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[17:53:05,254] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[17:53:05,256] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[17:53:05,283] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1955 bytes result sent to driver
[17:53:05,284] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 50 ms on localhost (1/1)
[17:53:05,284] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[17:53:05,284] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:67) finished in 0.050 s
[17:53:05,285] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:67, took 0.443184 s
[17:53:05,294] INFO  {CodeGenerator} Code generated in 5.73974 ms
[17:53:05,335] INFO  {CodeGenerator} Code generated in 9.304593 ms
[17:53:05,358] INFO  {CodeGenerator} Code generated in 18.834089 ms
[17:53:05,376] INFO  {SparkContext} Starting job: collect at Main.scala:68
[17:53:05,377] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:68)
[17:53:05,378] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:68) with 1 output partitions
[17:53:05,378] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:68)
[17:53:05,378] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[17:53:05,378] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[17:53:05,379] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68), which has no missing parents
[17:53:05,383] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.5 MB)
[17:53:05,385] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.5 MB)
[17:53:05,386] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:35565 (size: 10.2 KB, free: 1127.7 MB)
[17:53:05,387] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[17:53:05,387] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:68)
[17:53:05,387] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[17:53:05,390] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[17:53:05,390] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[17:53:05,396] INFO  {BlockManager} Found block rdd_2_0 locally
[17:53:05,522] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2324 bytes result sent to driver
[17:53:05,524] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 135 ms on localhost (1/1)
[17:53:05,524] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[17:53:05,524] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:68) finished in 0.137 s
[17:53:05,524] INFO  {DAGScheduler} looking for newly runnable stages
[17:53:05,525] INFO  {DAGScheduler} running: Set()
[17:53:05,525] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[17:53:05,525] INFO  {DAGScheduler} failed: Set()
[17:53:05,526] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68), which has no missing parents
[17:53:05,528] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[17:53:05,531] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[17:53:05,531] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:35565 (size: 3.9 KB, free: 1127.6 MB)
[17:53:05,532] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[17:53:05,532] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:68)
[17:53:05,532] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[17:53:05,534] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[17:53:05,534] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[17:53:05,538] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[17:53:05,538] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[17:53:05,541] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[17:53:05,543] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 9 ms on localhost (1/1)
[17:53:05,543] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[17:53:05,543] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:68) finished in 0.010 s
[17:53:05,544] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:68, took 0.167179 s
[17:53:05,688] INFO  {CodeGenerator} Code generated in 56.507354 ms
[17:53:05,699] INFO  {SparkContext} Starting job: show at Main.scala:83
[17:53:05,700] INFO  {DAGScheduler} Got job 6 (show at Main.scala:83) with 1 output partitions
[17:53:05,700] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:83)
[17:53:05,700] INFO  {DAGScheduler} Parents of final stage: List()
[17:53:05,701] INFO  {DAGScheduler} Missing parents: List()
[17:53:05,701] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83), which has no missing parents
[17:53:05,704] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.4 MB)
[17:53:05,706] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[17:53:05,707] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:35565 (size: 15.0 KB, free: 1127.6 MB)
[17:53:05,707] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[17:53:05,707] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:83)
[17:53:05,707] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[17:53:05,710] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:53:05,710] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[17:53:05,715] INFO  {BlockManager} Found block rdd_2_0 locally
[17:53:05,721] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[17:53:05,722] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[17:53:05,723] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 15 ms on localhost (1/1)
[17:53:05,723] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[17:53:05,723] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:83) finished in 0.015 s
[17:53:05,724] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:83, took 0.024321 s
[17:53:05,742] INFO  {CodeGenerator} Code generated in 15.580152 ms
[17:53:05,909] INFO  {CodeGenerator} Code generated in 69.951124 ms
[17:53:05,932] INFO  {SparkContext} Starting job: show at Main.scala:92
[17:53:05,933] INFO  {DAGScheduler} Got job 7 (show at Main.scala:92) with 1 output partitions
[17:53:05,933] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:92)
[17:53:05,933] INFO  {DAGScheduler} Parents of final stage: List()
[17:53:05,935] INFO  {DAGScheduler} Missing parents: List()
[17:53:05,936] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92), which has no missing parents
[17:53:05,944] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[17:53:05,949] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[17:53:05,960] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:35565 (size: 16.4 KB, free: 1127.6 MB)
[17:53:05,962] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[17:53:05,969] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:92)
[17:53:05,971] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[17:53:05,977] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:53:05,978] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[17:53:06,005] INFO  {BlockManager} Found block rdd_2_0 locally
[17:53:06,060] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[17:53:06,065] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4170 bytes result sent to driver
[17:53:06,072] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 97 ms on localhost (1/1)
[17:53:06,072] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[17:53:06,074] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:92) finished in 0.098 s
[17:53:06,078] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:92, took 0.146008 s
[17:53:06,142] INFO  {CodeGenerator} Code generated in 57.016067 ms
[17:53:06,357] INFO  {ContextCleaner} Cleaned accumulator 188
[17:53:06,357] INFO  {ContextCleaner} Cleaned accumulator 189
[17:53:06,357] INFO  {ContextCleaner} Cleaned accumulator 190
[17:53:06,357] INFO  {ContextCleaner} Cleaned accumulator 191
[17:53:06,357] INFO  {ContextCleaner} Cleaned accumulator 192
[17:53:06,357] INFO  {ContextCleaner} Cleaned accumulator 193
[17:53:06,357] INFO  {ContextCleaner} Cleaned accumulator 194
[17:53:06,357] INFO  {ContextCleaner} Cleaned accumulator 195
[17:53:06,358] INFO  {ContextCleaner} Cleaned accumulator 196
[17:53:06,358] INFO  {ContextCleaner} Cleaned accumulator 197
[17:53:06,358] INFO  {ContextCleaner} Cleaned accumulator 198
[17:53:06,358] INFO  {ContextCleaner} Cleaned accumulator 199
[17:53:06,367] INFO  {ContextCleaner} Cleaned shuffle 0
[17:53:06,370] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:35565 in memory (size: 3.9 KB, free: 1127.6 MB)
[17:53:06,384] INFO  {ContextCleaner} Cleaned accumulator 389
[17:53:06,385] INFO  {ContextCleaner} Cleaned accumulator 390
[17:53:06,387] INFO  {BlockManagerInfo} Removed broadcast_9_piece0 on 192.168.0.103:35565 in memory (size: 15.0 KB, free: 1127.6 MB)
[17:53:06,392] INFO  {ContextCleaner} Cleaned accumulator 435
[17:53:06,392] INFO  {ContextCleaner} Cleaned accumulator 436
[17:53:06,393] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 192.168.0.103:35565 in memory (size: 16.4 KB, free: 1127.7 MB)
[17:53:06,409] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:35565 in memory (size: 10.2 KB, free: 1127.7 MB)
[17:53:06,417] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:35565 in memory (size: 3.9 KB, free: 1127.7 MB)
[17:53:06,419] INFO  {ContextCleaner} Cleaned accumulator 288
[17:53:06,419] INFO  {ContextCleaner} Cleaned accumulator 289
[17:53:06,419] INFO  {ContextCleaner} Cleaned accumulator 290
[17:53:06,419] INFO  {ContextCleaner} Cleaned accumulator 291
[17:53:06,419] INFO  {ContextCleaner} Cleaned accumulator 292
[17:53:06,419] INFO  {ContextCleaner} Cleaned accumulator 293
[17:53:06,419] INFO  {ContextCleaner} Cleaned accumulator 294
[17:53:06,420] INFO  {ContextCleaner} Cleaned accumulator 295
[17:53:06,420] INFO  {ContextCleaner} Cleaned accumulator 296
[17:53:06,420] INFO  {ContextCleaner} Cleaned accumulator 297
[17:53:06,420] INFO  {ContextCleaner} Cleaned accumulator 298
[17:53:06,420] INFO  {ContextCleaner} Cleaned accumulator 299
[17:53:06,420] INFO  {ContextCleaner} Cleaned accumulator 300
[17:53:06,422] INFO  {ContextCleaner} Cleaned shuffle 1
[17:53:06,428] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:35565 in memory (size: 10.2 KB, free: 1127.7 MB)
[17:53:06,973] INFO  {CodeGenerator} Code generated in 17.845039 ms
[17:53:07,026] INFO  {CodeGenerator} Code generated in 17.34454 ms
[17:53:07,081] INFO  {CodeGenerator} Code generated in 12.869638 ms
[17:53:07,100] INFO  {CodeGenerator} Code generated in 8.048517 ms
[17:53:07,106] INFO  {SparkContext} Invoking stop() from shutdown hook
[17:53:07,112] INFO  {ServerConnector} Stopped ServerConnector@c0c8e73{HTTP/1.1}{0.0.0.0:4040}
[17:53:07,114] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[17:53:07,115] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[17:53:07,115] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[17:53:07,115] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[17:53:07,115] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[17:53:07,115] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[17:53:07,115] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[17:53:07,116] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[17:53:07,116] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[17:53:07,116] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[17:53:07,116] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[17:53:07,116] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[17:53:07,116] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[17:53:07,116] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[17:53:07,116] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[17:53:07,117] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[17:53:07,117] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[17:53:07,117] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[17:53:07,117] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[17:53:07,117] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[17:53:07,117] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[17:53:07,117] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[17:53:07,118] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[17:53:07,118] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[17:53:07,120] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[17:53:07,132] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[17:53:07,149] INFO  {MemoryStore} MemoryStore cleared
[17:53:07,149] INFO  {BlockManager} BlockManager stopped
[17:53:07,152] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[17:53:07,159] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[17:53:07,178] INFO  {SparkContext} Successfully stopped SparkContext
[17:53:07,179] INFO  {ShutdownHookManager} Shutdown hook called
[17:53:07,180] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-7b9209de-2cfe-4902-b1b0-4bb0ef10f501
[17:53:52,304] INFO  {SparkContext} Running Spark version 2.0.1
[17:53:52,626] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[17:53:52,830] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[17:53:52,831] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[17:53:52,930] INFO  {SecurityManager} Changing view acls to: victor
[17:53:52,932] INFO  {SecurityManager} Changing modify acls to: victor
[17:53:52,933] INFO  {SecurityManager} Changing view acls groups to: 
[17:53:52,935] INFO  {SecurityManager} Changing modify acls groups to: 
[17:53:52,936] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[17:53:53,358] INFO  {Utils} Successfully started service 'sparkDriver' on port 39255.
[17:53:53,377] INFO  {SparkEnv} Registering MapOutputTracker
[17:53:53,392] INFO  {SparkEnv} Registering BlockManagerMaster
[17:53:53,413] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-be377247-b2da-47a6-9915-d8d3be985ec9
[17:53:53,429] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[17:53:53,485] INFO  {SparkEnv} Registering OutputCommitCoordinator
[17:53:53,570] INFO  {log} Logging initialized @2102ms
[17:53:53,705] INFO  {Server} jetty-9.2.z-SNAPSHOT
[17:53:53,722] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[17:53:53,722] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[17:53:53,722] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[17:53:53,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[17:53:53,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[17:53:53,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[17:53:53,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[17:53:53,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[17:53:53,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[17:53:53,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[17:53:53,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[17:53:53,727] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[17:53:53,728] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[17:53:53,728] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[17:53:53,729] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[17:53:53,730] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[17:53:53,731] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[17:53:53,731] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[17:53:53,731] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[17:53:53,732] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[17:53:53,744] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[17:53:53,744] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[17:53:53,745] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[17:53:53,745] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[17:53:53,757] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[17:53:53,757] INFO  {Server} Started @2290ms
[17:53:53,757] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[17:53:53,759] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[17:53:53,857] INFO  {Executor} Starting executor ID driver on host localhost
[17:53:53,899] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37941.
[17:53:53,900] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:37941
[17:53:53,902] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 37941)
[17:53:53,906] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:37941 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 37941)
[17:53:53,910] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 37941)
[17:53:54,092] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[17:53:54,169] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[17:53:54,170] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[17:53:54,171] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[17:53:54,171] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[17:53:54,174] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[17:53:54,200] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[17:53:56,398] INFO  {FileSourceStrategy} Pruning directories with: 
[17:53:56,401] INFO  {FileSourceStrategy} Post-Scan Filters: 
[17:53:56,409] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[17:53:56,410] INFO  {FileSourceStrategy} Pushed Filters: 
[17:53:56,529] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[17:53:56,583] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[17:53:56,611] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:37941 (size: 14.6 KB, free: 1128.9 MB)
[17:53:56,619] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[17:53:56,624] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[17:53:57,228] INFO  {CodeGenerator} Code generated in 282.549645 ms
[17:53:57,465] INFO  {CodeGenerator} Code generated in 33.775679 ms
[17:53:57,523] INFO  {SparkContext} Starting job: show at Main.scala:33
[17:53:57,540] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[17:53:57,540] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[17:53:57,540] INFO  {DAGScheduler} Parents of final stage: List()
[17:53:57,544] INFO  {DAGScheduler} Missing parents: List()
[17:53:57,549] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[17:53:57,613] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[17:53:57,615] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[17:53:57,616] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:37941 (size: 8.5 KB, free: 1128.9 MB)
[17:53:57,617] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[17:53:57,621] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[17:53:57,625] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[17:53:57,672] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:53:57,681] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[17:53:57,736] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[17:53:57,750] INFO  {CodeGenerator} Code generated in 10.754102 ms
[17:53:57,919] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[17:53:57,920] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:37941 (size: 1239.2 KB, free: 1127.7 MB)
[17:53:57,935] INFO  {CodeGenerator} Code generated in 4.722974 ms
[17:53:57,967] INFO  {CodeGenerator} Code generated in 25.532676 ms
[17:53:57,991] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[17:53:57,997] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4550 bytes result sent to driver
[17:53:58,006] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 353 ms on localhost (1/1)
[17:53:58,007] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[17:53:58,010] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.370 s
[17:53:58,015] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.491401 s
[17:53:58,054] INFO  {CodeGenerator} Code generated in 18.384155 ms
[17:53:58,200] INFO  {ContextCleaner} Cleaned accumulator 3
[17:53:58,200] INFO  {ContextCleaner} Cleaned accumulator 4
[17:53:58,224] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:37941 in memory (size: 8.5 KB, free: 1127.7 MB)
[17:53:58,255] INFO  {CodeGenerator} Code generated in 109.987731 ms
[17:53:58,280] INFO  {SparkContext} Starting job: show at Main.scala:42
[17:53:58,281] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[17:53:58,281] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[17:53:58,281] INFO  {DAGScheduler} Parents of final stage: List()
[17:53:58,294] INFO  {DAGScheduler} Missing parents: List()
[17:53:58,295] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[17:53:58,309] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[17:53:58,314] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[17:53:58,316] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:37941 (size: 10.0 KB, free: 1127.7 MB)
[17:53:58,318] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[17:53:58,320] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[17:53:58,320] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[17:53:58,327] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:53:58,327] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[17:53:58,339] INFO  {BlockManager} Found block rdd_2_0 locally
[17:53:58,358] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[17:53:58,359] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[17:53:58,366] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
[17:53:58,366] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[17:53:58,367] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.043 s
[17:53:58,368] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.087648 s
[17:53:58,393] INFO  {CodeGenerator} Code generated in 17.722964 ms
[17:53:58,533] INFO  {ContextCleaner} Cleaned accumulator 49
[17:53:58,533] INFO  {ContextCleaner} Cleaned accumulator 50
[17:53:58,540] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:37941 in memory (size: 10.0 KB, free: 1127.7 MB)
[17:53:58,780] INFO  {CodeGenerator} Code generated in 124.031524 ms
[17:53:58,826] INFO  {SparkContext} Starting job: show at Main.scala:51
[17:53:58,828] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[17:53:58,828] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[17:53:58,828] INFO  {DAGScheduler} Parents of final stage: List()
[17:53:58,830] INFO  {DAGScheduler} Missing parents: List()
[17:53:58,830] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[17:53:58,837] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[17:53:58,840] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[17:53:58,840] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:37941 (size: 11.7 KB, free: 1127.7 MB)
[17:53:58,842] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[17:53:58,842] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[17:53:58,842] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[17:53:58,845] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:53:58,846] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[17:53:58,876] INFO  {BlockManager} Found block rdd_2_0 locally
[17:53:58,912] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[17:53:58,916] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[17:53:58,929] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 86 ms on localhost (1/1)
[17:53:58,929] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[17:53:58,930] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.087 s
[17:53:58,931] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.104186 s
[17:53:59,007] INFO  {CodeGenerator} Code generated in 71.131537 ms
[17:53:59,269] INFO  {CodeGenerator} Code generated in 131.982906 ms
[17:53:59,318] INFO  {SparkContext} Starting job: show at Main.scala:61
[17:53:59,320] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[17:53:59,320] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[17:53:59,320] INFO  {DAGScheduler} Parents of final stage: List()
[17:53:59,321] INFO  {DAGScheduler} Missing parents: List()
[17:53:59,321] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[17:53:59,327] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[17:53:59,330] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[17:53:59,330] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:37941 (size: 13.3 KB, free: 1127.7 MB)
[17:53:59,333] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[17:53:59,333] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[17:53:59,333] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[17:53:59,336] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:53:59,337] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[17:53:59,351] INFO  {BlockManager} Found block rdd_2_0 locally
[17:53:59,375] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[17:53:59,377] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4099 bytes result sent to driver
[17:53:59,379] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 45 ms on localhost (1/1)
[17:53:59,379] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[17:53:59,379] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.043 s
[17:53:59,380] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.062140 s
[17:53:59,408] INFO  {CodeGenerator} Code generated in 24.211175 ms
[17:53:59,595] INFO  {CodeGenerator} Code generated in 13.764336 ms
[17:53:59,642] INFO  {CodeGenerator} Code generated in 40.446586 ms
[17:53:59,771] INFO  {SparkContext} Starting job: collect at Main.scala:66
[17:53:59,778] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:66)
[17:53:59,782] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:66) with 1 output partitions
[17:53:59,782] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:66)
[17:53:59,782] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[17:53:59,782] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[17:53:59,784] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:66), which has no missing parents
[17:53:59,793] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[17:53:59,796] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[17:53:59,797] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:37941 (size: 10.2 KB, free: 1127.6 MB)
[17:53:59,798] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[17:53:59,805] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:66)
[17:53:59,805] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[17:53:59,808] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[17:53:59,808] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[17:53:59,817] INFO  {BlockManager} Found block rdd_2_0 locally
[17:54:00,176] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[17:54:00,179] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 372 ms on localhost (1/1)
[17:54:00,179] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[17:54:00,180] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:66) finished in 0.375 s
[17:54:00,181] INFO  {DAGScheduler} looking for newly runnable stages
[17:54:00,181] INFO  {DAGScheduler} running: Set()
[17:54:00,182] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[17:54:00,182] INFO  {DAGScheduler} failed: Set()
[17:54:00,184] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:66), which has no missing parents
[17:54:00,188] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[17:54:00,191] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[17:54:00,191] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:37941 (size: 3.9 KB, free: 1127.6 MB)
[17:54:00,192] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[17:54:00,192] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:66)
[17:54:00,192] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[17:54:00,195] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[17:54:00,195] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[17:54:00,210] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[17:54:00,213] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 7 ms
[17:54:00,233] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1955 bytes result sent to driver
[17:54:00,234] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 41 ms on localhost (1/1)
[17:54:00,234] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[17:54:00,235] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:66) finished in 0.042 s
[17:54:00,235] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:66, took 0.464044 s
[17:54:00,244] INFO  {CodeGenerator} Code generated in 5.565517 ms
[17:54:00,305] INFO  {CodeGenerator} Code generated in 23.294207 ms
[17:54:00,331] INFO  {CodeGenerator} Code generated in 18.705827 ms
[17:54:00,353] INFO  {SparkContext} Starting job: collect at Main.scala:67
[17:54:00,356] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:67)
[17:54:00,356] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:67) with 1 output partitions
[17:54:00,356] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:67)
[17:54:00,357] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[17:54:00,357] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[17:54:00,358] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:67), which has no missing parents
[17:54:00,362] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[17:54:00,365] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[17:54:00,366] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:37941 (size: 10.2 KB, free: 1127.6 MB)
[17:54:00,366] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[17:54:00,367] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:67)
[17:54:00,367] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[17:54:00,369] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[17:54:00,369] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[17:54:00,374] INFO  {BlockManager} Found block rdd_2_0 locally
[17:54:00,507] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2324 bytes result sent to driver
[17:54:00,509] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 140 ms on localhost (1/1)
[17:54:00,509] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[17:54:00,509] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:67) finished in 0.142 s
[17:54:00,509] INFO  {DAGScheduler} looking for newly runnable stages
[17:54:00,509] INFO  {DAGScheduler} running: Set()
[17:54:00,509] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[17:54:00,509] INFO  {DAGScheduler} failed: Set()
[17:54:00,510] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:67), which has no missing parents
[17:54:00,512] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[17:54:00,513] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[17:54:00,514] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:37941 (size: 3.9 KB, free: 1127.6 MB)
[17:54:00,515] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[17:54:00,515] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:67)
[17:54:00,515] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[17:54:00,516] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[17:54:00,517] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[17:54:00,519] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[17:54:00,520] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[17:54:00,523] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1955 bytes result sent to driver
[17:54:00,524] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (1/1)
[17:54:00,524] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[17:54:00,525] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:67) finished in 0.010 s
[17:54:00,525] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:67, took 0.171529 s
[17:54:00,605] INFO  {ContextCleaner} Cleaned accumulator 293
[17:54:00,605] INFO  {ContextCleaner} Cleaned accumulator 294
[17:54:00,605] INFO  {ContextCleaner} Cleaned accumulator 295
[17:54:00,605] INFO  {ContextCleaner} Cleaned accumulator 296
[17:54:00,605] INFO  {ContextCleaner} Cleaned accumulator 297
[17:54:00,605] INFO  {ContextCleaner} Cleaned accumulator 298
[17:54:00,605] INFO  {ContextCleaner} Cleaned accumulator 299
[17:54:00,606] INFO  {ContextCleaner} Cleaned accumulator 300
[17:54:00,617] INFO  {ContextCleaner} Cleaned shuffle 1
[17:54:00,621] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:37941 in memory (size: 10.2 KB, free: 1127.6 MB)
[17:54:00,623] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:37941 in memory (size: 3.9 KB, free: 1127.6 MB)
[17:54:00,624] INFO  {ContextCleaner} Cleaned accumulator 95
[17:54:00,624] INFO  {ContextCleaner} Cleaned accumulator 96
[17:54:00,625] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:37941 in memory (size: 11.7 KB, free: 1127.6 MB)
[17:54:00,626] INFO  {ContextCleaner} Cleaned accumulator 141
[17:54:00,626] INFO  {ContextCleaner} Cleaned accumulator 142
[17:54:00,627] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:37941 in memory (size: 13.3 KB, free: 1127.7 MB)
[17:54:00,627] INFO  {ContextCleaner} Cleaned accumulator 187
[17:54:00,628] INFO  {ContextCleaner} Cleaned accumulator 188
[17:54:00,628] INFO  {ContextCleaner} Cleaned accumulator 189
[17:54:00,628] INFO  {ContextCleaner} Cleaned accumulator 190
[17:54:00,628] INFO  {ContextCleaner} Cleaned accumulator 191
[17:54:00,628] INFO  {ContextCleaner} Cleaned accumulator 192
[17:54:00,629] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:37941 in memory (size: 10.2 KB, free: 1127.7 MB)
[17:54:00,630] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:37941 in memory (size: 3.9 KB, free: 1127.7 MB)
[17:54:00,631] INFO  {ContextCleaner} Cleaned accumulator 288
[17:54:00,632] INFO  {ContextCleaner} Cleaned accumulator 289
[17:54:00,632] INFO  {ContextCleaner} Cleaned accumulator 290
[17:54:00,632] INFO  {ContextCleaner} Cleaned accumulator 291
[17:54:00,632] INFO  {ContextCleaner} Cleaned accumulator 292
[17:54:00,632] INFO  {ContextCleaner} Cleaned accumulator 193
[17:54:00,632] INFO  {ContextCleaner} Cleaned accumulator 194
[17:54:00,632] INFO  {ContextCleaner} Cleaned accumulator 195
[17:54:00,632] INFO  {ContextCleaner} Cleaned accumulator 196
[17:54:00,632] INFO  {ContextCleaner} Cleaned accumulator 197
[17:54:00,633] INFO  {ContextCleaner} Cleaned accumulator 198
[17:54:00,633] INFO  {ContextCleaner} Cleaned accumulator 199
[17:54:00,633] INFO  {ContextCleaner} Cleaned shuffle 0
[17:54:00,673] INFO  {CodeGenerator} Code generated in 49.378151 ms
[17:54:00,693] INFO  {SparkContext} Starting job: show at Main.scala:82
[17:54:00,694] INFO  {DAGScheduler} Got job 6 (show at Main.scala:82) with 1 output partitions
[17:54:00,694] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:82)
[17:54:00,694] INFO  {DAGScheduler} Parents of final stage: List()
[17:54:00,695] INFO  {DAGScheduler} Missing parents: List()
[17:54:00,695] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:82), which has no missing parents
[17:54:00,698] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[17:54:00,701] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.5 MB)
[17:54:00,705] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:37941 (size: 15.1 KB, free: 1127.7 MB)
[17:54:00,706] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[17:54:00,706] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:82)
[17:54:00,706] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[17:54:00,709] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:54:00,710] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[17:54:00,716] INFO  {BlockManager} Found block rdd_2_0 locally
[17:54:00,724] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[17:54:00,725] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[17:54:00,726] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 19 ms on localhost (1/1)
[17:54:00,726] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[17:54:00,727] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:82) finished in 0.020 s
[17:54:00,727] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:82, took 0.033695 s
[17:54:00,759] INFO  {CodeGenerator} Code generated in 28.390097 ms
[17:54:00,948] INFO  {CodeGenerator} Code generated in 70.502792 ms
[17:54:00,969] INFO  {SparkContext} Starting job: show at Main.scala:91
[17:54:00,970] INFO  {DAGScheduler} Got job 7 (show at Main.scala:91) with 1 output partitions
[17:54:00,970] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:91)
[17:54:00,970] INFO  {DAGScheduler} Parents of final stage: List()
[17:54:00,974] INFO  {DAGScheduler} Missing parents: List()
[17:54:00,974] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:91), which has no missing parents
[17:54:00,980] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[17:54:00,984] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[17:54:00,985] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:37941 (size: 16.4 KB, free: 1127.6 MB)
[17:54:00,987] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[17:54:00,991] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:91)
[17:54:00,992] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[17:54:00,994] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[17:54:00,994] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[17:54:01,000] INFO  {BlockManager} Found block rdd_2_0 locally
[17:54:01,011] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[17:54:01,012] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[17:54:01,015] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 22 ms on localhost (1/1)
[17:54:01,016] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[17:54:01,020] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:91) finished in 0.028 s
[17:54:01,021] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:91, took 0.051777 s
[17:54:01,063] INFO  {CodeGenerator} Code generated in 36.977941 ms
[17:54:01,757] INFO  {CodeGenerator} Code generated in 28.208956 ms
[17:54:01,789] INFO  {CodeGenerator} Code generated in 21.884017 ms
[17:54:01,834] INFO  {CodeGenerator} Code generated in 9.203797 ms
[17:54:01,854] INFO  {CodeGenerator} Code generated in 12.576881 ms
[17:54:01,866] INFO  {SparkContext} Invoking stop() from shutdown hook
[17:54:01,873] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[17:54:01,876] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[17:54:01,876] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[17:54:01,876] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[17:54:01,877] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[17:54:01,877] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[17:54:01,877] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[17:54:01,877] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[17:54:01,877] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[17:54:01,877] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[17:54:01,877] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[17:54:01,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[17:54:01,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[17:54:01,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[17:54:01,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[17:54:01,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[17:54:01,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[17:54:01,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[17:54:01,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[17:54:01,879] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[17:54:01,879] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[17:54:01,879] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[17:54:01,879] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[17:54:01,879] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[17:54:01,879] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[17:54:01,883] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[17:54:01,897] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[17:54:01,907] INFO  {MemoryStore} MemoryStore cleared
[17:54:01,909] INFO  {BlockManager} BlockManager stopped
[17:54:01,914] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[17:54:01,924] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[17:54:01,933] INFO  {SparkContext} Successfully stopped SparkContext
[17:54:01,934] INFO  {ShutdownHookManager} Shutdown hook called
[17:54:01,935] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-25afd4fa-a2c5-47c8-b8b4-46223ebd60da
[18:06:45,780] INFO  {SparkContext} Running Spark version 2.0.1
[18:06:46,356] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[18:06:46,635] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[18:06:46,638] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[18:06:46,849] INFO  {SecurityManager} Changing view acls to: victor
[18:06:46,850] INFO  {SecurityManager} Changing modify acls to: victor
[18:06:46,851] INFO  {SecurityManager} Changing view acls groups to: 
[18:06:46,853] INFO  {SecurityManager} Changing modify acls groups to: 
[18:06:46,854] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[18:06:47,751] INFO  {Utils} Successfully started service 'sparkDriver' on port 34081.
[18:06:47,788] INFO  {SparkEnv} Registering MapOutputTracker
[18:06:47,826] INFO  {SparkEnv} Registering BlockManagerMaster
[18:06:47,863] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-a940b71e-dc82-47a1-8025-876fb44508b6
[18:06:47,905] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[18:06:48,016] INFO  {SparkEnv} Registering OutputCommitCoordinator
[18:06:48,198] INFO  {log} Logging initialized @3982ms
[18:06:48,461] INFO  {Server} jetty-9.2.z-SNAPSHOT
[18:06:48,484] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[18:06:48,485] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[18:06:48,485] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[18:06:48,485] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[18:06:48,485] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[18:06:48,486] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[18:06:48,486] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[18:06:48,486] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[18:06:48,486] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[18:06:48,487] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[18:06:48,487] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[18:06:48,487] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[18:06:48,487] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[18:06:48,488] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[18:06:48,488] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[18:06:48,488] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[18:06:48,488] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[18:06:48,488] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[18:06:48,489] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[18:06:48,489] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[18:06:48,497] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[18:06:48,497] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[18:06:48,499] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[18:06:48,499] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[18:06:48,506] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[18:06:48,507] INFO  {Server} Started @4294ms
[18:06:48,507] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[18:06:48,509] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[18:06:48,596] INFO  {Executor} Starting executor ID driver on host localhost
[18:06:48,630] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44681.
[18:06:48,632] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:44681
[18:06:48,634] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 44681)
[18:06:48,638] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:44681 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 44681)
[18:06:48,642] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 44681)
[18:06:48,799] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[18:06:48,844] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[18:06:48,845] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[18:06:48,846] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[18:06:48,847] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[18:06:48,849] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[18:06:48,864] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[18:06:50,944] INFO  {FileSourceStrategy} Pruning directories with: 
[18:06:50,947] INFO  {FileSourceStrategy} Post-Scan Filters: 
[18:06:50,952] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[18:06:50,953] INFO  {FileSourceStrategy} Pushed Filters: 
[18:06:51,077] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[18:06:51,125] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[18:06:51,153] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:44681 (size: 14.6 KB, free: 1128.9 MB)
[18:06:51,161] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[18:06:51,167] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[18:06:51,672] INFO  {CodeGenerator} Code generated in 219.082758 ms
[18:06:51,890] INFO  {CodeGenerator} Code generated in 29.421116 ms
[18:06:51,946] INFO  {SparkContext} Starting job: show at Main.scala:33
[18:06:51,972] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[18:06:51,973] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[18:06:51,973] INFO  {DAGScheduler} Parents of final stage: List()
[18:06:51,978] INFO  {DAGScheduler} Missing parents: List()
[18:06:51,983] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[18:06:52,047] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[18:06:52,050] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[18:06:52,051] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:44681 (size: 8.5 KB, free: 1128.9 MB)
[18:06:52,052] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[18:06:52,055] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[18:06:52,057] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[18:06:52,101] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:06:52,109] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[18:06:52,150] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[18:06:52,164] INFO  {CodeGenerator} Code generated in 9.806367 ms
[18:06:52,302] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[18:06:52,303] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:44681 (size: 1239.2 KB, free: 1127.7 MB)
[18:06:52,316] INFO  {CodeGenerator} Code generated in 3.873347 ms
[18:06:52,349] INFO  {CodeGenerator} Code generated in 25.72946 ms
[18:06:52,369] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[18:06:52,378] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4550 bytes result sent to driver
[18:06:52,386] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 302 ms on localhost (1/1)
[18:06:52,387] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[18:06:52,392] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.320 s
[18:06:52,398] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.452262 s
[18:06:52,441] INFO  {CodeGenerator} Code generated in 22.147375 ms
[18:06:52,510] INFO  {ContextCleaner} Cleaned accumulator 3
[18:06:52,510] INFO  {ContextCleaner} Cleaned accumulator 4
[18:06:52,526] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:44681 in memory (size: 8.5 KB, free: 1127.7 MB)
[18:06:52,621] INFO  {CodeGenerator} Code generated in 56.703071 ms
[18:06:52,640] INFO  {SparkContext} Starting job: show at Main.scala:42
[18:06:52,642] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[18:06:52,642] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[18:06:52,642] INFO  {DAGScheduler} Parents of final stage: List()
[18:06:52,645] INFO  {DAGScheduler} Missing parents: List()
[18:06:52,645] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[18:06:52,654] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[18:06:52,656] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[18:06:52,657] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:44681 (size: 10.0 KB, free: 1127.7 MB)
[18:06:52,657] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[18:06:52,657] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[18:06:52,657] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[18:06:52,665] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:06:52,665] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[18:06:52,680] INFO  {BlockManager} Found block rdd_2_0 locally
[18:06:52,701] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[18:06:52,702] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[18:06:52,704] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
[18:06:52,704] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[18:06:52,705] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.043 s
[18:06:52,705] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.065033 s
[18:06:52,741] INFO  {CodeGenerator} Code generated in 25.40945 ms
[18:06:52,881] INFO  {ContextCleaner} Cleaned accumulator 49
[18:06:52,882] INFO  {ContextCleaner} Cleaned accumulator 50
[18:06:52,884] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:44681 in memory (size: 10.0 KB, free: 1127.7 MB)
[18:06:53,077] INFO  {CodeGenerator} Code generated in 90.43803 ms
[18:06:53,096] INFO  {SparkContext} Starting job: show at Main.scala:51
[18:06:53,097] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[18:06:53,098] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[18:06:53,098] INFO  {DAGScheduler} Parents of final stage: List()
[18:06:53,099] INFO  {DAGScheduler} Missing parents: List()
[18:06:53,100] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[18:06:53,109] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[18:06:53,113] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[18:06:53,113] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:44681 (size: 11.7 KB, free: 1127.7 MB)
[18:06:53,115] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[18:06:53,115] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[18:06:53,115] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[18:06:53,118] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:06:53,119] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[18:06:53,140] INFO  {BlockManager} Found block rdd_2_0 locally
[18:06:53,170] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[18:06:53,173] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[18:06:53,178] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 62 ms on localhost (1/1)
[18:06:53,178] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[18:06:53,181] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.065 s
[18:06:53,184] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.087584 s
[18:06:53,228] INFO  {CodeGenerator} Code generated in 36.736831 ms
[18:06:53,426] INFO  {CodeGenerator} Code generated in 86.5525 ms
[18:06:53,453] INFO  {SparkContext} Starting job: show at Main.scala:61
[18:06:53,454] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[18:06:53,454] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[18:06:53,454] INFO  {DAGScheduler} Parents of final stage: List()
[18:06:53,456] INFO  {DAGScheduler} Missing parents: List()
[18:06:53,456] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[18:06:53,461] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[18:06:53,463] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[18:06:53,464] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:44681 (size: 13.3 KB, free: 1127.7 MB)
[18:06:53,465] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[18:06:53,465] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[18:06:53,465] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[18:06:53,467] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:06:53,468] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[18:06:53,481] INFO  {BlockManager} Found block rdd_2_0 locally
[18:06:53,493] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[18:06:53,494] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[18:06:53,495] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 29 ms on localhost (1/1)
[18:06:53,495] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[18:06:53,496] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.030 s
[18:06:53,497] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.043906 s
[18:06:53,517] INFO  {CodeGenerator} Code generated in 17.733705 ms
[18:06:53,672] INFO  {CodeGenerator} Code generated in 26.162821 ms
[18:06:53,723] INFO  {CodeGenerator} Code generated in 37.272594 ms
[18:06:53,802] INFO  {SparkContext} Starting job: collect at Main.scala:66
[18:06:53,812] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:66)
[18:06:53,813] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:66) with 1 output partitions
[18:06:53,813] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:66)
[18:06:53,813] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[18:06:53,813] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[18:06:53,815] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:66), which has no missing parents
[18:06:53,826] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[18:06:53,828] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[18:06:53,829] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:44681 (size: 10.1 KB, free: 1127.6 MB)
[18:06:53,829] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[18:06:53,832] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:66)
[18:06:53,832] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[18:06:53,837] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[18:06:53,837] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[18:06:53,846] INFO  {BlockManager} Found block rdd_2_0 locally
[18:06:54,354] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[18:06:54,356] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 523 ms on localhost (1/1)
[18:06:54,356] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[18:06:54,358] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:66) finished in 0.522 s
[18:06:54,358] INFO  {DAGScheduler} looking for newly runnable stages
[18:06:54,358] INFO  {DAGScheduler} running: Set()
[18:06:54,359] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[18:06:54,359] INFO  {DAGScheduler} failed: Set()
[18:06:54,360] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:66), which has no missing parents
[18:06:54,364] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[18:06:54,366] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[18:06:54,366] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:44681 (size: 3.9 KB, free: 1127.6 MB)
[18:06:54,367] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[18:06:54,367] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:66)
[18:06:54,367] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[18:06:54,370] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[18:06:54,371] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[18:06:54,382] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[18:06:54,383] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[18:06:54,395] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1955 bytes result sent to driver
[18:06:54,396] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 28 ms on localhost (1/1)
[18:06:54,396] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[18:06:54,396] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:66) finished in 0.028 s
[18:06:54,397] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:66, took 0.594737 s
[18:06:54,405] INFO  {CodeGenerator} Code generated in 5.645816 ms
[18:06:54,471] INFO  {CodeGenerator} Code generated in 20.916238 ms
[18:06:54,520] INFO  {CodeGenerator} Code generated in 39.01319 ms
[18:06:54,557] INFO  {SparkContext} Starting job: collect at Main.scala:67
[18:06:54,558] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:67)
[18:06:54,559] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:67) with 1 output partitions
[18:06:54,559] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:67)
[18:06:54,559] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[18:06:54,559] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[18:06:54,561] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:67), which has no missing parents
[18:06:54,566] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[18:06:54,568] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[18:06:54,569] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:44681 (size: 10.2 KB, free: 1127.6 MB)
[18:06:54,570] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[18:06:54,570] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:67)
[18:06:54,571] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[18:06:54,574] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[18:06:54,575] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[18:06:54,581] INFO  {BlockManager} Found block rdd_2_0 locally
[18:06:54,817] INFO  {ContextCleaner} Cleaned accumulator 197
[18:06:54,817] INFO  {ContextCleaner} Cleaned accumulator 198
[18:06:54,818] INFO  {ContextCleaner} Cleaned accumulator 199
[18:06:54,825] INFO  {ContextCleaner} Cleaned shuffle 0
[18:06:54,827] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:44681 in memory (size: 10.1 KB, free: 1127.6 MB)
[18:06:54,830] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:44681 in memory (size: 3.9 KB, free: 1127.6 MB)
[18:06:54,831] INFO  {ContextCleaner} Cleaned accumulator 288
[18:06:54,832] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:44681 in memory (size: 11.7 KB, free: 1127.7 MB)
[18:06:54,833] INFO  {ContextCleaner} Cleaned accumulator 141
[18:06:54,834] INFO  {ContextCleaner} Cleaned accumulator 142
[18:06:54,835] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:44681 in memory (size: 13.3 KB, free: 1127.7 MB)
[18:06:54,836] INFO  {ContextCleaner} Cleaned accumulator 187
[18:06:54,837] INFO  {ContextCleaner} Cleaned accumulator 188
[18:06:54,837] INFO  {ContextCleaner} Cleaned accumulator 189
[18:06:54,837] INFO  {ContextCleaner} Cleaned accumulator 190
[18:06:54,837] INFO  {ContextCleaner} Cleaned accumulator 191
[18:06:54,837] INFO  {ContextCleaner} Cleaned accumulator 192
[18:06:54,837] INFO  {ContextCleaner} Cleaned accumulator 193
[18:06:54,838] INFO  {ContextCleaner} Cleaned accumulator 194
[18:06:54,838] INFO  {ContextCleaner} Cleaned accumulator 195
[18:06:54,838] INFO  {ContextCleaner} Cleaned accumulator 196
[18:06:54,838] INFO  {ContextCleaner} Cleaned accumulator 95
[18:06:54,838] INFO  {ContextCleaner} Cleaned accumulator 96
[18:06:54,867] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[18:06:54,869] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 297 ms on localhost (1/1)
[18:06:54,870] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[18:06:54,871] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:67) finished in 0.299 s
[18:06:54,871] INFO  {DAGScheduler} looking for newly runnable stages
[18:06:54,872] INFO  {DAGScheduler} running: Set()
[18:06:54,872] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[18:06:54,872] INFO  {DAGScheduler} failed: Set()
[18:06:54,872] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:67), which has no missing parents
[18:06:54,875] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[18:06:54,878] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[18:06:54,879] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:44681 (size: 3.9 KB, free: 1127.7 MB)
[18:06:54,880] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[18:06:54,880] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:67)
[18:06:54,880] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[18:06:54,883] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[18:06:54,883] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[18:06:54,888] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[18:06:54,889] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[18:06:54,894] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[18:06:54,896] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 15 ms on localhost (1/1)
[18:06:54,896] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[18:06:54,897] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:67) finished in 0.016 s
[18:06:54,897] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:67, took 0.340396 s
[18:06:55,164] INFO  {CodeGenerator} Code generated in 121.542216 ms
[18:06:55,191] INFO  {SparkContext} Starting job: show at Main.scala:82
[18:06:55,192] INFO  {DAGScheduler} Got job 6 (show at Main.scala:82) with 1 output partitions
[18:06:55,192] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:82)
[18:06:55,193] INFO  {DAGScheduler} Parents of final stage: List()
[18:06:55,193] INFO  {DAGScheduler} Missing parents: List()
[18:06:55,194] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:82), which has no missing parents
[18:06:55,199] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[18:06:55,201] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[18:06:55,203] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:44681 (size: 15.0 KB, free: 1127.6 MB)
[18:06:55,203] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[18:06:55,204] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:82)
[18:06:55,204] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[18:06:55,207] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:06:55,208] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[18:06:55,219] INFO  {BlockManager} Found block rdd_2_0 locally
[18:06:55,233] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[18:06:55,235] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[18:06:55,236] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 31 ms on localhost (1/1)
[18:06:55,237] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[18:06:55,238] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:82) finished in 0.033 s
[18:06:55,239] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:82, took 0.047219 s
[18:06:55,271] INFO  {CodeGenerator} Code generated in 28.377149 ms
[18:06:55,437] INFO  {CodeGenerator} Code generated in 58.496349 ms
[18:06:55,447] INFO  {SparkContext} Starting job: show at Main.scala:91
[18:06:55,447] INFO  {DAGScheduler} Got job 7 (show at Main.scala:91) with 1 output partitions
[18:06:55,448] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:91)
[18:06:55,448] INFO  {DAGScheduler} Parents of final stage: List()
[18:06:55,448] INFO  {DAGScheduler} Missing parents: List()
[18:06:55,449] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:91), which has no missing parents
[18:06:55,452] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[18:06:55,454] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[18:06:55,455] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:44681 (size: 16.4 KB, free: 1127.6 MB)
[18:06:55,455] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[18:06:55,455] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:91)
[18:06:55,455] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[18:06:55,460] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:06:55,461] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[18:06:55,466] INFO  {BlockManager} Found block rdd_2_0 locally
[18:06:55,475] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[18:06:55,476] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[18:06:55,478] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 22 ms on localhost (1/1)
[18:06:55,478] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[18:06:55,479] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:91) finished in 0.023 s
[18:06:55,480] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:91, took 0.032727 s
[18:06:55,503] INFO  {CodeGenerator} Code generated in 20.662627 ms
[18:06:56,310] INFO  {CodeGenerator} Code generated in 33.952326 ms
[18:06:56,361] INFO  {CodeGenerator} Code generated in 25.629163 ms
[18:06:56,426] INFO  {CodeGenerator} Code generated in 15.202211 ms
[18:06:56,447] INFO  {CodeGenerator} Code generated in 8.126347 ms
[18:06:56,459] INFO  {SparkContext} Invoking stop() from shutdown hook
[18:06:56,468] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[18:06:56,472] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[18:06:56,473] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[18:06:56,473] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[18:06:56,473] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[18:06:56,473] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[18:06:56,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[18:06:56,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[18:06:56,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[18:06:56,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[18:06:56,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[18:06:56,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[18:06:56,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[18:06:56,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[18:06:56,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[18:06:56,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[18:06:56,477] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[18:06:56,477] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[18:06:56,477] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[18:06:56,477] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[18:06:56,478] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[18:06:56,478] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[18:06:56,478] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[18:06:56,478] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[18:06:56,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[18:06:56,481] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[18:06:56,500] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[18:06:56,524] INFO  {MemoryStore} MemoryStore cleared
[18:06:56,525] INFO  {BlockManager} BlockManager stopped
[18:06:56,528] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[18:06:56,533] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[18:06:56,541] INFO  {SparkContext} Successfully stopped SparkContext
[18:06:56,542] INFO  {ShutdownHookManager} Shutdown hook called
[18:06:56,544] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-992e271d-7451-4578-b0ce-8d3579c8628b
[18:10:04,277] INFO  {SparkContext} Running Spark version 2.0.1
[18:10:04,915] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[18:10:05,231] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[18:10:05,234] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[18:10:05,455] INFO  {SecurityManager} Changing view acls to: victor
[18:10:05,457] INFO  {SecurityManager} Changing modify acls to: victor
[18:10:05,459] INFO  {SecurityManager} Changing view acls groups to: 
[18:10:05,461] INFO  {SecurityManager} Changing modify acls groups to: 
[18:10:05,463] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[18:10:06,463] INFO  {Utils} Successfully started service 'sparkDriver' on port 38331.
[18:10:06,505] INFO  {SparkEnv} Registering MapOutputTracker
[18:10:06,546] INFO  {SparkEnv} Registering BlockManagerMaster
[18:10:06,580] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-359c41df-e634-486a-ba94-4ec0ee12b3db
[18:10:06,616] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[18:10:06,750] INFO  {SparkEnv} Registering OutputCommitCoordinator
[18:10:06,938] INFO  {log} Logging initialized @4660ms
[18:10:07,240] INFO  {Server} jetty-9.2.z-SNAPSHOT
[18:10:07,279] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[18:10:07,280] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[18:10:07,280] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[18:10:07,281] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[18:10:07,281] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[18:10:07,282] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[18:10:07,282] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[18:10:07,282] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[18:10:07,283] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[18:10:07,283] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[18:10:07,284] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[18:10:07,284] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[18:10:07,285] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[18:10:07,285] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[18:10:07,286] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[18:10:07,286] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[18:10:07,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[18:10:07,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[18:10:07,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[18:10:07,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[18:10:07,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[18:10:07,304] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[18:10:07,306] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[18:10:07,307] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[18:10:07,322] INFO  {ServerConnector} Started ServerConnector@56d0efc3{HTTP/1.1}{0.0.0.0:4040}
[18:10:07,322] INFO  {Server} Started @5047ms
[18:10:07,323] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[18:10:07,334] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[18:10:07,584] INFO  {Executor} Starting executor ID driver on host localhost
[18:10:07,655] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43325.
[18:10:07,657] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:43325
[18:10:07,663] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 43325)
[18:10:07,671] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:43325 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 43325)
[18:10:07,679] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 43325)
[18:10:08,014] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@72ccd81a{/metrics/json,null,AVAILABLE}
[18:10:08,175] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae76500{/SQL,null,AVAILABLE}
[18:10:08,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1133ec6e{/SQL/json,null,AVAILABLE}
[18:10:08,180] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/SQL/execution,null,AVAILABLE}
[18:10:08,181] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/SQL/execution/json,null,AVAILABLE}
[18:10:08,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bd7f8dc{/static/sql,null,AVAILABLE}
[18:10:08,236] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[18:10:10,802] INFO  {FileSourceStrategy} Pruning directories with: 
[18:10:10,805] INFO  {FileSourceStrategy} Post-Scan Filters: 
[18:10:10,810] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[18:10:10,810] INFO  {FileSourceStrategy} Pushed Filters: 
[18:10:10,929] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[18:10:10,981] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[18:10:11,000] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:43325 (size: 14.6 KB, free: 1128.9 MB)
[18:10:11,007] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[18:10:11,011] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[18:10:11,538] INFO  {CodeGenerator} Code generated in 230.39368 ms
[18:10:11,758] INFO  {CodeGenerator} Code generated in 27.056114 ms
[18:10:11,811] INFO  {SparkContext} Starting job: show at Main.scala:33
[18:10:11,837] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[18:10:11,838] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[18:10:11,839] INFO  {DAGScheduler} Parents of final stage: List()
[18:10:11,846] INFO  {DAGScheduler} Missing parents: List()
[18:10:11,855] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[18:10:11,938] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[18:10:11,940] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[18:10:11,941] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:43325 (size: 8.5 KB, free: 1128.9 MB)
[18:10:11,942] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[18:10:11,947] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[18:10:11,949] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[18:10:11,988] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:10:11,995] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[18:10:12,038] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[18:10:12,051] INFO  {CodeGenerator} Code generated in 10.278184 ms
[18:10:12,193] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[18:10:12,194] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:43325 (size: 1239.2 KB, free: 1127.7 MB)
[18:10:12,205] INFO  {CodeGenerator} Code generated in 4.382689 ms
[18:10:12,236] INFO  {CodeGenerator} Code generated in 24.972605 ms
[18:10:12,263] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[18:10:12,270] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4550 bytes result sent to driver
[18:10:12,279] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 306 ms on localhost (1/1)
[18:10:12,280] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[18:10:12,290] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.328 s
[18:10:12,301] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.489134 s
[18:10:12,370] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:43325 in memory (size: 8.5 KB, free: 1127.7 MB)
[18:10:12,378] INFO  {CodeGenerator} Code generated in 32.941228 ms
[18:10:12,506] INFO  {CodeGenerator} Code generated in 47.106899 ms
[18:10:12,530] INFO  {SparkContext} Starting job: show at Main.scala:42
[18:10:12,531] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[18:10:12,531] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[18:10:12,531] INFO  {DAGScheduler} Parents of final stage: List()
[18:10:12,534] INFO  {DAGScheduler} Missing parents: List()
[18:10:12,535] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[18:10:12,545] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[18:10:12,547] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[18:10:12,548] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:43325 (size: 10.0 KB, free: 1127.7 MB)
[18:10:12,549] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[18:10:12,549] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[18:10:12,549] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[18:10:12,561] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:10:12,562] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[18:10:12,580] INFO  {BlockManager} Found block rdd_2_0 locally
[18:10:12,600] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[18:10:12,602] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[18:10:12,604] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 48 ms on localhost (1/1)
[18:10:12,604] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[18:10:12,604] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.048 s
[18:10:12,605] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.074739 s
[18:10:12,640] INFO  {CodeGenerator} Code generated in 27.398747 ms
[18:10:12,814] INFO  {ContextCleaner} Cleaned accumulator 3
[18:10:12,814] INFO  {ContextCleaner} Cleaned accumulator 4
[18:10:12,814] INFO  {ContextCleaner} Cleaned accumulator 49
[18:10:12,814] INFO  {ContextCleaner} Cleaned accumulator 50
[18:10:12,816] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:43325 in memory (size: 10.0 KB, free: 1127.7 MB)
[18:10:12,976] INFO  {CodeGenerator} Code generated in 84.40868 ms
[18:10:12,996] INFO  {SparkContext} Starting job: show at Main.scala:51
[18:10:12,997] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[18:10:12,998] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[18:10:12,998] INFO  {DAGScheduler} Parents of final stage: List()
[18:10:13,002] INFO  {DAGScheduler} Missing parents: List()
[18:10:13,003] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[18:10:13,011] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[18:10:13,015] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[18:10:13,016] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:43325 (size: 11.7 KB, free: 1127.7 MB)
[18:10:13,018] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[18:10:13,019] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[18:10:13,020] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[18:10:13,033] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:10:13,037] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[18:10:13,046] INFO  {BlockManager} Found block rdd_2_0 locally
[18:10:13,072] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[18:10:13,074] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[18:10:13,076] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 51 ms on localhost (1/1)
[18:10:13,076] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[18:10:13,077] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.042 s
[18:10:13,077] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.081307 s
[18:10:13,147] INFO  {CodeGenerator} Code generated in 57.049169 ms
[18:10:13,438] INFO  {CodeGenerator} Code generated in 130.38733 ms
[18:10:13,472] INFO  {SparkContext} Starting job: show at Main.scala:61
[18:10:13,475] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[18:10:13,475] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[18:10:13,475] INFO  {DAGScheduler} Parents of final stage: List()
[18:10:13,476] INFO  {DAGScheduler} Missing parents: List()
[18:10:13,477] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[18:10:13,486] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[18:10:13,491] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[18:10:13,493] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:43325 (size: 13.3 KB, free: 1127.7 MB)
[18:10:13,494] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[18:10:13,494] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[18:10:13,495] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[18:10:13,499] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:10:13,500] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[18:10:13,517] INFO  {BlockManager} Found block rdd_2_0 locally
[18:10:13,534] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[18:10:13,536] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[18:10:13,538] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 42 ms on localhost (1/1)
[18:10:13,539] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[18:10:13,539] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.043 s
[18:10:13,540] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.067198 s
[18:10:13,582] INFO  {CodeGenerator} Code generated in 35.563591 ms
[18:10:13,701] INFO  {CodeGenerator} Code generated in 15.282691 ms
[18:10:13,740] INFO  {CodeGenerator} Code generated in 32.437085 ms
[18:10:13,812] INFO  {SparkContext} Starting job: collect at Main.scala:66
[18:10:13,821] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:66)
[18:10:13,824] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:66) with 1 output partitions
[18:10:13,825] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:66)
[18:10:13,825] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[18:10:13,826] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[18:10:13,834] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:66), which has no missing parents
[18:10:13,852] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[18:10:13,856] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[18:10:13,857] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:43325 (size: 10.2 KB, free: 1127.6 MB)
[18:10:13,858] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[18:10:13,865] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:66)
[18:10:13,866] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[18:10:13,873] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[18:10:13,873] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[18:10:13,891] INFO  {BlockManager} Found block rdd_2_0 locally
[18:10:14,383] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[18:10:14,390] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 522 ms on localhost (1/1)
[18:10:14,390] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[18:10:14,392] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:66) finished in 0.525 s
[18:10:14,393] INFO  {DAGScheduler} looking for newly runnable stages
[18:10:14,394] INFO  {DAGScheduler} running: Set()
[18:10:14,396] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[18:10:14,397] INFO  {DAGScheduler} failed: Set()
[18:10:14,399] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:66), which has no missing parents
[18:10:14,409] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[18:10:14,414] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[18:10:14,416] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:43325 (size: 3.9 KB, free: 1127.6 MB)
[18:10:14,418] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[18:10:14,419] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:66)
[18:10:14,419] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[18:10:14,429] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[18:10:14,430] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[18:10:14,458] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[18:10:14,461] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 9 ms
[18:10:14,496] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1955 bytes result sent to driver
[18:10:14,498] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 74 ms on localhost (1/1)
[18:10:14,498] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[18:10:14,499] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:66) finished in 0.077 s
[18:10:14,500] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:66, took 0.687211 s
[18:10:14,519] INFO  {CodeGenerator} Code generated in 12.366777 ms
[18:10:14,612] INFO  {CodeGenerator} Code generated in 21.27186 ms
[18:10:14,665] INFO  {CodeGenerator} Code generated in 40.339276 ms
[18:10:14,706] INFO  {SparkContext} Starting job: collect at Main.scala:67
[18:10:14,707] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:67)
[18:10:14,708] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:67) with 1 output partitions
[18:10:14,708] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:67)
[18:10:14,708] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[18:10:14,708] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[18:10:14,709] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:67), which has no missing parents
[18:10:14,718] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[18:10:14,720] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.2 KB, free 1127.4 MB)
[18:10:14,721] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:43325 (size: 10.2 KB, free: 1127.6 MB)
[18:10:14,722] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[18:10:14,722] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:67)
[18:10:14,723] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[18:10:14,726] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[18:10:14,726] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[18:10:14,733] INFO  {BlockManager} Found block rdd_2_0 locally
[18:10:15,020] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2324 bytes result sent to driver
[18:10:15,022] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 298 ms on localhost (1/1)
[18:10:15,022] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[18:10:15,024] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:67) finished in 0.301 s
[18:10:15,024] INFO  {DAGScheduler} looking for newly runnable stages
[18:10:15,024] INFO  {DAGScheduler} running: Set()
[18:10:15,025] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[18:10:15,025] INFO  {DAGScheduler} failed: Set()
[18:10:15,026] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:67), which has no missing parents
[18:10:15,029] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[18:10:15,033] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[18:10:15,034] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:43325 (size: 3.9 KB, free: 1127.6 MB)
[18:10:15,035] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[18:10:15,036] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:67)
[18:10:15,036] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[18:10:15,038] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[18:10:15,039] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[18:10:15,045] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[18:10:15,045] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[18:10:15,052] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[18:10:15,054] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 17 ms on localhost (1/1)
[18:10:15,054] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[18:10:15,055] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:67) finished in 0.015 s
[18:10:15,055] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:67, took 0.349183 s
[18:10:15,114] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:43325 in memory (size: 3.9 KB, free: 1127.6 MB)
[18:10:15,117] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:43325 in memory (size: 10.2 KB, free: 1127.6 MB)
[18:10:15,120] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:43325 in memory (size: 3.9 KB, free: 1127.6 MB)
[18:10:15,121] INFO  {ContextCleaner} Cleaned accumulator 288
[18:10:15,121] INFO  {ContextCleaner} Cleaned accumulator 289
[18:10:15,121] INFO  {ContextCleaner} Cleaned accumulator 290
[18:10:15,121] INFO  {ContextCleaner} Cleaned accumulator 291
[18:10:15,122] INFO  {ContextCleaner} Cleaned accumulator 292
[18:10:15,122] INFO  {ContextCleaner} Cleaned accumulator 293
[18:10:15,122] INFO  {ContextCleaner} Cleaned accumulator 294
[18:10:15,122] INFO  {ContextCleaner} Cleaned accumulator 295
[18:10:15,123] INFO  {ContextCleaner} Cleaned accumulator 296
[18:10:15,123] INFO  {ContextCleaner} Cleaned accumulator 297
[18:10:15,123] INFO  {ContextCleaner} Cleaned accumulator 298
[18:10:15,123] INFO  {ContextCleaner} Cleaned accumulator 299
[18:10:15,123] INFO  {ContextCleaner} Cleaned accumulator 300
[18:10:15,129] INFO  {ContextCleaner} Cleaned shuffle 1
[18:10:15,129] INFO  {ContextCleaner} Cleaned accumulator 95
[18:10:15,129] INFO  {ContextCleaner} Cleaned accumulator 96
[18:10:15,132] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:43325 in memory (size: 11.7 KB, free: 1127.7 MB)
[18:10:15,134] INFO  {ContextCleaner} Cleaned accumulator 141
[18:10:15,134] INFO  {ContextCleaner} Cleaned accumulator 142
[18:10:15,138] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:43325 in memory (size: 13.3 KB, free: 1127.7 MB)
[18:10:15,139] INFO  {ContextCleaner} Cleaned accumulator 187
[18:10:15,139] INFO  {ContextCleaner} Cleaned accumulator 188
[18:10:15,139] INFO  {ContextCleaner} Cleaned accumulator 189
[18:10:15,140] INFO  {ContextCleaner} Cleaned accumulator 190
[18:10:15,140] INFO  {ContextCleaner} Cleaned accumulator 191
[18:10:15,140] INFO  {ContextCleaner} Cleaned accumulator 192
[18:10:15,140] INFO  {ContextCleaner} Cleaned accumulator 193
[18:10:15,140] INFO  {ContextCleaner} Cleaned accumulator 194
[18:10:15,140] INFO  {ContextCleaner} Cleaned accumulator 195
[18:10:15,141] INFO  {ContextCleaner} Cleaned accumulator 196
[18:10:15,141] INFO  {ContextCleaner} Cleaned accumulator 197
[18:10:15,141] INFO  {ContextCleaner} Cleaned accumulator 198
[18:10:15,141] INFO  {ContextCleaner} Cleaned accumulator 199
[18:10:15,142] INFO  {ContextCleaner} Cleaned shuffle 0
[18:10:15,146] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:43325 in memory (size: 10.2 KB, free: 1127.7 MB)
[18:10:15,320] INFO  {CodeGenerator} Code generated in 89.982258 ms
[18:10:15,337] INFO  {SparkContext} Starting job: show at Main.scala:82
[18:10:15,338] INFO  {DAGScheduler} Got job 6 (show at Main.scala:82) with 1 output partitions
[18:10:15,338] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:82)
[18:10:15,338] INFO  {DAGScheduler} Parents of final stage: List()
[18:10:15,339] INFO  {DAGScheduler} Missing parents: List()
[18:10:15,341] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:82), which has no missing parents
[18:10:15,347] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[18:10:15,352] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1127.5 MB)
[18:10:15,354] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:43325 (size: 15.1 KB, free: 1127.7 MB)
[18:10:15,355] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[18:10:15,355] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:82)
[18:10:15,355] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[18:10:15,358] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:10:15,358] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[18:10:15,365] INFO  {BlockManager} Found block rdd_2_0 locally
[18:10:15,373] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[18:10:15,375] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[18:10:15,376] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 20 ms on localhost (1/1)
[18:10:15,376] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[18:10:15,377] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:82) finished in 0.020 s
[18:10:15,377] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:82, took 0.040298 s
[18:10:15,400] INFO  {CodeGenerator} Code generated in 19.661227 ms
[18:10:15,658] INFO  {CodeGenerator} Code generated in 124.230249 ms
[18:10:15,671] INFO  {SparkContext} Starting job: show at Main.scala:91
[18:10:15,675] INFO  {DAGScheduler} Got job 7 (show at Main.scala:91) with 1 output partitions
[18:10:15,676] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:91)
[18:10:15,676] INFO  {DAGScheduler} Parents of final stage: List()
[18:10:15,677] INFO  {DAGScheduler} Missing parents: List()
[18:10:15,678] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:91), which has no missing parents
[18:10:15,687] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[18:10:15,693] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[18:10:15,695] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:43325 (size: 16.4 KB, free: 1127.6 MB)
[18:10:15,696] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[18:10:15,696] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:91)
[18:10:15,696] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[18:10:15,698] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:10:15,699] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[18:10:15,706] INFO  {BlockManager} Found block rdd_2_0 locally
[18:10:15,715] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[18:10:15,716] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[18:10:15,718] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 20 ms on localhost (1/1)
[18:10:15,718] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[18:10:15,719] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:91) finished in 0.022 s
[18:10:15,719] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:91, took 0.047438 s
[18:10:15,746] INFO  {CodeGenerator} Code generated in 22.152698 ms
[18:10:16,588] INFO  {SparkContext} Starting job: show at Main.scala:118
[18:10:16,590] INFO  {DAGScheduler} Got job 8 (show at Main.scala:118) with 1 output partitions
[18:10:16,590] INFO  {DAGScheduler} Final stage: ResultStage 10 (show at Main.scala:118)
[18:10:16,590] INFO  {DAGScheduler} Parents of final stage: List()
[18:10:16,592] INFO  {DAGScheduler} Missing parents: List()
[18:10:16,593] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[35] at show at Main.scala:118), which has no missing parents
[18:10:16,604] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 62.1 KB, free 1127.3 MB)
[18:10:16,609] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.3 MB)
[18:10:16,610] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:43325 (size: 16.4 KB, free: 1127.6 MB)
[18:10:16,612] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[18:10:16,612] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[35] at show at Main.scala:118)
[18:10:16,613] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[18:10:16,616] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:10:16,617] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[18:10:16,636] INFO  {BlockManager} Found block rdd_2_0 locally
[18:10:16,646] WARN  {Executor} 1 block locks were not released by TID = 10:
[rdd_2_0]
[18:10:16,648] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 4083 bytes result sent to driver
[18:10:16,652] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 37 ms on localhost (1/1)
[18:10:16,652] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[18:10:16,656] INFO  {DAGScheduler} ResultStage 10 (show at Main.scala:118) finished in 0.040 s
[18:10:16,658] INFO  {DAGScheduler} Job 8 finished: show at Main.scala:118, took 0.070153 s
[18:10:16,704] INFO  {CodeGenerator} Code generated in 38.964646 ms
[18:10:16,866] INFO  {CodeGenerator} Code generated in 63.119456 ms
[18:10:16,883] INFO  {SparkContext} Starting job: show at Main.scala:122
[18:10:16,886] INFO  {DAGScheduler} Got job 9 (show at Main.scala:122) with 1 output partitions
[18:10:16,886] INFO  {DAGScheduler} Final stage: ResultStage 11 (show at Main.scala:122)
[18:10:16,886] INFO  {DAGScheduler} Parents of final stage: List()
[18:10:16,890] INFO  {DAGScheduler} Missing parents: List()
[18:10:16,891] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[38] at show at Main.scala:122), which has no missing parents
[18:10:16,899] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 37.5 KB, free 1127.3 MB)
[18:10:16,903] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.3 KB, free 1127.3 MB)
[18:10:16,904] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:43325 (size: 12.3 KB, free: 1127.6 MB)
[18:10:16,906] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[18:10:16,906] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[38] at show at Main.scala:122)
[18:10:16,906] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[18:10:16,910] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:10:16,911] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[18:10:16,925] INFO  {BlockManager} Found block rdd_2_0 locally
[18:10:16,938] WARN  {Executor} 1 block locks were not released by TID = 11:
[rdd_2_0]
[18:10:16,940] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 1991 bytes result sent to driver
[18:10:16,942] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 34 ms on localhost (1/1)
[18:10:16,942] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[18:10:16,943] INFO  {DAGScheduler} ResultStage 11 (show at Main.scala:122) finished in 0.034 s
[18:10:16,943] INFO  {DAGScheduler} Job 9 finished: show at Main.scala:122, took 0.059656 s
[18:10:16,958] INFO  {CodeGenerator} Code generated in 13.468625 ms
[18:10:16,984] INFO  {SparkContext} Invoking stop() from shutdown hook
[18:10:16,996] INFO  {ServerConnector} Stopped ServerConnector@56d0efc3{HTTP/1.1}{0.0.0.0:4040}
[18:10:17,011] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[18:10:17,012] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[18:10:17,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[18:10:17,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[18:10:17,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[18:10:17,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[18:10:17,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[18:10:17,017] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[18:10:17,021] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[18:10:17,024] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[18:10:17,025] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[18:10:17,025] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[18:10:17,027] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[18:10:17,027] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[18:10:17,028] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[18:10:17,029] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[18:10:17,031] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[18:10:17,032] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[18:10:17,034] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[18:10:17,036] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[18:10:17,037] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[18:10:17,038] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[18:10:17,038] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[18:10:17,038] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[18:10:17,042] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[18:10:17,086] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[18:10:17,111] INFO  {MemoryStore} MemoryStore cleared
[18:10:17,112] INFO  {BlockManager} BlockManager stopped
[18:10:17,113] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[18:10:17,118] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[18:10:17,134] INFO  {SparkContext} Successfully stopped SparkContext
[18:10:17,136] INFO  {ShutdownHookManager} Shutdown hook called
[18:10:17,138] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f4db5a17-14e1-46fe-a423-f65de507df5e
[18:11:59,468] INFO  {SparkContext} Running Spark version 2.0.1
[18:12:00,112] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[18:12:00,405] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[18:12:00,407] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[18:12:00,646] INFO  {SecurityManager} Changing view acls to: victor
[18:12:00,649] INFO  {SecurityManager} Changing modify acls to: victor
[18:12:00,651] INFO  {SecurityManager} Changing view acls groups to: 
[18:12:00,653] INFO  {SecurityManager} Changing modify acls groups to: 
[18:12:00,655] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[18:12:01,751] INFO  {Utils} Successfully started service 'sparkDriver' on port 40915.
[18:12:01,798] INFO  {SparkEnv} Registering MapOutputTracker
[18:12:01,848] INFO  {SparkEnv} Registering BlockManagerMaster
[18:12:01,884] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-05e9dc2c-da7c-42d0-9fdd-4a2471896680
[18:12:01,918] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[18:12:02,066] INFO  {SparkEnv} Registering OutputCommitCoordinator
[18:12:02,248] INFO  {log} Logging initialized @4525ms
[18:12:02,538] INFO  {Server} jetty-9.2.z-SNAPSHOT
[18:12:02,579] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[18:12:02,580] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[18:12:02,580] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[18:12:02,581] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[18:12:02,582] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[18:12:02,582] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[18:12:02,583] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[18:12:02,584] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[18:12:02,584] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[18:12:02,585] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[18:12:02,585] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[18:12:02,586] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[18:12:02,586] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[18:12:02,587] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[18:12:02,587] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[18:12:02,588] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[18:12:02,588] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[18:12:02,588] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[18:12:02,589] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[18:12:02,590] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[18:12:02,609] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[18:12:02,610] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[18:12:02,613] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[18:12:02,614] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[18:12:02,633] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[18:12:02,635] INFO  {Server} Started @4914ms
[18:12:02,636] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[18:12:02,640] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[18:12:02,841] INFO  {Executor} Starting executor ID driver on host localhost
[18:12:02,904] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43041.
[18:12:02,906] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:43041
[18:12:02,910] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 43041)
[18:12:02,917] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:43041 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 43041)
[18:12:02,925] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 43041)
[18:12:03,295] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[18:12:03,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL,null,AVAILABLE}
[18:12:03,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/json,null,AVAILABLE}
[18:12:03,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@302fec27{/SQL/execution,null,AVAILABLE}
[18:12:03,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@48c40605{/SQL/execution/json,null,AVAILABLE}
[18:12:03,439] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2f2bf0e2{/static/sql,null,AVAILABLE}
[18:12:03,481] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[18:12:07,482] INFO  {FileSourceStrategy} Pruning directories with: 
[18:12:07,486] INFO  {FileSourceStrategy} Post-Scan Filters: 
[18:12:07,497] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[18:12:07,497] INFO  {FileSourceStrategy} Pushed Filters: 
[18:12:07,640] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[18:12:07,692] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[18:12:07,695] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:43041 (size: 14.6 KB, free: 1128.9 MB)
[18:12:07,701] INFO  {SparkContext} Created broadcast 0 from cache at Main.scala:23
[18:12:07,705] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[18:12:08,253] INFO  {CodeGenerator} Code generated in 261.17349 ms
[18:12:08,493] INFO  {CodeGenerator} Code generated in 33.96645 ms
[18:12:08,543] INFO  {SparkContext} Starting job: show at Main.scala:33
[18:12:08,576] INFO  {DAGScheduler} Got job 0 (show at Main.scala:33) with 1 output partitions
[18:12:08,577] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:33)
[18:12:08,577] INFO  {DAGScheduler} Parents of final stage: List()
[18:12:08,584] INFO  {DAGScheduler} Missing parents: List()
[18:12:08,588] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33), which has no missing parents
[18:12:08,667] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 1128.7 MB)
[18:12:08,670] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[18:12:08,671] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:43041 (size: 8.5 KB, free: 1128.9 MB)
[18:12:08,672] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[18:12:08,680] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at show at Main.scala:33)
[18:12:08,684] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[18:12:08,718] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:12:08,727] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[18:12:08,781] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[18:12:08,794] INFO  {CodeGenerator} Code generated in 9.178017 ms
[18:12:08,984] INFO  {MemoryStore} Block rdd_2_0 stored as values in memory (estimated size 1239.2 KB, free 1127.5 MB)
[18:12:08,984] INFO  {BlockManagerInfo} Added rdd_2_0 in memory on 192.168.0.103:43041 (size: 1239.2 KB, free: 1127.7 MB)
[18:12:08,995] INFO  {CodeGenerator} Code generated in 4.315352 ms
[18:12:09,029] INFO  {CodeGenerator} Code generated in 25.861458 ms
[18:12:09,052] WARN  {Executor} 1 block locks were not released by TID = 0:
[rdd_2_0]
[18:12:09,059] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 4623 bytes result sent to driver
[18:12:09,074] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 368 ms on localhost (1/1)
[18:12:09,079] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[18:12:09,086] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:33) finished in 0.393 s
[18:12:09,092] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:33, took 0.549033 s
[18:12:09,124] INFO  {CodeGenerator} Code generated in 16.168695 ms
[18:12:09,276] INFO  {CodeGenerator} Code generated in 47.404432 ms
[18:12:09,299] INFO  {SparkContext} Starting job: show at Main.scala:42
[18:12:09,300] INFO  {DAGScheduler} Got job 1 (show at Main.scala:42) with 1 output partitions
[18:12:09,301] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:42)
[18:12:09,301] INFO  {DAGScheduler} Parents of final stage: List()
[18:12:09,303] INFO  {DAGScheduler} Missing parents: List()
[18:12:09,304] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42), which has no missing parents
[18:12:09,319] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 25.6 KB, free 1127.5 MB)
[18:12:09,324] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KB, free 1127.5 MB)
[18:12:09,325] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:43041 (size: 10.0 KB, free: 1127.7 MB)
[18:12:09,325] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[18:12:09,325] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:42)
[18:12:09,326] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[18:12:09,331] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:12:09,332] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[18:12:09,361] INFO  {BlockManager} Found block rdd_2_0 locally
[18:12:09,394] WARN  {Executor} 1 block locks were not released by TID = 1:
[rdd_2_0]
[18:12:09,395] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 3929 bytes result sent to driver
[18:12:09,398] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 69 ms on localhost (1/1)
[18:12:09,399] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[18:12:09,399] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:42) finished in 0.070 s
[18:12:09,400] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:42, took 0.100920 s
[18:12:09,440] INFO  {CodeGenerator} Code generated in 17.512202 ms
[18:12:09,727] INFO  {ContextCleaner} Cleaned accumulator 3
[18:12:09,727] INFO  {ContextCleaner} Cleaned accumulator 4
[18:12:09,772] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:43041 in memory (size: 8.5 KB, free: 1127.7 MB)
[18:12:09,778] INFO  {ContextCleaner} Cleaned accumulator 49
[18:12:09,779] INFO  {ContextCleaner} Cleaned accumulator 50
[18:12:09,780] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:43041 in memory (size: 10.0 KB, free: 1127.7 MB)
[18:12:09,881] INFO  {CodeGenerator} Code generated in 95.786725 ms
[18:12:09,915] INFO  {SparkContext} Starting job: show at Main.scala:51
[18:12:09,917] INFO  {DAGScheduler} Got job 2 (show at Main.scala:51) with 1 output partitions
[18:12:09,917] INFO  {DAGScheduler} Final stage: ResultStage 2 (show at Main.scala:51)
[18:12:09,918] INFO  {DAGScheduler} Parents of final stage: List()
[18:12:09,919] INFO  {DAGScheduler} Missing parents: List()
[18:12:09,921] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51), which has no missing parents
[18:12:09,933] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 34.3 KB, free 1127.5 MB)
[18:12:09,940] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1127.5 MB)
[18:12:09,942] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:43041 (size: 11.7 KB, free: 1127.7 MB)
[18:12:09,944] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[18:12:09,945] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at Main.scala:51)
[18:12:09,945] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[18:12:09,951] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:12:09,951] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[18:12:09,973] INFO  {BlockManager} Found block rdd_2_0 locally
[18:12:09,995] WARN  {Executor} 1 block locks were not released by TID = 2:
[rdd_2_0]
[18:12:09,997] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 4003 bytes result sent to driver
[18:12:10,002] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 55 ms on localhost (1/1)
[18:12:10,003] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[18:12:10,005] INFO  {DAGScheduler} ResultStage 2 (show at Main.scala:51) finished in 0.058 s
[18:12:10,006] INFO  {DAGScheduler} Job 2 finished: show at Main.scala:51, took 0.090911 s
[18:12:10,059] INFO  {CodeGenerator} Code generated in 42.492901 ms
[18:12:10,398] INFO  {CodeGenerator} Code generated in 155.615942 ms
[18:12:10,436] INFO  {SparkContext} Starting job: show at Main.scala:61
[18:12:10,439] INFO  {DAGScheduler} Got job 3 (show at Main.scala:61) with 1 output partitions
[18:12:10,439] INFO  {DAGScheduler} Final stage: ResultStage 3 (show at Main.scala:61)
[18:12:10,439] INFO  {DAGScheduler} Parents of final stage: List()
[18:12:10,440] INFO  {DAGScheduler} Missing parents: List()
[18:12:10,441] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61), which has no missing parents
[18:12:10,449] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 40.2 KB, free 1127.5 MB)
[18:12:10,453] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1127.5 MB)
[18:12:10,454] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:43041 (size: 13.3 KB, free: 1127.7 MB)
[18:12:10,455] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[18:12:10,456] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at show at Main.scala:61)
[18:12:10,456] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[18:12:10,459] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:12:10,460] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[18:12:10,476] INFO  {BlockManager} Found block rdd_2_0 locally
[18:12:10,500] WARN  {Executor} 1 block locks were not released by TID = 3:
[rdd_2_0]
[18:12:10,501] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 4012 bytes result sent to driver
[18:12:10,505] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 47 ms on localhost (1/1)
[18:12:10,505] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[18:12:10,506] INFO  {DAGScheduler} ResultStage 3 (show at Main.scala:61) finished in 0.049 s
[18:12:10,507] INFO  {DAGScheduler} Job 3 finished: show at Main.scala:61, took 0.070657 s
[18:12:10,558] INFO  {CodeGenerator} Code generated in 44.376294 ms
[18:12:10,855] INFO  {CodeGenerator} Code generated in 34.279719 ms
[18:12:10,922] INFO  {CodeGenerator} Code generated in 50.955031 ms
[18:12:11,012] INFO  {SparkContext} Starting job: collect at Main.scala:66
[18:12:11,020] INFO  {DAGScheduler} Registering RDD 17 (collect at Main.scala:66)
[18:12:11,022] INFO  {DAGScheduler} Got job 4 (collect at Main.scala:66) with 1 output partitions
[18:12:11,022] INFO  {DAGScheduler} Final stage: ResultStage 5 (collect at Main.scala:66)
[18:12:11,022] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 4)
[18:12:11,023] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 4)
[18:12:11,032] INFO  {DAGScheduler} Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:66), which has no missing parents
[18:12:11,049] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[18:12:11,053] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[18:12:11,055] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:43041 (size: 10.1 KB, free: 1127.6 MB)
[18:12:11,056] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[18:12:11,062] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at collect at Main.scala:66)
[18:12:11,062] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[18:12:11,070] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[18:12:11,071] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[18:12:11,085] INFO  {BlockManager} Found block rdd_2_0 locally
[18:12:11,914] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 2411 bytes result sent to driver
[18:12:11,926] INFO  {DAGScheduler} ShuffleMapStage 4 (collect at Main.scala:66) finished in 0.862 s
[18:12:11,928] INFO  {DAGScheduler} looking for newly runnable stages
[18:12:11,932] INFO  {DAGScheduler} running: Set()
[18:12:11,934] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 858 ms on localhost (1/1)
[18:12:11,935] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[18:12:11,936] INFO  {DAGScheduler} waiting: Set(ResultStage 5)
[18:12:11,938] INFO  {DAGScheduler} failed: Set()
[18:12:11,947] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:66), which has no missing parents
[18:12:11,961] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 1127.4 MB)
[18:12:11,965] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.4 MB)
[18:12:11,966] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:43041 (size: 3.9 KB, free: 1127.6 MB)
[18:12:11,967] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[18:12:11,968] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at collect at Main.scala:66)
[18:12:11,968] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[18:12:11,975] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5317 bytes)
[18:12:11,975] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[18:12:12,019] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[18:12:12,025] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 20 ms
[18:12:12,064] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1868 bytes result sent to driver
[18:12:12,067] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 96 ms on localhost (1/1)
[18:12:12,069] INFO  {DAGScheduler} ResultStage 5 (collect at Main.scala:66) finished in 0.098 s
[18:12:12,069] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[18:12:12,070] INFO  {DAGScheduler} Job 4 finished: collect at Main.scala:66, took 1.058341 s
[18:12:12,096] INFO  {CodeGenerator} Code generated in 17.47239 ms
[18:12:12,216] INFO  {CodeGenerator} Code generated in 29.39043 ms
[18:12:12,286] INFO  {CodeGenerator} Code generated in 55.819533 ms
[18:12:12,336] INFO  {SparkContext} Starting job: collect at Main.scala:67
[18:12:12,339] INFO  {DAGScheduler} Registering RDD 23 (collect at Main.scala:67)
[18:12:12,340] INFO  {DAGScheduler} Got job 5 (collect at Main.scala:67) with 1 output partitions
[18:12:12,340] INFO  {DAGScheduler} Final stage: ResultStage 7 (collect at Main.scala:67)
[18:12:12,340] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 6)
[18:12:12,341] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 6)
[18:12:12,348] INFO  {DAGScheduler} Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:67), which has no missing parents
[18:12:12,357] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 24.5 KB, free 1127.4 MB)
[18:12:12,362] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.1 KB, free 1127.4 MB)
[18:12:12,364] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:43041 (size: 10.1 KB, free: 1127.6 MB)
[18:12:12,366] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[18:12:12,366] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at collect at Main.scala:67)
[18:12:12,366] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[18:12:12,371] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[18:12:12,371] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[18:12:12,383] INFO  {BlockManager} Found block rdd_2_0 locally
[18:12:12,621] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:43041 in memory (size: 10.1 KB, free: 1127.6 MB)
[18:12:12,624] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:43041 in memory (size: 3.9 KB, free: 1127.6 MB)
[18:12:12,626] INFO  {ContextCleaner} Cleaned accumulator 288
[18:12:12,628] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:43041 in memory (size: 13.3 KB, free: 1127.7 MB)
[18:12:12,629] INFO  {ContextCleaner} Cleaned accumulator 187
[18:12:12,629] INFO  {ContextCleaner} Cleaned accumulator 188
[18:12:12,629] INFO  {ContextCleaner} Cleaned accumulator 189
[18:12:12,630] INFO  {ContextCleaner} Cleaned accumulator 190
[18:12:12,630] INFO  {ContextCleaner} Cleaned accumulator 191
[18:12:12,630] INFO  {ContextCleaner} Cleaned accumulator 192
[18:12:12,630] INFO  {ContextCleaner} Cleaned accumulator 193
[18:12:12,631] INFO  {ContextCleaner} Cleaned accumulator 194
[18:12:12,631] INFO  {ContextCleaner} Cleaned accumulator 195
[18:12:12,631] INFO  {ContextCleaner} Cleaned accumulator 196
[18:12:12,631] INFO  {ContextCleaner} Cleaned accumulator 197
[18:12:12,632] INFO  {ContextCleaner} Cleaned accumulator 198
[18:12:12,632] INFO  {ContextCleaner} Cleaned accumulator 199
[18:12:12,643] INFO  {ContextCleaner} Cleaned shuffle 0
[18:12:12,650] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:43041 in memory (size: 11.7 KB, free: 1127.7 MB)
[18:12:12,653] INFO  {ContextCleaner} Cleaned accumulator 141
[18:12:12,653] INFO  {ContextCleaner} Cleaned accumulator 142
[18:12:12,692] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2397 bytes result sent to driver
[18:12:12,694] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 326 ms on localhost (1/1)
[18:12:12,695] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[18:12:12,696] INFO  {DAGScheduler} ShuffleMapStage 6 (collect at Main.scala:67) finished in 0.329 s
[18:12:12,696] INFO  {DAGScheduler} looking for newly runnable stages
[18:12:12,696] INFO  {DAGScheduler} running: Set()
[18:12:12,696] INFO  {DAGScheduler} waiting: Set(ResultStage 7)
[18:12:12,696] INFO  {DAGScheduler} failed: Set()
[18:12:12,697] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:67), which has no missing parents
[18:12:12,701] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1127.5 MB)
[18:12:12,704] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1127.5 MB)
[18:12:12,705] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:43041 (size: 3.9 KB, free: 1127.7 MB)
[18:12:12,706] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[18:12:12,707] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collect at Main.scala:67)
[18:12:12,707] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[18:12:12,710] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5317 bytes)
[18:12:12,711] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[18:12:12,717] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[18:12:12,717] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[18:12:12,727] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1868 bytes result sent to driver
[18:12:12,729] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 21 ms on localhost (1/1)
[18:12:12,730] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[18:12:12,732] INFO  {DAGScheduler} ResultStage 7 (collect at Main.scala:67) finished in 0.024 s
[18:12:12,735] INFO  {DAGScheduler} Job 5 finished: collect at Main.scala:67, took 0.398570 s
[18:12:13,075] INFO  {CodeGenerator} Code generated in 167.577055 ms
[18:12:13,094] INFO  {SparkContext} Starting job: show at Main.scala:82
[18:12:13,096] INFO  {DAGScheduler} Got job 6 (show at Main.scala:82) with 1 output partitions
[18:12:13,096] INFO  {DAGScheduler} Final stage: ResultStage 8 (show at Main.scala:82)
[18:12:13,096] INFO  {DAGScheduler} Parents of final stage: List()
[18:12:13,097] INFO  {DAGScheduler} Missing parents: List()
[18:12:13,098] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:82), which has no missing parents
[18:12:13,104] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 53.4 KB, free 1127.5 MB)
[18:12:13,107] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1127.4 MB)
[18:12:13,108] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:43041 (size: 15.0 KB, free: 1127.6 MB)
[18:12:13,109] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[18:12:13,109] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at show at Main.scala:82)
[18:12:13,110] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[18:12:13,118] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:12:13,119] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[18:12:13,132] INFO  {BlockManager} Found block rdd_2_0 locally
[18:12:13,148] WARN  {Executor} 1 block locks were not released by TID = 8:
[rdd_2_0]
[18:12:13,150] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 4020 bytes result sent to driver
[18:12:13,153] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 39 ms on localhost (1/1)
[18:12:13,153] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[18:12:13,154] INFO  {DAGScheduler} ResultStage 8 (show at Main.scala:82) finished in 0.041 s
[18:12:13,156] INFO  {DAGScheduler} Job 6 finished: show at Main.scala:82, took 0.061270 s
[18:12:13,205] INFO  {CodeGenerator} Code generated in 42.606155 ms
[18:12:13,523] INFO  {CodeGenerator} Code generated in 147.670803 ms
[18:12:13,555] INFO  {SparkContext} Starting job: show at Main.scala:91
[18:12:13,558] INFO  {DAGScheduler} Got job 7 (show at Main.scala:91) with 1 output partitions
[18:12:13,558] INFO  {DAGScheduler} Final stage: ResultStage 9 (show at Main.scala:91)
[18:12:13,558] INFO  {DAGScheduler} Parents of final stage: List()
[18:12:13,560] INFO  {DAGScheduler} Missing parents: List()
[18:12:13,561] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:91), which has no missing parents
[18:12:13,577] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 62.1 KB, free 1127.4 MB)
[18:12:13,582] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1127.4 MB)
[18:12:13,584] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:43041 (size: 16.4 KB, free: 1127.6 MB)
[18:12:13,586] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[18:12:13,587] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at show at Main.scala:91)
[18:12:13,588] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[18:12:13,592] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[18:12:13,592] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[18:12:13,607] INFO  {BlockManager} Found block rdd_2_0 locally
[18:12:13,628] WARN  {Executor} 1 block locks were not released by TID = 9:
[rdd_2_0]
[18:12:13,630] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 4083 bytes result sent to driver
[18:12:13,633] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 42 ms on localhost (1/1)
[18:12:13,633] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[18:12:13,635] INFO  {DAGScheduler} ResultStage 9 (show at Main.scala:91) finished in 0.045 s
[18:12:13,636] INFO  {DAGScheduler} Job 7 finished: show at Main.scala:91, took 0.080549 s
[18:12:13,689] INFO  {CodeGenerator} Code generated in 45.523623 ms
[18:12:14,672] INFO  {CodeGenerator} Code generated in 60.012582 ms
[18:12:14,744] INFO  {CodeGenerator} Code generated in 41.794102 ms
[18:12:14,854] INFO  {CodeGenerator} Code generated in 28.091203 ms
[18:12:14,887] INFO  {CodeGenerator} Code generated in 13.89306 ms
[18:12:14,908] INFO  {SparkContext} Invoking stop() from shutdown hook
[18:12:14,927] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[18:12:14,938] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[18:12:14,939] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[18:12:14,940] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[18:12:14,940] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[18:12:14,941] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[18:12:14,942] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[18:12:14,943] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[18:12:14,944] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[18:12:14,946] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[18:12:14,946] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[18:12:14,947] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[18:12:14,948] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[18:12:14,951] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[18:12:14,952] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[18:12:14,952] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[18:12:14,953] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[18:12:14,954] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[18:12:14,954] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[18:12:14,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[18:12:14,964] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[18:12:14,964] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[18:12:14,964] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[18:12:14,965] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[18:12:14,973] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[18:12:14,986] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[18:12:15,053] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[18:12:15,139] INFO  {MemoryStore} MemoryStore cleared
[18:12:15,141] INFO  {BlockManager} BlockManager stopped
[18:12:15,149] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[18:12:15,162] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[18:12:15,175] INFO  {SparkContext} Successfully stopped SparkContext
[18:12:15,177] INFO  {ShutdownHookManager} Shutdown hook called
[18:12:15,179] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-9cd24043-13c5-4760-8800-50df2dc9a6ca
