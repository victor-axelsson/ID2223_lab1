[12:54:11,948] INFO  {SparkContext} Running Spark version 2.0.1
[12:54:13,282] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:54:13,632] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[12:54:13,633] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:54:13,856] INFO  {SecurityManager} Changing view acls to: victor
[12:54:13,856] INFO  {SecurityManager} Changing modify acls to: victor
[12:54:13,857] INFO  {SecurityManager} Changing view acls groups to: 
[12:54:13,858] INFO  {SecurityManager} Changing modify acls groups to: 
[12:54:13,859] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:54:14,415] INFO  {Utils} Successfully started service 'sparkDriver' on port 37953.
[12:54:14,464] INFO  {SparkEnv} Registering MapOutputTracker
[12:54:14,531] INFO  {SparkEnv} Registering BlockManagerMaster
[12:54:14,548] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-24485974-f0cc-437e-97a0-5cbc144d0413
[12:54:14,597] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:54:14,697] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:54:14,929] INFO  {log} Logging initialized @4458ms
[12:54:15,074] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:54:15,094] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[12:54:15,094] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[12:54:15,094] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[12:54:15,094] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[12:54:15,095] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[12:54:15,095] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[12:54:15,095] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[12:54:15,095] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[12:54:15,095] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[12:54:15,096] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[12:54:15,096] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[12:54:15,096] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[12:54:15,096] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[12:54:15,096] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[12:54:15,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[12:54:15,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[12:54:15,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[12:54:15,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[12:54:15,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[12:54:15,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[12:54:15,102] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[12:54:15,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[12:54:15,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[12:54:15,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[12:54:15,109] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[12:54:15,110] INFO  {Server} Started @4640ms
[12:54:15,111] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:54:15,113] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[12:54:15,315] INFO  {Executor} Starting executor ID driver on host localhost
[12:54:15,357] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38959.
[12:54:15,358] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:38959
[12:54:15,363] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 38959)
[12:54:15,374] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:38959 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 38959)
[12:54:15,392] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 38959)
[12:54:15,553] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[12:54:16,543] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[12:54:16,627] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:54:16,629] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:38959 (size: 14.6 KB, free: 1128.9 MB)
[12:54:16,633] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:26
[12:54:18,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@66d25ba9{/SQL,null,AVAILABLE}
[12:54:18,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5efe47fd{/SQL/json,null,AVAILABLE}
[12:54:18,430] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@266e9dda{/SQL/execution,null,AVAILABLE}
[12:54:18,431] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@27a6fef2{/SQL/execution/json,null,AVAILABLE}
[12:54:18,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5e1a5f{/static/sql,null,AVAILABLE}
[12:54:18,477] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:54:19,073] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:54:19,087] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[12:54:19,090] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[12:54:19,090] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[12:54:19,090] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[12:54:19,091] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[12:54:19,091] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[12:54:19,091] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[12:54:19,091] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[12:54:19,092] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[12:54:19,092] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[12:54:19,092] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[12:54:19,092] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[12:54:19,093] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[12:54:19,093] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[12:54:19,093] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[12:54:19,094] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[12:54:19,094] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[12:54:19,094] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[12:54:19,095] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[12:54:19,095] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[12:54:19,095] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[12:54:19,095] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[12:54:19,096] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[12:54:19,096] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[12:54:19,096] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[12:54:19,098] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[12:54:19,108] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:54:19,112] INFO  {MemoryStore} MemoryStore cleared
[12:54:19,112] INFO  {BlockManager} BlockManager stopped
[12:54:19,119] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:54:19,138] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:54:19,142] INFO  {SparkContext} Successfully stopped SparkContext
[12:54:19,143] INFO  {ShutdownHookManager} Shutdown hook called
[12:54:19,144] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f18fc31d-78c2-43fe-bbd6-578525994997
[12:55:21,541] INFO  {SparkContext} Running Spark version 2.0.1
[12:55:21,767] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:55:21,874] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[12:55:21,874] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:55:21,944] INFO  {SecurityManager} Changing view acls to: victor
[12:55:21,945] INFO  {SecurityManager} Changing modify acls to: victor
[12:55:21,945] INFO  {SecurityManager} Changing view acls groups to: 
[12:55:21,946] INFO  {SecurityManager} Changing modify acls groups to: 
[12:55:21,946] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:55:22,319] INFO  {Utils} Successfully started service 'sparkDriver' on port 36945.
[12:55:22,336] INFO  {SparkEnv} Registering MapOutputTracker
[12:55:22,350] INFO  {SparkEnv} Registering BlockManagerMaster
[12:55:22,361] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-02fcb0a7-8f0d-405c-b06e-dbf9b202f1b9
[12:55:22,376] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:55:22,429] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:55:22,511] INFO  {log} Logging initialized @1634ms
[12:55:22,616] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:55:22,632] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[12:55:22,632] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[12:55:22,632] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[12:55:22,632] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[12:55:22,633] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[12:55:22,633] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[12:55:22,633] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[12:55:22,633] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[12:55:22,633] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[12:55:22,633] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[12:55:22,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[12:55:22,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[12:55:22,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[12:55:22,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[12:55:22,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[12:55:22,635] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[12:55:22,635] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[12:55:22,635] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[12:55:22,635] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[12:55:22,635] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[12:55:22,640] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[12:55:22,640] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[12:55:22,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[12:55:22,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[12:55:22,646] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[12:55:22,646] INFO  {Server} Started @1770ms
[12:55:22,646] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:55:22,648] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[12:55:22,722] INFO  {Executor} Starting executor ID driver on host localhost
[12:55:22,752] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33921.
[12:55:22,752] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:33921
[12:55:22,754] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 33921)
[12:55:22,757] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:33921 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 33921)
[12:55:22,760] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 33921)
[12:55:22,914] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[12:55:23,461] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[12:55:23,521] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:55:23,523] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:33921 (size: 14.6 KB, free: 1128.9 MB)
[12:55:23,526] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:26
[12:55:25,019] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@66d25ba9{/SQL,null,AVAILABLE}
[12:55:25,020] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5efe47fd{/SQL/json,null,AVAILABLE}
[12:55:25,020] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@266e9dda{/SQL/execution,null,AVAILABLE}
[12:55:25,021] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@27a6fef2{/SQL/execution/json,null,AVAILABLE}
[12:55:25,022] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5e1a5f{/static/sql,null,AVAILABLE}
[12:55:25,050] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:55:26,532] INFO  {CodeGenerator} Code generated in 205.758838 ms
[12:55:26,702] INFO  {CodeGenerator} Code generated in 66.897637 ms
[12:55:26,867] INFO  {FileInputFormat} Total input paths to process : 2
[12:55:26,869] INFO  {FileInputFormat} Total input paths to process : 2
[12:55:26,910] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[12:55:26,964] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[12:55:26,993] INFO  {DAGScheduler} Registering RDD 6 (collect at PipelineBuilder.scala:59)
[12:55:26,995] INFO  {DAGScheduler} Got job 0 (collect at PipelineBuilder.scala:59) with 1 output partitions
[12:55:26,996] INFO  {DAGScheduler} Final stage: ResultStage 1 (collect at PipelineBuilder.scala:59)
[12:55:26,996] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 0)
[12:55:26,998] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 0)
[12:55:27,002] INFO  {DAGScheduler} Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at collect at PipelineBuilder.scala:59), which has no missing parents
[12:55:27,067] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 34.3 KB, free 1128.7 MB)
[12:55:27,069] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1128.7 MB)
[12:55:27,070] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:33921 (size: 14.4 KB, free: 1128.9 MB)
[12:55:27,070] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:55:27,073] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at collect at PipelineBuilder.scala:59)
[12:55:27,074] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:55:27,126] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[12:55:27,135] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:55:27,180] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[12:55:27,257] INFO  {CodeGenerator} Code generated in 12.197862 ms
[12:55:27,281] INFO  {CodeGenerator} Code generated in 17.405163 ms
[12:55:27,310] INFO  {CodeGenerator} Code generated in 7.419828 ms
[12:55:27,448] INFO  {ContextCleaner} Cleaned accumulator 0
[12:55:27,487] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[12:55:27,492] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[12:55:27,493] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[12:55:27,496] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[12:55:27,769] INFO  {CodeGenerator} Code generated in 18.192262 ms
[12:55:28,064] ERROR {Executor} Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "file:/home/victor/desktop/dataset/fakedata/a.tar.gz"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more
[12:55:28,099] WARN  {TaskSetManager} Lost task 0.0 in stage 0.0 (TID 0, localhost): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "file:/home/victor/desktop/dataset/fakedata/a.tar.gz"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more

[12:55:28,102] ERROR {TaskSetManager} Task 0 in stage 0.0 failed 1 times; aborting job
[12:55:28,105] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:55:28,111] INFO  {TaskSchedulerImpl} Cancelling stage 0
[12:55:28,113] INFO  {DAGScheduler} ShuffleMapStage 0 (collect at PipelineBuilder.scala:59) failed in 1.030 s
[12:55:28,114] INFO  {DAGScheduler} Job 0 failed: collect at PipelineBuilder.scala:59, took 1.150225 s
[12:55:28,460] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:55:28,472] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[12:55:28,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[12:55:28,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[12:55:28,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[12:55:28,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[12:55:28,477] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[12:55:28,477] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[12:55:28,477] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[12:55:28,477] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[12:55:28,478] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[12:55:28,478] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[12:55:28,478] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[12:55:28,478] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[12:55:28,478] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[12:55:28,478] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[12:55:28,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[12:55:28,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[12:55:28,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[12:55:28,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[12:55:28,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[12:55:28,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[12:55:28,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[12:55:28,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[12:55:28,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[12:55:28,480] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[12:55:28,481] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[12:55:28,485] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:33921 in memory (size: 14.4 KB, free: 1128.9 MB)
[12:55:28,571] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:55:28,577] INFO  {MemoryStore} MemoryStore cleared
[12:55:28,578] INFO  {BlockManager} BlockManager stopped
[12:55:28,580] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:55:28,583] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:55:28,585] INFO  {SparkContext} Successfully stopped SparkContext
[12:55:28,586] INFO  {ShutdownHookManager} Shutdown hook called
[12:55:28,587] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-b7538920-804b-4d8b-8ef7-2a8a727432cc
[12:55:52,933] INFO  {SparkContext} Running Spark version 2.0.1
[12:55:53,215] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:55:53,331] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[12:55:53,331] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:55:53,413] INFO  {SecurityManager} Changing view acls to: victor
[12:55:53,413] INFO  {SecurityManager} Changing modify acls to: victor
[12:55:53,414] INFO  {SecurityManager} Changing view acls groups to: 
[12:55:53,414] INFO  {SecurityManager} Changing modify acls groups to: 
[12:55:53,415] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:55:53,765] INFO  {Utils} Successfully started service 'sparkDriver' on port 45701.
[12:55:53,783] INFO  {SparkEnv} Registering MapOutputTracker
[12:55:53,797] INFO  {SparkEnv} Registering BlockManagerMaster
[12:55:53,810] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-ae0d33ee-14fa-4ed4-bc36-9ac11d8c376c
[12:55:53,827] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:55:53,893] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:55:53,976] INFO  {log} Logging initialized @2279ms
[12:55:54,093] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:55:54,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[12:55:54,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[12:55:54,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[12:55:54,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[12:55:54,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[12:55:54,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[12:55:54,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[12:55:54,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[12:55:54,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[12:55:54,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[12:55:54,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[12:55:54,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[12:55:54,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[12:55:54,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[12:55:54,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[12:55:54,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[12:55:54,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[12:55:54,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[12:55:54,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[12:55:54,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[12:55:54,123] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[12:55:54,124] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[12:55:54,124] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[12:55:54,125] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[12:55:54,130] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[12:55:54,130] INFO  {Server} Started @2434ms
[12:55:54,130] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:55:54,132] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[12:55:54,221] INFO  {Executor} Starting executor ID driver on host localhost
[12:55:54,241] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37595.
[12:55:54,242] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:37595
[12:55:54,244] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 37595)
[12:55:54,247] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:37595 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 37595)
[12:55:54,250] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 37595)
[12:55:54,403] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[12:55:54,874] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[12:55:54,924] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:55:54,927] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:37595 (size: 14.6 KB, free: 1128.9 MB)
[12:55:54,931] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:26
[12:55:56,452] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@66d25ba9{/SQL,null,AVAILABLE}
[12:55:56,453] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5efe47fd{/SQL/json,null,AVAILABLE}
[12:55:56,453] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@266e9dda{/SQL/execution,null,AVAILABLE}
[12:55:56,454] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@27a6fef2{/SQL/execution/json,null,AVAILABLE}
[12:55:56,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5e1a5f{/static/sql,null,AVAILABLE}
[12:55:56,496] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:55:56,893] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:55:56,897] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[12:55:56,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[12:55:56,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[12:55:56,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[12:55:56,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[12:55:56,900] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[12:55:56,900] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[12:55:56,900] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[12:55:56,900] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[12:55:56,900] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[12:55:56,900] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[12:55:56,901] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[12:55:56,901] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[12:55:56,901] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[12:55:56,901] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[12:55:56,901] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[12:55:56,901] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[12:55:56,901] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[12:55:56,902] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[12:55:56,902] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[12:55:56,902] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[12:55:56,902] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[12:55:56,902] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[12:55:56,902] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[12:55:56,902] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[12:55:56,904] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[12:55:56,910] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:55:56,913] INFO  {MemoryStore} MemoryStore cleared
[12:55:56,914] INFO  {BlockManager} BlockManager stopped
[12:55:56,918] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:55:56,920] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:55:56,922] INFO  {SparkContext} Successfully stopped SparkContext
[12:55:56,922] INFO  {ShutdownHookManager} Shutdown hook called
[12:55:56,923] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-af0fda22-67d8-4ddd-b276-a70179cefe11
[12:56:13,663] INFO  {SparkContext} Running Spark version 2.0.1
[12:56:13,890] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:56:14,002] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[12:56:14,003] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:56:14,080] INFO  {SecurityManager} Changing view acls to: victor
[12:56:14,081] INFO  {SecurityManager} Changing modify acls to: victor
[12:56:14,082] INFO  {SecurityManager} Changing view acls groups to: 
[12:56:14,083] INFO  {SecurityManager} Changing modify acls groups to: 
[12:56:14,083] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:56:14,459] INFO  {Utils} Successfully started service 'sparkDriver' on port 38897.
[12:56:14,477] INFO  {SparkEnv} Registering MapOutputTracker
[12:56:14,496] INFO  {SparkEnv} Registering BlockManagerMaster
[12:56:14,509] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-bf5dfc7a-a6d3-4611-9fa4-fb98826ac0a3
[12:56:14,524] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:56:14,582] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:56:14,669] INFO  {log} Logging initialized @1651ms
[12:56:14,777] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:56:14,792] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[12:56:14,792] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[12:56:14,792] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[12:56:14,792] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[12:56:14,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[12:56:14,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[12:56:14,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[12:56:14,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[12:56:14,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[12:56:14,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[12:56:14,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[12:56:14,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[12:56:14,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[12:56:14,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[12:56:14,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[12:56:14,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[12:56:14,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[12:56:14,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[12:56:14,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[12:56:14,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[12:56:14,800] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[12:56:14,800] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[12:56:14,801] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[12:56:14,801] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[12:56:14,806] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[12:56:14,807] INFO  {Server} Started @1790ms
[12:56:14,807] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:56:14,808] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[12:56:14,896] INFO  {Executor} Starting executor ID driver on host localhost
[12:56:14,918] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45225.
[12:56:14,918] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:45225
[12:56:14,920] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 45225)
[12:56:14,924] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:45225 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 45225)
[12:56:14,930] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 45225)
[12:56:15,109] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[12:56:15,621] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[12:56:15,678] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:56:15,682] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:45225 (size: 14.6 KB, free: 1128.9 MB)
[12:56:15,687] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:26
[12:56:17,221] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@66d25ba9{/SQL,null,AVAILABLE}
[12:56:17,221] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5efe47fd{/SQL/json,null,AVAILABLE}
[12:56:17,222] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@266e9dda{/SQL/execution,null,AVAILABLE}
[12:56:17,223] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@27a6fef2{/SQL/execution/json,null,AVAILABLE}
[12:56:17,224] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5e1a5f{/static/sql,null,AVAILABLE}
[12:56:17,251] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:56:18,092] INFO  {CodeGenerator} Code generated in 214.824331 ms
[12:56:18,159] INFO  {FileInputFormat} Total input paths to process : 2
[12:56:18,161] INFO  {FileInputFormat} Total input paths to process : 2
[12:56:18,175] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[12:56:18,182] INFO  {SparkContext} Starting job: show at Main.scala:38
[12:56:18,193] INFO  {DAGScheduler} Got job 0 (show at Main.scala:38) with 1 output partitions
[12:56:18,194] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:38)
[12:56:18,194] INFO  {DAGScheduler} Parents of final stage: List()
[12:56:18,195] INFO  {DAGScheduler} Missing parents: List()
[12:56:18,201] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[6] at show at Main.scala:38), which has no missing parents
[12:56:18,218] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.8 KB, free 1128.7 MB)
[12:56:18,220] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.6 KB, free 1128.7 MB)
[12:56:18,221] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:45225 (size: 8.6 KB, free: 1128.9 MB)
[12:56:18,222] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:56:18,224] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at show at Main.scala:38)
[12:56:18,226] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:56:18,263] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5523 bytes)
[12:56:18,269] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:56:18,302] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[12:56:18,327] INFO  {CodeGenerator} Code generated in 14.217551 ms
[12:56:18,354] INFO  {CodeGenerator} Code generated in 20.52522 ms
[12:56:18,368] INFO  {CodeGenerator} Code generated in 7.782549 ms
[12:56:18,408] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[12:56:18,414] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[12:56:18,415] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[12:56:18,417] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[12:56:18,761] INFO  {CodeGenerator} Code generated in 16.94957 ms
[12:56:19,201] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 930199 bytes result sent to driver
[12:56:19,228] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 982 ms on localhost (1/1)
[12:56:19,229] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:56:19,233] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:38) finished in 1.000 s
[12:56:19,238] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:38, took 1.055779 s
[12:56:19,273] INFO  {CodeGenerator} Code generated in 21.758515 ms
[12:56:19,300] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:56:19,305] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[12:56:19,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[12:56:19,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[12:56:19,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[12:56:19,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[12:56:19,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[12:56:19,308] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[12:56:19,308] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[12:56:19,308] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[12:56:19,308] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[12:56:19,308] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[12:56:19,309] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[12:56:19,309] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[12:56:19,309] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[12:56:19,309] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[12:56:19,309] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[12:56:19,310] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[12:56:19,310] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[12:56:19,310] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[12:56:19,310] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[12:56:19,310] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[12:56:19,311] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[12:56:19,311] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[12:56:19,311] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[12:56:19,311] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[12:56:19,313] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[12:56:19,321] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:56:19,325] INFO  {MemoryStore} MemoryStore cleared
[12:56:19,325] INFO  {BlockManager} BlockManager stopped
[12:56:19,331] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:56:19,333] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:56:19,340] INFO  {SparkContext} Successfully stopped SparkContext
[12:56:19,341] INFO  {ShutdownHookManager} Shutdown hook called
[12:56:19,342] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-b4269dd4-5807-4e34-ab33-dfdbd22d4c82
[12:56:36,642] INFO  {SparkContext} Running Spark version 2.0.1
[12:56:37,201] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:56:37,440] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[12:56:37,441] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:56:37,609] INFO  {SecurityManager} Changing view acls to: victor
[12:56:37,611] INFO  {SecurityManager} Changing modify acls to: victor
[12:56:37,613] INFO  {SecurityManager} Changing view acls groups to: 
[12:56:37,615] INFO  {SecurityManager} Changing modify acls groups to: 
[12:56:37,616] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:56:38,413] INFO  {Utils} Successfully started service 'sparkDriver' on port 34453.
[12:56:38,452] INFO  {SparkEnv} Registering MapOutputTracker
[12:56:38,490] INFO  {SparkEnv} Registering BlockManagerMaster
[12:56:38,519] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-c5b88885-d299-4c36-a79e-dbc6af31d56c
[12:56:38,567] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:56:38,705] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:56:38,803] INFO  {log} Logging initialized @3475ms
[12:56:38,910] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:56:38,924] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[12:56:38,925] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[12:56:38,925] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[12:56:38,925] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[12:56:38,925] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[12:56:38,925] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[12:56:38,926] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[12:56:38,926] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[12:56:38,926] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[12:56:38,926] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[12:56:38,926] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[12:56:38,927] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[12:56:38,927] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[12:56:38,927] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[12:56:38,927] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[12:56:38,927] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[12:56:38,927] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[12:56:38,928] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[12:56:38,928] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[12:56:38,928] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[12:56:38,933] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[12:56:38,933] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[12:56:38,934] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[12:56:38,934] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[12:56:38,939] INFO  {ServerConnector} Started ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[12:56:38,939] INFO  {Server} Started @3612ms
[12:56:38,940] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:56:38,941] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[12:56:39,030] INFO  {Executor} Starting executor ID driver on host localhost
[12:56:39,050] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43357.
[12:56:39,051] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:43357
[12:56:39,052] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 43357)
[12:56:39,055] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:43357 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 43357)
[12:56:39,059] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 43357)
[12:56:39,210] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[12:56:39,681] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[12:56:39,730] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:56:39,733] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:43357 (size: 14.6 KB, free: 1128.9 MB)
[12:56:39,737] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:26
[12:56:41,161] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5efe47fd{/SQL,null,AVAILABLE}
[12:56:41,162] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e3236d{/SQL/json,null,AVAILABLE}
[12:56:41,163] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@27a6fef2{/SQL/execution,null,AVAILABLE}
[12:56:41,164] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2dba05b1{/SQL/execution/json,null,AVAILABLE}
[12:56:41,166] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@19ae2ee5{/static/sql,null,AVAILABLE}
[12:56:41,203] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:56:42,089] INFO  {CodeGenerator} Code generated in 233.369963 ms
[12:56:42,151] INFO  {FileInputFormat} Total input paths to process : 2
[12:56:42,153] INFO  {FileInputFormat} Total input paths to process : 2
[12:56:42,167] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[12:56:42,175] INFO  {SparkContext} Starting job: show at Main.scala:38
[12:56:42,197] INFO  {DAGScheduler} Got job 0 (show at Main.scala:38) with 1 output partitions
[12:56:42,197] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:38)
[12:56:42,198] INFO  {DAGScheduler} Parents of final stage: List()
[12:56:42,200] INFO  {DAGScheduler} Missing parents: List()
[12:56:42,207] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[6] at show at Main.scala:38), which has no missing parents
[12:56:42,236] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.8 KB, free 1128.7 MB)
[12:56:42,239] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.6 KB, free 1128.7 MB)
[12:56:42,240] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:43357 (size: 8.6 KB, free: 1128.9 MB)
[12:56:42,241] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:56:42,244] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at show at Main.scala:38)
[12:56:42,246] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:56:42,292] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5523 bytes)
[12:56:42,298] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:56:42,336] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[12:56:42,360] INFO  {CodeGenerator} Code generated in 13.038025 ms
[12:56:42,390] INFO  {CodeGenerator} Code generated in 23.772944 ms
[12:56:42,405] INFO  {CodeGenerator} Code generated in 7.607857 ms
[12:56:42,451] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[12:56:42,457] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[12:56:42,457] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[12:56:42,460] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[12:56:42,877] INFO  {CodeGenerator} Code generated in 26.053757 ms
[12:56:43,599] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 930199 bytes result sent to driver
[12:56:43,618] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 1348 ms on localhost (1/1)
[12:56:43,621] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:56:43,630] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:38) finished in 1.374 s
[12:56:43,641] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:38, took 1.466210 s
[12:56:43,721] INFO  {CodeGenerator} Code generated in 45.246011 ms
[12:56:43,766] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:56:43,774] INFO  {ServerConnector} Stopped ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[12:56:43,778] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[12:56:43,778] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[12:56:43,778] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[12:56:43,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[12:56:43,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[12:56:43,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[12:56:43,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[12:56:43,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[12:56:43,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[12:56:43,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[12:56:43,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[12:56:43,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[12:56:43,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[12:56:43,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[12:56:43,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[12:56:43,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[12:56:43,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[12:56:43,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[12:56:43,783] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[12:56:43,783] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[12:56:43,783] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[12:56:43,784] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[12:56:43,784] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[12:56:43,784] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[12:56:43,787] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[12:56:43,804] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:56:43,814] INFO  {MemoryStore} MemoryStore cleared
[12:56:43,815] INFO  {BlockManager} BlockManager stopped
[12:56:43,828] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:56:43,833] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:56:43,837] INFO  {SparkContext} Successfully stopped SparkContext
[12:56:43,839] INFO  {ShutdownHookManager} Shutdown hook called
[12:56:43,841] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-0572ecbc-1ee2-49ac-87b4-9f18a30a5fd5
[12:58:10,158] INFO  {SparkContext} Running Spark version 2.0.1
[12:58:10,413] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:58:10,541] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[12:58:10,542] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:58:10,639] INFO  {SecurityManager} Changing view acls to: victor
[12:58:10,639] INFO  {SecurityManager} Changing modify acls to: victor
[12:58:10,640] INFO  {SecurityManager} Changing view acls groups to: 
[12:58:10,641] INFO  {SecurityManager} Changing modify acls groups to: 
[12:58:10,642] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:58:11,002] INFO  {Utils} Successfully started service 'sparkDriver' on port 33425.
[12:58:11,021] INFO  {SparkEnv} Registering MapOutputTracker
[12:58:11,036] INFO  {SparkEnv} Registering BlockManagerMaster
[12:58:11,049] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e12ea3b9-d2b5-4ccd-b2ba-9fae7b15fb8b
[12:58:11,065] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:58:11,109] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:58:11,203] INFO  {log} Logging initialized @1726ms
[12:58:11,314] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:58:11,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62e20a76{/jobs,null,AVAILABLE}
[12:58:11,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2cc44ad{/jobs/json,null,AVAILABLE}
[12:58:11,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@44b3606b{/jobs/job,null,AVAILABLE}
[12:58:11,332] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1477089c{/jobs/job/json,null,AVAILABLE}
[12:58:11,332] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@663411de{/stages,null,AVAILABLE}
[12:58:11,332] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@63dd899{/stages/json,null,AVAILABLE}
[12:58:11,333] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59d2400d{/stages/stage,null,AVAILABLE}
[12:58:11,333] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@75cd8043{/stages/stage/json,null,AVAILABLE}
[12:58:11,333] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@33b1c5c5{/stages/pool,null,AVAILABLE}
[12:58:11,333] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5b202a3a{/stages/pool/json,null,AVAILABLE}
[12:58:11,334] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10b9db7b{/storage,null,AVAILABLE}
[12:58:11,334] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@9ef8eb7{/storage/json,null,AVAILABLE}
[12:58:11,334] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@34cdeda2{/storage/rdd,null,AVAILABLE}
[12:58:11,334] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ee660fb{/storage/rdd/json,null,AVAILABLE}
[12:58:11,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@305a0c5f{/environment,null,AVAILABLE}
[12:58:11,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4535b6d5{/environment/json,null,AVAILABLE}
[12:58:11,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1ecee32c{/executors,null,AVAILABLE}
[12:58:11,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4372b9b6{/executors/json,null,AVAILABLE}
[12:58:11,335] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@232a7d73{/executors/threadDump,null,AVAILABLE}
[12:58:11,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b41e4dd{/executors/threadDump/json,null,AVAILABLE}
[12:58:11,341] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@22ffa91a{/static,null,AVAILABLE}
[12:58:11,342] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@74960bfa{/,null,AVAILABLE}
[12:58:11,343] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@42721fe{/api,null,AVAILABLE}
[12:58:11,343] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@40844aab{/stages/stage/kill,null,AVAILABLE}
[12:58:11,348] INFO  {ServerConnector} Started ServerConnector@4b45dcb8{HTTP/1.1}{0.0.0.0:4040}
[12:58:11,349] INFO  {Server} Started @1873ms
[12:58:11,349] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:58:11,351] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[12:58:11,451] INFO  {Executor} Starting executor ID driver on host localhost
[12:58:11,472] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41853.
[12:58:11,473] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:41853
[12:58:11,475] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 41853)
[12:58:11,478] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:41853 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 41853)
[12:58:11,481] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 41853)
[12:58:11,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[12:58:12,175] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[12:58:12,242] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:58:12,244] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:41853 (size: 14.6 KB, free: 1128.9 MB)
[12:58:12,248] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:26
[12:58:14,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5efe47fd{/SQL,null,AVAILABLE}
[12:58:14,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e3236d{/SQL/json,null,AVAILABLE}
[12:58:14,628] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@27a6fef2{/SQL/execution,null,AVAILABLE}
[12:58:14,628] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2dba05b1{/SQL/execution/json,null,AVAILABLE}
[12:58:14,629] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@19ae2ee5{/static/sql,null,AVAILABLE}
[12:58:14,654] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:58:15,507] INFO  {CodeGenerator} Code generated in 229.529289 ms
[12:58:15,584] INFO  {FileInputFormat} Total input paths to process : 2
[12:58:15,586] INFO  {FileInputFormat} Total input paths to process : 2
[12:58:15,600] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[12:58:15,607] INFO  {SparkContext} Starting job: show at Main.scala:36
[12:58:15,621] INFO  {DAGScheduler} Got job 0 (show at Main.scala:36) with 1 output partitions
[12:58:15,622] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:36)
[12:58:15,623] INFO  {DAGScheduler} Parents of final stage: List()
[12:58:15,625] INFO  {DAGScheduler} Missing parents: List()
[12:58:15,631] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[6] at show at Main.scala:36), which has no missing parents
[12:58:15,658] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 18.8 KB, free 1128.7 MB)
[12:58:15,661] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.6 KB, free 1128.7 MB)
[12:58:15,662] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:41853 (size: 8.6 KB, free: 1128.9 MB)
[12:58:15,663] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:58:15,666] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at show at Main.scala:36)
[12:58:15,668] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:58:15,737] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5523 bytes)
[12:58:15,743] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:58:15,776] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[12:58:15,807] INFO  {CodeGenerator} Code generated in 18.071885 ms
[12:58:15,836] INFO  {CodeGenerator} Code generated in 22.429391 ms
[12:58:15,851] INFO  {CodeGenerator} Code generated in 8.892334 ms
[12:58:15,895] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[12:58:15,901] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[12:58:15,901] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[12:58:15,904] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[12:58:16,173] INFO  {CodeGenerator} Code generated in 20.139627 ms
[12:58:16,450] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 930112 bytes result sent to driver
[12:58:16,462] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 751 ms on localhost (1/1)
[12:58:16,464] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:58:16,468] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:36) finished in 0.770 s
[12:58:16,474] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:36, took 0.866790 s
[12:58:16,524] INFO  {CodeGenerator} Code generated in 27.542107 ms
[12:58:16,568] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:58:16,572] INFO  {ServerConnector} Stopped ServerConnector@4b45dcb8{HTTP/1.1}{0.0.0.0:4040}
[12:58:16,574] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@40844aab{/stages/stage/kill,null,UNAVAILABLE}
[12:58:16,574] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@42721fe{/api,null,UNAVAILABLE}
[12:58:16,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@74960bfa{/,null,UNAVAILABLE}
[12:58:16,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@22ffa91a{/static,null,UNAVAILABLE}
[12:58:16,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4b41e4dd{/executors/threadDump/json,null,UNAVAILABLE}
[12:58:16,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@232a7d73{/executors/threadDump,null,UNAVAILABLE}
[12:58:16,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4372b9b6{/executors/json,null,UNAVAILABLE}
[12:58:16,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1ecee32c{/executors,null,UNAVAILABLE}
[12:58:16,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4535b6d5{/environment/json,null,UNAVAILABLE}
[12:58:16,575] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@305a0c5f{/environment,null,UNAVAILABLE}
[12:58:16,576] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6ee660fb{/storage/rdd/json,null,UNAVAILABLE}
[12:58:16,576] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@34cdeda2{/storage/rdd,null,UNAVAILABLE}
[12:58:16,576] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@9ef8eb7{/storage/json,null,UNAVAILABLE}
[12:58:16,576] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10b9db7b{/storage,null,UNAVAILABLE}
[12:58:16,576] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5b202a3a{/stages/pool/json,null,UNAVAILABLE}
[12:58:16,576] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@33b1c5c5{/stages/pool,null,UNAVAILABLE}
[12:58:16,576] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@75cd8043{/stages/stage/json,null,UNAVAILABLE}
[12:58:16,576] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59d2400d{/stages/stage,null,UNAVAILABLE}
[12:58:16,577] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@63dd899{/stages/json,null,UNAVAILABLE}
[12:58:16,577] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@663411de{/stages,null,UNAVAILABLE}
[12:58:16,577] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1477089c{/jobs/job/json,null,UNAVAILABLE}
[12:58:16,577] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@44b3606b{/jobs/job,null,UNAVAILABLE}
[12:58:16,577] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2cc44ad{/jobs/json,null,UNAVAILABLE}
[12:58:16,577] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@62e20a76{/jobs,null,UNAVAILABLE}
[12:58:16,579] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[12:58:16,587] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:58:16,591] INFO  {MemoryStore} MemoryStore cleared
[12:58:16,591] INFO  {BlockManager} BlockManager stopped
[12:58:16,596] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:58:16,598] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:58:16,611] INFO  {SparkContext} Successfully stopped SparkContext
[12:58:16,612] INFO  {ShutdownHookManager} Shutdown hook called
[12:58:16,613] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-7f0c85b5-f92e-4245-9b4b-1d0320cfef63
[12:59:42,215] INFO  {SparkContext} Running Spark version 2.0.1
[12:59:42,818] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[12:59:43,068] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[12:59:43,069] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[12:59:43,221] INFO  {SecurityManager} Changing view acls to: victor
[12:59:43,223] INFO  {SecurityManager} Changing modify acls to: victor
[12:59:43,224] INFO  {SecurityManager} Changing view acls groups to: 
[12:59:43,226] INFO  {SecurityManager} Changing modify acls groups to: 
[12:59:43,228] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[12:59:43,990] INFO  {Utils} Successfully started service 'sparkDriver' on port 34751.
[12:59:44,028] INFO  {SparkEnv} Registering MapOutputTracker
[12:59:44,065] INFO  {SparkEnv} Registering BlockManagerMaster
[12:59:44,093] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-54cad602-b0ab-4229-bb81-a9d9657d21fd
[12:59:44,130] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[12:59:44,235] INFO  {SparkEnv} Registering OutputCommitCoordinator
[12:59:44,420] INFO  {log} Logging initialized @3740ms
[12:59:44,620] INFO  {Server} jetty-9.2.z-SNAPSHOT
[12:59:44,635] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[12:59:44,635] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[12:59:44,636] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[12:59:44,636] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[12:59:44,636] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[12:59:44,636] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[12:59:44,636] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[12:59:44,637] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[12:59:44,637] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[12:59:44,637] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[12:59:44,637] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[12:59:44,637] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[12:59:44,637] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[12:59:44,638] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[12:59:44,638] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[12:59:44,638] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[12:59:44,638] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[12:59:44,638] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[12:59:44,639] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[12:59:44,639] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[12:59:44,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[12:59:44,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[12:59:44,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[12:59:44,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[12:59:44,649] INFO  {ServerConnector} Started ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[12:59:44,649] INFO  {Server} Started @3973ms
[12:59:44,649] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[12:59:44,651] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[12:59:44,724] INFO  {Executor} Starting executor ID driver on host localhost
[12:59:44,745] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35109.
[12:59:44,745] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:35109
[12:59:44,747] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 35109)
[12:59:44,750] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:35109 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 35109)
[12:59:44,753] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 35109)
[12:59:44,904] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[12:59:45,386] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[12:59:45,435] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[12:59:45,437] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:35109 (size: 14.6 KB, free: 1128.9 MB)
[12:59:45,443] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:26
[12:59:46,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5efe47fd{/SQL,null,AVAILABLE}
[12:59:46,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e3236d{/SQL/json,null,AVAILABLE}
[12:59:46,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@27a6fef2{/SQL/execution,null,AVAILABLE}
[12:59:46,931] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2dba05b1{/SQL/execution/json,null,AVAILABLE}
[12:59:46,932] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@19ae2ee5{/static/sql,null,AVAILABLE}
[12:59:46,959] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[12:59:47,852] INFO  {CodeGenerator} Code generated in 184.117434 ms
[12:59:47,918] INFO  {CodeGenerator} Code generated in 46.091125 ms
[12:59:47,994] INFO  {FileInputFormat} Total input paths to process : 2
[12:59:47,997] INFO  {FileInputFormat} Total input paths to process : 2
[12:59:48,012] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[12:59:48,051] INFO  {SparkContext} Starting job: foreach at Main.scala:36
[12:59:48,063] INFO  {DAGScheduler} Registering RDD 6 (foreach at Main.scala:36)
[12:59:48,065] INFO  {DAGScheduler} Got job 0 (foreach at Main.scala:36) with 1 output partitions
[12:59:48,066] INFO  {DAGScheduler} Final stage: ResultStage 1 (foreach at Main.scala:36)
[12:59:48,066] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 0)
[12:59:48,068] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 0)
[12:59:48,073] INFO  {DAGScheduler} Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at foreach at Main.scala:36), which has no missing parents
[12:59:48,095] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 21.7 KB, free 1128.7 MB)
[12:59:48,098] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.5 KB, free 1128.7 MB)
[12:59:48,099] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:35109 (size: 9.5 KB, free: 1128.9 MB)
[12:59:48,099] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[12:59:48,102] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at foreach at Main.scala:36)
[12:59:48,103] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[12:59:48,145] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[12:59:48,152] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[12:59:48,187] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[12:59:48,210] INFO  {CodeGenerator} Code generated in 12.523473 ms
[12:59:48,235] INFO  {CodeGenerator} Code generated in 18.111834 ms
[12:59:48,249] INFO  {CodeGenerator} Code generated in 7.574608 ms
[12:59:48,302] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[12:59:48,308] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[12:59:48,309] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[12:59:48,311] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[12:59:48,489] INFO  {ContextCleaner} Cleaned accumulator 6
[12:59:48,651] INFO  {CodeGenerator} Code generated in 18.914962 ms
[12:59:49,005] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2223 bytes result sent to driver
[12:59:49,012] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 890 ms on localhost (1/1)
[12:59:49,013] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[12:59:49,019] INFO  {DAGScheduler} ShuffleMapStage 0 (foreach at Main.scala:36) finished in 0.908 s
[12:59:49,019] INFO  {DAGScheduler} looking for newly runnable stages
[12:59:49,020] INFO  {DAGScheduler} running: Set()
[12:59:49,020] INFO  {DAGScheduler} waiting: Set(ResultStage 1)
[12:59:49,021] INFO  {DAGScheduler} failed: Set()
[12:59:49,022] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:36), which has no missing parents
[12:59:49,039] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 17.9 KB, free 1128.7 MB)
[12:59:49,041] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.8 KB, free 1128.7 MB)
[12:59:49,041] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:35109 (size: 8.8 KB, free: 1128.9 MB)
[12:59:49,042] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[12:59:49,043] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:36)
[12:59:49,043] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[12:59:49,048] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5317 bytes)
[12:59:49,048] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[12:59:49,066] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[12:59:49,067] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[12:59:49,095] INFO  {CodeGenerator} Code generated in 14.407334 ms
[12:59:49,249] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:35109 in memory (size: 9.5 KB, free: 1128.9 MB)
[12:59:49,306] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2208 bytes result sent to driver
[12:59:49,308] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 262 ms on localhost (1/1)
[12:59:49,308] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[12:59:49,309] INFO  {DAGScheduler} ResultStage 1 (foreach at Main.scala:36) finished in 0.263 s
[12:59:49,316] INFO  {DAGScheduler} Job 0 finished: foreach at Main.scala:36, took 1.264697 s
[12:59:49,337] INFO  {SparkContext} Invoking stop() from shutdown hook
[12:59:49,342] INFO  {ServerConnector} Stopped ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[12:59:49,344] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[12:59:49,344] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[12:59:49,344] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[12:59:49,344] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[12:59:49,344] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[12:59:49,344] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[12:59:49,344] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[12:59:49,345] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[12:59:49,345] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[12:59:49,345] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[12:59:49,345] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[12:59:49,345] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[12:59:49,345] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[12:59:49,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[12:59:49,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[12:59:49,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[12:59:49,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[12:59:49,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[12:59:49,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[12:59:49,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[12:59:49,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[12:59:49,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[12:59:49,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[12:59:49,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[12:59:49,348] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[12:59:49,358] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[12:59:49,364] INFO  {MemoryStore} MemoryStore cleared
[12:59:49,364] INFO  {BlockManager} BlockManager stopped
[12:59:49,365] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[12:59:49,368] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[12:59:49,370] INFO  {SparkContext} Successfully stopped SparkContext
[12:59:49,370] INFO  {ShutdownHookManager} Shutdown hook called
[12:59:49,371] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-243293d7-49b4-4fe1-ba62-1dfe86fadad6
[13:01:38,994] INFO  {SparkContext} Running Spark version 2.0.1
[13:01:39,237] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:01:39,345] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:01:39,346] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:01:39,431] INFO  {SecurityManager} Changing view acls to: victor
[13:01:39,432] INFO  {SecurityManager} Changing modify acls to: victor
[13:01:39,433] INFO  {SecurityManager} Changing view acls groups to: 
[13:01:39,434] INFO  {SecurityManager} Changing modify acls groups to: 
[13:01:39,435] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:01:39,860] INFO  {Utils} Successfully started service 'sparkDriver' on port 39559.
[13:01:39,876] INFO  {SparkEnv} Registering MapOutputTracker
[13:01:39,891] INFO  {SparkEnv} Registering BlockManagerMaster
[13:01:39,904] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-25af72c9-6c3c-43cf-8227-f58a449a358d
[13:01:39,919] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:01:39,966] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:01:40,048] INFO  {log} Logging initialized @2517ms
[13:01:40,174] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:01:40,193] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[13:01:40,193] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[13:01:40,194] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[13:01:40,194] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[13:01:40,194] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[13:01:40,194] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[13:01:40,195] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[13:01:40,195] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[13:01:40,195] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[13:01:40,195] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[13:01:40,196] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[13:01:40,196] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[13:01:40,196] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[13:01:40,196] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[13:01:40,196] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[13:01:40,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[13:01:40,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[13:01:40,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[13:01:40,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[13:01:40,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[13:01:40,203] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[13:01:40,203] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[13:01:40,204] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[13:01:40,204] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[13:01:40,210] INFO  {ServerConnector} Started ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[13:01:40,211] INFO  {Server} Started @2681ms
[13:01:40,211] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:01:40,212] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:01:40,329] INFO  {Executor} Starting executor ID driver on host localhost
[13:01:40,358] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41751.
[13:01:40,359] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:41751
[13:01:40,361] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 41751)
[13:01:40,364] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:41751 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 41751)
[13:01:40,370] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 41751)
[13:01:40,609] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[13:01:41,798] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[13:01:41,922] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:01:41,927] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:41751 (size: 14.6 KB, free: 1128.9 MB)
[13:01:41,936] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:26
[13:01:43,503] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5efe47fd{/SQL,null,AVAILABLE}
[13:01:43,504] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e3236d{/SQL/json,null,AVAILABLE}
[13:01:43,505] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@27a6fef2{/SQL/execution,null,AVAILABLE}
[13:01:43,505] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2dba05b1{/SQL/execution/json,null,AVAILABLE}
[13:01:43,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@19ae2ee5{/static/sql,null,AVAILABLE}
[13:01:43,547] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:01:44,254] INFO  {ContextCleaner} Cleaned accumulator 6
[13:01:44,358] INFO  {CodeGenerator} Code generated in 207.223018 ms
[13:01:44,412] INFO  {CodeGenerator} Code generated in 37.482051 ms
[13:01:44,484] INFO  {FileInputFormat} Total input paths to process : 2
[13:01:44,487] INFO  {FileInputFormat} Total input paths to process : 2
[13:01:44,500] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[13:01:44,524] INFO  {SparkContext} Starting job: foreach at Main.scala:36
[13:01:44,537] INFO  {DAGScheduler} Registering RDD 6 (foreach at Main.scala:36)
[13:01:44,539] INFO  {DAGScheduler} Got job 0 (foreach at Main.scala:36) with 1 output partitions
[13:01:44,539] INFO  {DAGScheduler} Final stage: ResultStage 1 (foreach at Main.scala:36)
[13:01:44,540] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 0)
[13:01:44,541] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 0)
[13:01:44,548] INFO  {DAGScheduler} Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at foreach at Main.scala:36), which has no missing parents
[13:01:44,571] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 21.7 KB, free 1128.7 MB)
[13:01:44,572] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.5 KB, free 1128.7 MB)
[13:01:44,573] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:41751 (size: 9.5 KB, free: 1128.9 MB)
[13:01:44,573] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:01:44,576] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at foreach at Main.scala:36)
[13:01:44,577] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:01:44,610] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:01:44,616] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:01:44,647] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:01:44,676] INFO  {CodeGenerator} Code generated in 12.237451 ms
[13:01:44,703] INFO  {CodeGenerator} Code generated in 20.263001 ms
[13:01:44,717] INFO  {CodeGenerator} Code generated in 7.360605 ms
[13:01:44,774] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[13:01:44,780] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[13:01:44,780] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[13:01:44,783] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[13:01:45,121] INFO  {CodeGenerator} Code generated in 16.075397 ms
[13:01:45,834] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2223 bytes result sent to driver
[13:01:45,853] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 1258 ms on localhost (1/1)
[13:01:45,861] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:01:45,883] INFO  {DAGScheduler} ShuffleMapStage 0 (foreach at Main.scala:36) finished in 1.298 s
[13:01:45,885] INFO  {DAGScheduler} looking for newly runnable stages
[13:01:45,885] INFO  {DAGScheduler} running: Set()
[13:01:45,886] INFO  {DAGScheduler} waiting: Set(ResultStage 1)
[13:01:45,886] INFO  {DAGScheduler} failed: Set()
[13:01:45,888] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:36), which has no missing parents
[13:01:45,913] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 17.9 KB, free 1128.7 MB)
[13:01:45,916] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.8 KB, free 1128.7 MB)
[13:01:45,917] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:41751 (size: 8.8 KB, free: 1128.9 MB)
[13:01:45,918] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[13:01:45,920] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:36)
[13:01:45,920] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:01:45,927] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5317 bytes)
[13:01:45,928] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:01:45,953] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:01:45,955] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[13:01:46,003] INFO  {CodeGenerator} Code generated in 27.406778 ms
[13:01:46,061] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2222 bytes result sent to driver
[13:01:46,065] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 143 ms on localhost (1/1)
[13:01:46,066] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:01:46,067] INFO  {DAGScheduler} ResultStage 1 (foreach at Main.scala:36) finished in 0.145 s
[13:01:46,082] INFO  {DAGScheduler} Job 0 finished: foreach at Main.scala:36, took 1.557997 s
[13:01:46,109] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:01:46,115] INFO  {ServerConnector} Stopped ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[13:01:46,118] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[13:01:46,118] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[13:01:46,118] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[13:01:46,118] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[13:01:46,118] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[13:01:46,118] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[13:01:46,119] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[13:01:46,119] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[13:01:46,119] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[13:01:46,119] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[13:01:46,119] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[13:01:46,119] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[13:01:46,120] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[13:01:46,120] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[13:01:46,120] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[13:01:46,120] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[13:01:46,120] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[13:01:46,120] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[13:01:46,121] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[13:01:46,121] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[13:01:46,121] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[13:01:46,121] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[13:01:46,121] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[13:01:46,121] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[13:01:46,123] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:01:46,138] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:01:46,143] INFO  {MemoryStore} MemoryStore cleared
[13:01:46,144] INFO  {BlockManager} BlockManager stopped
[13:01:46,151] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:01:46,153] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:01:46,155] INFO  {SparkContext} Successfully stopped SparkContext
[13:01:46,155] INFO  {ShutdownHookManager} Shutdown hook called
[13:01:46,156] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-688850b2-5e79-49a0-af33-dfb0853b8697
[13:02:15,668] INFO  {SparkContext} Running Spark version 2.0.1
[13:02:15,925] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:02:16,054] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:02:16,055] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:02:16,148] INFO  {SecurityManager} Changing view acls to: victor
[13:02:16,148] INFO  {SecurityManager} Changing modify acls to: victor
[13:02:16,149] INFO  {SecurityManager} Changing view acls groups to: 
[13:02:16,149] INFO  {SecurityManager} Changing modify acls groups to: 
[13:02:16,150] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:02:16,487] INFO  {Utils} Successfully started service 'sparkDriver' on port 41237.
[13:02:16,507] INFO  {SparkEnv} Registering MapOutputTracker
[13:02:16,522] INFO  {SparkEnv} Registering BlockManagerMaster
[13:02:16,533] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-74ae1bfe-2153-49df-a44a-33bda801c22a
[13:02:16,548] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:02:16,593] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:02:16,674] INFO  {log} Logging initialized @1681ms
[13:02:16,787] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:02:16,802] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs,null,AVAILABLE}
[13:02:16,802] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,AVAILABLE}
[13:02:16,802] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,AVAILABLE}
[13:02:16,802] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,AVAILABLE}
[13:02:16,803] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages,null,AVAILABLE}
[13:02:16,803] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,AVAILABLE}
[13:02:16,803] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,AVAILABLE}
[13:02:16,803] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,AVAILABLE}
[13:02:16,803] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,AVAILABLE}
[13:02:16,803] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,AVAILABLE}
[13:02:16,804] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,AVAILABLE}
[13:02:16,804] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,AVAILABLE}
[13:02:16,804] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,AVAILABLE}
[13:02:16,804] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,AVAILABLE}
[13:02:16,804] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,AVAILABLE}
[13:02:16,804] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,AVAILABLE}
[13:02:16,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors,null,AVAILABLE}
[13:02:16,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,AVAILABLE}
[13:02:16,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,AVAILABLE}
[13:02:16,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,AVAILABLE}
[13:02:16,810] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/static,null,AVAILABLE}
[13:02:16,810] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/,null,AVAILABLE}
[13:02:16,811] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/api,null,AVAILABLE}
[13:02:16,811] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,AVAILABLE}
[13:02:16,816] INFO  {ServerConnector} Started ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[13:02:16,816] INFO  {Server} Started @1824ms
[13:02:16,816] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:02:16,818] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:02:16,891] INFO  {Executor} Starting executor ID driver on host localhost
[13:02:16,913] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45455.
[13:02:16,913] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:45455
[13:02:16,915] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 45455)
[13:02:16,918] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:45455 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 45455)
[13:02:16,920] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 45455)
[13:02:17,070] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@493dfb8e{/metrics/json,null,AVAILABLE}
[13:02:18,103] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[13:02:18,230] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:02:18,235] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:45455 (size: 14.6 KB, free: 1128.9 MB)
[13:02:18,245] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:26
[13:02:20,660] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:02:20,664] INFO  {ServerConnector} Stopped ServerConnector@78f5c518{HTTP/1.1}{0.0.0.0:4040}
[13:02:20,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/kill,null,UNAVAILABLE}
[13:02:20,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/api,null,UNAVAILABLE}
[13:02:20,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/,null,UNAVAILABLE}
[13:02:20,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/static,null,UNAVAILABLE}
[13:02:20,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/executors/threadDump/json,null,UNAVAILABLE}
[13:02:20,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/executors/threadDump,null,UNAVAILABLE}
[13:02:20,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/json,null,UNAVAILABLE}
[13:02:20,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors,null,UNAVAILABLE}
[13:02:20,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/environment/json,null,UNAVAILABLE}
[13:02:20,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/environment,null,UNAVAILABLE}
[13:02:20,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/storage/rdd/json,null,UNAVAILABLE}
[13:02:20,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/storage/rdd,null,UNAVAILABLE}
[13:02:20,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/json,null,UNAVAILABLE}
[13:02:20,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage,null,UNAVAILABLE}
[13:02:20,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/stages/pool/json,null,UNAVAILABLE}
[13:02:20,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/stages/pool,null,UNAVAILABLE}
[13:02:20,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/stage/json,null,UNAVAILABLE}
[13:02:20,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/stage,null,UNAVAILABLE}
[13:02:20,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/json,null,UNAVAILABLE}
[13:02:20,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages,null,UNAVAILABLE}
[13:02:20,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/jobs/job/json,null,UNAVAILABLE}
[13:02:20,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/jobs/job,null,UNAVAILABLE}
[13:02:20,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/json,null,UNAVAILABLE}
[13:02:20,671] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs,null,UNAVAILABLE}
[13:02:20,672] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:02:20,682] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:02:20,686] INFO  {MemoryStore} MemoryStore cleared
[13:02:20,686] INFO  {BlockManager} BlockManager stopped
[13:02:20,692] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:02:20,695] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:02:20,697] INFO  {SparkContext} Successfully stopped SparkContext
[13:02:20,698] INFO  {ShutdownHookManager} Shutdown hook called
[13:02:20,698] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-56add0b7-1bae-4a9d-a3b6-d889bbb00dc5
[13:05:38,750] INFO  {SparkContext} Running Spark version 2.0.1
[13:05:39,174] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:05:39,488] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:05:39,488] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:05:39,654] INFO  {SecurityManager} Changing view acls to: victor
[13:05:39,656] INFO  {SecurityManager} Changing modify acls to: victor
[13:05:39,658] INFO  {SecurityManager} Changing view acls groups to: 
[13:05:39,660] INFO  {SecurityManager} Changing modify acls groups to: 
[13:05:39,662] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:05:40,495] INFO  {Utils} Successfully started service 'sparkDriver' on port 33977.
[13:05:40,533] INFO  {SparkEnv} Registering MapOutputTracker
[13:05:40,568] INFO  {SparkEnv} Registering BlockManagerMaster
[13:05:40,600] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-bad7badb-f09d-43b7-b783-08eecf43282b
[13:05:40,638] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:05:40,776] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:05:40,986] INFO  {log} Logging initialized @2876ms
[13:05:41,237] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:05:41,275] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[13:05:41,276] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[13:05:41,278] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[13:05:41,278] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[13:05:41,279] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[13:05:41,279] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[13:05:41,280] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[13:05:41,280] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[13:05:41,281] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[13:05:41,281] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[13:05:41,281] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[13:05:41,282] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[13:05:41,282] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[13:05:41,283] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[13:05:41,283] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[13:05:41,284] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[13:05:41,284] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[13:05:41,284] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[13:05:41,285] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[13:05:41,285] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[13:05:41,296] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[13:05:41,297] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[13:05:41,298] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[13:05:41,299] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[13:05:41,310] INFO  {ServerConnector} Started ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:05:41,311] INFO  {Server} Started @3203ms
[13:05:41,311] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:05:41,314] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:05:41,474] INFO  {Executor} Starting executor ID driver on host localhost
[13:05:41,520] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37967.
[13:05:41,521] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:37967
[13:05:41,524] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 37967)
[13:05:41,529] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:37967 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 37967)
[13:05:41,536] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 37967)
[13:05:41,891] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[13:05:42,525] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[13:05:42,585] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:05:42,587] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:37967 (size: 14.6 KB, free: 1128.9 MB)
[13:05:42,591] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:29
[13:05:44,017] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b7f06c7{/SQL,null,AVAILABLE}
[13:05:44,017] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@729c8063{/SQL/json,null,AVAILABLE}
[13:05:44,018] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31e739bf{/SQL/execution,null,AVAILABLE}
[13:05:44,018] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7743ec{/SQL/execution/json,null,AVAILABLE}
[13:05:44,020] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@316cda31{/static/sql,null,AVAILABLE}
[13:05:44,045] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:05:44,874] INFO  {CodeGenerator} Code generated in 200.796253 ms
[13:05:44,923] INFO  {CodeGenerator} Code generated in 34.845094 ms
[13:05:44,996] INFO  {FileInputFormat} Total input paths to process : 2
[13:05:44,998] INFO  {FileInputFormat} Total input paths to process : 2
[13:05:45,011] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[13:05:45,039] INFO  {SparkContext} Starting job: foreach at Main.scala:41
[13:05:45,051] INFO  {DAGScheduler} Registering RDD 7 (foreach at Main.scala:41)
[13:05:45,053] INFO  {DAGScheduler} Got job 0 (foreach at Main.scala:41) with 1 output partitions
[13:05:45,053] INFO  {DAGScheduler} Final stage: ResultStage 1 (foreach at Main.scala:41)
[13:05:45,054] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 0)
[13:05:45,055] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 0)
[13:05:45,061] INFO  {DAGScheduler} Submitting ShuffleMapStage 0 (MapPartitionsRDD[7] at foreach at Main.scala:41), which has no missing parents
[13:05:45,086] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 16.5 KB, free 1128.7 MB)
[13:05:45,089] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 1128.7 MB)
[13:05:45,090] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:37967 (size: 7.7 KB, free: 1128.9 MB)
[13:05:45,091] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:05:45,094] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[7] at foreach at Main.scala:41)
[13:05:45,096] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:05:45,135] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:05:45,144] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:05:45,178] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:05:45,200] INFO  {CodeGenerator} Code generated in 11.589579 ms
[13:05:45,221] INFO  {CodeGenerator} Code generated in 14.229313 ms
[13:05:45,233] INFO  {CodeGenerator} Code generated in 6.790423 ms
[13:05:45,287] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[13:05:45,293] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[13:05:45,294] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[13:05:45,296] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[13:05:45,473] INFO  {ContextCleaner} Cleaned accumulator 6
[13:05:45,617] INFO  {CodeGenerator} Code generated in 8.828992 ms
[13:05:46,145] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2223 bytes result sent to driver
[13:05:46,158] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 1043 ms on localhost (1/1)
[13:05:46,159] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:05:46,163] INFO  {DAGScheduler} ShuffleMapStage 0 (foreach at Main.scala:41) finished in 1.060 s
[13:05:46,164] INFO  {DAGScheduler} looking for newly runnable stages
[13:05:46,164] INFO  {DAGScheduler} running: Set()
[13:05:46,164] INFO  {DAGScheduler} waiting: Set(ResultStage 1)
[13:05:46,165] INFO  {DAGScheduler} failed: Set()
[13:05:46,166] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[11] at foreach at Main.scala:41), which has no missing parents
[13:05:46,183] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 14.8 KB, free 1128.7 MB)
[13:05:46,185] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 1128.7 MB)
[13:05:46,186] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:37967 (size: 7.4 KB, free: 1128.9 MB)
[13:05:46,187] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[13:05:46,188] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at foreach at Main.scala:41)
[13:05:46,188] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:05:46,192] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5317 bytes)
[13:05:46,193] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:05:46,209] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:05:46,210] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[13:05:46,233] INFO  {CodeGenerator} Code generated in 8.860541 ms
[13:05:46,314] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2222 bytes result sent to driver
[13:05:46,316] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 126 ms on localhost (1/1)
[13:05:46,316] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:05:46,317] INFO  {DAGScheduler} ResultStage 1 (foreach at Main.scala:41) finished in 0.126 s
[13:05:46,323] INFO  {DAGScheduler} Job 0 finished: foreach at Main.scala:41, took 1.283733 s
[13:05:46,580] INFO  {CodeGenerator} Code generated in 15.028214 ms
[13:05:46,625] INFO  {CodeGenerator} Code generated in 35.687513 ms
[13:05:46,687] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[13:05:46,688] INFO  {DAGScheduler} Registering RDD 14 (collect at PipelineBuilder.scala:59)
[13:05:46,689] INFO  {DAGScheduler} Got job 1 (collect at PipelineBuilder.scala:59) with 1 output partitions
[13:05:46,689] INFO  {DAGScheduler} Final stage: ResultStage 3 (collect at PipelineBuilder.scala:59)
[13:05:46,689] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[13:05:46,690] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[13:05:46,690] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:05:46,695] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 30.9 KB, free 1128.7 MB)
[13:05:46,698] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.7 KB, free 1128.7 MB)
[13:05:46,698] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:37967 (size: 12.7 KB, free: 1128.9 MB)
[13:05:46,699] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[13:05:46,700] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at collect at PipelineBuilder.scala:59)
[13:05:46,700] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:05:46,702] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:05:46,702] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:05:46,715] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:05:47,257] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:37967 in memory (size: 7.4 KB, free: 1128.9 MB)
[13:05:47,264] INFO  {ContextCleaner} Cleaned accumulator 103
[13:05:48,161] ERROR {Executor} Exception in task 0.0 in stage 2.0 (TID 2)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "0.419193351817
2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more
[13:05:48,206] WARN  {TaskSetManager} Lost task 0.0 in stage 2.0 (TID 2, localhost): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "0.419193351817
2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more

[13:05:48,209] ERROR {TaskSetManager} Task 0 in stage 2.0 failed 1 times; aborting job
[13:05:48,211] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:05:48,217] INFO  {TaskSchedulerImpl} Cancelling stage 2
[13:05:48,220] INFO  {DAGScheduler} ShuffleMapStage 2 (collect at PipelineBuilder.scala:59) failed in 1.519 s
[13:05:48,222] INFO  {DAGScheduler} Job 1 failed: collect at PipelineBuilder.scala:59, took 1.534406 s
[13:05:48,233] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:05:48,247] INFO  {ServerConnector} Stopped ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:05:48,251] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[13:05:48,252] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[13:05:48,252] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[13:05:48,252] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[13:05:48,253] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[13:05:48,253] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[13:05:48,254] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[13:05:48,254] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[13:05:48,254] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[13:05:48,255] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[13:05:48,255] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[13:05:48,256] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[13:05:48,256] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[13:05:48,257] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[13:05:48,257] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[13:05:48,257] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[13:05:48,258] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[13:05:48,259] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[13:05:48,259] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[13:05:48,260] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[13:05:48,260] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[13:05:48,260] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[13:05:48,260] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[13:05:48,261] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[13:05:48,263] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:05:48,282] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:05:48,292] INFO  {MemoryStore} MemoryStore cleared
[13:05:48,293] INFO  {BlockManager} BlockManager stopped
[13:05:48,297] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:05:48,302] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:05:48,308] INFO  {SparkContext} Successfully stopped SparkContext
[13:05:48,308] INFO  {ShutdownHookManager} Shutdown hook called
[13:05:48,310] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-26b790cb-7f04-46f0-a155-36f7998dcabe
[13:06:25,402] INFO  {SparkContext} Running Spark version 2.0.1
[13:06:25,956] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:06:26,235] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:06:26,236] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:06:26,419] INFO  {SecurityManager} Changing view acls to: victor
[13:06:26,421] INFO  {SecurityManager} Changing modify acls to: victor
[13:06:26,423] INFO  {SecurityManager} Changing view acls groups to: 
[13:06:26,424] INFO  {SecurityManager} Changing modify acls groups to: 
[13:06:26,426] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:06:27,376] INFO  {Utils} Successfully started service 'sparkDriver' on port 46867.
[13:06:27,421] INFO  {SparkEnv} Registering MapOutputTracker
[13:06:27,454] INFO  {SparkEnv} Registering BlockManagerMaster
[13:06:27,482] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-95d6fd83-549b-41a0-bfcf-f8a9cca2692f
[13:06:27,518] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:06:27,625] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:06:27,823] INFO  {log} Logging initialized @3895ms
[13:06:28,084] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:06:28,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[13:06:28,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[13:06:28,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[13:06:28,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[13:06:28,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[13:06:28,123] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[13:06:28,123] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[13:06:28,124] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[13:06:28,124] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[13:06:28,124] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[13:06:28,125] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[13:06:28,126] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[13:06:28,126] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[13:06:28,126] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[13:06:28,127] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[13:06:28,128] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[13:06:28,128] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[13:06:28,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[13:06:28,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[13:06:28,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[13:06:28,145] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[13:06:28,145] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[13:06:28,147] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[13:06:28,147] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[13:06:28,160] INFO  {ServerConnector} Started ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:06:28,160] INFO  {Server} Started @4237ms
[13:06:28,161] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:06:28,164] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:06:28,272] INFO  {Executor} Starting executor ID driver on host localhost
[13:06:28,294] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38083.
[13:06:28,295] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:38083
[13:06:28,297] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 38083)
[13:06:28,301] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:38083 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 38083)
[13:06:28,307] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 38083)
[13:06:28,474] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[13:06:28,984] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[13:06:29,049] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:06:29,051] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:38083 (size: 14.6 KB, free: 1128.9 MB)
[13:06:29,063] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:29
[13:06:30,455] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b7f06c7{/SQL,null,AVAILABLE}
[13:06:30,455] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@729c8063{/SQL/json,null,AVAILABLE}
[13:06:30,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31e739bf{/SQL/execution,null,AVAILABLE}
[13:06:30,457] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7743ec{/SQL/execution/json,null,AVAILABLE}
[13:06:30,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@316cda31{/static/sql,null,AVAILABLE}
[13:06:30,481] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:06:31,259] INFO  {CodeGenerator} Code generated in 211.313917 ms
[13:06:31,342] INFO  {FileInputFormat} Total input paths to process : 2
[13:06:31,344] INFO  {FileInputFormat} Total input paths to process : 2
[13:06:31,357] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[13:06:31,365] INFO  {SparkContext} Starting job: show at Main.scala:41
[13:06:31,379] INFO  {DAGScheduler} Got job 0 (show at Main.scala:41) with 1 output partitions
[13:06:31,379] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:41)
[13:06:31,380] INFO  {DAGScheduler} Parents of final stage: List()
[13:06:31,381] INFO  {DAGScheduler} Missing parents: List()
[13:06:31,386] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[7] at show at Main.scala:41), which has no missing parents
[13:06:31,402] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 14.3 KB, free 1128.7 MB)
[13:06:31,405] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1128.7 MB)
[13:06:31,406] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:38083 (size: 6.8 KB, free: 1128.9 MB)
[13:06:31,407] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:06:31,410] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at show at Main.scala:41)
[13:06:31,411] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:06:31,453] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5523 bytes)
[13:06:31,461] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:06:31,494] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:06:31,516] INFO  {CodeGenerator} Code generated in 11.495517 ms
[13:06:31,538] INFO  {CodeGenerator} Code generated in 16.276399 ms
[13:06:31,559] INFO  {CodeGenerator} Code generated in 10.174378 ms
[13:06:31,612] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[13:06:31,620] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[13:06:31,621] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[13:06:31,625] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[13:06:31,962] INFO  {CodeGenerator} Code generated in 11.351419 ms
[13:06:32,619] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 929926 bytes result sent to driver
[13:06:32,626] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 1195 ms on localhost (1/1)
[13:06:32,627] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:06:32,632] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:41) finished in 1.212 s
[13:06:32,638] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:41, took 1.272516 s
[13:06:32,664] INFO  {CodeGenerator} Code generated in 7.521371 ms
[13:06:32,918] INFO  {CodeGenerator} Code generated in 13.675593 ms
[13:06:32,967] INFO  {CodeGenerator} Code generated in 37.61552 ms
[13:06:33,069] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[13:06:33,073] INFO  {DAGScheduler} Registering RDD 10 (collect at PipelineBuilder.scala:59)
[13:06:33,075] INFO  {DAGScheduler} Got job 1 (collect at PipelineBuilder.scala:59) with 1 output partitions
[13:06:33,075] INFO  {DAGScheduler} Final stage: ResultStage 2 (collect at PipelineBuilder.scala:59)
[13:06:33,075] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 1)
[13:06:33,075] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 1)
[13:06:33,077] INFO  {DAGScheduler} Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:06:33,086] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 30.9 KB, free 1128.7 MB)
[13:06:33,089] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 12.7 KB, free 1128.7 MB)
[13:06:33,090] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:38083 (size: 12.7 KB, free: 1128.9 MB)
[13:06:33,090] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[13:06:33,092] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at collect at PipelineBuilder.scala:59)
[13:06:33,093] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:06:33,096] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:06:33,096] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:06:33,109] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:06:33,309] INFO  {ContextCleaner} Cleaned accumulator 50
[13:06:33,816] ERROR {Executor} Exception in task 0.0 in stage 1.0 (TID 1)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "0.419193351817
2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more
[13:06:33,836] WARN  {TaskSetManager} Lost task 0.0 in stage 1.0 (TID 1, localhost): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "0.419193351817
2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more

[13:06:33,838] ERROR {TaskSetManager} Task 0 in stage 1.0 failed 1 times; aborting job
[13:06:33,839] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:06:33,843] INFO  {TaskSchedulerImpl} Cancelling stage 1
[13:06:33,845] INFO  {DAGScheduler} ShuffleMapStage 1 (collect at PipelineBuilder.scala:59) failed in 0.751 s
[13:06:33,846] INFO  {DAGScheduler} Job 1 failed: collect at PipelineBuilder.scala:59, took 0.776491 s
[13:06:33,854] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:06:33,860] INFO  {ServerConnector} Stopped ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:06:33,862] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[13:06:33,863] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[13:06:33,863] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[13:06:33,863] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[13:06:33,863] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[13:06:33,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[13:06:33,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[13:06:33,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[13:06:33,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[13:06:33,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[13:06:33,864] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[13:06:33,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[13:06:33,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[13:06:33,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[13:06:33,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[13:06:33,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[13:06:33,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[13:06:33,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[13:06:33,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[13:06:33,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[13:06:33,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[13:06:33,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[13:06:33,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[13:06:33,867] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[13:06:33,868] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:06:33,879] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:06:33,884] INFO  {MemoryStore} MemoryStore cleared
[13:06:33,884] INFO  {BlockManager} BlockManager stopped
[13:06:33,889] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:06:33,892] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:06:33,900] INFO  {SparkContext} Successfully stopped SparkContext
[13:06:33,901] INFO  {ShutdownHookManager} Shutdown hook called
[13:06:33,902] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a09678c6-3681-41ea-b25a-e04266991822
[13:08:00,839] INFO  {SparkContext} Running Spark version 2.0.1
[13:08:01,064] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:08:01,180] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:08:01,181] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:08:01,242] INFO  {SecurityManager} Changing view acls to: victor
[13:08:01,243] INFO  {SecurityManager} Changing modify acls to: victor
[13:08:01,243] INFO  {SecurityManager} Changing view acls groups to: 
[13:08:01,244] INFO  {SecurityManager} Changing modify acls groups to: 
[13:08:01,245] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:08:01,623] INFO  {Utils} Successfully started service 'sparkDriver' on port 40569.
[13:08:01,641] INFO  {SparkEnv} Registering MapOutputTracker
[13:08:01,655] INFO  {SparkEnv} Registering BlockManagerMaster
[13:08:01,667] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-f6db1bd8-0dd2-4d77-9c92-881f73d0028e
[13:08:01,682] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:08:01,739] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:08:01,818] INFO  {log} Logging initialized @1615ms
[13:08:01,928] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:08:01,943] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[13:08:01,943] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[13:08:01,944] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[13:08:01,944] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[13:08:01,944] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[13:08:01,944] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[13:08:01,944] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[13:08:01,945] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[13:08:01,945] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[13:08:01,945] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[13:08:01,945] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[13:08:01,945] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[13:08:01,945] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[13:08:01,946] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[13:08:01,946] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[13:08:01,946] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[13:08:01,946] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[13:08:01,946] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[13:08:01,946] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[13:08:01,947] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[13:08:01,951] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[13:08:01,952] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[13:08:01,952] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[13:08:01,952] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[13:08:01,957] INFO  {ServerConnector} Started ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:08:01,958] INFO  {Server} Started @1755ms
[13:08:01,958] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:08:01,960] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:08:02,039] INFO  {Executor} Starting executor ID driver on host localhost
[13:08:02,064] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44379.
[13:08:02,064] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:44379
[13:08:02,066] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 44379)
[13:08:02,069] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:44379 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 44379)
[13:08:02,072] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 44379)
[13:08:02,222] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[13:08:02,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL,null,AVAILABLE}
[13:08:02,288] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/json,null,AVAILABLE}
[13:08:02,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution,null,AVAILABLE}
[13:08:02,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/execution/json,null,AVAILABLE}
[13:08:02,291] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54107f42{/static/sql,null,AVAILABLE}
[13:08:02,303] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:08:04,164] INFO  {FileSourceStrategy} Pruning directories with: 
[13:08:04,166] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:08:04,171] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:08:04,172] INFO  {FileSourceStrategy} Pushed Filters: 
[13:08:04,285] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[13:08:04,331] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:08:04,333] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:44379 (size: 14.6 KB, free: 1128.9 MB)
[13:08:04,342] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:42
[13:08:04,346] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 9480334 bytes, open cost is considered as scanning 4194304 bytes.
[13:08:04,884] INFO  {CodeGenerator} Code generated in 208.729551 ms
[13:08:05,003] INFO  {SparkContext} Starting job: show at Main.scala:42
[13:08:05,023] INFO  {DAGScheduler} Got job 0 (show at Main.scala:42) with 1 output partitions
[13:08:05,023] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:42)
[13:08:05,024] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:05,025] INFO  {DAGScheduler} Missing parents: List()
[13:08:05,028] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:42), which has no missing parents
[13:08:05,044] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[13:08:05,046] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1128.7 MB)
[13:08:05,046] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:44379 (size: 6.3 KB, free: 1128.9 MB)
[13:08:05,047] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:08:05,049] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:42)
[13:08:05,051] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:08:05,085] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5980 bytes)
[13:08:05,091] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:08:05,141] INFO  {CodeGenerator} Code generated in 16.370568 ms
[13:08:05,157] INFO  {CodeGenerator} Code generated in 8.974082 ms
[13:08:05,169] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/a.tar.gz, range: 0-545863, partition values: [empty row]
[13:08:05,178] INFO  {CodeGenerator} Code generated in 7.195012 ms
[13:08:05,257] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:08:05,356] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/b.tar.gz, range: 0-545863, partition values: [empty row]
[13:08:05,358] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:08:05,578] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2460 bytes result sent to driver
[13:08:05,586] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 519 ms on localhost (1/1)
[13:08:05,587] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:08:05,590] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:42) finished in 0.532 s
[13:08:05,595] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:42, took 0.590964 s
[13:08:05,615] INFO  {CodeGenerator} Code generated in 11.019602 ms
[13:08:05,652] INFO  {FileSourceStrategy} Pruning directories with: 
[13:08:05,652] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:08:05,653] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:08:05,653] INFO  {FileSourceStrategy} Pushed Filters: 
[13:08:05,660] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[13:08:05,672] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[13:08:05,674] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:44379 (size: 14.6 KB, free: 1128.9 MB)
[13:08:05,676] INFO  {SparkContext} Created broadcast 2 from foreach at Main.scala:45
[13:08:05,677] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 9480334 bytes, open cost is considered as scanning 4194304 bytes.
[13:08:05,693] INFO  {FileSourceStrategy} Pruning directories with: 
[13:08:05,693] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:08:05,694] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:08:05,694] INFO  {FileSourceStrategy} Pushed Filters: 
[13:08:05,699] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[13:08:05,707] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[13:08:05,708] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:44379 (size: 14.6 KB, free: 1128.9 MB)
[13:08:05,709] INFO  {SparkContext} Created broadcast 3 from foreach at Main.scala:45
[13:08:05,709] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 9480334 bytes, open cost is considered as scanning 4194304 bytes.
[13:08:05,733] INFO  {CodeGenerator} Code generated in 9.57287 ms
[13:08:05,758] INFO  {CodeGenerator} Code generated in 18.383331 ms
[13:08:05,787] INFO  {SparkContext} Starting job: foreach at Main.scala:45
[13:08:05,791] INFO  {DAGScheduler} Registering RDD 6 (foreach at Main.scala:45)
[13:08:05,792] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:45) with 1 output partitions
[13:08:05,792] INFO  {DAGScheduler} Final stage: ResultStage 2 (foreach at Main.scala:45)
[13:08:05,792] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 1)
[13:08:05,792] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 1)
[13:08:05,793] INFO  {DAGScheduler} Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at foreach at Main.scala:45), which has no missing parents
[13:08:05,807] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 15.0 KB, free 1128.4 MB)
[13:08:05,809] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.1 KB, free 1128.4 MB)
[13:08:05,810] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:44379 (size: 7.1 KB, free: 1128.8 MB)
[13:08:05,810] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[13:08:05,812] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at foreach at Main.scala:45)
[13:08:05,812] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:08:05,815] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 6054 bytes)
[13:08:05,816] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:08:05,845] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/a.tar.gz, range: 0-545863, partition values: [empty row]
[13:08:05,848] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:08:05,874] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/b.tar.gz, range: 0-545863, partition values: [empty row]
[13:08:05,875] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:08:05,916] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2150 bytes result sent to driver
[13:08:05,919] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 106 ms on localhost (1/1)
[13:08:05,919] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:08:05,920] INFO  {DAGScheduler} ShuffleMapStage 1 (foreach at Main.scala:45) finished in 0.107 s
[13:08:05,921] INFO  {DAGScheduler} looking for newly runnable stages
[13:08:05,921] INFO  {DAGScheduler} running: Set()
[13:08:05,922] INFO  {DAGScheduler} waiting: Set(ResultStage 2)
[13:08:05,922] INFO  {DAGScheduler} failed: Set()
[13:08:05,923] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[10] at foreach at Main.scala:45), which has no missing parents
[13:08:05,939] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 13.8 KB, free 1128.4 MB)
[13:08:05,941] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.0 KB, free 1128.4 MB)
[13:08:05,942] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:44379 (size: 7.0 KB, free: 1128.8 MB)
[13:08:05,943] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[13:08:05,943] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at foreach at Main.scala:45)
[13:08:05,943] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:08:05,949] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5317 bytes)
[13:08:05,949] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:08:05,969] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:08:05,970] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[13:08:05,985] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 2135 bytes result sent to driver
[13:08:05,987] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 41 ms on localhost (1/1)
[13:08:05,987] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:08:05,988] INFO  {DAGScheduler} ResultStage 2 (foreach at Main.scala:45) finished in 0.041 s
[13:08:05,988] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:45, took 0.200654 s
[13:08:06,222] INFO  {FileSourceStrategy} Pruning directories with: 
[13:08:06,222] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:08:06,223] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:08:06,223] INFO  {FileSourceStrategy} Pushed Filters: 
[13:08:06,227] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.3 MB)
[13:08:06,235] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.3 MB)
[13:08:06,236] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:44379 (size: 14.6 KB, free: 1128.8 MB)
[13:08:06,237] INFO  {SparkContext} Created broadcast 6 from collect at PipelineBuilder.scala:59
[13:08:06,237] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 9480334 bytes, open cost is considered as scanning 4194304 bytes.
[13:08:06,275] INFO  {CodeGenerator} Code generated in 12.670822 ms
[13:08:06,314] INFO  {CodeGenerator} Code generated in 31.581089 ms
[13:08:06,362] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[13:08:06,363] INFO  {DAGScheduler} Registering RDD 13 (collect at PipelineBuilder.scala:59)
[13:08:06,363] INFO  {DAGScheduler} Got job 2 (collect at PipelineBuilder.scala:59) with 1 output partitions
[13:08:06,363] INFO  {DAGScheduler} Final stage: ResultStage 4 (collect at PipelineBuilder.scala:59)
[13:08:06,363] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 3)
[13:08:06,364] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 3)
[13:08:06,364] INFO  {DAGScheduler} Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:08:06,368] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 29.5 KB, free 1128.2 MB)
[13:08:06,370] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.1 KB, free 1128.2 MB)
[13:08:06,370] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:44379 (size: 12.1 KB, free: 1128.8 MB)
[13:08:06,371] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[13:08:06,371] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at PipelineBuilder.scala:59)
[13:08:06,371] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[13:08:06,373] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 6054 bytes)
[13:08:06,373] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[13:08:06,390] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/a.tar.gz, range: 0-545863, partition values: [empty row]
[13:08:06,392] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:08:06,412] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/b.tar.gz, range: 0-545863, partition values: [empty row]
[13:08:06,413] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:08:06,713] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:44379 in memory (size: 14.6 KB, free: 1128.8 MB)
[13:08:06,718] INFO  {ContextCleaner} Cleaned accumulator 50
[13:08:06,718] INFO  {ContextCleaner} Cleaned accumulator 51
[13:08:06,718] INFO  {ContextCleaner} Cleaned accumulator 52
[13:08:06,718] INFO  {ContextCleaner} Cleaned accumulator 53
[13:08:06,718] INFO  {ContextCleaner} Cleaned accumulator 54
[13:08:06,718] INFO  {ContextCleaner} Cleaned accumulator 55
[13:08:06,719] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:44379 in memory (size: 14.6 KB, free: 1128.8 MB)
[13:08:06,720] INFO  {ContextCleaner} Cleaned accumulator 56
[13:08:06,720] INFO  {ContextCleaner} Cleaned accumulator 57
[13:08:06,720] INFO  {ContextCleaner} Cleaned accumulator 58
[13:08:06,720] INFO  {ContextCleaner} Cleaned accumulator 59
[13:08:06,720] INFO  {ContextCleaner} Cleaned accumulator 60
[13:08:06,720] INFO  {ContextCleaner} Cleaned accumulator 61
[13:08:06,721] INFO  {ContextCleaner} Cleaned accumulator 62
[13:08:06,721] INFO  {ContextCleaner} Cleaned accumulator 63
[13:08:06,721] INFO  {ContextCleaner} Cleaned accumulator 64
[13:08:06,724] INFO  {ContextCleaner} Cleaned shuffle 0
[13:08:06,726] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:44379 in memory (size: 7.1 KB, free: 1128.8 MB)
[13:08:06,728] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:44379 in memory (size: 7.0 KB, free: 1128.9 MB)
[13:08:06,728] INFO  {ContextCleaner} Cleaned accumulator 153
[13:08:06,753] ERROR {Executor} Exception in task 0.0 in stage 3.0 (TID 3)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "millionsong.txt                                                                                     000664  001750  001750  00004605563 13200125716 015051  0                                                                                                    ustar 00victor                          victor                          000000  000000                                                                                                                                                                         2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more
[13:08:06,774] WARN  {TaskSetManager} Lost task 0.0 in stage 3.0 (TID 3, localhost): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "millionsong.txt                                                                                     000664  001750  001750  00004605563 13200125716 015051  0                                                                                                    ustar 00victor                          victor                          000000  000000                                                                                                                                                                         2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more

[13:08:06,776] ERROR {TaskSetManager} Task 0 in stage 3.0 failed 1 times; aborting job
[13:08:06,776] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[13:08:06,780] INFO  {TaskSchedulerImpl} Cancelling stage 3
[13:08:06,781] INFO  {DAGScheduler} ShuffleMapStage 3 (collect at PipelineBuilder.scala:59) failed in 0.409 s
[13:08:06,782] INFO  {DAGScheduler} Job 2 failed: collect at PipelineBuilder.scala:59, took 0.420261 s
[13:08:06,787] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:08:06,791] INFO  {ServerConnector} Stopped ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:08:06,792] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[13:08:06,793] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[13:08:06,793] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[13:08:06,793] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[13:08:06,793] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[13:08:06,793] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[13:08:06,793] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[13:08:06,793] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[13:08:06,793] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[13:08:06,794] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[13:08:06,794] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[13:08:06,794] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[13:08:06,794] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[13:08:06,794] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[13:08:06,794] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[13:08:06,794] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[13:08:06,794] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[13:08:06,794] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[13:08:06,794] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[13:08:06,795] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[13:08:06,795] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[13:08:06,795] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[13:08:06,795] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[13:08:06,795] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[13:08:06,796] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:08:06,805] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:08:06,809] INFO  {MemoryStore} MemoryStore cleared
[13:08:06,810] INFO  {BlockManager} BlockManager stopped
[13:08:06,811] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:08:06,813] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:08:06,819] INFO  {SparkContext} Successfully stopped SparkContext
[13:08:06,820] INFO  {ShutdownHookManager} Shutdown hook called
[13:08:06,821] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-88c187e1-26f0-4b31-9c26-0609a8a20ddd
[13:08:34,837] INFO  {SparkContext} Running Spark version 2.0.1
[13:08:35,081] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:08:35,190] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:08:35,191] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:08:35,290] INFO  {SecurityManager} Changing view acls to: victor
[13:08:35,291] INFO  {SecurityManager} Changing modify acls to: victor
[13:08:35,292] INFO  {SecurityManager} Changing view acls groups to: 
[13:08:35,292] INFO  {SecurityManager} Changing modify acls groups to: 
[13:08:35,293] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:08:35,976] INFO  {Utils} Successfully started service 'sparkDriver' on port 33109.
[13:08:36,013] INFO  {SparkEnv} Registering MapOutputTracker
[13:08:36,047] INFO  {SparkEnv} Registering BlockManagerMaster
[13:08:36,076] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-d40bbd1f-9bfc-4b75-bdf1-95e0dbb8528d
[13:08:36,111] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:08:36,235] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:08:36,408] INFO  {log} Logging initialized @2204ms
[13:08:36,639] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:08:36,675] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[13:08:36,675] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[13:08:36,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[13:08:36,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[13:08:36,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[13:08:36,678] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[13:08:36,678] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[13:08:36,679] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[13:08:36,679] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[13:08:36,680] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[13:08:36,680] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[13:08:36,681] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[13:08:36,681] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[13:08:36,682] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[13:08:36,682] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[13:08:36,683] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[13:08:36,683] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[13:08:36,683] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[13:08:36,684] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[13:08:36,684] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[13:08:36,699] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[13:08:36,700] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[13:08:36,701] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[13:08:36,702] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[13:08:36,716] INFO  {ServerConnector} Started ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:08:36,716] INFO  {Server} Started @2514ms
[13:08:36,716] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:08:36,720] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:08:36,925] INFO  {Executor} Starting executor ID driver on host localhost
[13:08:36,974] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41453.
[13:08:36,976] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:41453
[13:08:36,980] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 41453)
[13:08:36,987] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:41453 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 41453)
[13:08:36,994] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 41453)
[13:08:37,340] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[13:08:37,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL,null,AVAILABLE}
[13:08:37,443] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ae81e1{/SQL/json,null,AVAILABLE}
[13:08:37,445] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution,null,AVAILABLE}
[13:08:37,446] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2a2da905{/SQL/execution/json,null,AVAILABLE}
[13:08:37,451] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54107f42{/static/sql,null,AVAILABLE}
[13:08:37,488] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:08:39,809] INFO  {FileSourceStrategy} Pruning directories with: 
[13:08:39,812] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:08:39,816] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:08:39,816] INFO  {FileSourceStrategy} Pushed Filters: 
[13:08:39,928] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[13:08:39,975] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:08:39,977] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:41453 (size: 14.6 KB, free: 1128.9 MB)
[13:08:39,986] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:42
[13:08:39,989] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:08:40,522] INFO  {CodeGenerator} Code generated in 210.213196 ms
[13:08:40,634] INFO  {SparkContext} Starting job: show at Main.scala:42
[13:08:40,652] INFO  {DAGScheduler} Got job 0 (show at Main.scala:42) with 1 output partitions
[13:08:40,653] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:42)
[13:08:40,653] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:40,654] INFO  {DAGScheduler} Missing parents: List()
[13:08:40,659] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:42), which has no missing parents
[13:08:40,675] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[13:08:40,678] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1128.7 MB)
[13:08:40,679] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:41453 (size: 6.3 KB, free: 1128.9 MB)
[13:08:40,679] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:08:40,682] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:42)
[13:08:40,683] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:08:40,725] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[13:08:40,731] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:08:40,792] INFO  {CodeGenerator} Code generated in 17.723415 ms
[13:08:40,809] INFO  {CodeGenerator} Code generated in 8.583636 ms
[13:08:40,821] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:40,830] INFO  {CodeGenerator} Code generated in 7.485144 ms
[13:08:40,961] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2775 bytes result sent to driver
[13:08:40,970] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 267 ms on localhost (1/1)
[13:08:40,971] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:08:40,975] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:42) finished in 0.284 s
[13:08:40,981] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:42, took 0.346124 s
[13:08:41,006] INFO  {CodeGenerator} Code generated in 12.515347 ms
[13:08:41,042] INFO  {FileSourceStrategy} Pruning directories with: 
[13:08:41,042] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:08:41,043] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:08:41,043] INFO  {FileSourceStrategy} Pushed Filters: 
[13:08:41,049] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[13:08:41,060] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[13:08:41,061] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:41453 (size: 14.6 KB, free: 1128.9 MB)
[13:08:41,063] INFO  {SparkContext} Created broadcast 2 from foreach at Main.scala:45
[13:08:41,063] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:08:41,078] INFO  {FileSourceStrategy} Pruning directories with: 
[13:08:41,078] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:08:41,078] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:08:41,078] INFO  {FileSourceStrategy} Pushed Filters: 
[13:08:41,083] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[13:08:41,091] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[13:08:41,092] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:41453 (size: 14.6 KB, free: 1128.9 MB)
[13:08:41,093] INFO  {SparkContext} Created broadcast 3 from foreach at Main.scala:45
[13:08:41,094] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:08:41,117] INFO  {CodeGenerator} Code generated in 9.391533 ms
[13:08:41,143] INFO  {CodeGenerator} Code generated in 19.729084 ms
[13:08:41,173] INFO  {SparkContext} Starting job: foreach at Main.scala:45
[13:08:41,176] INFO  {DAGScheduler} Registering RDD 6 (foreach at Main.scala:45)
[13:08:41,177] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:45) with 1 output partitions
[13:08:41,178] INFO  {DAGScheduler} Final stage: ResultStage 2 (foreach at Main.scala:45)
[13:08:41,178] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 1)
[13:08:41,178] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 1)
[13:08:41,179] INFO  {DAGScheduler} Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at foreach at Main.scala:45), which has no missing parents
[13:08:41,189] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 15.0 KB, free 1128.4 MB)
[13:08:41,191] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.1 KB, free 1128.4 MB)
[13:08:41,191] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:41453 (size: 7.1 KB, free: 1128.8 MB)
[13:08:41,192] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[13:08:41,194] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at foreach at Main.scala:45)
[13:08:41,194] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:08:41,197] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[13:08:41,197] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:08:41,222] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:41,280] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2150 bytes result sent to driver
[13:08:41,283] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 89 ms on localhost (1/1)
[13:08:41,283] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:08:41,285] INFO  {DAGScheduler} ShuffleMapStage 1 (foreach at Main.scala:45) finished in 0.090 s
[13:08:41,285] INFO  {DAGScheduler} looking for newly runnable stages
[13:08:41,286] INFO  {DAGScheduler} running: Set()
[13:08:41,288] INFO  {DAGScheduler} waiting: Set(ResultStage 2)
[13:08:41,289] INFO  {DAGScheduler} failed: Set()
[13:08:41,292] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[10] at foreach at Main.scala:45), which has no missing parents
[13:08:41,308] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 13.8 KB, free 1128.4 MB)
[13:08:41,310] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.0 KB, free 1128.4 MB)
[13:08:41,311] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:41453 (size: 7.0 KB, free: 1128.8 MB)
[13:08:41,311] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[13:08:41,312] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at foreach at Main.scala:45)
[13:08:41,312] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:08:41,316] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5317 bytes)
[13:08:41,316] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:08:41,335] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:08:41,337] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[13:08:41,359] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 2222 bytes result sent to driver
[13:08:41,363] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 48 ms on localhost (1/1)
[13:08:41,363] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:08:41,363] INFO  {DAGScheduler} ResultStage 2 (foreach at Main.scala:45) finished in 0.049 s
[13:08:41,364] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:45, took 0.190955 s
[13:08:41,494] INFO  {ContextCleaner} Cleaned accumulator 2
[13:08:41,506] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 192.168.0.103:41453 in memory (size: 14.6 KB, free: 1128.9 MB)
[13:08:41,508] INFO  {ContextCleaner} Cleaned accumulator 0
[13:08:41,508] INFO  {ContextCleaner} Cleaned accumulator 1
[13:08:41,508] INFO  {ContextCleaner} Cleaned accumulator 3
[13:08:41,509] INFO  {ContextCleaner} Cleaned accumulator 4
[13:08:41,509] INFO  {ContextCleaner} Cleaned accumulator 5
[13:08:41,510] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:41453 in memory (size: 6.3 KB, free: 1128.9 MB)
[13:08:41,511] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:41453 in memory (size: 14.6 KB, free: 1128.9 MB)
[13:08:41,512] INFO  {ContextCleaner} Cleaned accumulator 50
[13:08:41,512] INFO  {ContextCleaner} Cleaned accumulator 51
[13:08:41,512] INFO  {ContextCleaner} Cleaned accumulator 52
[13:08:41,513] INFO  {ContextCleaner} Cleaned accumulator 53
[13:08:41,513] INFO  {ContextCleaner} Cleaned accumulator 54
[13:08:41,513] INFO  {ContextCleaner} Cleaned accumulator 55
[13:08:41,513] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:41453 in memory (size: 14.6 KB, free: 1128.9 MB)
[13:08:41,514] INFO  {ContextCleaner} Cleaned accumulator 56
[13:08:41,514] INFO  {ContextCleaner} Cleaned accumulator 57
[13:08:41,514] INFO  {ContextCleaner} Cleaned accumulator 58
[13:08:41,514] INFO  {ContextCleaner} Cleaned accumulator 59
[13:08:41,514] INFO  {ContextCleaner} Cleaned accumulator 60
[13:08:41,514] INFO  {ContextCleaner} Cleaned accumulator 61
[13:08:41,514] INFO  {ContextCleaner} Cleaned accumulator 62
[13:08:41,514] INFO  {ContextCleaner} Cleaned accumulator 63
[13:08:41,515] INFO  {ContextCleaner} Cleaned accumulator 64
[13:08:41,517] INFO  {ContextCleaner} Cleaned shuffle 0
[13:08:41,518] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:41453 in memory (size: 7.1 KB, free: 1128.9 MB)
[13:08:41,523] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:41453 in memory (size: 7.0 KB, free: 1128.9 MB)
[13:08:41,705] INFO  {FileSourceStrategy} Pruning directories with: 
[13:08:41,705] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:08:41,706] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:08:41,706] INFO  {FileSourceStrategy} Pushed Filters: 
[13:08:41,710] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[13:08:41,717] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:08:41,718] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:41453 (size: 14.6 KB, free: 1128.9 MB)
[13:08:41,719] INFO  {SparkContext} Created broadcast 6 from collect at PipelineBuilder.scala:59
[13:08:41,719] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:08:41,762] INFO  {CodeGenerator} Code generated in 16.084627 ms
[13:08:41,808] INFO  {CodeGenerator} Code generated in 37.596578 ms
[13:08:41,860] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[13:08:41,861] INFO  {DAGScheduler} Registering RDD 13 (collect at PipelineBuilder.scala:59)
[13:08:41,861] INFO  {DAGScheduler} Got job 2 (collect at PipelineBuilder.scala:59) with 1 output partitions
[13:08:41,861] INFO  {DAGScheduler} Final stage: ResultStage 4 (collect at PipelineBuilder.scala:59)
[13:08:41,861] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 3)
[13:08:41,861] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 3)
[13:08:41,862] INFO  {DAGScheduler} Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:08:41,866] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 29.5 KB, free 1128.7 MB)
[13:08:41,868] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.1 KB, free 1128.7 MB)
[13:08:41,868] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:41453 (size: 12.1 KB, free: 1128.9 MB)
[13:08:41,869] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[13:08:41,869] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at PipelineBuilder.scala:59)
[13:08:41,869] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[13:08:41,872] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[13:08:41,872] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[13:08:41,894] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:42,139] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 2406 bytes result sent to driver
[13:08:42,141] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 271 ms on localhost (1/1)
[13:08:42,142] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[13:08:42,142] INFO  {DAGScheduler} ShuffleMapStage 3 (collect at PipelineBuilder.scala:59) finished in 0.273 s
[13:08:42,143] INFO  {DAGScheduler} looking for newly runnable stages
[13:08:42,143] INFO  {DAGScheduler} running: Set()
[13:08:42,143] INFO  {DAGScheduler} waiting: Set(ResultStage 4)
[13:08:42,143] INFO  {DAGScheduler} failed: Set()
[13:08:42,143] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[16] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:08:42,146] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[13:08:42,148] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[13:08:42,149] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:41453 (size: 3.9 KB, free: 1128.9 MB)
[13:08:42,149] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[13:08:42,149] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at collect at PipelineBuilder.scala:59)
[13:08:42,149] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[13:08:42,151] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, ANY, 5317 bytes)
[13:08:42,152] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[13:08:42,157] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:08:42,157] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[13:08:42,161] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1955 bytes result sent to driver
[13:08:42,162] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 12 ms on localhost (1/1)
[13:08:42,163] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[13:08:42,163] INFO  {DAGScheduler} ResultStage 4 (collect at PipelineBuilder.scala:59) finished in 0.013 s
[13:08:42,163] INFO  {DAGScheduler} Job 2 finished: collect at PipelineBuilder.scala:59, took 0.303280 s
[13:08:42,174] INFO  {CodeGenerator} Code generated in 6.991099 ms
[13:08:42,349] INFO  {FileSourceStrategy} Pruning directories with: 
[13:08:42,349] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:08:42,349] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:08:42,349] INFO  {FileSourceStrategy} Pushed Filters: 
[13:08:42,353] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[13:08:42,362] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[13:08:42,362] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:41453 (size: 14.6 KB, free: 1128.9 MB)
[13:08:42,363] INFO  {SparkContext} Created broadcast 9 from rdd at MyLinearRegressionImpl.scala:92
[13:08:42,363] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:08:42,452] INFO  {CodeGenerator} Code generated in 71.73396 ms
[13:08:42,477] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:63
[13:08:42,478] INFO  {DAGScheduler} Got job 3 (count at MyLinearRegressionImpl.scala:63) with 1 output partitions
[13:08:42,478] INFO  {DAGScheduler} Final stage: ResultStage 5 (count at MyLinearRegressionImpl.scala:63)
[13:08:42,478] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:42,479] INFO  {DAGScheduler} Missing parents: List()
[13:08:42,479] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[21] at map at MyLinearRegressionImpl.scala:92), which has no missing parents
[13:08:42,486] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 44.0 KB, free 1128.5 MB)
[13:08:42,607] INFO  {ContextCleaner} Cleaned accumulator 156
[13:08:42,608] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:41453 in memory (size: 3.9 KB, free: 1128.9 MB)
[13:08:42,608] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.9 KB, free 1128.5 MB)
[13:08:42,609] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:41453 (size: 14.9 KB, free: 1128.8 MB)
[13:08:42,610] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:41453 in memory (size: 12.1 KB, free: 1128.9 MB)
[13:08:42,610] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[13:08:42,610] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at map at MyLinearRegressionImpl.scala:92)
[13:08:42,611] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[13:08:42,612] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:41453 in memory (size: 14.6 KB, free: 1128.9 MB)
[13:08:42,613] INFO  {ContextCleaner} Cleaned accumulator 153
[13:08:42,613] INFO  {ContextCleaner} Cleaned accumulator 154
[13:08:42,613] INFO  {ContextCleaner} Cleaned accumulator 155
[13:08:42,613] INFO  {ContextCleaner} Cleaned accumulator 157
[13:08:42,613] INFO  {ContextCleaner} Cleaned accumulator 158
[13:08:42,613] INFO  {ContextCleaner} Cleaned accumulator 159
[13:08:42,613] INFO  {ContextCleaner} Cleaned accumulator 160
[13:08:42,613] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:42,613] INFO  {ContextCleaner} Cleaned accumulator 161
[13:08:42,613] INFO  {ContextCleaner} Cleaned accumulator 162
[13:08:42,614] INFO  {ContextCleaner} Cleaned accumulator 163
[13:08:42,614] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[13:08:42,614] INFO  {ContextCleaner} Cleaned accumulator 164
[13:08:42,614] INFO  {ContextCleaner} Cleaned accumulator 165
[13:08:42,614] INFO  {ContextCleaner} Cleaned accumulator 166
[13:08:42,614] INFO  {ContextCleaner} Cleaned accumulator 167
[13:08:42,614] INFO  {ContextCleaner} Cleaned accumulator 168
[13:08:42,614] INFO  {ContextCleaner} Cleaned accumulator 169
[13:08:42,615] INFO  {ContextCleaner} Cleaned shuffle 1
[13:08:42,639] INFO  {CodeGenerator} Code generated in 9.198351 ms
[13:08:42,640] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:43,104] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1843 bytes result sent to driver
[13:08:43,105] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 494 ms on localhost (1/1)
[13:08:43,105] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[13:08:43,106] INFO  {DAGScheduler} ResultStage 5 (count at MyLinearRegressionImpl.scala:63) finished in 0.495 s
[13:08:43,106] INFO  {DAGScheduler} Job 3 finished: count at MyLinearRegressionImpl.scala:63, took 0.628982 s
[13:08:43,118] INFO  {SparkContext} Starting job: take at MyLinearRegressionImpl.scala:64
[13:08:43,119] INFO  {DAGScheduler} Got job 4 (take at MyLinearRegressionImpl.scala:64) with 1 output partitions
[13:08:43,119] INFO  {DAGScheduler} Final stage: ResultStage 6 (take at MyLinearRegressionImpl.scala:64)
[13:08:43,119] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:43,119] INFO  {DAGScheduler} Missing parents: List()
[13:08:43,119] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at map at MyLinearRegressionImpl.scala:92), which has no missing parents
[13:08:43,122] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 44.2 KB, free 1128.7 MB)
[13:08:43,124] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1128.6 MB)
[13:08:43,125] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:41453 (size: 15.0 KB, free: 1128.9 MB)
[13:08:43,125] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[13:08:43,126] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at map at MyLinearRegressionImpl.scala:92)
[13:08:43,126] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[13:08:43,128] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:43,128] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[13:08:43,135] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:43,156] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2677 bytes result sent to driver
[13:08:43,158] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 32 ms on localhost (1/1)
[13:08:43,158] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[13:08:43,158] INFO  {DAGScheduler} ResultStage 6 (take at MyLinearRegressionImpl.scala:64) finished in 0.032 s
[13:08:43,159] INFO  {DAGScheduler} Job 4 finished: take at MyLinearRegressionImpl.scala:64, took 0.041028 s
[13:08:43,180] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:43,181] INFO  {DAGScheduler} Got job 5 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:43,181] INFO  {DAGScheduler} Final stage: ResultStage 7 (sum at MyLinearRegressionImpl.scala:24)
[13:08:43,181] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:43,181] INFO  {DAGScheduler} Missing parents: List()
[13:08:43,182] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[23] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:43,186] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:08:43,188] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.4 KB, free 1128.6 MB)
[13:08:43,189] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:41453 (size: 15.4 KB, free: 1128.8 MB)
[13:08:43,190] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[13:08:43,190] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at map at MyLinearRegressionImpl.scala:22)
[13:08:43,190] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[13:08:43,192] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5956 bytes)
[13:08:43,192] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[13:08:43,207] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:43,429] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1772 bytes result sent to driver
[13:08:43,430] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 239 ms on localhost (1/1)
[13:08:43,430] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[13:08:43,431] INFO  {DAGScheduler} ResultStage 7 (sum at MyLinearRegressionImpl.scala:24) finished in 0.240 s
[13:08:43,431] INFO  {DAGScheduler} Job 5 finished: sum at MyLinearRegressionImpl.scala:24, took 0.250916 s
[13:08:43,434] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:43,435] INFO  {DAGScheduler} Got job 6 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:43,435] INFO  {DAGScheduler} Final stage: ResultStage 8 (count at MyLinearRegressionImpl.scala:26)
[13:08:43,435] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:43,435] INFO  {DAGScheduler} Missing parents: List()
[13:08:43,436] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[22] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:43,439] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:43,441] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1128.5 MB)
[13:08:43,441] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 192.168.0.103:41453 (size: 15.1 KB, free: 1128.8 MB)
[13:08:43,442] INFO  {SparkContext} Created broadcast 13 from broadcast at DAGScheduler.scala:1012
[13:08:43,442] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[22] at map at MyLinearRegressionImpl.scala:36)
[13:08:43,442] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[13:08:43,444] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:43,444] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[13:08:43,452] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:43,617] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 192.168.0.103:41453 in memory (size: 15.0 KB, free: 1128.8 MB)
[13:08:43,620] INFO  {BlockManagerInfo} Removed broadcast_12_piece0 on 192.168.0.103:41453 in memory (size: 15.4 KB, free: 1128.9 MB)
[13:08:43,669] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 1843 bytes result sent to driver
[13:08:43,670] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 227 ms on localhost (1/1)
[13:08:43,670] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[13:08:43,671] INFO  {DAGScheduler} ResultStage 8 (count at MyLinearRegressionImpl.scala:26) finished in 0.228 s
[13:08:43,671] INFO  {DAGScheduler} Job 6 finished: count at MyLinearRegressionImpl.scala:26, took 0.236449 s
[13:08:43,704] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:43,705] INFO  {DAGScheduler} Got job 7 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:43,705] INFO  {DAGScheduler} Final stage: ResultStage 9 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:43,705] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:43,705] INFO  {DAGScheduler} Missing parents: List()
[13:08:43,705] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[24] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:43,708] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:43,710] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.4 KB, free 1128.6 MB)
[13:08:43,711] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 192.168.0.103:41453 (size: 15.4 KB, free: 1128.8 MB)
[13:08:43,711] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[13:08:43,711] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[24] at map at MyLinearRegressionImpl.scala:54)
[13:08:43,711] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[13:08:43,713] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5959 bytes)
[13:08:43,713] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[13:08:43,720] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:43,898] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 2499 bytes result sent to driver
[13:08:43,899] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 187 ms on localhost (1/1)
[13:08:43,900] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[13:08:43,900] INFO  {DAGScheduler} ResultStage 9 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.188 s
[13:08:43,901] INFO  {DAGScheduler} Job 7 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.196273 s
[13:08:43,909] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:43,910] INFO  {DAGScheduler} Got job 8 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:43,910] INFO  {DAGScheduler} Final stage: ResultStage 10 (sum at MyLinearRegressionImpl.scala:24)
[13:08:43,910] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:43,911] INFO  {DAGScheduler} Missing parents: List()
[13:08:43,911] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[26] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:43,913] INFO  {MemoryStore} Block broadcast_15 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:43,915] INFO  {MemoryStore} Block broadcast_15_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:43,915] INFO  {BlockManagerInfo} Added broadcast_15_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:43,916] INFO  {SparkContext} Created broadcast 15 from broadcast at DAGScheduler.scala:1012
[13:08:43,916] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at map at MyLinearRegressionImpl.scala:22)
[13:08:43,916] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[13:08:43,918] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5956 bytes)
[13:08:43,918] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[13:08:43,927] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:44,026] INFO  {BlockManagerInfo} Removed broadcast_14_piece0 on 192.168.0.103:41453 in memory (size: 15.4 KB, free: 1128.8 MB)
[13:08:44,028] INFO  {BlockManagerInfo} Removed broadcast_13_piece0 on 192.168.0.103:41453 in memory (size: 15.1 KB, free: 1128.9 MB)
[13:08:44,112] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 1758 bytes result sent to driver
[13:08:44,113] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 196 ms on localhost (1/1)
[13:08:44,113] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[13:08:44,114] INFO  {DAGScheduler} ResultStage 10 (sum at MyLinearRegressionImpl.scala:24) finished in 0.198 s
[13:08:44,114] INFO  {DAGScheduler} Job 8 finished: sum at MyLinearRegressionImpl.scala:24, took 0.204637 s
[13:08:44,117] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:44,118] INFO  {DAGScheduler} Got job 9 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:44,118] INFO  {DAGScheduler} Final stage: ResultStage 11 (count at MyLinearRegressionImpl.scala:26)
[13:08:44,118] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:44,118] INFO  {DAGScheduler} Missing parents: List()
[13:08:44,119] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[25] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:44,122] INFO  {MemoryStore} Block broadcast_16 stored as values in memory (estimated size 45.0 KB, free 1128.6 MB)
[13:08:44,124] INFO  {MemoryStore} Block broadcast_16_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.6 MB)
[13:08:44,125] INFO  {BlockManagerInfo} Added broadcast_16_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:44,125] INFO  {SparkContext} Created broadcast 16 from broadcast at DAGScheduler.scala:1012
[13:08:44,126] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[25] at map at MyLinearRegressionImpl.scala:36)
[13:08:44,126] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[13:08:44,127] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:44,127] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[13:08:44,134] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:44,289] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 1683 bytes result sent to driver
[13:08:44,291] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 165 ms on localhost (1/1)
[13:08:44,291] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[13:08:44,292] INFO  {DAGScheduler} ResultStage 11 (count at MyLinearRegressionImpl.scala:26) finished in 0.166 s
[13:08:44,292] INFO  {DAGScheduler} Job 9 finished: count at MyLinearRegressionImpl.scala:26, took 0.174754 s
[13:08:44,299] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:44,300] INFO  {DAGScheduler} Got job 10 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:44,300] INFO  {DAGScheduler} Final stage: ResultStage 12 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:44,300] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:44,300] INFO  {DAGScheduler} Missing parents: List()
[13:08:44,300] INFO  {DAGScheduler} Submitting ResultStage 12 (MapPartitionsRDD[27] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:44,302] INFO  {MemoryStore} Block broadcast_17 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:44,304] INFO  {MemoryStore} Block broadcast_17_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:44,304] INFO  {BlockManagerInfo} Added broadcast_17_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:44,305] INFO  {SparkContext} Created broadcast 17 from broadcast at DAGScheduler.scala:1012
[13:08:44,305] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[27] at map at MyLinearRegressionImpl.scala:54)
[13:08:44,305] INFO  {TaskSchedulerImpl} Adding task set 12.0 with 1 tasks
[13:08:44,306] INFO  {TaskSetManager} Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5959 bytes)
[13:08:44,306] INFO  {Executor} Running task 0.0 in stage 12.0 (TID 12)
[13:08:44,312] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:44,489] INFO  {BlockManagerInfo} Removed broadcast_15_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:44,490] INFO  {BlockManagerInfo} Removed broadcast_16_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.9 MB)
[13:08:44,531] INFO  {Executor} Finished task 0.0 in stage 12.0 (TID 12). 2572 bytes result sent to driver
[13:08:44,532] INFO  {TaskSetManager} Finished task 0.0 in stage 12.0 (TID 12) in 227 ms on localhost (1/1)
[13:08:44,532] INFO  {TaskSchedulerImpl} Removed TaskSet 12.0, whose tasks have all completed, from pool 
[13:08:44,532] INFO  {DAGScheduler} ResultStage 12 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.227 s
[13:08:44,533] INFO  {DAGScheduler} Job 10 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.233700 s
[13:08:44,539] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:44,539] INFO  {DAGScheduler} Got job 11 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:44,539] INFO  {DAGScheduler} Final stage: ResultStage 13 (sum at MyLinearRegressionImpl.scala:24)
[13:08:44,539] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:44,540] INFO  {DAGScheduler} Missing parents: List()
[13:08:44,540] INFO  {DAGScheduler} Submitting ResultStage 13 (MapPartitionsRDD[29] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:44,542] INFO  {MemoryStore} Block broadcast_18 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:08:44,544] INFO  {MemoryStore} Block broadcast_18_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:44,544] INFO  {BlockManagerInfo} Added broadcast_18_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:44,545] INFO  {SparkContext} Created broadcast 18 from broadcast at DAGScheduler.scala:1012
[13:08:44,545] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[29] at map at MyLinearRegressionImpl.scala:22)
[13:08:44,545] INFO  {TaskSchedulerImpl} Adding task set 13.0 with 1 tasks
[13:08:44,547] INFO  {TaskSetManager} Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5956 bytes)
[13:08:44,547] INFO  {Executor} Running task 0.0 in stage 13.0 (TID 13)
[13:08:44,554] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:44,717] INFO  {Executor} Finished task 0.0 in stage 13.0 (TID 13). 1685 bytes result sent to driver
[13:08:44,718] INFO  {TaskSetManager} Finished task 0.0 in stage 13.0 (TID 13) in 173 ms on localhost (1/1)
[13:08:44,718] INFO  {TaskSchedulerImpl} Removed TaskSet 13.0, whose tasks have all completed, from pool 
[13:08:44,719] INFO  {DAGScheduler} ResultStage 13 (sum at MyLinearRegressionImpl.scala:24) finished in 0.174 s
[13:08:44,719] INFO  {DAGScheduler} Job 11 finished: sum at MyLinearRegressionImpl.scala:24, took 0.180467 s
[13:08:44,722] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:44,723] INFO  {DAGScheduler} Got job 12 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:44,723] INFO  {DAGScheduler} Final stage: ResultStage 14 (count at MyLinearRegressionImpl.scala:26)
[13:08:44,723] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:44,724] INFO  {DAGScheduler} Missing parents: List()
[13:08:44,724] INFO  {DAGScheduler} Submitting ResultStage 14 (MapPartitionsRDD[28] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:44,727] INFO  {MemoryStore} Block broadcast_19 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:44,729] INFO  {MemoryStore} Block broadcast_19_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:44,729] INFO  {BlockManagerInfo} Added broadcast_19_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:44,730] INFO  {SparkContext} Created broadcast 19 from broadcast at DAGScheduler.scala:1012
[13:08:44,730] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[28] at map at MyLinearRegressionImpl.scala:36)
[13:08:44,730] INFO  {TaskSchedulerImpl} Adding task set 14.0 with 1 tasks
[13:08:44,732] INFO  {TaskSetManager} Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:44,732] INFO  {Executor} Running task 0.0 in stage 14.0 (TID 14)
[13:08:44,741] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:44,913] INFO  {Executor} Finished task 0.0 in stage 14.0 (TID 14). 1683 bytes result sent to driver
[13:08:44,914] INFO  {TaskSetManager} Finished task 0.0 in stage 14.0 (TID 14) in 183 ms on localhost (1/1)
[13:08:44,914] INFO  {TaskSchedulerImpl} Removed TaskSet 14.0, whose tasks have all completed, from pool 
[13:08:44,914] INFO  {DAGScheduler} ResultStage 14 (count at MyLinearRegressionImpl.scala:26) finished in 0.183 s
[13:08:44,915] INFO  {DAGScheduler} Job 12 finished: count at MyLinearRegressionImpl.scala:26, took 0.192410 s
[13:08:44,918] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:44,919] INFO  {DAGScheduler} Got job 13 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:44,919] INFO  {DAGScheduler} Final stage: ResultStage 15 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:44,919] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:44,919] INFO  {DAGScheduler} Missing parents: List()
[13:08:44,919] INFO  {DAGScheduler} Submitting ResultStage 15 (MapPartitionsRDD[30] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:44,924] INFO  {MemoryStore} Block broadcast_20 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:44,924] INFO  {BlockManagerInfo} Removed broadcast_19_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:44,926] INFO  {BlockManagerInfo} Removed broadcast_17_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:44,926] INFO  {MemoryStore} Block broadcast_20_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:44,926] INFO  {BlockManagerInfo} Added broadcast_20_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:44,927] INFO  {SparkContext} Created broadcast 20 from broadcast at DAGScheduler.scala:1012
[13:08:44,927] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[30] at map at MyLinearRegressionImpl.scala:54)
[13:08:44,927] INFO  {BlockManagerInfo} Removed broadcast_18_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:44,927] INFO  {TaskSchedulerImpl} Adding task set 15.0 with 1 tasks
[13:08:44,929] INFO  {TaskSetManager} Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, PROCESS_LOCAL, 5959 bytes)
[13:08:44,929] INFO  {Executor} Running task 0.0 in stage 15.0 (TID 15)
[13:08:44,935] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:45,089] INFO  {Executor} Finished task 0.0 in stage 15.0 (TID 15). 2499 bytes result sent to driver
[13:08:45,090] INFO  {TaskSetManager} Finished task 0.0 in stage 15.0 (TID 15) in 163 ms on localhost (1/1)
[13:08:45,090] INFO  {TaskSchedulerImpl} Removed TaskSet 15.0, whose tasks have all completed, from pool 
[13:08:45,090] INFO  {DAGScheduler} ResultStage 15 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.163 s
[13:08:45,091] INFO  {DAGScheduler} Job 13 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.172514 s
[13:08:45,096] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:45,097] INFO  {DAGScheduler} Got job 14 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:45,097] INFO  {DAGScheduler} Final stage: ResultStage 16 (sum at MyLinearRegressionImpl.scala:24)
[13:08:45,097] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:45,097] INFO  {DAGScheduler} Missing parents: List()
[13:08:45,098] INFO  {DAGScheduler} Submitting ResultStage 16 (MapPartitionsRDD[32] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:45,100] INFO  {MemoryStore} Block broadcast_21 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:08:45,101] INFO  {MemoryStore} Block broadcast_21_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:45,102] INFO  {BlockManagerInfo} Added broadcast_21_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:45,102] INFO  {SparkContext} Created broadcast 21 from broadcast at DAGScheduler.scala:1012
[13:08:45,102] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[32] at map at MyLinearRegressionImpl.scala:22)
[13:08:45,102] INFO  {TaskSchedulerImpl} Adding task set 16.0 with 1 tasks
[13:08:45,104] INFO  {TaskSetManager} Starting task 0.0 in stage 16.0 (TID 16, localhost, partition 0, PROCESS_LOCAL, 5956 bytes)
[13:08:45,104] INFO  {Executor} Running task 0.0 in stage 16.0 (TID 16)
[13:08:45,111] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:45,260] INFO  {Executor} Finished task 0.0 in stage 16.0 (TID 16). 1685 bytes result sent to driver
[13:08:45,261] INFO  {TaskSetManager} Finished task 0.0 in stage 16.0 (TID 16) in 158 ms on localhost (1/1)
[13:08:45,261] INFO  {TaskSchedulerImpl} Removed TaskSet 16.0, whose tasks have all completed, from pool 
[13:08:45,261] INFO  {DAGScheduler} ResultStage 16 (sum at MyLinearRegressionImpl.scala:24) finished in 0.158 s
[13:08:45,262] INFO  {DAGScheduler} Job 14 finished: sum at MyLinearRegressionImpl.scala:24, took 0.165360 s
[13:08:45,264] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:45,265] INFO  {DAGScheduler} Got job 15 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:45,265] INFO  {DAGScheduler} Final stage: ResultStage 17 (count at MyLinearRegressionImpl.scala:26)
[13:08:45,265] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:45,266] INFO  {DAGScheduler} Missing parents: List()
[13:08:45,266] INFO  {DAGScheduler} Submitting ResultStage 17 (MapPartitionsRDD[31] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:45,267] INFO  {MemoryStore} Block broadcast_22 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:45,269] INFO  {MemoryStore} Block broadcast_22_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:45,269] INFO  {BlockManagerInfo} Added broadcast_22_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:45,270] INFO  {SparkContext} Created broadcast 22 from broadcast at DAGScheduler.scala:1012
[13:08:45,270] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[31] at map at MyLinearRegressionImpl.scala:36)
[13:08:45,270] INFO  {TaskSchedulerImpl} Adding task set 17.0 with 1 tasks
[13:08:45,272] INFO  {TaskSetManager} Starting task 0.0 in stage 17.0 (TID 17, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:45,272] INFO  {Executor} Running task 0.0 in stage 17.0 (TID 17)
[13:08:45,277] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:45,423] INFO  {BlockManagerInfo} Removed broadcast_20_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:45,424] INFO  {BlockManagerInfo} Removed broadcast_21_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:45,460] INFO  {Executor} Finished task 0.0 in stage 17.0 (TID 17). 1756 bytes result sent to driver
[13:08:45,461] INFO  {TaskSetManager} Finished task 0.0 in stage 17.0 (TID 17) in 190 ms on localhost (1/1)
[13:08:45,461] INFO  {TaskSchedulerImpl} Removed TaskSet 17.0, whose tasks have all completed, from pool 
[13:08:45,461] INFO  {DAGScheduler} ResultStage 17 (count at MyLinearRegressionImpl.scala:26) finished in 0.190 s
[13:08:45,462] INFO  {DAGScheduler} Job 15 finished: count at MyLinearRegressionImpl.scala:26, took 0.197214 s
[13:08:45,464] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:45,465] INFO  {DAGScheduler} Got job 16 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:45,465] INFO  {DAGScheduler} Final stage: ResultStage 18 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:45,465] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:45,465] INFO  {DAGScheduler} Missing parents: List()
[13:08:45,465] INFO  {DAGScheduler} Submitting ResultStage 18 (MapPartitionsRDD[33] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:45,467] INFO  {MemoryStore} Block broadcast_23 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:45,468] INFO  {MemoryStore} Block broadcast_23_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:45,469] INFO  {BlockManagerInfo} Added broadcast_23_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:45,469] INFO  {SparkContext} Created broadcast 23 from broadcast at DAGScheduler.scala:1012
[13:08:45,469] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[33] at map at MyLinearRegressionImpl.scala:54)
[13:08:45,469] INFO  {TaskSchedulerImpl} Adding task set 18.0 with 1 tasks
[13:08:45,471] INFO  {TaskSetManager} Starting task 0.0 in stage 18.0 (TID 18, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:45,471] INFO  {Executor} Running task 0.0 in stage 18.0 (TID 18)
[13:08:45,476] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:45,623] INFO  {Executor} Finished task 0.0 in stage 18.0 (TID 18). 2499 bytes result sent to driver
[13:08:45,624] INFO  {TaskSetManager} Finished task 0.0 in stage 18.0 (TID 18) in 154 ms on localhost (1/1)
[13:08:45,624] INFO  {TaskSchedulerImpl} Removed TaskSet 18.0, whose tasks have all completed, from pool 
[13:08:45,625] INFO  {DAGScheduler} ResultStage 18 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.155 s
[13:08:45,625] INFO  {DAGScheduler} Job 16 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.160531 s
[13:08:45,632] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:45,633] INFO  {DAGScheduler} Got job 17 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:45,633] INFO  {DAGScheduler} Final stage: ResultStage 19 (sum at MyLinearRegressionImpl.scala:24)
[13:08:45,633] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:45,633] INFO  {DAGScheduler} Missing parents: List()
[13:08:45,633] INFO  {DAGScheduler} Submitting ResultStage 19 (MapPartitionsRDD[35] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:45,635] INFO  {MemoryStore} Block broadcast_24 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:45,637] INFO  {MemoryStore} Block broadcast_24_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:45,638] INFO  {BlockManagerInfo} Added broadcast_24_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:45,638] INFO  {SparkContext} Created broadcast 24 from broadcast at DAGScheduler.scala:1012
[13:08:45,639] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[35] at map at MyLinearRegressionImpl.scala:22)
[13:08:45,639] INFO  {TaskSchedulerImpl} Adding task set 19.0 with 1 tasks
[13:08:45,641] INFO  {TaskSetManager} Starting task 0.0 in stage 19.0 (TID 19, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:45,641] INFO  {Executor} Running task 0.0 in stage 19.0 (TID 19)
[13:08:45,648] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:45,791] INFO  {Executor} Finished task 0.0 in stage 19.0 (TID 19). 1685 bytes result sent to driver
[13:08:45,792] INFO  {TaskSetManager} Finished task 0.0 in stage 19.0 (TID 19) in 153 ms on localhost (1/1)
[13:08:45,792] INFO  {TaskSchedulerImpl} Removed TaskSet 19.0, whose tasks have all completed, from pool 
[13:08:45,793] INFO  {DAGScheduler} ResultStage 19 (sum at MyLinearRegressionImpl.scala:24) finished in 0.154 s
[13:08:45,793] INFO  {DAGScheduler} Job 17 finished: sum at MyLinearRegressionImpl.scala:24, took 0.160788 s
[13:08:45,796] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:45,797] INFO  {DAGScheduler} Got job 18 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:45,797] INFO  {DAGScheduler} Final stage: ResultStage 20 (count at MyLinearRegressionImpl.scala:26)
[13:08:45,797] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:45,797] INFO  {DAGScheduler} Missing parents: List()
[13:08:45,797] INFO  {DAGScheduler} Submitting ResultStage 20 (MapPartitionsRDD[34] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:45,799] INFO  {MemoryStore} Block broadcast_25 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:45,801] INFO  {MemoryStore} Block broadcast_25_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:45,801] INFO  {BlockManagerInfo} Added broadcast_25_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:45,802] INFO  {SparkContext} Created broadcast 25 from broadcast at DAGScheduler.scala:1012
[13:08:45,802] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[34] at map at MyLinearRegressionImpl.scala:36)
[13:08:45,802] INFO  {TaskSchedulerImpl} Adding task set 20.0 with 1 tasks
[13:08:45,804] INFO  {TaskSetManager} Starting task 0.0 in stage 20.0 (TID 20, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:45,804] INFO  {Executor} Running task 0.0 in stage 20.0 (TID 20)
[13:08:45,809] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:45,890] INFO  {BlockManagerInfo} Removed broadcast_22_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:45,891] INFO  {BlockManagerInfo} Removed broadcast_23_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:45,893] INFO  {BlockManagerInfo} Removed broadcast_24_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:45,967] INFO  {Executor} Finished task 0.0 in stage 20.0 (TID 20). 1756 bytes result sent to driver
[13:08:45,968] INFO  {TaskSetManager} Finished task 0.0 in stage 20.0 (TID 20) in 165 ms on localhost (1/1)
[13:08:45,968] INFO  {TaskSchedulerImpl} Removed TaskSet 20.0, whose tasks have all completed, from pool 
[13:08:45,968] INFO  {DAGScheduler} ResultStage 20 (count at MyLinearRegressionImpl.scala:26) finished in 0.166 s
[13:08:45,969] INFO  {DAGScheduler} Job 18 finished: count at MyLinearRegressionImpl.scala:26, took 0.172763 s
[13:08:45,973] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:45,973] INFO  {DAGScheduler} Got job 19 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:45,973] INFO  {DAGScheduler} Final stage: ResultStage 21 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:45,974] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:45,974] INFO  {DAGScheduler} Missing parents: List()
[13:08:45,974] INFO  {DAGScheduler} Submitting ResultStage 21 (MapPartitionsRDD[36] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:45,976] INFO  {MemoryStore} Block broadcast_26 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:45,978] INFO  {MemoryStore} Block broadcast_26_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:45,979] INFO  {BlockManagerInfo} Added broadcast_26_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:45,979] INFO  {SparkContext} Created broadcast 26 from broadcast at DAGScheduler.scala:1012
[13:08:45,979] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[36] at map at MyLinearRegressionImpl.scala:54)
[13:08:45,979] INFO  {TaskSchedulerImpl} Adding task set 21.0 with 1 tasks
[13:08:45,981] INFO  {TaskSetManager} Starting task 0.0 in stage 21.0 (TID 21, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:45,981] INFO  {Executor} Running task 0.0 in stage 21.0 (TID 21)
[13:08:45,986] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:46,132] INFO  {Executor} Finished task 0.0 in stage 21.0 (TID 21). 2499 bytes result sent to driver
[13:08:46,133] INFO  {TaskSetManager} Finished task 0.0 in stage 21.0 (TID 21) in 153 ms on localhost (1/1)
[13:08:46,133] INFO  {TaskSchedulerImpl} Removed TaskSet 21.0, whose tasks have all completed, from pool 
[13:08:46,133] INFO  {DAGScheduler} ResultStage 21 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.153 s
[13:08:46,134] INFO  {DAGScheduler} Job 19 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.161023 s
[13:08:46,140] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:46,141] INFO  {DAGScheduler} Got job 20 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:46,141] INFO  {DAGScheduler} Final stage: ResultStage 22 (sum at MyLinearRegressionImpl.scala:24)
[13:08:46,141] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:46,141] INFO  {DAGScheduler} Missing parents: List()
[13:08:46,141] INFO  {DAGScheduler} Submitting ResultStage 22 (MapPartitionsRDD[38] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:46,143] INFO  {MemoryStore} Block broadcast_27 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:46,145] INFO  {MemoryStore} Block broadcast_27_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:46,145] INFO  {BlockManagerInfo} Added broadcast_27_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:46,145] INFO  {SparkContext} Created broadcast 27 from broadcast at DAGScheduler.scala:1012
[13:08:46,146] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[38] at map at MyLinearRegressionImpl.scala:22)
[13:08:46,146] INFO  {TaskSchedulerImpl} Adding task set 22.0 with 1 tasks
[13:08:46,147] INFO  {TaskSetManager} Starting task 0.0 in stage 22.0 (TID 22, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:46,147] INFO  {Executor} Running task 0.0 in stage 22.0 (TID 22)
[13:08:46,152] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:46,304] INFO  {Executor} Finished task 0.0 in stage 22.0 (TID 22). 1685 bytes result sent to driver
[13:08:46,305] INFO  {TaskSetManager} Finished task 0.0 in stage 22.0 (TID 22) in 159 ms on localhost (1/1)
[13:08:46,305] INFO  {TaskSchedulerImpl} Removed TaskSet 22.0, whose tasks have all completed, from pool 
[13:08:46,305] INFO  {DAGScheduler} ResultStage 22 (sum at MyLinearRegressionImpl.scala:24) finished in 0.159 s
[13:08:46,305] INFO  {DAGScheduler} Job 20 finished: sum at MyLinearRegressionImpl.scala:24, took 0.165336 s
[13:08:46,308] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:46,308] INFO  {DAGScheduler} Got job 21 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:46,308] INFO  {DAGScheduler} Final stage: ResultStage 23 (count at MyLinearRegressionImpl.scala:26)
[13:08:46,308] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:46,309] INFO  {DAGScheduler} Missing parents: List()
[13:08:46,309] INFO  {DAGScheduler} Submitting ResultStage 23 (MapPartitionsRDD[37] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:46,310] INFO  {MemoryStore} Block broadcast_28 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:46,312] INFO  {MemoryStore} Block broadcast_28_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:46,312] INFO  {BlockManagerInfo} Added broadcast_28_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:46,313] INFO  {SparkContext} Created broadcast 28 from broadcast at DAGScheduler.scala:1012
[13:08:46,313] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[37] at map at MyLinearRegressionImpl.scala:36)
[13:08:46,313] INFO  {TaskSchedulerImpl} Adding task set 23.0 with 1 tasks
[13:08:46,315] INFO  {TaskSetManager} Starting task 0.0 in stage 23.0 (TID 23, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:46,316] INFO  {Executor} Running task 0.0 in stage 23.0 (TID 23)
[13:08:46,321] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:46,418] INFO  {BlockManagerInfo} Removed broadcast_25_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:46,419] INFO  {BlockManagerInfo} Removed broadcast_26_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:46,420] INFO  {BlockManagerInfo} Removed broadcast_27_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:46,493] INFO  {Executor} Finished task 0.0 in stage 23.0 (TID 23). 1756 bytes result sent to driver
[13:08:46,494] INFO  {TaskSetManager} Finished task 0.0 in stage 23.0 (TID 23) in 181 ms on localhost (1/1)
[13:08:46,494] INFO  {TaskSchedulerImpl} Removed TaskSet 23.0, whose tasks have all completed, from pool 
[13:08:46,494] INFO  {DAGScheduler} ResultStage 23 (count at MyLinearRegressionImpl.scala:26) finished in 0.181 s
[13:08:46,495] INFO  {DAGScheduler} Job 21 finished: count at MyLinearRegressionImpl.scala:26, took 0.186980 s
[13:08:46,498] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:46,499] INFO  {DAGScheduler} Got job 22 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:46,499] INFO  {DAGScheduler} Final stage: ResultStage 24 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:46,499] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:46,499] INFO  {DAGScheduler} Missing parents: List()
[13:08:46,499] INFO  {DAGScheduler} Submitting ResultStage 24 (MapPartitionsRDD[39] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:46,500] INFO  {MemoryStore} Block broadcast_29 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:46,502] INFO  {MemoryStore} Block broadcast_29_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:46,502] INFO  {BlockManagerInfo} Added broadcast_29_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:46,502] INFO  {SparkContext} Created broadcast 29 from broadcast at DAGScheduler.scala:1012
[13:08:46,503] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[39] at map at MyLinearRegressionImpl.scala:54)
[13:08:46,503] INFO  {TaskSchedulerImpl} Adding task set 24.0 with 1 tasks
[13:08:46,504] INFO  {TaskSetManager} Starting task 0.0 in stage 24.0 (TID 24, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:46,504] INFO  {Executor} Running task 0.0 in stage 24.0 (TID 24)
[13:08:46,509] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:46,663] INFO  {Executor} Finished task 0.0 in stage 24.0 (TID 24). 2586 bytes result sent to driver
[13:08:46,664] INFO  {TaskSetManager} Finished task 0.0 in stage 24.0 (TID 24) in 161 ms on localhost (1/1)
[13:08:46,664] INFO  {TaskSchedulerImpl} Removed TaskSet 24.0, whose tasks have all completed, from pool 
[13:08:46,664] INFO  {DAGScheduler} ResultStage 24 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.161 s
[13:08:46,665] INFO  {DAGScheduler} Job 22 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.166341 s
[13:08:46,670] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:46,671] INFO  {DAGScheduler} Got job 23 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:46,671] INFO  {DAGScheduler} Final stage: ResultStage 25 (sum at MyLinearRegressionImpl.scala:24)
[13:08:46,671] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:46,672] INFO  {DAGScheduler} Missing parents: List()
[13:08:46,672] INFO  {DAGScheduler} Submitting ResultStage 25 (MapPartitionsRDD[41] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:46,674] INFO  {MemoryStore} Block broadcast_30 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:46,675] INFO  {MemoryStore} Block broadcast_30_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:46,676] INFO  {BlockManagerInfo} Added broadcast_30_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:46,677] INFO  {SparkContext} Created broadcast 30 from broadcast at DAGScheduler.scala:1012
[13:08:46,677] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[41] at map at MyLinearRegressionImpl.scala:22)
[13:08:46,677] INFO  {TaskSchedulerImpl} Adding task set 25.0 with 1 tasks
[13:08:46,678] INFO  {TaskSetManager} Starting task 0.0 in stage 25.0 (TID 25, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:46,679] INFO  {Executor} Running task 0.0 in stage 25.0 (TID 25)
[13:08:46,684] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:46,832] INFO  {Executor} Finished task 0.0 in stage 25.0 (TID 25). 1685 bytes result sent to driver
[13:08:46,833] INFO  {TaskSetManager} Finished task 0.0 in stage 25.0 (TID 25) in 156 ms on localhost (1/1)
[13:08:46,833] INFO  {TaskSchedulerImpl} Removed TaskSet 25.0, whose tasks have all completed, from pool 
[13:08:46,833] INFO  {DAGScheduler} ResultStage 25 (sum at MyLinearRegressionImpl.scala:24) finished in 0.156 s
[13:08:46,834] INFO  {DAGScheduler} Job 23 finished: sum at MyLinearRegressionImpl.scala:24, took 0.163111 s
[13:08:46,836] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:46,837] INFO  {DAGScheduler} Got job 24 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:46,837] INFO  {DAGScheduler} Final stage: ResultStage 26 (count at MyLinearRegressionImpl.scala:26)
[13:08:46,837] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:46,837] INFO  {DAGScheduler} Missing parents: List()
[13:08:46,837] INFO  {DAGScheduler} Submitting ResultStage 26 (MapPartitionsRDD[40] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:46,840] INFO  {MemoryStore} Block broadcast_31 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:46,842] INFO  {MemoryStore} Block broadcast_31_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:46,842] INFO  {BlockManagerInfo} Added broadcast_31_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:46,843] INFO  {SparkContext} Created broadcast 31 from broadcast at DAGScheduler.scala:1012
[13:08:46,843] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[40] at map at MyLinearRegressionImpl.scala:36)
[13:08:46,843] INFO  {TaskSchedulerImpl} Adding task set 26.0 with 1 tasks
[13:08:46,844] INFO  {TaskSetManager} Starting task 0.0 in stage 26.0 (TID 26, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:46,844] INFO  {Executor} Running task 0.0 in stage 26.0 (TID 26)
[13:08:46,850] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:46,934] INFO  {BlockManagerInfo} Removed broadcast_28_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:46,935] INFO  {BlockManagerInfo} Removed broadcast_29_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:46,935] INFO  {BlockManagerInfo} Removed broadcast_30_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:47,005] INFO  {Executor} Finished task 0.0 in stage 26.0 (TID 26). 1756 bytes result sent to driver
[13:08:47,006] INFO  {TaskSetManager} Finished task 0.0 in stage 26.0 (TID 26) in 163 ms on localhost (1/1)
[13:08:47,006] INFO  {TaskSchedulerImpl} Removed TaskSet 26.0, whose tasks have all completed, from pool 
[13:08:47,006] INFO  {DAGScheduler} ResultStage 26 (count at MyLinearRegressionImpl.scala:26) finished in 0.163 s
[13:08:47,007] INFO  {DAGScheduler} Job 24 finished: count at MyLinearRegressionImpl.scala:26, took 0.170423 s
[13:08:47,009] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:47,010] INFO  {DAGScheduler} Got job 25 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:47,010] INFO  {DAGScheduler} Final stage: ResultStage 27 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:47,010] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:47,010] INFO  {DAGScheduler} Missing parents: List()
[13:08:47,010] INFO  {DAGScheduler} Submitting ResultStage 27 (MapPartitionsRDD[42] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:47,012] INFO  {MemoryStore} Block broadcast_32 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:47,013] INFO  {MemoryStore} Block broadcast_32_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:47,013] INFO  {BlockManagerInfo} Added broadcast_32_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:47,014] INFO  {SparkContext} Created broadcast 32 from broadcast at DAGScheduler.scala:1012
[13:08:47,014] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[42] at map at MyLinearRegressionImpl.scala:54)
[13:08:47,014] INFO  {TaskSchedulerImpl} Adding task set 27.0 with 1 tasks
[13:08:47,015] INFO  {TaskSetManager} Starting task 0.0 in stage 27.0 (TID 27, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:47,015] INFO  {Executor} Running task 0.0 in stage 27.0 (TID 27)
[13:08:47,019] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:47,172] INFO  {Executor} Finished task 0.0 in stage 27.0 (TID 27). 2499 bytes result sent to driver
[13:08:47,173] INFO  {TaskSetManager} Finished task 0.0 in stage 27.0 (TID 27) in 159 ms on localhost (1/1)
[13:08:47,173] INFO  {TaskSchedulerImpl} Removed TaskSet 27.0, whose tasks have all completed, from pool 
[13:08:47,174] INFO  {DAGScheduler} ResultStage 27 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.159 s
[13:08:47,174] INFO  {DAGScheduler} Job 25 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.164505 s
[13:08:47,178] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:47,179] INFO  {DAGScheduler} Got job 26 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:47,179] INFO  {DAGScheduler} Final stage: ResultStage 28 (sum at MyLinearRegressionImpl.scala:24)
[13:08:47,179] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:47,179] INFO  {DAGScheduler} Missing parents: List()
[13:08:47,179] INFO  {DAGScheduler} Submitting ResultStage 28 (MapPartitionsRDD[44] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:47,181] INFO  {MemoryStore} Block broadcast_33 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:47,183] INFO  {MemoryStore} Block broadcast_33_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:47,183] INFO  {BlockManagerInfo} Added broadcast_33_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:47,184] INFO  {SparkContext} Created broadcast 33 from broadcast at DAGScheduler.scala:1012
[13:08:47,184] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[44] at map at MyLinearRegressionImpl.scala:22)
[13:08:47,184] INFO  {TaskSchedulerImpl} Adding task set 28.0 with 1 tasks
[13:08:47,185] INFO  {TaskSetManager} Starting task 0.0 in stage 28.0 (TID 28, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:47,186] INFO  {Executor} Running task 0.0 in stage 28.0 (TID 28)
[13:08:47,190] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:47,345] INFO  {Executor} Finished task 0.0 in stage 28.0 (TID 28). 1685 bytes result sent to driver
[13:08:47,345] INFO  {TaskSetManager} Finished task 0.0 in stage 28.0 (TID 28) in 161 ms on localhost (1/1)
[13:08:47,345] INFO  {TaskSchedulerImpl} Removed TaskSet 28.0, whose tasks have all completed, from pool 
[13:08:47,346] INFO  {DAGScheduler} ResultStage 28 (sum at MyLinearRegressionImpl.scala:24) finished in 0.162 s
[13:08:47,346] INFO  {DAGScheduler} Job 26 finished: sum at MyLinearRegressionImpl.scala:24, took 0.167905 s
[13:08:47,348] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:47,349] INFO  {DAGScheduler} Got job 27 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:47,349] INFO  {DAGScheduler} Final stage: ResultStage 29 (count at MyLinearRegressionImpl.scala:26)
[13:08:47,349] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:47,349] INFO  {DAGScheduler} Missing parents: List()
[13:08:47,349] INFO  {DAGScheduler} Submitting ResultStage 29 (MapPartitionsRDD[43] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:47,352] INFO  {MemoryStore} Block broadcast_34 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:47,353] INFO  {MemoryStore} Block broadcast_34_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:47,354] INFO  {BlockManagerInfo} Added broadcast_34_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:47,354] INFO  {SparkContext} Created broadcast 34 from broadcast at DAGScheduler.scala:1012
[13:08:47,355] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[43] at map at MyLinearRegressionImpl.scala:36)
[13:08:47,355] INFO  {TaskSchedulerImpl} Adding task set 29.0 with 1 tasks
[13:08:47,356] INFO  {TaskSetManager} Starting task 0.0 in stage 29.0 (TID 29, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:47,356] INFO  {Executor} Running task 0.0 in stage 29.0 (TID 29)
[13:08:47,361] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:47,505] INFO  {BlockManagerInfo} Removed broadcast_31_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:47,506] INFO  {BlockManagerInfo} Removed broadcast_32_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:47,507] INFO  {BlockManagerInfo} Removed broadcast_33_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:47,540] INFO  {Executor} Finished task 0.0 in stage 29.0 (TID 29). 1756 bytes result sent to driver
[13:08:47,541] INFO  {TaskSetManager} Finished task 0.0 in stage 29.0 (TID 29) in 186 ms on localhost (1/1)
[13:08:47,541] INFO  {TaskSchedulerImpl} Removed TaskSet 29.0, whose tasks have all completed, from pool 
[13:08:47,541] INFO  {DAGScheduler} ResultStage 29 (count at MyLinearRegressionImpl.scala:26) finished in 0.186 s
[13:08:47,541] INFO  {DAGScheduler} Job 27 finished: count at MyLinearRegressionImpl.scala:26, took 0.193155 s
[13:08:47,544] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:47,545] INFO  {DAGScheduler} Got job 28 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:47,545] INFO  {DAGScheduler} Final stage: ResultStage 30 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:47,545] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:47,545] INFO  {DAGScheduler} Missing parents: List()
[13:08:47,545] INFO  {DAGScheduler} Submitting ResultStage 30 (MapPartitionsRDD[45] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:47,546] INFO  {MemoryStore} Block broadcast_35 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:47,547] INFO  {MemoryStore} Block broadcast_35_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:47,548] INFO  {BlockManagerInfo} Added broadcast_35_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:47,548] INFO  {SparkContext} Created broadcast 35 from broadcast at DAGScheduler.scala:1012
[13:08:47,548] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[45] at map at MyLinearRegressionImpl.scala:54)
[13:08:47,548] INFO  {TaskSchedulerImpl} Adding task set 30.0 with 1 tasks
[13:08:47,549] INFO  {TaskSetManager} Starting task 0.0 in stage 30.0 (TID 30, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:47,550] INFO  {Executor} Running task 0.0 in stage 30.0 (TID 30)
[13:08:47,554] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:47,703] INFO  {Executor} Finished task 0.0 in stage 30.0 (TID 30). 2499 bytes result sent to driver
[13:08:47,703] INFO  {TaskSetManager} Finished task 0.0 in stage 30.0 (TID 30) in 155 ms on localhost (1/1)
[13:08:47,703] INFO  {TaskSchedulerImpl} Removed TaskSet 30.0, whose tasks have all completed, from pool 
[13:08:47,704] INFO  {DAGScheduler} ResultStage 30 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.156 s
[13:08:47,704] INFO  {DAGScheduler} Job 28 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.159869 s
[13:08:47,709] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:47,709] INFO  {DAGScheduler} Got job 29 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:47,709] INFO  {DAGScheduler} Final stage: ResultStage 31 (sum at MyLinearRegressionImpl.scala:24)
[13:08:47,709] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:47,709] INFO  {DAGScheduler} Missing parents: List()
[13:08:47,710] INFO  {DAGScheduler} Submitting ResultStage 31 (MapPartitionsRDD[47] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:47,711] INFO  {MemoryStore} Block broadcast_36 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:47,713] INFO  {MemoryStore} Block broadcast_36_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:47,713] INFO  {BlockManagerInfo} Added broadcast_36_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:47,713] INFO  {SparkContext} Created broadcast 36 from broadcast at DAGScheduler.scala:1012
[13:08:47,714] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[47] at map at MyLinearRegressionImpl.scala:22)
[13:08:47,714] INFO  {TaskSchedulerImpl} Adding task set 31.0 with 1 tasks
[13:08:47,715] INFO  {TaskSetManager} Starting task 0.0 in stage 31.0 (TID 31, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:47,715] INFO  {Executor} Running task 0.0 in stage 31.0 (TID 31)
[13:08:47,719] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:47,869] INFO  {Executor} Finished task 0.0 in stage 31.0 (TID 31). 1685 bytes result sent to driver
[13:08:47,870] INFO  {TaskSetManager} Finished task 0.0 in stage 31.0 (TID 31) in 156 ms on localhost (1/1)
[13:08:47,870] INFO  {TaskSchedulerImpl} Removed TaskSet 31.0, whose tasks have all completed, from pool 
[13:08:47,871] INFO  {DAGScheduler} ResultStage 31 (sum at MyLinearRegressionImpl.scala:24) finished in 0.157 s
[13:08:47,871] INFO  {DAGScheduler} Job 29 finished: sum at MyLinearRegressionImpl.scala:24, took 0.162320 s
[13:08:47,874] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:47,875] INFO  {DAGScheduler} Got job 30 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:47,875] INFO  {DAGScheduler} Final stage: ResultStage 32 (count at MyLinearRegressionImpl.scala:26)
[13:08:47,875] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:47,875] INFO  {DAGScheduler} Missing parents: List()
[13:08:47,876] INFO  {DAGScheduler} Submitting ResultStage 32 (MapPartitionsRDD[46] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:47,878] INFO  {MemoryStore} Block broadcast_37 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:47,881] INFO  {MemoryStore} Block broadcast_37_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:47,881] INFO  {BlockManagerInfo} Added broadcast_37_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:47,882] INFO  {SparkContext} Created broadcast 37 from broadcast at DAGScheduler.scala:1012
[13:08:47,882] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[46] at map at MyLinearRegressionImpl.scala:36)
[13:08:47,882] INFO  {TaskSchedulerImpl} Adding task set 32.0 with 1 tasks
[13:08:47,884] INFO  {TaskSetManager} Starting task 0.0 in stage 32.0 (TID 32, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:47,885] INFO  {Executor} Running task 0.0 in stage 32.0 (TID 32)
[13:08:47,891] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:48,041] INFO  {Executor} Finished task 0.0 in stage 32.0 (TID 32). 1683 bytes result sent to driver
[13:08:48,045] INFO  {TaskSetManager} Finished task 0.0 in stage 32.0 (TID 32) in 161 ms on localhost (1/1)
[13:08:48,045] INFO  {TaskSchedulerImpl} Removed TaskSet 32.0, whose tasks have all completed, from pool 
[13:08:48,045] INFO  {BlockManagerInfo} Removed broadcast_34_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:48,045] INFO  {DAGScheduler} ResultStage 32 (count at MyLinearRegressionImpl.scala:26) finished in 0.163 s
[13:08:48,045] INFO  {DAGScheduler} Job 30 finished: count at MyLinearRegressionImpl.scala:26, took 0.170858 s
[13:08:48,046] INFO  {BlockManagerInfo} Removed broadcast_35_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:48,047] INFO  {BlockManagerInfo} Removed broadcast_36_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:48,048] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:48,049] INFO  {DAGScheduler} Got job 31 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:48,049] INFO  {DAGScheduler} Final stage: ResultStage 33 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:48,049] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:48,049] INFO  {DAGScheduler} Missing parents: List()
[13:08:48,049] INFO  {DAGScheduler} Submitting ResultStage 33 (MapPartitionsRDD[48] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:48,051] INFO  {MemoryStore} Block broadcast_38 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:48,052] INFO  {MemoryStore} Block broadcast_38_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:48,052] INFO  {BlockManagerInfo} Added broadcast_38_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:48,052] INFO  {SparkContext} Created broadcast 38 from broadcast at DAGScheduler.scala:1012
[13:08:48,053] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[48] at map at MyLinearRegressionImpl.scala:54)
[13:08:48,053] INFO  {TaskSchedulerImpl} Adding task set 33.0 with 1 tasks
[13:08:48,054] INFO  {TaskSetManager} Starting task 0.0 in stage 33.0 (TID 33, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:48,054] INFO  {Executor} Running task 0.0 in stage 33.0 (TID 33)
[13:08:48,059] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:48,219] INFO  {Executor} Finished task 0.0 in stage 33.0 (TID 33). 2499 bytes result sent to driver
[13:08:48,220] INFO  {TaskSetManager} Finished task 0.0 in stage 33.0 (TID 33) in 167 ms on localhost (1/1)
[13:08:48,220] INFO  {TaskSchedulerImpl} Removed TaskSet 33.0, whose tasks have all completed, from pool 
[13:08:48,220] INFO  {DAGScheduler} ResultStage 33 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.167 s
[13:08:48,221] INFO  {DAGScheduler} Job 31 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.172191 s
[13:08:48,225] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:48,225] INFO  {DAGScheduler} Got job 32 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:48,225] INFO  {DAGScheduler} Final stage: ResultStage 34 (sum at MyLinearRegressionImpl.scala:24)
[13:08:48,225] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:48,225] INFO  {DAGScheduler} Missing parents: List()
[13:08:48,226] INFO  {DAGScheduler} Submitting ResultStage 34 (MapPartitionsRDD[50] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:48,227] INFO  {MemoryStore} Block broadcast_39 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:48,228] INFO  {MemoryStore} Block broadcast_39_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:48,229] INFO  {BlockManagerInfo} Added broadcast_39_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:48,229] INFO  {SparkContext} Created broadcast 39 from broadcast at DAGScheduler.scala:1012
[13:08:48,229] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[50] at map at MyLinearRegressionImpl.scala:22)
[13:08:48,229] INFO  {TaskSchedulerImpl} Adding task set 34.0 with 1 tasks
[13:08:48,230] INFO  {TaskSetManager} Starting task 0.0 in stage 34.0 (TID 34, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:48,230] INFO  {Executor} Running task 0.0 in stage 34.0 (TID 34)
[13:08:48,234] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:48,389] INFO  {Executor} Finished task 0.0 in stage 34.0 (TID 34). 1685 bytes result sent to driver
[13:08:48,389] INFO  {TaskSetManager} Finished task 0.0 in stage 34.0 (TID 34) in 159 ms on localhost (1/1)
[13:08:48,390] INFO  {TaskSchedulerImpl} Removed TaskSet 34.0, whose tasks have all completed, from pool 
[13:08:48,390] INFO  {DAGScheduler} ResultStage 34 (sum at MyLinearRegressionImpl.scala:24) finished in 0.161 s
[13:08:48,390] INFO  {DAGScheduler} Job 32 finished: sum at MyLinearRegressionImpl.scala:24, took 0.165118 s
[13:08:48,392] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:48,392] INFO  {DAGScheduler} Got job 33 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:48,393] INFO  {DAGScheduler} Final stage: ResultStage 35 (count at MyLinearRegressionImpl.scala:26)
[13:08:48,393] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:48,393] INFO  {DAGScheduler} Missing parents: List()
[13:08:48,393] INFO  {DAGScheduler} Submitting ResultStage 35 (MapPartitionsRDD[49] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:48,395] INFO  {MemoryStore} Block broadcast_40 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:48,396] INFO  {MemoryStore} Block broadcast_40_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:48,396] INFO  {BlockManagerInfo} Added broadcast_40_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:48,397] INFO  {SparkContext} Created broadcast 40 from broadcast at DAGScheduler.scala:1012
[13:08:48,397] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[49] at map at MyLinearRegressionImpl.scala:36)
[13:08:48,397] INFO  {TaskSchedulerImpl} Adding task set 35.0 with 1 tasks
[13:08:48,398] INFO  {TaskSetManager} Starting task 0.0 in stage 35.0 (TID 35, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:48,398] INFO  {Executor} Running task 0.0 in stage 35.0 (TID 35)
[13:08:48,403] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:48,556] INFO  {Executor} Finished task 0.0 in stage 35.0 (TID 35). 1683 bytes result sent to driver
[13:08:48,557] INFO  {TaskSetManager} Finished task 0.0 in stage 35.0 (TID 35) in 159 ms on localhost (1/1)
[13:08:48,557] INFO  {TaskSchedulerImpl} Removed TaskSet 35.0, whose tasks have all completed, from pool 
[13:08:48,557] INFO  {DAGScheduler} ResultStage 35 (count at MyLinearRegressionImpl.scala:26) finished in 0.160 s
[13:08:48,557] INFO  {DAGScheduler} Job 33 finished: count at MyLinearRegressionImpl.scala:26, took 0.165033 s
[13:08:48,561] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:48,561] INFO  {DAGScheduler} Got job 34 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:48,561] INFO  {DAGScheduler} Final stage: ResultStage 36 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:48,561] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:48,562] INFO  {DAGScheduler} Missing parents: List()
[13:08:48,562] INFO  {DAGScheduler} Submitting ResultStage 36 (MapPartitionsRDD[51] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:48,564] INFO  {MemoryStore} Block broadcast_41 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:08:48,565] INFO  {MemoryStore} Block broadcast_41_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:08:48,566] INFO  {BlockManagerInfo} Added broadcast_41_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:48,566] INFO  {SparkContext} Created broadcast 41 from broadcast at DAGScheduler.scala:1012
[13:08:48,566] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[51] at map at MyLinearRegressionImpl.scala:54)
[13:08:48,566] INFO  {TaskSchedulerImpl} Adding task set 36.0 with 1 tasks
[13:08:48,568] INFO  {TaskSetManager} Starting task 0.0 in stage 36.0 (TID 36, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:48,568] INFO  {Executor} Running task 0.0 in stage 36.0 (TID 36)
[13:08:48,575] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:48,658] INFO  {BlockManagerInfo} Removed broadcast_37_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:48,659] INFO  {BlockManagerInfo} Removed broadcast_38_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:48,660] INFO  {BlockManagerInfo} Removed broadcast_39_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:48,661] INFO  {BlockManagerInfo} Removed broadcast_40_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.9 MB)
[13:08:48,748] INFO  {Executor} Finished task 0.0 in stage 36.0 (TID 36). 2572 bytes result sent to driver
[13:08:48,748] INFO  {TaskSetManager} Finished task 0.0 in stage 36.0 (TID 36) in 181 ms on localhost (1/1)
[13:08:48,748] INFO  {TaskSchedulerImpl} Removed TaskSet 36.0, whose tasks have all completed, from pool 
[13:08:48,749] INFO  {DAGScheduler} ResultStage 36 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.182 s
[13:08:48,749] INFO  {DAGScheduler} Job 34 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.187918 s
[13:08:48,753] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:48,754] INFO  {DAGScheduler} Got job 35 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:48,754] INFO  {DAGScheduler} Final stage: ResultStage 37 (sum at MyLinearRegressionImpl.scala:24)
[13:08:48,754] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:48,754] INFO  {DAGScheduler} Missing parents: List()
[13:08:48,754] INFO  {DAGScheduler} Submitting ResultStage 37 (MapPartitionsRDD[53] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:48,755] INFO  {MemoryStore} Block broadcast_42 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:08:48,757] INFO  {MemoryStore} Block broadcast_42_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:48,757] INFO  {BlockManagerInfo} Added broadcast_42_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:48,757] INFO  {SparkContext} Created broadcast 42 from broadcast at DAGScheduler.scala:1012
[13:08:48,757] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[53] at map at MyLinearRegressionImpl.scala:22)
[13:08:48,757] INFO  {TaskSchedulerImpl} Adding task set 37.0 with 1 tasks
[13:08:48,758] INFO  {TaskSetManager} Starting task 0.0 in stage 37.0 (TID 37, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:48,759] INFO  {Executor} Running task 0.0 in stage 37.0 (TID 37)
[13:08:48,762] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:48,912] INFO  {Executor} Finished task 0.0 in stage 37.0 (TID 37). 1685 bytes result sent to driver
[13:08:48,913] INFO  {TaskSetManager} Finished task 0.0 in stage 37.0 (TID 37) in 155 ms on localhost (1/1)
[13:08:48,913] INFO  {TaskSchedulerImpl} Removed TaskSet 37.0, whose tasks have all completed, from pool 
[13:08:48,913] INFO  {DAGScheduler} ResultStage 37 (sum at MyLinearRegressionImpl.scala:24) finished in 0.155 s
[13:08:48,913] INFO  {DAGScheduler} Job 35 finished: sum at MyLinearRegressionImpl.scala:24, took 0.160085 s
[13:08:48,916] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:48,916] INFO  {DAGScheduler} Got job 36 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:48,916] INFO  {DAGScheduler} Final stage: ResultStage 38 (count at MyLinearRegressionImpl.scala:26)
[13:08:48,916] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:48,916] INFO  {DAGScheduler} Missing parents: List()
[13:08:48,916] INFO  {DAGScheduler} Submitting ResultStage 38 (MapPartitionsRDD[52] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:48,918] INFO  {MemoryStore} Block broadcast_43 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:48,919] INFO  {MemoryStore} Block broadcast_43_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:48,919] INFO  {BlockManagerInfo} Added broadcast_43_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:48,920] INFO  {SparkContext} Created broadcast 43 from broadcast at DAGScheduler.scala:1012
[13:08:48,920] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[52] at map at MyLinearRegressionImpl.scala:36)
[13:08:48,920] INFO  {TaskSchedulerImpl} Adding task set 38.0 with 1 tasks
[13:08:48,921] INFO  {TaskSetManager} Starting task 0.0 in stage 38.0 (TID 38, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:48,921] INFO  {Executor} Running task 0.0 in stage 38.0 (TID 38)
[13:08:48,930] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:49,085] INFO  {Executor} Finished task 0.0 in stage 38.0 (TID 38). 1683 bytes result sent to driver
[13:08:49,086] INFO  {TaskSetManager} Finished task 0.0 in stage 38.0 (TID 38) in 166 ms on localhost (1/1)
[13:08:49,086] INFO  {TaskSchedulerImpl} Removed TaskSet 38.0, whose tasks have all completed, from pool 
[13:08:49,086] INFO  {DAGScheduler} ResultStage 38 (count at MyLinearRegressionImpl.scala:26) finished in 0.166 s
[13:08:49,087] INFO  {DAGScheduler} Job 36 finished: count at MyLinearRegressionImpl.scala:26, took 0.170879 s
[13:08:49,090] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:49,091] INFO  {DAGScheduler} Got job 37 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:49,091] INFO  {DAGScheduler} Final stage: ResultStage 39 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:49,091] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:49,091] INFO  {DAGScheduler} Missing parents: List()
[13:08:49,091] INFO  {DAGScheduler} Submitting ResultStage 39 (MapPartitionsRDD[54] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:49,093] INFO  {MemoryStore} Block broadcast_44 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:49,094] INFO  {MemoryStore} Block broadcast_44_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:49,095] INFO  {BlockManagerInfo} Added broadcast_44_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:49,095] INFO  {SparkContext} Created broadcast 44 from broadcast at DAGScheduler.scala:1012
[13:08:49,095] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[54] at map at MyLinearRegressionImpl.scala:54)
[13:08:49,095] INFO  {TaskSchedulerImpl} Adding task set 39.0 with 1 tasks
[13:08:49,097] INFO  {TaskSetManager} Starting task 0.0 in stage 39.0 (TID 39, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:49,097] INFO  {Executor} Running task 0.0 in stage 39.0 (TID 39)
[13:08:49,101] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:49,234] INFO  {BlockManagerInfo} Removed broadcast_41_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:49,235] INFO  {BlockManagerInfo} Removed broadcast_42_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:49,235] INFO  {BlockManagerInfo} Removed broadcast_43_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.9 MB)
[13:08:49,256] INFO  {Executor} Finished task 0.0 in stage 39.0 (TID 39). 2572 bytes result sent to driver
[13:08:49,256] INFO  {TaskSetManager} Finished task 0.0 in stage 39.0 (TID 39) in 160 ms on localhost (1/1)
[13:08:49,257] INFO  {TaskSchedulerImpl} Removed TaskSet 39.0, whose tasks have all completed, from pool 
[13:08:49,257] INFO  {DAGScheduler} ResultStage 39 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.161 s
[13:08:49,257] INFO  {DAGScheduler} Job 37 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.166831 s
[13:08:49,264] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:49,264] INFO  {DAGScheduler} Got job 38 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:49,264] INFO  {DAGScheduler} Final stage: ResultStage 40 (sum at MyLinearRegressionImpl.scala:24)
[13:08:49,264] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:49,265] INFO  {DAGScheduler} Missing parents: List()
[13:08:49,265] INFO  {DAGScheduler} Submitting ResultStage 40 (MapPartitionsRDD[56] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:49,266] INFO  {MemoryStore} Block broadcast_45 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:08:49,268] INFO  {MemoryStore} Block broadcast_45_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:49,268] INFO  {BlockManagerInfo} Added broadcast_45_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:49,269] INFO  {SparkContext} Created broadcast 45 from broadcast at DAGScheduler.scala:1012
[13:08:49,269] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[56] at map at MyLinearRegressionImpl.scala:22)
[13:08:49,269] INFO  {TaskSchedulerImpl} Adding task set 40.0 with 1 tasks
[13:08:49,270] INFO  {TaskSetManager} Starting task 0.0 in stage 40.0 (TID 40, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:49,270] INFO  {Executor} Running task 0.0 in stage 40.0 (TID 40)
[13:08:49,274] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:49,425] INFO  {Executor} Finished task 0.0 in stage 40.0 (TID 40). 1685 bytes result sent to driver
[13:08:49,425] INFO  {TaskSetManager} Finished task 0.0 in stage 40.0 (TID 40) in 156 ms on localhost (1/1)
[13:08:49,425] INFO  {TaskSchedulerImpl} Removed TaskSet 40.0, whose tasks have all completed, from pool 
[13:08:49,426] INFO  {DAGScheduler} ResultStage 40 (sum at MyLinearRegressionImpl.scala:24) finished in 0.157 s
[13:08:49,426] INFO  {DAGScheduler} Job 38 finished: sum at MyLinearRegressionImpl.scala:24, took 0.161991 s
[13:08:49,429] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:49,430] INFO  {DAGScheduler} Got job 39 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:49,430] INFO  {DAGScheduler} Final stage: ResultStage 41 (count at MyLinearRegressionImpl.scala:26)
[13:08:49,430] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:49,430] INFO  {DAGScheduler} Missing parents: List()
[13:08:49,430] INFO  {DAGScheduler} Submitting ResultStage 41 (MapPartitionsRDD[55] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:49,432] INFO  {MemoryStore} Block broadcast_46 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:49,433] INFO  {MemoryStore} Block broadcast_46_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:49,433] INFO  {BlockManagerInfo} Added broadcast_46_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:49,433] INFO  {SparkContext} Created broadcast 46 from broadcast at DAGScheduler.scala:1012
[13:08:49,434] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[55] at map at MyLinearRegressionImpl.scala:36)
[13:08:49,434] INFO  {TaskSchedulerImpl} Adding task set 41.0 with 1 tasks
[13:08:49,434] INFO  {TaskSetManager} Starting task 0.0 in stage 41.0 (TID 41, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:49,435] INFO  {Executor} Running task 0.0 in stage 41.0 (TID 41)
[13:08:49,439] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:49,585] INFO  {Executor} Finished task 0.0 in stage 41.0 (TID 41). 1683 bytes result sent to driver
[13:08:49,586] INFO  {TaskSetManager} Finished task 0.0 in stage 41.0 (TID 41) in 152 ms on localhost (1/1)
[13:08:49,586] INFO  {TaskSchedulerImpl} Removed TaskSet 41.0, whose tasks have all completed, from pool 
[13:08:49,586] INFO  {DAGScheduler} ResultStage 41 (count at MyLinearRegressionImpl.scala:26) finished in 0.152 s
[13:08:49,587] INFO  {DAGScheduler} Job 39 finished: count at MyLinearRegressionImpl.scala:26, took 0.157020 s
[13:08:49,590] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:49,591] INFO  {DAGScheduler} Got job 40 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:49,591] INFO  {DAGScheduler} Final stage: ResultStage 42 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:49,591] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:49,591] INFO  {DAGScheduler} Missing parents: List()
[13:08:49,591] INFO  {DAGScheduler} Submitting ResultStage 42 (MapPartitionsRDD[57] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:49,593] INFO  {MemoryStore} Block broadcast_47 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:49,595] INFO  {MemoryStore} Block broadcast_47_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:49,595] INFO  {BlockManagerInfo} Added broadcast_47_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:49,596] INFO  {SparkContext} Created broadcast 47 from broadcast at DAGScheduler.scala:1012
[13:08:49,596] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[57] at map at MyLinearRegressionImpl.scala:54)
[13:08:49,596] INFO  {TaskSchedulerImpl} Adding task set 42.0 with 1 tasks
[13:08:49,597] INFO  {TaskSetManager} Starting task 0.0 in stage 42.0 (TID 42, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:49,597] INFO  {Executor} Running task 0.0 in stage 42.0 (TID 42)
[13:08:49,604] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:49,759] INFO  {Executor} Finished task 0.0 in stage 42.0 (TID 42). 2499 bytes result sent to driver
[13:08:49,760] INFO  {TaskSetManager} Finished task 0.0 in stage 42.0 (TID 42) in 163 ms on localhost (1/1)
[13:08:49,760] INFO  {TaskSchedulerImpl} Removed TaskSet 42.0, whose tasks have all completed, from pool 
[13:08:49,760] INFO  {DAGScheduler} ResultStage 42 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.164 s
[13:08:49,760] INFO  {DAGScheduler} Job 40 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.169712 s
[13:08:49,766] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:49,767] INFO  {DAGScheduler} Got job 41 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:49,767] INFO  {DAGScheduler} Final stage: ResultStage 43 (sum at MyLinearRegressionImpl.scala:24)
[13:08:49,767] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:49,767] INFO  {DAGScheduler} Missing parents: List()
[13:08:49,767] INFO  {DAGScheduler} Submitting ResultStage 43 (MapPartitionsRDD[59] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:49,769] INFO  {MemoryStore} Block broadcast_48 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:08:49,771] INFO  {MemoryStore} Block broadcast_48_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:08:49,771] INFO  {BlockManagerInfo} Added broadcast_48_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:49,772] INFO  {SparkContext} Created broadcast 48 from broadcast at DAGScheduler.scala:1012
[13:08:49,772] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[59] at map at MyLinearRegressionImpl.scala:22)
[13:08:49,772] INFO  {TaskSchedulerImpl} Adding task set 43.0 with 1 tasks
[13:08:49,773] INFO  {TaskSetManager} Starting task 0.0 in stage 43.0 (TID 43, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:49,773] INFO  {Executor} Running task 0.0 in stage 43.0 (TID 43)
[13:08:49,776] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:49,865] INFO  {BlockManagerInfo} Removed broadcast_44_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:49,866] INFO  {BlockManagerInfo} Removed broadcast_45_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:49,866] INFO  {BlockManagerInfo} Removed broadcast_46_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:49,867] INFO  {BlockManagerInfo} Removed broadcast_47_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:49,948] INFO  {Executor} Finished task 0.0 in stage 43.0 (TID 43). 1758 bytes result sent to driver
[13:08:49,948] INFO  {TaskSetManager} Finished task 0.0 in stage 43.0 (TID 43) in 176 ms on localhost (1/1)
[13:08:49,948] INFO  {TaskSchedulerImpl} Removed TaskSet 43.0, whose tasks have all completed, from pool 
[13:08:49,948] INFO  {DAGScheduler} ResultStage 43 (sum at MyLinearRegressionImpl.scala:24) finished in 0.176 s
[13:08:49,949] INFO  {DAGScheduler} Job 41 finished: sum at MyLinearRegressionImpl.scala:24, took 0.182664 s
[13:08:49,951] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:49,951] INFO  {DAGScheduler} Got job 42 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:49,951] INFO  {DAGScheduler} Final stage: ResultStage 44 (count at MyLinearRegressionImpl.scala:26)
[13:08:49,951] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:49,951] INFO  {DAGScheduler} Missing parents: List()
[13:08:49,952] INFO  {DAGScheduler} Submitting ResultStage 44 (MapPartitionsRDD[58] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:49,953] INFO  {MemoryStore} Block broadcast_49 stored as values in memory (estimated size 45.0 KB, free 1128.6 MB)
[13:08:49,954] INFO  {MemoryStore} Block broadcast_49_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.6 MB)
[13:08:49,955] INFO  {BlockManagerInfo} Added broadcast_49_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:49,955] INFO  {SparkContext} Created broadcast 49 from broadcast at DAGScheduler.scala:1012
[13:08:49,955] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[58] at map at MyLinearRegressionImpl.scala:36)
[13:08:49,955] INFO  {TaskSchedulerImpl} Adding task set 44.0 with 1 tasks
[13:08:49,956] INFO  {TaskSetManager} Starting task 0.0 in stage 44.0 (TID 44, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:49,956] INFO  {Executor} Running task 0.0 in stage 44.0 (TID 44)
[13:08:49,961] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:50,109] INFO  {Executor} Finished task 0.0 in stage 44.0 (TID 44). 1683 bytes result sent to driver
[13:08:50,109] INFO  {TaskSetManager} Finished task 0.0 in stage 44.0 (TID 44) in 153 ms on localhost (1/1)
[13:08:50,109] INFO  {TaskSchedulerImpl} Removed TaskSet 44.0, whose tasks have all completed, from pool 
[13:08:50,109] INFO  {DAGScheduler} ResultStage 44 (count at MyLinearRegressionImpl.scala:26) finished in 0.153 s
[13:08:50,110] INFO  {DAGScheduler} Job 42 finished: count at MyLinearRegressionImpl.scala:26, took 0.158873 s
[13:08:50,113] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:50,114] INFO  {DAGScheduler} Got job 43 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:50,114] INFO  {DAGScheduler} Final stage: ResultStage 45 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:50,114] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:50,114] INFO  {DAGScheduler} Missing parents: List()
[13:08:50,114] INFO  {DAGScheduler} Submitting ResultStage 45 (MapPartitionsRDD[60] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:50,116] INFO  {MemoryStore} Block broadcast_50 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:50,118] INFO  {MemoryStore} Block broadcast_50_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:50,118] INFO  {BlockManagerInfo} Added broadcast_50_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:50,119] INFO  {SparkContext} Created broadcast 50 from broadcast at DAGScheduler.scala:1012
[13:08:50,119] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[60] at map at MyLinearRegressionImpl.scala:54)
[13:08:50,119] INFO  {TaskSchedulerImpl} Adding task set 45.0 with 1 tasks
[13:08:50,120] INFO  {TaskSetManager} Starting task 0.0 in stage 45.0 (TID 45, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:50,120] INFO  {Executor} Running task 0.0 in stage 45.0 (TID 45)
[13:08:50,125] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:50,277] INFO  {Executor} Finished task 0.0 in stage 45.0 (TID 45). 2499 bytes result sent to driver
[13:08:50,277] INFO  {TaskSetManager} Finished task 0.0 in stage 45.0 (TID 45) in 158 ms on localhost (1/1)
[13:08:50,277] INFO  {TaskSchedulerImpl} Removed TaskSet 45.0, whose tasks have all completed, from pool 
[13:08:50,278] INFO  {DAGScheduler} ResultStage 45 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.159 s
[13:08:50,278] INFO  {DAGScheduler} Job 43 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.164414 s
[13:08:50,282] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:50,283] INFO  {DAGScheduler} Got job 44 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:50,283] INFO  {DAGScheduler} Final stage: ResultStage 46 (sum at MyLinearRegressionImpl.scala:24)
[13:08:50,283] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:50,283] INFO  {DAGScheduler} Missing parents: List()
[13:08:50,283] INFO  {DAGScheduler} Submitting ResultStage 46 (MapPartitionsRDD[62] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:50,285] INFO  {MemoryStore} Block broadcast_51 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:50,287] INFO  {MemoryStore} Block broadcast_51_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:50,287] INFO  {BlockManagerInfo} Added broadcast_51_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:50,287] INFO  {SparkContext} Created broadcast 51 from broadcast at DAGScheduler.scala:1012
[13:08:50,287] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[62] at map at MyLinearRegressionImpl.scala:22)
[13:08:50,288] INFO  {TaskSchedulerImpl} Adding task set 46.0 with 1 tasks
[13:08:50,288] INFO  {TaskSetManager} Starting task 0.0 in stage 46.0 (TID 46, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:50,289] INFO  {Executor} Running task 0.0 in stage 46.0 (TID 46)
[13:08:50,293] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:50,439] INFO  {Executor} Finished task 0.0 in stage 46.0 (TID 46). 1685 bytes result sent to driver
[13:08:50,440] INFO  {TaskSetManager} Finished task 0.0 in stage 46.0 (TID 46) in 152 ms on localhost (1/1)
[13:08:50,440] INFO  {TaskSchedulerImpl} Removed TaskSet 46.0, whose tasks have all completed, from pool 
[13:08:50,440] INFO  {DAGScheduler} ResultStage 46 (sum at MyLinearRegressionImpl.scala:24) finished in 0.152 s
[13:08:50,440] INFO  {DAGScheduler} Job 44 finished: sum at MyLinearRegressionImpl.scala:24, took 0.158184 s
[13:08:50,443] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:50,443] INFO  {DAGScheduler} Got job 45 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:50,443] INFO  {DAGScheduler} Final stage: ResultStage 47 (count at MyLinearRegressionImpl.scala:26)
[13:08:50,443] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:50,443] INFO  {DAGScheduler} Missing parents: List()
[13:08:50,443] INFO  {DAGScheduler} Submitting ResultStage 47 (MapPartitionsRDD[61] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:50,445] INFO  {MemoryStore} Block broadcast_52 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:08:50,446] INFO  {MemoryStore} Block broadcast_52_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:08:50,446] INFO  {BlockManagerInfo} Added broadcast_52_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:50,447] INFO  {SparkContext} Created broadcast 52 from broadcast at DAGScheduler.scala:1012
[13:08:50,447] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[61] at map at MyLinearRegressionImpl.scala:36)
[13:08:50,447] INFO  {TaskSchedulerImpl} Adding task set 47.0 with 1 tasks
[13:08:50,448] INFO  {TaskSetManager} Starting task 0.0 in stage 47.0 (TID 47, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:50,448] INFO  {Executor} Running task 0.0 in stage 47.0 (TID 47)
[13:08:50,452] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:50,469] INFO  {BlockManagerInfo} Removed broadcast_48_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:50,470] INFO  {BlockManagerInfo} Removed broadcast_49_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:50,471] INFO  {BlockManagerInfo} Removed broadcast_50_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:50,471] INFO  {BlockManagerInfo} Removed broadcast_51_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:50,603] INFO  {Executor} Finished task 0.0 in stage 47.0 (TID 47). 1756 bytes result sent to driver
[13:08:50,603] INFO  {TaskSetManager} Finished task 0.0 in stage 47.0 (TID 47) in 156 ms on localhost (1/1)
[13:08:50,603] INFO  {TaskSchedulerImpl} Removed TaskSet 47.0, whose tasks have all completed, from pool 
[13:08:50,603] INFO  {DAGScheduler} ResultStage 47 (count at MyLinearRegressionImpl.scala:26) finished in 0.156 s
[13:08:50,604] INFO  {DAGScheduler} Job 45 finished: count at MyLinearRegressionImpl.scala:26, took 0.160977 s
[13:08:50,607] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:50,608] INFO  {DAGScheduler} Got job 46 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:50,608] INFO  {DAGScheduler} Final stage: ResultStage 48 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:50,608] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:50,608] INFO  {DAGScheduler} Missing parents: List()
[13:08:50,608] INFO  {DAGScheduler} Submitting ResultStage 48 (MapPartitionsRDD[63] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:50,610] INFO  {MemoryStore} Block broadcast_53 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:50,612] INFO  {MemoryStore} Block broadcast_53_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:50,612] INFO  {BlockManagerInfo} Added broadcast_53_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:50,613] INFO  {SparkContext} Created broadcast 53 from broadcast at DAGScheduler.scala:1012
[13:08:50,613] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[63] at map at MyLinearRegressionImpl.scala:54)
[13:08:50,613] INFO  {TaskSchedulerImpl} Adding task set 48.0 with 1 tasks
[13:08:50,614] INFO  {TaskSetManager} Starting task 0.0 in stage 48.0 (TID 48, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:50,614] INFO  {Executor} Running task 0.0 in stage 48.0 (TID 48)
[13:08:50,617] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:50,769] INFO  {Executor} Finished task 0.0 in stage 48.0 (TID 48). 2499 bytes result sent to driver
[13:08:50,769] INFO  {TaskSetManager} Finished task 0.0 in stage 48.0 (TID 48) in 156 ms on localhost (1/1)
[13:08:50,770] INFO  {TaskSchedulerImpl} Removed TaskSet 48.0, whose tasks have all completed, from pool 
[13:08:50,770] INFO  {DAGScheduler} ResultStage 48 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.157 s
[13:08:50,770] INFO  {DAGScheduler} Job 46 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.162646 s
[13:08:50,776] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:50,776] INFO  {DAGScheduler} Got job 47 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:50,776] INFO  {DAGScheduler} Final stage: ResultStage 49 (sum at MyLinearRegressionImpl.scala:24)
[13:08:50,776] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:50,776] INFO  {DAGScheduler} Missing parents: List()
[13:08:50,776] INFO  {DAGScheduler} Submitting ResultStage 49 (MapPartitionsRDD[65] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:50,778] INFO  {MemoryStore} Block broadcast_54 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:50,779] INFO  {MemoryStore} Block broadcast_54_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:50,780] INFO  {BlockManagerInfo} Added broadcast_54_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:50,780] INFO  {SparkContext} Created broadcast 54 from broadcast at DAGScheduler.scala:1012
[13:08:50,780] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[65] at map at MyLinearRegressionImpl.scala:22)
[13:08:50,780] INFO  {TaskSchedulerImpl} Adding task set 49.0 with 1 tasks
[13:08:50,781] INFO  {TaskSetManager} Starting task 0.0 in stage 49.0 (TID 49, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:50,781] INFO  {Executor} Running task 0.0 in stage 49.0 (TID 49)
[13:08:50,785] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:50,944] INFO  {Executor} Finished task 0.0 in stage 49.0 (TID 49). 1685 bytes result sent to driver
[13:08:50,944] INFO  {TaskSetManager} Finished task 0.0 in stage 49.0 (TID 49) in 164 ms on localhost (1/1)
[13:08:50,944] INFO  {TaskSchedulerImpl} Removed TaskSet 49.0, whose tasks have all completed, from pool 
[13:08:50,944] INFO  {DAGScheduler} ResultStage 49 (sum at MyLinearRegressionImpl.scala:24) finished in 0.164 s
[13:08:50,944] INFO  {DAGScheduler} Job 47 finished: sum at MyLinearRegressionImpl.scala:24, took 0.168847 s
[13:08:50,946] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:50,947] INFO  {DAGScheduler} Got job 48 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:50,947] INFO  {DAGScheduler} Final stage: ResultStage 50 (count at MyLinearRegressionImpl.scala:26)
[13:08:50,947] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:50,947] INFO  {DAGScheduler} Missing parents: List()
[13:08:50,947] INFO  {DAGScheduler} Submitting ResultStage 50 (MapPartitionsRDD[64] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:50,949] INFO  {MemoryStore} Block broadcast_55 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:50,950] INFO  {MemoryStore} Block broadcast_55_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:50,950] INFO  {BlockManagerInfo} Added broadcast_55_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:50,951] INFO  {SparkContext} Created broadcast 55 from broadcast at DAGScheduler.scala:1012
[13:08:50,951] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[64] at map at MyLinearRegressionImpl.scala:36)
[13:08:50,951] INFO  {TaskSchedulerImpl} Adding task set 50.0 with 1 tasks
[13:08:50,951] INFO  {TaskSetManager} Starting task 0.0 in stage 50.0 (TID 50, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:50,951] INFO  {Executor} Running task 0.0 in stage 50.0 (TID 50)
[13:08:50,955] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:51,084] INFO  {BlockManagerInfo} Removed broadcast_52_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:51,085] INFO  {BlockManagerInfo} Removed broadcast_53_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:51,085] INFO  {BlockManagerInfo} Removed broadcast_54_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:51,116] INFO  {Executor} Finished task 0.0 in stage 50.0 (TID 50). 1843 bytes result sent to driver
[13:08:51,117] INFO  {TaskSetManager} Finished task 0.0 in stage 50.0 (TID 50) in 166 ms on localhost (1/1)
[13:08:51,117] INFO  {TaskSchedulerImpl} Removed TaskSet 50.0, whose tasks have all completed, from pool 
[13:08:51,117] INFO  {DAGScheduler} ResultStage 50 (count at MyLinearRegressionImpl.scala:26) finished in 0.166 s
[13:08:51,118] INFO  {DAGScheduler} Job 48 finished: count at MyLinearRegressionImpl.scala:26, took 0.171044 s
[13:08:51,123] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:51,124] INFO  {DAGScheduler} Got job 49 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:51,124] INFO  {DAGScheduler} Final stage: ResultStage 51 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:51,124] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:51,124] INFO  {DAGScheduler} Missing parents: List()
[13:08:51,124] INFO  {DAGScheduler} Submitting ResultStage 51 (MapPartitionsRDD[66] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:51,126] INFO  {MemoryStore} Block broadcast_56 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:51,127] INFO  {MemoryStore} Block broadcast_56_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:51,128] INFO  {BlockManagerInfo} Added broadcast_56_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:51,128] INFO  {SparkContext} Created broadcast 56 from broadcast at DAGScheduler.scala:1012
[13:08:51,128] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[66] at map at MyLinearRegressionImpl.scala:54)
[13:08:51,128] INFO  {TaskSchedulerImpl} Adding task set 51.0 with 1 tasks
[13:08:51,129] INFO  {TaskSetManager} Starting task 0.0 in stage 51.0 (TID 51, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:51,129] INFO  {Executor} Running task 0.0 in stage 51.0 (TID 51)
[13:08:51,133] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:51,289] INFO  {Executor} Finished task 0.0 in stage 51.0 (TID 51). 2499 bytes result sent to driver
[13:08:51,289] INFO  {TaskSetManager} Finished task 0.0 in stage 51.0 (TID 51) in 161 ms on localhost (1/1)
[13:08:51,289] INFO  {TaskSchedulerImpl} Removed TaskSet 51.0, whose tasks have all completed, from pool 
[13:08:51,290] INFO  {DAGScheduler} ResultStage 51 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.162 s
[13:08:51,290] INFO  {DAGScheduler} Job 49 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.167027 s
[13:08:51,295] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:51,295] INFO  {DAGScheduler} Got job 50 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:51,295] INFO  {DAGScheduler} Final stage: ResultStage 52 (sum at MyLinearRegressionImpl.scala:24)
[13:08:51,295] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:51,295] INFO  {DAGScheduler} Missing parents: List()
[13:08:51,296] INFO  {DAGScheduler} Submitting ResultStage 52 (MapPartitionsRDD[68] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:51,297] INFO  {MemoryStore} Block broadcast_57 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:51,299] INFO  {MemoryStore} Block broadcast_57_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:51,299] INFO  {BlockManagerInfo} Added broadcast_57_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:51,300] INFO  {SparkContext} Created broadcast 57 from broadcast at DAGScheduler.scala:1012
[13:08:51,300] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[68] at map at MyLinearRegressionImpl.scala:22)
[13:08:51,300] INFO  {TaskSchedulerImpl} Adding task set 52.0 with 1 tasks
[13:08:51,301] INFO  {TaskSetManager} Starting task 0.0 in stage 52.0 (TID 52, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:51,301] INFO  {Executor} Running task 0.0 in stage 52.0 (TID 52)
[13:08:51,305] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:51,457] INFO  {Executor} Finished task 0.0 in stage 52.0 (TID 52). 1685 bytes result sent to driver
[13:08:51,458] INFO  {TaskSetManager} Finished task 0.0 in stage 52.0 (TID 52) in 158 ms on localhost (1/1)
[13:08:51,458] INFO  {TaskSchedulerImpl} Removed TaskSet 52.0, whose tasks have all completed, from pool 
[13:08:51,458] INFO  {DAGScheduler} ResultStage 52 (sum at MyLinearRegressionImpl.scala:24) finished in 0.158 s
[13:08:51,458] INFO  {DAGScheduler} Job 50 finished: sum at MyLinearRegressionImpl.scala:24, took 0.163506 s
[13:08:51,460] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:51,460] INFO  {DAGScheduler} Got job 51 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:51,461] INFO  {DAGScheduler} Final stage: ResultStage 53 (count at MyLinearRegressionImpl.scala:26)
[13:08:51,461] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:51,461] INFO  {DAGScheduler} Missing parents: List()
[13:08:51,461] INFO  {DAGScheduler} Submitting ResultStage 53 (MapPartitionsRDD[67] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:51,462] INFO  {MemoryStore} Block broadcast_58 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:51,463] INFO  {MemoryStore} Block broadcast_58_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:51,463] INFO  {BlockManagerInfo} Added broadcast_58_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:51,464] INFO  {SparkContext} Created broadcast 58 from broadcast at DAGScheduler.scala:1012
[13:08:51,464] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[67] at map at MyLinearRegressionImpl.scala:36)
[13:08:51,464] INFO  {TaskSchedulerImpl} Adding task set 53.0 with 1 tasks
[13:08:51,465] INFO  {TaskSetManager} Starting task 0.0 in stage 53.0 (TID 53, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:51,465] INFO  {Executor} Running task 0.0 in stage 53.0 (TID 53)
[13:08:51,468] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:51,615] INFO  {Executor} Finished task 0.0 in stage 53.0 (TID 53). 1683 bytes result sent to driver
[13:08:51,616] INFO  {TaskSetManager} Finished task 0.0 in stage 53.0 (TID 53) in 152 ms on localhost (1/1)
[13:08:51,616] INFO  {TaskSchedulerImpl} Removed TaskSet 53.0, whose tasks have all completed, from pool 
[13:08:51,616] INFO  {DAGScheduler} ResultStage 53 (count at MyLinearRegressionImpl.scala:26) finished in 0.152 s
[13:08:51,617] INFO  {DAGScheduler} Job 51 finished: count at MyLinearRegressionImpl.scala:26, took 0.156351 s
[13:08:51,619] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:51,619] INFO  {DAGScheduler} Got job 52 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:51,619] INFO  {DAGScheduler} Final stage: ResultStage 54 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:51,619] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:51,619] INFO  {DAGScheduler} Missing parents: List()
[13:08:51,620] INFO  {DAGScheduler} Submitting ResultStage 54 (MapPartitionsRDD[69] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:51,621] INFO  {MemoryStore} Block broadcast_59 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:08:51,622] INFO  {MemoryStore} Block broadcast_59_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:08:51,622] INFO  {BlockManagerInfo} Added broadcast_59_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:51,623] INFO  {SparkContext} Created broadcast 59 from broadcast at DAGScheduler.scala:1012
[13:08:51,623] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[69] at map at MyLinearRegressionImpl.scala:54)
[13:08:51,623] INFO  {TaskSchedulerImpl} Adding task set 54.0 with 1 tasks
[13:08:51,624] INFO  {TaskSetManager} Starting task 0.0 in stage 54.0 (TID 54, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:51,624] INFO  {Executor} Running task 0.0 in stage 54.0 (TID 54)
[13:08:51,629] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:51,758] INFO  {BlockManagerInfo} Removed broadcast_55_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:51,759] INFO  {BlockManagerInfo} Removed broadcast_56_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:51,759] INFO  {BlockManagerInfo} Removed broadcast_57_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:51,760] INFO  {BlockManagerInfo} Removed broadcast_58_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.9 MB)
[13:08:51,826] INFO  {Executor} Finished task 0.0 in stage 54.0 (TID 54). 2572 bytes result sent to driver
[13:08:51,827] INFO  {TaskSetManager} Finished task 0.0 in stage 54.0 (TID 54) in 204 ms on localhost (1/1)
[13:08:51,827] INFO  {TaskSchedulerImpl} Removed TaskSet 54.0, whose tasks have all completed, from pool 
[13:08:51,827] INFO  {DAGScheduler} ResultStage 54 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.204 s
[13:08:51,827] INFO  {DAGScheduler} Job 52 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.208090 s
[13:08:51,831] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:51,831] INFO  {DAGScheduler} Got job 53 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:51,831] INFO  {DAGScheduler} Final stage: ResultStage 55 (sum at MyLinearRegressionImpl.scala:24)
[13:08:51,832] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:51,832] INFO  {DAGScheduler} Missing parents: List()
[13:08:51,832] INFO  {DAGScheduler} Submitting ResultStage 55 (MapPartitionsRDD[71] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:51,833] INFO  {MemoryStore} Block broadcast_60 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:08:51,835] INFO  {MemoryStore} Block broadcast_60_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:51,835] INFO  {BlockManagerInfo} Added broadcast_60_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:51,836] INFO  {SparkContext} Created broadcast 60 from broadcast at DAGScheduler.scala:1012
[13:08:51,836] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[71] at map at MyLinearRegressionImpl.scala:22)
[13:08:51,836] INFO  {TaskSchedulerImpl} Adding task set 55.0 with 1 tasks
[13:08:51,836] INFO  {TaskSetManager} Starting task 0.0 in stage 55.0 (TID 55, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:51,837] INFO  {Executor} Running task 0.0 in stage 55.0 (TID 55)
[13:08:51,842] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:52,002] INFO  {Executor} Finished task 0.0 in stage 55.0 (TID 55). 1685 bytes result sent to driver
[13:08:52,003] INFO  {TaskSetManager} Finished task 0.0 in stage 55.0 (TID 55) in 167 ms on localhost (1/1)
[13:08:52,003] INFO  {DAGScheduler} ResultStage 55 (sum at MyLinearRegressionImpl.scala:24) finished in 0.167 s
[13:08:52,040] INFO  {TaskSchedulerImpl} Removed TaskSet 55.0, whose tasks have all completed, from pool 
[13:08:52,040] INFO  {DAGScheduler} Job 53 finished: sum at MyLinearRegressionImpl.scala:24, took 0.209341 s
[13:08:52,043] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:52,043] INFO  {DAGScheduler} Got job 54 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:52,043] INFO  {DAGScheduler} Final stage: ResultStage 56 (count at MyLinearRegressionImpl.scala:26)
[13:08:52,043] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:52,043] INFO  {DAGScheduler} Missing parents: List()
[13:08:52,044] INFO  {DAGScheduler} Submitting ResultStage 56 (MapPartitionsRDD[70] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:52,047] INFO  {MemoryStore} Block broadcast_61 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:52,048] INFO  {MemoryStore} Block broadcast_61_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:52,049] INFO  {BlockManagerInfo} Added broadcast_61_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:52,049] INFO  {SparkContext} Created broadcast 61 from broadcast at DAGScheduler.scala:1012
[13:08:52,049] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[70] at map at MyLinearRegressionImpl.scala:36)
[13:08:52,049] INFO  {TaskSchedulerImpl} Adding task set 56.0 with 1 tasks
[13:08:52,050] INFO  {TaskSetManager} Starting task 0.0 in stage 56.0 (TID 56, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:52,051] INFO  {Executor} Running task 0.0 in stage 56.0 (TID 56)
[13:08:52,056] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:52,246] INFO  {Executor} Finished task 0.0 in stage 56.0 (TID 56). 1683 bytes result sent to driver
[13:08:52,246] INFO  {TaskSetManager} Finished task 0.0 in stage 56.0 (TID 56) in 196 ms on localhost (1/1)
[13:08:52,246] INFO  {TaskSchedulerImpl} Removed TaskSet 56.0, whose tasks have all completed, from pool 
[13:08:52,246] INFO  {DAGScheduler} ResultStage 56 (count at MyLinearRegressionImpl.scala:26) finished in 0.196 s
[13:08:52,247] INFO  {DAGScheduler} Job 54 finished: count at MyLinearRegressionImpl.scala:26, took 0.204041 s
[13:08:52,249] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:52,249] INFO  {DAGScheduler} Got job 55 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:52,249] INFO  {DAGScheduler} Final stage: ResultStage 57 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:52,249] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:52,250] INFO  {DAGScheduler} Missing parents: List()
[13:08:52,250] INFO  {DAGScheduler} Submitting ResultStage 57 (MapPartitionsRDD[72] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:52,251] INFO  {MemoryStore} Block broadcast_62 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:52,252] INFO  {MemoryStore} Block broadcast_62_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:52,253] INFO  {BlockManagerInfo} Added broadcast_62_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:52,253] INFO  {SparkContext} Created broadcast 62 from broadcast at DAGScheduler.scala:1012
[13:08:52,253] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[72] at map at MyLinearRegressionImpl.scala:54)
[13:08:52,253] INFO  {TaskSchedulerImpl} Adding task set 57.0 with 1 tasks
[13:08:52,254] INFO  {TaskSetManager} Starting task 0.0 in stage 57.0 (TID 57, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:52,254] INFO  {Executor} Running task 0.0 in stage 57.0 (TID 57)
[13:08:52,257] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:52,412] INFO  {Executor} Finished task 0.0 in stage 57.0 (TID 57). 2499 bytes result sent to driver
[13:08:52,413] INFO  {TaskSetManager} Finished task 0.0 in stage 57.0 (TID 57) in 159 ms on localhost (1/1)
[13:08:52,413] INFO  {TaskSchedulerImpl} Removed TaskSet 57.0, whose tasks have all completed, from pool 
[13:08:52,413] INFO  {DAGScheduler} ResultStage 57 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.160 s
[13:08:52,414] INFO  {DAGScheduler} Job 55 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.164511 s
[13:08:52,419] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:52,420] INFO  {DAGScheduler} Got job 56 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:52,420] INFO  {DAGScheduler} Final stage: ResultStage 58 (sum at MyLinearRegressionImpl.scala:24)
[13:08:52,420] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:52,420] INFO  {DAGScheduler} Missing parents: List()
[13:08:52,420] INFO  {DAGScheduler} Submitting ResultStage 58 (MapPartitionsRDD[74] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:52,423] INFO  {MemoryStore} Block broadcast_63 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:08:52,426] INFO  {MemoryStore} Block broadcast_63_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:08:52,426] INFO  {BlockManagerInfo} Added broadcast_63_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:52,426] INFO  {SparkContext} Created broadcast 63 from broadcast at DAGScheduler.scala:1012
[13:08:52,426] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[74] at map at MyLinearRegressionImpl.scala:22)
[13:08:52,426] INFO  {TaskSchedulerImpl} Adding task set 58.0 with 1 tasks
[13:08:52,427] INFO  {TaskSetManager} Starting task 0.0 in stage 58.0 (TID 58, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:52,427] INFO  {Executor} Running task 0.0 in stage 58.0 (TID 58)
[13:08:52,431] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:52,512] INFO  {BlockManagerInfo} Removed broadcast_62_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:52,513] INFO  {BlockManagerInfo} Removed broadcast_61_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:52,514] INFO  {BlockManagerInfo} Removed broadcast_59_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:52,515] INFO  {BlockManagerInfo} Removed broadcast_60_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:52,602] INFO  {Executor} Finished task 0.0 in stage 58.0 (TID 58). 1758 bytes result sent to driver
[13:08:52,603] INFO  {TaskSetManager} Finished task 0.0 in stage 58.0 (TID 58) in 176 ms on localhost (1/1)
[13:08:52,603] INFO  {TaskSchedulerImpl} Removed TaskSet 58.0, whose tasks have all completed, from pool 
[13:08:52,603] INFO  {DAGScheduler} ResultStage 58 (sum at MyLinearRegressionImpl.scala:24) finished in 0.176 s
[13:08:52,603] INFO  {DAGScheduler} Job 56 finished: sum at MyLinearRegressionImpl.scala:24, took 0.184169 s
[13:08:52,606] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:52,607] INFO  {DAGScheduler} Got job 57 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:52,607] INFO  {DAGScheduler} Final stage: ResultStage 59 (count at MyLinearRegressionImpl.scala:26)
[13:08:52,607] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:52,607] INFO  {DAGScheduler} Missing parents: List()
[13:08:52,609] INFO  {DAGScheduler} Submitting ResultStage 59 (MapPartitionsRDD[73] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:52,611] INFO  {MemoryStore} Block broadcast_64 stored as values in memory (estimated size 45.0 KB, free 1128.6 MB)
[13:08:52,612] INFO  {MemoryStore} Block broadcast_64_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.6 MB)
[13:08:52,613] INFO  {BlockManagerInfo} Added broadcast_64_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:52,613] INFO  {SparkContext} Created broadcast 64 from broadcast at DAGScheduler.scala:1012
[13:08:52,613] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[73] at map at MyLinearRegressionImpl.scala:36)
[13:08:52,613] INFO  {TaskSchedulerImpl} Adding task set 59.0 with 1 tasks
[13:08:52,614] INFO  {TaskSetManager} Starting task 0.0 in stage 59.0 (TID 59, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:52,614] INFO  {Executor} Running task 0.0 in stage 59.0 (TID 59)
[13:08:52,618] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:52,762] INFO  {Executor} Finished task 0.0 in stage 59.0 (TID 59). 1683 bytes result sent to driver
[13:08:52,763] INFO  {TaskSetManager} Finished task 0.0 in stage 59.0 (TID 59) in 150 ms on localhost (1/1)
[13:08:52,763] INFO  {TaskSchedulerImpl} Removed TaskSet 59.0, whose tasks have all completed, from pool 
[13:08:52,763] INFO  {DAGScheduler} ResultStage 59 (count at MyLinearRegressionImpl.scala:26) finished in 0.150 s
[13:08:52,763] INFO  {DAGScheduler} Job 57 finished: count at MyLinearRegressionImpl.scala:26, took 0.157122 s
[13:08:52,766] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:52,766] INFO  {DAGScheduler} Got job 58 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:52,766] INFO  {DAGScheduler} Final stage: ResultStage 60 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:52,766] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:52,766] INFO  {DAGScheduler} Missing parents: List()
[13:08:52,767] INFO  {DAGScheduler} Submitting ResultStage 60 (MapPartitionsRDD[75] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:52,768] INFO  {MemoryStore} Block broadcast_65 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:52,769] INFO  {MemoryStore} Block broadcast_65_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:52,769] INFO  {BlockManagerInfo} Added broadcast_65_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:52,770] INFO  {SparkContext} Created broadcast 65 from broadcast at DAGScheduler.scala:1012
[13:08:52,770] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[75] at map at MyLinearRegressionImpl.scala:54)
[13:08:52,770] INFO  {TaskSchedulerImpl} Adding task set 60.0 with 1 tasks
[13:08:52,771] INFO  {TaskSetManager} Starting task 0.0 in stage 60.0 (TID 60, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:52,771] INFO  {Executor} Running task 0.0 in stage 60.0 (TID 60)
[13:08:52,775] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:52,931] INFO  {Executor} Finished task 0.0 in stage 60.0 (TID 60). 2499 bytes result sent to driver
[13:08:52,931] INFO  {TaskSetManager} Finished task 0.0 in stage 60.0 (TID 60) in 161 ms on localhost (1/1)
[13:08:52,932] INFO  {TaskSchedulerImpl} Removed TaskSet 60.0, whose tasks have all completed, from pool 
[13:08:52,932] INFO  {DAGScheduler} ResultStage 60 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.162 s
[13:08:52,932] INFO  {DAGScheduler} Job 58 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.165987 s
[13:08:52,937] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:52,938] INFO  {DAGScheduler} Got job 59 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:52,938] INFO  {DAGScheduler} Final stage: ResultStage 61 (sum at MyLinearRegressionImpl.scala:24)
[13:08:52,938] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:52,938] INFO  {DAGScheduler} Missing parents: List()
[13:08:52,938] INFO  {DAGScheduler} Submitting ResultStage 61 (MapPartitionsRDD[77] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:52,940] INFO  {MemoryStore} Block broadcast_66 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:52,941] INFO  {MemoryStore} Block broadcast_66_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:52,942] INFO  {BlockManagerInfo} Added broadcast_66_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:52,942] INFO  {SparkContext} Created broadcast 66 from broadcast at DAGScheduler.scala:1012
[13:08:52,942] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[77] at map at MyLinearRegressionImpl.scala:22)
[13:08:52,943] INFO  {TaskSchedulerImpl} Adding task set 61.0 with 1 tasks
[13:08:52,943] INFO  {TaskSetManager} Starting task 0.0 in stage 61.0 (TID 61, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:52,944] INFO  {Executor} Running task 0.0 in stage 61.0 (TID 61)
[13:08:52,948] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:53,104] INFO  {Executor} Finished task 0.0 in stage 61.0 (TID 61). 1685 bytes result sent to driver
[13:08:53,104] INFO  {TaskSetManager} Finished task 0.0 in stage 61.0 (TID 61) in 161 ms on localhost (1/1)
[13:08:53,105] INFO  {TaskSchedulerImpl} Removed TaskSet 61.0, whose tasks have all completed, from pool 
[13:08:53,105] INFO  {DAGScheduler} ResultStage 61 (sum at MyLinearRegressionImpl.scala:24) finished in 0.162 s
[13:08:53,105] INFO  {DAGScheduler} Job 59 finished: sum at MyLinearRegressionImpl.scala:24, took 0.167677 s
[13:08:53,107] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:53,107] INFO  {DAGScheduler} Got job 60 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:53,107] INFO  {DAGScheduler} Final stage: ResultStage 62 (count at MyLinearRegressionImpl.scala:26)
[13:08:53,107] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:53,107] INFO  {DAGScheduler} Missing parents: List()
[13:08:53,107] INFO  {DAGScheduler} Submitting ResultStage 62 (MapPartitionsRDD[76] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:53,109] INFO  {MemoryStore} Block broadcast_67 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:08:53,110] INFO  {MemoryStore} Block broadcast_67_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:08:53,110] INFO  {BlockManagerInfo} Added broadcast_67_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:53,110] INFO  {SparkContext} Created broadcast 67 from broadcast at DAGScheduler.scala:1012
[13:08:53,111] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[76] at map at MyLinearRegressionImpl.scala:36)
[13:08:53,111] INFO  {TaskSchedulerImpl} Adding task set 62.0 with 1 tasks
[13:08:53,111] INFO  {TaskSetManager} Starting task 0.0 in stage 62.0 (TID 62, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:53,111] INFO  {Executor} Running task 0.0 in stage 62.0 (TID 62)
[13:08:53,115] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:53,163] INFO  {BlockManagerInfo} Removed broadcast_63_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:53,164] INFO  {BlockManagerInfo} Removed broadcast_66_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:53,165] INFO  {BlockManagerInfo} Removed broadcast_64_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:53,165] INFO  {BlockManagerInfo} Removed broadcast_65_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:53,272] INFO  {Executor} Finished task 0.0 in stage 62.0 (TID 62). 1756 bytes result sent to driver
[13:08:53,273] INFO  {TaskSetManager} Finished task 0.0 in stage 62.0 (TID 62) in 162 ms on localhost (1/1)
[13:08:53,273] INFO  {TaskSchedulerImpl} Removed TaskSet 62.0, whose tasks have all completed, from pool 
[13:08:53,273] INFO  {DAGScheduler} ResultStage 62 (count at MyLinearRegressionImpl.scala:26) finished in 0.162 s
[13:08:53,273] INFO  {DAGScheduler} Job 60 finished: count at MyLinearRegressionImpl.scala:26, took 0.166416 s
[13:08:53,276] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:53,277] INFO  {DAGScheduler} Got job 61 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:53,277] INFO  {DAGScheduler} Final stage: ResultStage 63 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:53,277] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:53,277] INFO  {DAGScheduler} Missing parents: List()
[13:08:53,277] INFO  {DAGScheduler} Submitting ResultStage 63 (MapPartitionsRDD[78] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:53,279] INFO  {MemoryStore} Block broadcast_68 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:53,280] INFO  {MemoryStore} Block broadcast_68_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:53,281] INFO  {BlockManagerInfo} Added broadcast_68_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:53,281] INFO  {SparkContext} Created broadcast 68 from broadcast at DAGScheduler.scala:1012
[13:08:53,281] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[78] at map at MyLinearRegressionImpl.scala:54)
[13:08:53,281] INFO  {TaskSchedulerImpl} Adding task set 63.0 with 1 tasks
[13:08:53,282] INFO  {TaskSetManager} Starting task 0.0 in stage 63.0 (TID 63, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:53,282] INFO  {Executor} Running task 0.0 in stage 63.0 (TID 63)
[13:08:53,286] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:53,507] INFO  {Executor} Finished task 0.0 in stage 63.0 (TID 63). 2499 bytes result sent to driver
[13:08:53,508] INFO  {TaskSetManager} Finished task 0.0 in stage 63.0 (TID 63) in 225 ms on localhost (1/1)
[13:08:53,508] INFO  {TaskSchedulerImpl} Removed TaskSet 63.0, whose tasks have all completed, from pool 
[13:08:53,508] INFO  {DAGScheduler} ResultStage 63 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.227 s
[13:08:53,508] INFO  {DAGScheduler} Job 61 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.231902 s
[13:08:53,513] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:53,514] INFO  {DAGScheduler} Got job 62 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:53,514] INFO  {DAGScheduler} Final stage: ResultStage 64 (sum at MyLinearRegressionImpl.scala:24)
[13:08:53,514] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:53,514] INFO  {DAGScheduler} Missing parents: List()
[13:08:53,514] INFO  {DAGScheduler} Submitting ResultStage 64 (MapPartitionsRDD[80] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:53,516] INFO  {MemoryStore} Block broadcast_69 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:53,519] INFO  {MemoryStore} Block broadcast_69_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:53,519] INFO  {BlockManagerInfo} Added broadcast_69_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:53,520] INFO  {SparkContext} Created broadcast 69 from broadcast at DAGScheduler.scala:1012
[13:08:53,520] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[80] at map at MyLinearRegressionImpl.scala:22)
[13:08:53,520] INFO  {TaskSchedulerImpl} Adding task set 64.0 with 1 tasks
[13:08:53,521] INFO  {TaskSetManager} Starting task 0.0 in stage 64.0 (TID 64, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:53,521] INFO  {Executor} Running task 0.0 in stage 64.0 (TID 64)
[13:08:53,526] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:53,678] INFO  {Executor} Finished task 0.0 in stage 64.0 (TID 64). 1685 bytes result sent to driver
[13:08:53,679] INFO  {TaskSetManager} Finished task 0.0 in stage 64.0 (TID 64) in 158 ms on localhost (1/1)
[13:08:53,679] INFO  {TaskSchedulerImpl} Removed TaskSet 64.0, whose tasks have all completed, from pool 
[13:08:53,679] INFO  {DAGScheduler} ResultStage 64 (sum at MyLinearRegressionImpl.scala:24) finished in 0.159 s
[13:08:53,679] INFO  {DAGScheduler} Job 62 finished: sum at MyLinearRegressionImpl.scala:24, took 0.165731 s
[13:08:53,681] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:53,681] INFO  {DAGScheduler} Got job 63 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:53,681] INFO  {DAGScheduler} Final stage: ResultStage 65 (count at MyLinearRegressionImpl.scala:26)
[13:08:53,681] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:53,681] INFO  {DAGScheduler} Missing parents: List()
[13:08:53,682] INFO  {DAGScheduler} Submitting ResultStage 65 (MapPartitionsRDD[79] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:53,683] INFO  {MemoryStore} Block broadcast_70 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:53,685] INFO  {MemoryStore} Block broadcast_70_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:53,685] INFO  {BlockManagerInfo} Added broadcast_70_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:53,686] INFO  {SparkContext} Created broadcast 70 from broadcast at DAGScheduler.scala:1012
[13:08:53,686] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[79] at map at MyLinearRegressionImpl.scala:36)
[13:08:53,686] INFO  {TaskSchedulerImpl} Adding task set 65.0 with 1 tasks
[13:08:53,687] INFO  {TaskSetManager} Starting task 0.0 in stage 65.0 (TID 65, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:53,687] INFO  {Executor} Running task 0.0 in stage 65.0 (TID 65)
[13:08:53,691] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:53,836] INFO  {Executor} Finished task 0.0 in stage 65.0 (TID 65). 1683 bytes result sent to driver
[13:08:53,837] INFO  {TaskSetManager} Finished task 0.0 in stage 65.0 (TID 65) in 149 ms on localhost (1/1)
[13:08:53,837] INFO  {TaskSchedulerImpl} Removed TaskSet 65.0, whose tasks have all completed, from pool 
[13:08:53,837] INFO  {DAGScheduler} ResultStage 65 (count at MyLinearRegressionImpl.scala:26) finished in 0.151 s
[13:08:53,837] INFO  {DAGScheduler} Job 63 finished: count at MyLinearRegressionImpl.scala:26, took 0.156399 s
[13:08:53,840] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:53,841] INFO  {DAGScheduler} Got job 64 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:53,841] INFO  {DAGScheduler} Final stage: ResultStage 66 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:53,841] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:53,841] INFO  {DAGScheduler} Missing parents: List()
[13:08:53,841] INFO  {DAGScheduler} Submitting ResultStage 66 (MapPartitionsRDD[81] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:53,842] INFO  {MemoryStore} Block broadcast_71 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:08:53,843] INFO  {MemoryStore} Block broadcast_71_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:08:53,843] INFO  {BlockManagerInfo} Added broadcast_71_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:53,844] INFO  {SparkContext} Created broadcast 71 from broadcast at DAGScheduler.scala:1012
[13:08:53,844] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[81] at map at MyLinearRegressionImpl.scala:54)
[13:08:53,844] INFO  {TaskSchedulerImpl} Adding task set 66.0 with 1 tasks
[13:08:53,845] INFO  {TaskSetManager} Starting task 0.0 in stage 66.0 (TID 66, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:53,845] INFO  {Executor} Running task 0.0 in stage 66.0 (TID 66)
[13:08:53,850] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:53,900] INFO  {BlockManagerInfo} Removed broadcast_67_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:53,901] INFO  {BlockManagerInfo} Removed broadcast_68_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:53,901] INFO  {BlockManagerInfo} Removed broadcast_69_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:53,903] INFO  {BlockManagerInfo} Removed broadcast_70_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.9 MB)
[13:08:54,020] INFO  {Executor} Finished task 0.0 in stage 66.0 (TID 66). 2572 bytes result sent to driver
[13:08:54,020] INFO  {TaskSetManager} Finished task 0.0 in stage 66.0 (TID 66) in 176 ms on localhost (1/1)
[13:08:54,020] INFO  {TaskSchedulerImpl} Removed TaskSet 66.0, whose tasks have all completed, from pool 
[13:08:54,021] INFO  {DAGScheduler} ResultStage 66 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.177 s
[13:08:54,021] INFO  {DAGScheduler} Job 64 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.180575 s
[13:08:54,025] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:54,025] INFO  {DAGScheduler} Got job 65 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:54,025] INFO  {DAGScheduler} Final stage: ResultStage 67 (sum at MyLinearRegressionImpl.scala:24)
[13:08:54,025] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:54,025] INFO  {DAGScheduler} Missing parents: List()
[13:08:54,025] INFO  {DAGScheduler} Submitting ResultStage 67 (MapPartitionsRDD[83] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:54,027] INFO  {MemoryStore} Block broadcast_72 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:08:54,028] INFO  {MemoryStore} Block broadcast_72_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:54,029] INFO  {BlockManagerInfo} Added broadcast_72_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:54,029] INFO  {SparkContext} Created broadcast 72 from broadcast at DAGScheduler.scala:1012
[13:08:54,029] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[83] at map at MyLinearRegressionImpl.scala:22)
[13:08:54,029] INFO  {TaskSchedulerImpl} Adding task set 67.0 with 1 tasks
[13:08:54,030] INFO  {TaskSetManager} Starting task 0.0 in stage 67.0 (TID 67, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:54,030] INFO  {Executor} Running task 0.0 in stage 67.0 (TID 67)
[13:08:54,034] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:54,193] INFO  {Executor} Finished task 0.0 in stage 67.0 (TID 67). 1685 bytes result sent to driver
[13:08:54,193] INFO  {TaskSetManager} Finished task 0.0 in stage 67.0 (TID 67) in 164 ms on localhost (1/1)
[13:08:54,193] INFO  {TaskSchedulerImpl} Removed TaskSet 67.0, whose tasks have all completed, from pool 
[13:08:54,194] INFO  {DAGScheduler} ResultStage 67 (sum at MyLinearRegressionImpl.scala:24) finished in 0.165 s
[13:08:54,194] INFO  {DAGScheduler} Job 65 finished: sum at MyLinearRegressionImpl.scala:24, took 0.168959 s
[13:08:54,196] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:54,196] INFO  {DAGScheduler} Got job 66 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:54,196] INFO  {DAGScheduler} Final stage: ResultStage 68 (count at MyLinearRegressionImpl.scala:26)
[13:08:54,196] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:54,196] INFO  {DAGScheduler} Missing parents: List()
[13:08:54,196] INFO  {DAGScheduler} Submitting ResultStage 68 (MapPartitionsRDD[82] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:54,197] INFO  {MemoryStore} Block broadcast_73 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:54,198] INFO  {MemoryStore} Block broadcast_73_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:54,199] INFO  {BlockManagerInfo} Added broadcast_73_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:54,199] INFO  {SparkContext} Created broadcast 73 from broadcast at DAGScheduler.scala:1012
[13:08:54,199] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[82] at map at MyLinearRegressionImpl.scala:36)
[13:08:54,199] INFO  {TaskSchedulerImpl} Adding task set 68.0 with 1 tasks
[13:08:54,200] INFO  {TaskSetManager} Starting task 0.0 in stage 68.0 (TID 68, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:54,200] INFO  {Executor} Running task 0.0 in stage 68.0 (TID 68)
[13:08:54,203] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:54,353] INFO  {Executor} Finished task 0.0 in stage 68.0 (TID 68). 1683 bytes result sent to driver
[13:08:54,354] INFO  {TaskSetManager} Finished task 0.0 in stage 68.0 (TID 68) in 155 ms on localhost (1/1)
[13:08:54,354] INFO  {TaskSchedulerImpl} Removed TaskSet 68.0, whose tasks have all completed, from pool 
[13:08:54,354] INFO  {DAGScheduler} ResultStage 68 (count at MyLinearRegressionImpl.scala:26) finished in 0.155 s
[13:08:54,354] INFO  {DAGScheduler} Job 66 finished: count at MyLinearRegressionImpl.scala:26, took 0.158803 s
[13:08:54,357] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:54,357] INFO  {DAGScheduler} Got job 67 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:54,357] INFO  {DAGScheduler} Final stage: ResultStage 69 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:54,357] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:54,358] INFO  {DAGScheduler} Missing parents: List()
[13:08:54,358] INFO  {DAGScheduler} Submitting ResultStage 69 (MapPartitionsRDD[84] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:54,359] INFO  {MemoryStore} Block broadcast_74 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:54,360] INFO  {MemoryStore} Block broadcast_74_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:54,361] INFO  {BlockManagerInfo} Added broadcast_74_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:54,361] INFO  {SparkContext} Created broadcast 74 from broadcast at DAGScheduler.scala:1012
[13:08:54,361] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[84] at map at MyLinearRegressionImpl.scala:54)
[13:08:54,361] INFO  {TaskSchedulerImpl} Adding task set 69.0 with 1 tasks
[13:08:54,362] INFO  {TaskSetManager} Starting task 0.0 in stage 69.0 (TID 69, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:54,362] INFO  {Executor} Running task 0.0 in stage 69.0 (TID 69)
[13:08:54,366] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:54,512] INFO  {Executor} Finished task 0.0 in stage 69.0 (TID 69). 2499 bytes result sent to driver
[13:08:54,513] INFO  {TaskSetManager} Finished task 0.0 in stage 69.0 (TID 69) in 150 ms on localhost (1/1)
[13:08:54,513] INFO  {TaskSchedulerImpl} Removed TaskSet 69.0, whose tasks have all completed, from pool 
[13:08:54,513] INFO  {DAGScheduler} ResultStage 69 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.151 s
[13:08:54,513] INFO  {DAGScheduler} Job 67 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.155968 s
[13:08:54,517] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:54,518] INFO  {DAGScheduler} Got job 68 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:54,518] INFO  {DAGScheduler} Final stage: ResultStage 70 (sum at MyLinearRegressionImpl.scala:24)
[13:08:54,518] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:54,518] INFO  {DAGScheduler} Missing parents: List()
[13:08:54,518] INFO  {DAGScheduler} Submitting ResultStage 70 (MapPartitionsRDD[86] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:54,520] INFO  {MemoryStore} Block broadcast_75 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:08:54,521] INFO  {MemoryStore} Block broadcast_75_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:08:54,521] INFO  {BlockManagerInfo} Added broadcast_75_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:54,522] INFO  {SparkContext} Created broadcast 75 from broadcast at DAGScheduler.scala:1012
[13:08:54,522] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[86] at map at MyLinearRegressionImpl.scala:22)
[13:08:54,522] INFO  {TaskSchedulerImpl} Adding task set 70.0 with 1 tasks
[13:08:54,523] INFO  {TaskSetManager} Starting task 0.0 in stage 70.0 (TID 70, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:54,523] INFO  {Executor} Running task 0.0 in stage 70.0 (TID 70)
[13:08:54,527] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:54,555] INFO  {BlockManagerInfo} Removed broadcast_71_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:54,556] INFO  {BlockManagerInfo} Removed broadcast_73_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:54,557] INFO  {BlockManagerInfo} Removed broadcast_74_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:54,558] INFO  {BlockManagerInfo} Removed broadcast_72_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:54,689] INFO  {Executor} Finished task 0.0 in stage 70.0 (TID 70). 1758 bytes result sent to driver
[13:08:54,690] INFO  {TaskSetManager} Finished task 0.0 in stage 70.0 (TID 70) in 168 ms on localhost (1/1)
[13:08:54,691] INFO  {TaskSchedulerImpl} Removed TaskSet 70.0, whose tasks have all completed, from pool 
[13:08:54,691] INFO  {DAGScheduler} ResultStage 70 (sum at MyLinearRegressionImpl.scala:24) finished in 0.169 s
[13:08:54,692] INFO  {DAGScheduler} Job 68 finished: sum at MyLinearRegressionImpl.scala:24, took 0.174269 s
[13:08:54,694] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:54,695] INFO  {DAGScheduler} Got job 69 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:54,695] INFO  {DAGScheduler} Final stage: ResultStage 71 (count at MyLinearRegressionImpl.scala:26)
[13:08:54,695] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:54,695] INFO  {DAGScheduler} Missing parents: List()
[13:08:54,695] INFO  {DAGScheduler} Submitting ResultStage 71 (MapPartitionsRDD[85] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:54,696] INFO  {MemoryStore} Block broadcast_76 stored as values in memory (estimated size 45.0 KB, free 1128.6 MB)
[13:08:54,697] INFO  {MemoryStore} Block broadcast_76_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.6 MB)
[13:08:54,698] INFO  {BlockManagerInfo} Added broadcast_76_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:54,698] INFO  {SparkContext} Created broadcast 76 from broadcast at DAGScheduler.scala:1012
[13:08:54,698] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[85] at map at MyLinearRegressionImpl.scala:36)
[13:08:54,698] INFO  {TaskSchedulerImpl} Adding task set 71.0 with 1 tasks
[13:08:54,699] INFO  {TaskSetManager} Starting task 0.0 in stage 71.0 (TID 71, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:54,699] INFO  {Executor} Running task 0.0 in stage 71.0 (TID 71)
[13:08:54,707] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:54,870] INFO  {Executor} Finished task 0.0 in stage 71.0 (TID 71). 1683 bytes result sent to driver
[13:08:54,871] INFO  {TaskSetManager} Finished task 0.0 in stage 71.0 (TID 71) in 172 ms on localhost (1/1)
[13:08:54,871] INFO  {TaskSchedulerImpl} Removed TaskSet 71.0, whose tasks have all completed, from pool 
[13:08:54,871] INFO  {DAGScheduler} ResultStage 71 (count at MyLinearRegressionImpl.scala:26) finished in 0.172 s
[13:08:54,871] INFO  {DAGScheduler} Job 69 finished: count at MyLinearRegressionImpl.scala:26, took 0.177096 s
[13:08:54,874] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:54,875] INFO  {DAGScheduler} Got job 70 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:54,875] INFO  {DAGScheduler} Final stage: ResultStage 72 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:54,875] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:54,875] INFO  {DAGScheduler} Missing parents: List()
[13:08:54,876] INFO  {DAGScheduler} Submitting ResultStage 72 (MapPartitionsRDD[87] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:54,878] INFO  {MemoryStore} Block broadcast_77 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:54,880] INFO  {MemoryStore} Block broadcast_77_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:54,881] INFO  {BlockManagerInfo} Added broadcast_77_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:54,882] INFO  {SparkContext} Created broadcast 77 from broadcast at DAGScheduler.scala:1012
[13:08:54,883] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[87] at map at MyLinearRegressionImpl.scala:54)
[13:08:54,883] INFO  {TaskSchedulerImpl} Adding task set 72.0 with 1 tasks
[13:08:54,883] INFO  {TaskSetManager} Starting task 0.0 in stage 72.0 (TID 72, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:54,883] INFO  {Executor} Running task 0.0 in stage 72.0 (TID 72)
[13:08:54,887] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:55,043] INFO  {Executor} Finished task 0.0 in stage 72.0 (TID 72). 2499 bytes result sent to driver
[13:08:55,043] INFO  {TaskSetManager} Finished task 0.0 in stage 72.0 (TID 72) in 160 ms on localhost (1/1)
[13:08:55,043] INFO  {TaskSchedulerImpl} Removed TaskSet 72.0, whose tasks have all completed, from pool 
[13:08:55,043] INFO  {DAGScheduler} ResultStage 72 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.160 s
[13:08:55,044] INFO  {DAGScheduler} Job 70 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.169234 s
[13:08:55,047] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:55,048] INFO  {DAGScheduler} Got job 71 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:55,048] INFO  {DAGScheduler} Final stage: ResultStage 73 (sum at MyLinearRegressionImpl.scala:24)
[13:08:55,048] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:55,048] INFO  {DAGScheduler} Missing parents: List()
[13:08:55,048] INFO  {DAGScheduler} Submitting ResultStage 73 (MapPartitionsRDD[89] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:55,050] INFO  {MemoryStore} Block broadcast_78 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:55,051] INFO  {MemoryStore} Block broadcast_78_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:55,052] INFO  {BlockManagerInfo} Added broadcast_78_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:55,052] INFO  {SparkContext} Created broadcast 78 from broadcast at DAGScheduler.scala:1012
[13:08:55,052] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[89] at map at MyLinearRegressionImpl.scala:22)
[13:08:55,052] INFO  {TaskSchedulerImpl} Adding task set 73.0 with 1 tasks
[13:08:55,053] INFO  {TaskSetManager} Starting task 0.0 in stage 73.0 (TID 73, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:55,054] INFO  {Executor} Running task 0.0 in stage 73.0 (TID 73)
[13:08:55,058] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:55,210] INFO  {Executor} Finished task 0.0 in stage 73.0 (TID 73). 1685 bytes result sent to driver
[13:08:55,210] INFO  {TaskSetManager} Finished task 0.0 in stage 73.0 (TID 73) in 157 ms on localhost (1/1)
[13:08:55,210] INFO  {TaskSchedulerImpl} Removed TaskSet 73.0, whose tasks have all completed, from pool 
[13:08:55,210] INFO  {DAGScheduler} ResultStage 73 (sum at MyLinearRegressionImpl.scala:24) finished in 0.158 s
[13:08:55,211] INFO  {DAGScheduler} Job 71 finished: sum at MyLinearRegressionImpl.scala:24, took 0.163127 s
[13:08:55,213] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:55,213] INFO  {DAGScheduler} Got job 72 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:55,213] INFO  {DAGScheduler} Final stage: ResultStage 74 (count at MyLinearRegressionImpl.scala:26)
[13:08:55,213] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:55,213] INFO  {DAGScheduler} Missing parents: List()
[13:08:55,214] INFO  {DAGScheduler} Submitting ResultStage 74 (MapPartitionsRDD[88] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:55,215] INFO  {MemoryStore} Block broadcast_79 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:08:55,217] INFO  {MemoryStore} Block broadcast_79_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:08:55,217] INFO  {BlockManagerInfo} Added broadcast_79_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:55,217] INFO  {SparkContext} Created broadcast 79 from broadcast at DAGScheduler.scala:1012
[13:08:55,217] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[88] at map at MyLinearRegressionImpl.scala:36)
[13:08:55,218] INFO  {TaskSchedulerImpl} Adding task set 74.0 with 1 tasks
[13:08:55,219] INFO  {TaskSetManager} Starting task 0.0 in stage 74.0 (TID 74, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:55,219] INFO  {Executor} Running task 0.0 in stage 74.0 (TID 74)
[13:08:55,222] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:55,273] INFO  {BlockManagerInfo} Removed broadcast_75_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:55,273] INFO  {BlockManagerInfo} Removed broadcast_78_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:55,274] INFO  {BlockManagerInfo} Removed broadcast_76_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:55,274] INFO  {BlockManagerInfo} Removed broadcast_77_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:55,375] INFO  {Executor} Finished task 0.0 in stage 74.0 (TID 74). 1756 bytes result sent to driver
[13:08:55,375] INFO  {TaskSetManager} Finished task 0.0 in stage 74.0 (TID 74) in 157 ms on localhost (1/1)
[13:08:55,376] INFO  {TaskSchedulerImpl} Removed TaskSet 74.0, whose tasks have all completed, from pool 
[13:08:55,376] INFO  {DAGScheduler} ResultStage 74 (count at MyLinearRegressionImpl.scala:26) finished in 0.158 s
[13:08:55,376] INFO  {DAGScheduler} Job 72 finished: count at MyLinearRegressionImpl.scala:26, took 0.163065 s
[13:08:55,378] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:55,379] INFO  {DAGScheduler} Got job 73 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:55,379] INFO  {DAGScheduler} Final stage: ResultStage 75 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:55,379] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:55,379] INFO  {DAGScheduler} Missing parents: List()
[13:08:55,379] INFO  {DAGScheduler} Submitting ResultStage 75 (MapPartitionsRDD[90] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:55,381] INFO  {MemoryStore} Block broadcast_80 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:55,383] INFO  {MemoryStore} Block broadcast_80_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:55,383] INFO  {BlockManagerInfo} Added broadcast_80_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:55,384] INFO  {SparkContext} Created broadcast 80 from broadcast at DAGScheduler.scala:1012
[13:08:55,384] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[90] at map at MyLinearRegressionImpl.scala:54)
[13:08:55,384] INFO  {TaskSchedulerImpl} Adding task set 75.0 with 1 tasks
[13:08:55,385] INFO  {TaskSetManager} Starting task 0.0 in stage 75.0 (TID 75, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:55,385] INFO  {Executor} Running task 0.0 in stage 75.0 (TID 75)
[13:08:55,388] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:55,538] INFO  {Executor} Finished task 0.0 in stage 75.0 (TID 75). 2499 bytes result sent to driver
[13:08:55,539] INFO  {TaskSetManager} Finished task 0.0 in stage 75.0 (TID 75) in 155 ms on localhost (1/1)
[13:08:55,539] INFO  {TaskSchedulerImpl} Removed TaskSet 75.0, whose tasks have all completed, from pool 
[13:08:55,539] INFO  {DAGScheduler} ResultStage 75 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.155 s
[13:08:55,539] INFO  {DAGScheduler} Job 73 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.160720 s
[13:08:55,543] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:55,544] INFO  {DAGScheduler} Got job 74 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:55,544] INFO  {DAGScheduler} Final stage: ResultStage 76 (sum at MyLinearRegressionImpl.scala:24)
[13:08:55,544] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:55,544] INFO  {DAGScheduler} Missing parents: List()
[13:08:55,544] INFO  {DAGScheduler} Submitting ResultStage 76 (MapPartitionsRDD[92] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:55,546] INFO  {MemoryStore} Block broadcast_81 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:55,567] INFO  {MemoryStore} Block broadcast_81_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:55,568] INFO  {BlockManagerInfo} Added broadcast_81_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:55,568] INFO  {SparkContext} Created broadcast 81 from broadcast at DAGScheduler.scala:1012
[13:08:55,568] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[92] at map at MyLinearRegressionImpl.scala:22)
[13:08:55,568] INFO  {TaskSchedulerImpl} Adding task set 76.0 with 1 tasks
[13:08:55,569] INFO  {TaskSetManager} Starting task 0.0 in stage 76.0 (TID 76, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:55,569] INFO  {Executor} Running task 0.0 in stage 76.0 (TID 76)
[13:08:55,574] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:55,721] INFO  {Executor} Finished task 0.0 in stage 76.0 (TID 76). 1685 bytes result sent to driver
[13:08:55,721] INFO  {TaskSetManager} Finished task 0.0 in stage 76.0 (TID 76) in 152 ms on localhost (1/1)
[13:08:55,721] INFO  {TaskSchedulerImpl} Removed TaskSet 76.0, whose tasks have all completed, from pool 
[13:08:55,722] INFO  {DAGScheduler} ResultStage 76 (sum at MyLinearRegressionImpl.scala:24) finished in 0.153 s
[13:08:55,722] INFO  {DAGScheduler} Job 74 finished: sum at MyLinearRegressionImpl.scala:24, took 0.178534 s
[13:08:55,724] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:55,725] INFO  {DAGScheduler} Got job 75 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:55,725] INFO  {DAGScheduler} Final stage: ResultStage 77 (count at MyLinearRegressionImpl.scala:26)
[13:08:55,725] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:55,725] INFO  {DAGScheduler} Missing parents: List()
[13:08:55,725] INFO  {DAGScheduler} Submitting ResultStage 77 (MapPartitionsRDD[91] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:55,727] INFO  {MemoryStore} Block broadcast_82 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:55,728] INFO  {MemoryStore} Block broadcast_82_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:55,729] INFO  {BlockManagerInfo} Added broadcast_82_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:55,729] INFO  {SparkContext} Created broadcast 82 from broadcast at DAGScheduler.scala:1012
[13:08:55,729] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[91] at map at MyLinearRegressionImpl.scala:36)
[13:08:55,729] INFO  {TaskSchedulerImpl} Adding task set 77.0 with 1 tasks
[13:08:55,730] INFO  {TaskSetManager} Starting task 0.0 in stage 77.0 (TID 77, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:55,731] INFO  {Executor} Running task 0.0 in stage 77.0 (TID 77)
[13:08:55,734] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:55,882] INFO  {Executor} Finished task 0.0 in stage 77.0 (TID 77). 1683 bytes result sent to driver
[13:08:55,882] INFO  {TaskSetManager} Finished task 0.0 in stage 77.0 (TID 77) in 152 ms on localhost (1/1)
[13:08:55,882] INFO  {TaskSchedulerImpl} Removed TaskSet 77.0, whose tasks have all completed, from pool 
[13:08:55,882] INFO  {DAGScheduler} ResultStage 77 (count at MyLinearRegressionImpl.scala:26) finished in 0.152 s
[13:08:55,883] INFO  {DAGScheduler} Job 75 finished: count at MyLinearRegressionImpl.scala:26, took 0.158155 s
[13:08:55,886] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:55,886] INFO  {DAGScheduler} Got job 76 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:55,886] INFO  {DAGScheduler} Final stage: ResultStage 78 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:55,886] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:55,886] INFO  {DAGScheduler} Missing parents: List()
[13:08:55,886] INFO  {DAGScheduler} Submitting ResultStage 78 (MapPartitionsRDD[93] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:55,888] INFO  {MemoryStore} Block broadcast_83 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:08:55,890] INFO  {MemoryStore} Block broadcast_83_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:08:55,890] INFO  {BlockManagerInfo} Added broadcast_83_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:55,891] INFO  {SparkContext} Created broadcast 83 from broadcast at DAGScheduler.scala:1012
[13:08:55,891] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[93] at map at MyLinearRegressionImpl.scala:54)
[13:08:55,891] INFO  {TaskSchedulerImpl} Adding task set 78.0 with 1 tasks
[13:08:55,892] INFO  {TaskSetManager} Starting task 0.0 in stage 78.0 (TID 78, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:55,892] INFO  {Executor} Running task 0.0 in stage 78.0 (TID 78)
[13:08:55,898] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:55,958] INFO  {BlockManagerInfo} Removed broadcast_80_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:55,958] INFO  {BlockManagerInfo} Removed broadcast_81_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:55,959] INFO  {BlockManagerInfo} Removed broadcast_82_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:55,959] INFO  {BlockManagerInfo} Removed broadcast_79_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.9 MB)
[13:08:56,048] INFO  {Executor} Finished task 0.0 in stage 78.0 (TID 78). 2572 bytes result sent to driver
[13:08:56,049] INFO  {TaskSetManager} Finished task 0.0 in stage 78.0 (TID 78) in 158 ms on localhost (1/1)
[13:08:56,049] INFO  {TaskSchedulerImpl} Removed TaskSet 78.0, whose tasks have all completed, from pool 
[13:08:56,049] INFO  {DAGScheduler} ResultStage 78 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.158 s
[13:08:56,050] INFO  {DAGScheduler} Job 76 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.163987 s
[13:08:56,053] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:56,054] INFO  {DAGScheduler} Got job 77 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:56,054] INFO  {DAGScheduler} Final stage: ResultStage 79 (sum at MyLinearRegressionImpl.scala:24)
[13:08:56,054] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:56,054] INFO  {DAGScheduler} Missing parents: List()
[13:08:56,054] INFO  {DAGScheduler} Submitting ResultStage 79 (MapPartitionsRDD[95] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:56,056] INFO  {MemoryStore} Block broadcast_84 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:08:56,057] INFO  {MemoryStore} Block broadcast_84_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:56,057] INFO  {BlockManagerInfo} Added broadcast_84_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:56,058] INFO  {SparkContext} Created broadcast 84 from broadcast at DAGScheduler.scala:1012
[13:08:56,058] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[95] at map at MyLinearRegressionImpl.scala:22)
[13:08:56,058] INFO  {TaskSchedulerImpl} Adding task set 79.0 with 1 tasks
[13:08:56,059] INFO  {TaskSetManager} Starting task 0.0 in stage 79.0 (TID 79, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:56,060] INFO  {Executor} Running task 0.0 in stage 79.0 (TID 79)
[13:08:56,063] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:56,225] INFO  {Executor} Finished task 0.0 in stage 79.0 (TID 79). 1685 bytes result sent to driver
[13:08:56,226] INFO  {TaskSetManager} Finished task 0.0 in stage 79.0 (TID 79) in 167 ms on localhost (1/1)
[13:08:56,226] INFO  {TaskSchedulerImpl} Removed TaskSet 79.0, whose tasks have all completed, from pool 
[13:08:56,226] INFO  {DAGScheduler} ResultStage 79 (sum at MyLinearRegressionImpl.scala:24) finished in 0.168 s
[13:08:56,227] INFO  {DAGScheduler} Job 77 finished: sum at MyLinearRegressionImpl.scala:24, took 0.173164 s
[13:08:56,230] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:56,231] INFO  {DAGScheduler} Got job 78 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:56,231] INFO  {DAGScheduler} Final stage: ResultStage 80 (count at MyLinearRegressionImpl.scala:26)
[13:08:56,231] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:56,231] INFO  {DAGScheduler} Missing parents: List()
[13:08:56,231] INFO  {DAGScheduler} Submitting ResultStage 80 (MapPartitionsRDD[94] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:56,233] INFO  {MemoryStore} Block broadcast_85 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:56,234] INFO  {MemoryStore} Block broadcast_85_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:56,235] INFO  {BlockManagerInfo} Added broadcast_85_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:56,235] INFO  {SparkContext} Created broadcast 85 from broadcast at DAGScheduler.scala:1012
[13:08:56,235] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[94] at map at MyLinearRegressionImpl.scala:36)
[13:08:56,235] INFO  {TaskSchedulerImpl} Adding task set 80.0 with 1 tasks
[13:08:56,236] INFO  {TaskSetManager} Starting task 0.0 in stage 80.0 (TID 80, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:56,236] INFO  {Executor} Running task 0.0 in stage 80.0 (TID 80)
[13:08:56,240] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:56,404] INFO  {Executor} Finished task 0.0 in stage 80.0 (TID 80). 1770 bytes result sent to driver
[13:08:56,404] INFO  {TaskSetManager} Finished task 0.0 in stage 80.0 (TID 80) in 168 ms on localhost (1/1)
[13:08:56,404] INFO  {TaskSchedulerImpl} Removed TaskSet 80.0, whose tasks have all completed, from pool 
[13:08:56,405] INFO  {DAGScheduler} ResultStage 80 (count at MyLinearRegressionImpl.scala:26) finished in 0.170 s
[13:08:56,405] INFO  {DAGScheduler} Job 78 finished: count at MyLinearRegressionImpl.scala:26, took 0.174804 s
[13:08:56,407] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:56,408] INFO  {DAGScheduler} Got job 79 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:56,408] INFO  {DAGScheduler} Final stage: ResultStage 81 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:56,408] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:56,408] INFO  {DAGScheduler} Missing parents: List()
[13:08:56,408] INFO  {DAGScheduler} Submitting ResultStage 81 (MapPartitionsRDD[96] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:56,409] INFO  {MemoryStore} Block broadcast_86 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:56,411] INFO  {MemoryStore} Block broadcast_86_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:56,411] INFO  {BlockManagerInfo} Added broadcast_86_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:56,411] INFO  {SparkContext} Created broadcast 86 from broadcast at DAGScheduler.scala:1012
[13:08:56,411] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[96] at map at MyLinearRegressionImpl.scala:54)
[13:08:56,411] INFO  {TaskSchedulerImpl} Adding task set 81.0 with 1 tasks
[13:08:56,412] INFO  {TaskSetManager} Starting task 0.0 in stage 81.0 (TID 81, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:56,412] INFO  {Executor} Running task 0.0 in stage 81.0 (TID 81)
[13:08:56,417] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:56,570] INFO  {Executor} Finished task 0.0 in stage 81.0 (TID 81). 2499 bytes result sent to driver
[13:08:56,570] INFO  {TaskSetManager} Finished task 0.0 in stage 81.0 (TID 81) in 158 ms on localhost (1/1)
[13:08:56,571] INFO  {TaskSchedulerImpl} Removed TaskSet 81.0, whose tasks have all completed, from pool 
[13:08:56,571] INFO  {DAGScheduler} ResultStage 81 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.159 s
[13:08:56,571] INFO  {DAGScheduler} Job 79 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.163631 s
[13:08:56,575] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:56,575] INFO  {DAGScheduler} Got job 80 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:56,575] INFO  {DAGScheduler} Final stage: ResultStage 82 (sum at MyLinearRegressionImpl.scala:24)
[13:08:56,575] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:56,576] INFO  {DAGScheduler} Missing parents: List()
[13:08:56,576] INFO  {DAGScheduler} Submitting ResultStage 82 (MapPartitionsRDD[98] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:56,577] INFO  {MemoryStore} Block broadcast_87 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:08:56,578] INFO  {MemoryStore} Block broadcast_87_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:08:56,579] INFO  {BlockManagerInfo} Added broadcast_87_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:56,579] INFO  {SparkContext} Created broadcast 87 from broadcast at DAGScheduler.scala:1012
[13:08:56,579] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[98] at map at MyLinearRegressionImpl.scala:22)
[13:08:56,579] INFO  {TaskSchedulerImpl} Adding task set 82.0 with 1 tasks
[13:08:56,580] INFO  {TaskSetManager} Starting task 0.0 in stage 82.0 (TID 82, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:56,580] INFO  {Executor} Running task 0.0 in stage 82.0 (TID 82)
[13:08:56,583] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:56,671] INFO  {BlockManagerInfo} Removed broadcast_83_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:56,672] INFO  {BlockManagerInfo} Removed broadcast_84_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:56,673] INFO  {BlockManagerInfo} Removed broadcast_85_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:56,673] INFO  {BlockManagerInfo} Removed broadcast_86_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:56,739] INFO  {Executor} Finished task 0.0 in stage 82.0 (TID 82). 1758 bytes result sent to driver
[13:08:56,740] INFO  {TaskSetManager} Finished task 0.0 in stage 82.0 (TID 82) in 160 ms on localhost (1/1)
[13:08:56,740] INFO  {TaskSchedulerImpl} Removed TaskSet 82.0, whose tasks have all completed, from pool 
[13:08:56,740] INFO  {DAGScheduler} ResultStage 82 (sum at MyLinearRegressionImpl.scala:24) finished in 0.161 s
[13:08:56,740] INFO  {DAGScheduler} Job 80 finished: sum at MyLinearRegressionImpl.scala:24, took 0.165011 s
[13:08:56,743] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:56,743] INFO  {DAGScheduler} Got job 81 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:56,743] INFO  {DAGScheduler} Final stage: ResultStage 83 (count at MyLinearRegressionImpl.scala:26)
[13:08:56,743] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:56,744] INFO  {DAGScheduler} Missing parents: List()
[13:08:56,744] INFO  {DAGScheduler} Submitting ResultStage 83 (MapPartitionsRDD[97] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:56,747] INFO  {MemoryStore} Block broadcast_88 stored as values in memory (estimated size 45.0 KB, free 1128.6 MB)
[13:08:56,748] INFO  {MemoryStore} Block broadcast_88_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.6 MB)
[13:08:56,748] INFO  {BlockManagerInfo} Added broadcast_88_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:56,749] INFO  {SparkContext} Created broadcast 88 from broadcast at DAGScheduler.scala:1012
[13:08:56,749] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[97] at map at MyLinearRegressionImpl.scala:36)
[13:08:56,749] INFO  {TaskSchedulerImpl} Adding task set 83.0 with 1 tasks
[13:08:56,750] INFO  {TaskSetManager} Starting task 0.0 in stage 83.0 (TID 83, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:56,750] INFO  {Executor} Running task 0.0 in stage 83.0 (TID 83)
[13:08:56,753] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:56,902] INFO  {Executor} Finished task 0.0 in stage 83.0 (TID 83). 1770 bytes result sent to driver
[13:08:56,902] INFO  {TaskSetManager} Finished task 0.0 in stage 83.0 (TID 83) in 153 ms on localhost (1/1)
[13:08:56,903] INFO  {TaskSchedulerImpl} Removed TaskSet 83.0, whose tasks have all completed, from pool 
[13:08:56,903] INFO  {DAGScheduler} ResultStage 83 (count at MyLinearRegressionImpl.scala:26) finished in 0.154 s
[13:08:56,903] INFO  {DAGScheduler} Job 81 finished: count at MyLinearRegressionImpl.scala:26, took 0.160077 s
[13:08:56,906] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:56,907] INFO  {DAGScheduler} Got job 82 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:56,907] INFO  {DAGScheduler} Final stage: ResultStage 84 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:56,907] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:56,907] INFO  {DAGScheduler} Missing parents: List()
[13:08:56,907] INFO  {DAGScheduler} Submitting ResultStage 84 (MapPartitionsRDD[99] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:56,909] INFO  {MemoryStore} Block broadcast_89 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:56,910] INFO  {MemoryStore} Block broadcast_89_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:56,910] INFO  {BlockManagerInfo} Added broadcast_89_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:56,911] INFO  {SparkContext} Created broadcast 89 from broadcast at DAGScheduler.scala:1012
[13:08:56,911] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[99] at map at MyLinearRegressionImpl.scala:54)
[13:08:56,911] INFO  {TaskSchedulerImpl} Adding task set 84.0 with 1 tasks
[13:08:56,913] INFO  {TaskSetManager} Starting task 0.0 in stage 84.0 (TID 84, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:56,913] INFO  {Executor} Running task 0.0 in stage 84.0 (TID 84)
[13:08:56,917] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:57,067] INFO  {Executor} Finished task 0.0 in stage 84.0 (TID 84). 2499 bytes result sent to driver
[13:08:57,068] INFO  {TaskSetManager} Finished task 0.0 in stage 84.0 (TID 84) in 155 ms on localhost (1/1)
[13:08:57,068] INFO  {TaskSchedulerImpl} Removed TaskSet 84.0, whose tasks have all completed, from pool 
[13:08:57,068] INFO  {DAGScheduler} ResultStage 84 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.157 s
[13:08:57,068] INFO  {DAGScheduler} Job 82 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.161686 s
[13:08:57,074] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:57,074] INFO  {DAGScheduler} Got job 83 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:57,074] INFO  {DAGScheduler} Final stage: ResultStage 85 (sum at MyLinearRegressionImpl.scala:24)
[13:08:57,074] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:57,074] INFO  {DAGScheduler} Missing parents: List()
[13:08:57,074] INFO  {DAGScheduler} Submitting ResultStage 85 (MapPartitionsRDD[101] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:57,076] INFO  {MemoryStore} Block broadcast_90 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:57,077] INFO  {MemoryStore} Block broadcast_90_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:57,078] INFO  {BlockManagerInfo} Added broadcast_90_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:57,078] INFO  {SparkContext} Created broadcast 90 from broadcast at DAGScheduler.scala:1012
[13:08:57,078] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[101] at map at MyLinearRegressionImpl.scala:22)
[13:08:57,078] INFO  {TaskSchedulerImpl} Adding task set 85.0 with 1 tasks
[13:08:57,079] INFO  {TaskSetManager} Starting task 0.0 in stage 85.0 (TID 85, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:57,079] INFO  {Executor} Running task 0.0 in stage 85.0 (TID 85)
[13:08:57,083] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:57,227] INFO  {Executor} Finished task 0.0 in stage 85.0 (TID 85). 1685 bytes result sent to driver
[13:08:57,228] INFO  {TaskSetManager} Finished task 0.0 in stage 85.0 (TID 85) in 149 ms on localhost (1/1)
[13:08:57,228] INFO  {TaskSchedulerImpl} Removed TaskSet 85.0, whose tasks have all completed, from pool 
[13:08:57,228] INFO  {DAGScheduler} ResultStage 85 (sum at MyLinearRegressionImpl.scala:24) finished in 0.150 s
[13:08:57,228] INFO  {DAGScheduler} Job 83 finished: sum at MyLinearRegressionImpl.scala:24, took 0.154718 s
[13:08:57,230] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:57,231] INFO  {DAGScheduler} Got job 84 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:57,231] INFO  {DAGScheduler} Final stage: ResultStage 86 (count at MyLinearRegressionImpl.scala:26)
[13:08:57,231] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:57,231] INFO  {DAGScheduler} Missing parents: List()
[13:08:57,231] INFO  {DAGScheduler} Submitting ResultStage 86 (MapPartitionsRDD[100] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:57,233] INFO  {MemoryStore} Block broadcast_91 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:08:57,234] INFO  {MemoryStore} Block broadcast_91_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:08:57,234] INFO  {BlockManagerInfo} Added broadcast_91_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:57,235] INFO  {SparkContext} Created broadcast 91 from broadcast at DAGScheduler.scala:1012
[13:08:57,235] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[100] at map at MyLinearRegressionImpl.scala:36)
[13:08:57,235] INFO  {TaskSchedulerImpl} Adding task set 86.0 with 1 tasks
[13:08:57,236] INFO  {TaskSetManager} Starting task 0.0 in stage 86.0 (TID 86, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:57,236] INFO  {Executor} Running task 0.0 in stage 86.0 (TID 86)
[13:08:57,240] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:57,348] INFO  {BlockManagerInfo} Removed broadcast_87_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:57,348] INFO  {BlockManagerInfo} Removed broadcast_88_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:57,349] INFO  {BlockManagerInfo} Removed broadcast_89_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:57,350] INFO  {BlockManagerInfo} Removed broadcast_90_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:57,388] INFO  {Executor} Finished task 0.0 in stage 86.0 (TID 86). 1843 bytes result sent to driver
[13:08:57,388] INFO  {TaskSetManager} Finished task 0.0 in stage 86.0 (TID 86) in 152 ms on localhost (1/1)
[13:08:57,388] INFO  {TaskSchedulerImpl} Removed TaskSet 86.0, whose tasks have all completed, from pool 
[13:08:57,389] INFO  {DAGScheduler} ResultStage 86 (count at MyLinearRegressionImpl.scala:26) finished in 0.154 s
[13:08:57,389] INFO  {DAGScheduler} Job 84 finished: count at MyLinearRegressionImpl.scala:26, took 0.158180 s
[13:08:57,392] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:57,392] INFO  {DAGScheduler} Got job 85 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:57,392] INFO  {DAGScheduler} Final stage: ResultStage 87 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:57,392] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:57,393] INFO  {DAGScheduler} Missing parents: List()
[13:08:57,393] INFO  {DAGScheduler} Submitting ResultStage 87 (MapPartitionsRDD[102] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:57,394] INFO  {MemoryStore} Block broadcast_92 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:57,396] INFO  {MemoryStore} Block broadcast_92_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:57,396] INFO  {BlockManagerInfo} Added broadcast_92_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:57,396] INFO  {SparkContext} Created broadcast 92 from broadcast at DAGScheduler.scala:1012
[13:08:57,397] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[102] at map at MyLinearRegressionImpl.scala:54)
[13:08:57,397] INFO  {TaskSchedulerImpl} Adding task set 87.0 with 1 tasks
[13:08:57,398] INFO  {TaskSetManager} Starting task 0.0 in stage 87.0 (TID 87, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:57,398] INFO  {Executor} Running task 0.0 in stage 87.0 (TID 87)
[13:08:57,401] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:57,554] INFO  {Executor} Finished task 0.0 in stage 87.0 (TID 87). 2499 bytes result sent to driver
[13:08:57,555] INFO  {TaskSetManager} Finished task 0.0 in stage 87.0 (TID 87) in 158 ms on localhost (1/1)
[13:08:57,555] INFO  {TaskSchedulerImpl} Removed TaskSet 87.0, whose tasks have all completed, from pool 
[13:08:57,555] INFO  {DAGScheduler} ResultStage 87 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.158 s
[13:08:57,555] INFO  {DAGScheduler} Job 85 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.163283 s
[13:08:57,559] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:57,559] INFO  {DAGScheduler} Got job 86 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:57,559] INFO  {DAGScheduler} Final stage: ResultStage 88 (sum at MyLinearRegressionImpl.scala:24)
[13:08:57,559] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:57,559] INFO  {DAGScheduler} Missing parents: List()
[13:08:57,560] INFO  {DAGScheduler} Submitting ResultStage 88 (MapPartitionsRDD[104] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:57,561] INFO  {MemoryStore} Block broadcast_93 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:57,562] INFO  {MemoryStore} Block broadcast_93_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:57,562] INFO  {BlockManagerInfo} Added broadcast_93_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:57,562] INFO  {SparkContext} Created broadcast 93 from broadcast at DAGScheduler.scala:1012
[13:08:57,563] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[104] at map at MyLinearRegressionImpl.scala:22)
[13:08:57,563] INFO  {TaskSchedulerImpl} Adding task set 88.0 with 1 tasks
[13:08:57,563] INFO  {TaskSetManager} Starting task 0.0 in stage 88.0 (TID 88, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:57,563] INFO  {Executor} Running task 0.0 in stage 88.0 (TID 88)
[13:08:57,567] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:57,716] INFO  {Executor} Finished task 0.0 in stage 88.0 (TID 88). 1685 bytes result sent to driver
[13:08:57,717] INFO  {TaskSetManager} Finished task 0.0 in stage 88.0 (TID 88) in 154 ms on localhost (1/1)
[13:08:57,717] INFO  {TaskSchedulerImpl} Removed TaskSet 88.0, whose tasks have all completed, from pool 
[13:08:57,717] INFO  {DAGScheduler} ResultStage 88 (sum at MyLinearRegressionImpl.scala:24) finished in 0.154 s
[13:08:57,717] INFO  {DAGScheduler} Job 86 finished: sum at MyLinearRegressionImpl.scala:24, took 0.158317 s
[13:08:57,719] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:57,720] INFO  {DAGScheduler} Got job 87 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:57,720] INFO  {DAGScheduler} Final stage: ResultStage 89 (count at MyLinearRegressionImpl.scala:26)
[13:08:57,720] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:57,720] INFO  {DAGScheduler} Missing parents: List()
[13:08:57,720] INFO  {DAGScheduler} Submitting ResultStage 89 (MapPartitionsRDD[103] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:57,722] INFO  {MemoryStore} Block broadcast_94 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:57,723] INFO  {MemoryStore} Block broadcast_94_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:57,724] INFO  {BlockManagerInfo} Added broadcast_94_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:57,724] INFO  {SparkContext} Created broadcast 94 from broadcast at DAGScheduler.scala:1012
[13:08:57,725] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[103] at map at MyLinearRegressionImpl.scala:36)
[13:08:57,725] INFO  {TaskSchedulerImpl} Adding task set 89.0 with 1 tasks
[13:08:57,726] INFO  {TaskSetManager} Starting task 0.0 in stage 89.0 (TID 89, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:57,726] INFO  {Executor} Running task 0.0 in stage 89.0 (TID 89)
[13:08:57,729] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:57,880] INFO  {Executor} Finished task 0.0 in stage 89.0 (TID 89). 1683 bytes result sent to driver
[13:08:57,881] INFO  {TaskSetManager} Finished task 0.0 in stage 89.0 (TID 89) in 156 ms on localhost (1/1)
[13:08:57,881] INFO  {TaskSchedulerImpl} Removed TaskSet 89.0, whose tasks have all completed, from pool 
[13:08:57,882] INFO  {DAGScheduler} ResultStage 89 (count at MyLinearRegressionImpl.scala:26) finished in 0.157 s
[13:08:57,882] INFO  {DAGScheduler} Job 87 finished: count at MyLinearRegressionImpl.scala:26, took 0.162769 s
[13:08:57,889] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:57,889] INFO  {DAGScheduler} Got job 88 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:57,889] INFO  {DAGScheduler} Final stage: ResultStage 90 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:57,889] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:57,889] INFO  {DAGScheduler} Missing parents: List()
[13:08:57,890] INFO  {DAGScheduler} Submitting ResultStage 90 (MapPartitionsRDD[105] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:57,891] INFO  {MemoryStore} Block broadcast_95 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:08:57,892] INFO  {MemoryStore} Block broadcast_95_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:08:57,892] INFO  {BlockManagerInfo} Added broadcast_95_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:57,893] INFO  {SparkContext} Created broadcast 95 from broadcast at DAGScheduler.scala:1012
[13:08:57,893] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[105] at map at MyLinearRegressionImpl.scala:54)
[13:08:57,893] INFO  {TaskSchedulerImpl} Adding task set 90.0 with 1 tasks
[13:08:57,894] INFO  {TaskSetManager} Starting task 0.0 in stage 90.0 (TID 90, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:57,894] INFO  {Executor} Running task 0.0 in stage 90.0 (TID 90)
[13:08:57,897] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:58,149] INFO  {BlockManagerInfo} Removed broadcast_91_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:58,150] INFO  {Executor} Finished task 0.0 in stage 90.0 (TID 90). 2572 bytes result sent to driver
[13:08:58,150] INFO  {BlockManagerInfo} Removed broadcast_92_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:58,150] INFO  {TaskSetManager} Finished task 0.0 in stage 90.0 (TID 90) in 257 ms on localhost (1/1)
[13:08:58,150] INFO  {TaskSchedulerImpl} Removed TaskSet 90.0, whose tasks have all completed, from pool 
[13:08:58,150] INFO  {DAGScheduler} ResultStage 90 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.257 s
[13:08:58,151] INFO  {DAGScheduler} Job 88 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.261937 s
[13:08:58,151] INFO  {BlockManagerInfo} Removed broadcast_93_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:58,152] INFO  {BlockManagerInfo} Removed broadcast_94_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.9 MB)
[13:08:58,157] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:58,157] INFO  {DAGScheduler} Got job 89 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:58,157] INFO  {DAGScheduler} Final stage: ResultStage 91 (sum at MyLinearRegressionImpl.scala:24)
[13:08:58,157] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:58,157] INFO  {DAGScheduler} Missing parents: List()
[13:08:58,158] INFO  {DAGScheduler} Submitting ResultStage 91 (MapPartitionsRDD[107] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:58,159] INFO  {MemoryStore} Block broadcast_96 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:08:58,160] INFO  {MemoryStore} Block broadcast_96_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:58,160] INFO  {BlockManagerInfo} Added broadcast_96_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:58,161] INFO  {SparkContext} Created broadcast 96 from broadcast at DAGScheduler.scala:1012
[13:08:58,161] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[107] at map at MyLinearRegressionImpl.scala:22)
[13:08:58,161] INFO  {TaskSchedulerImpl} Adding task set 91.0 with 1 tasks
[13:08:58,162] INFO  {TaskSetManager} Starting task 0.0 in stage 91.0 (TID 91, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:58,162] INFO  {Executor} Running task 0.0 in stage 91.0 (TID 91)
[13:08:58,167] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:58,315] INFO  {Executor} Finished task 0.0 in stage 91.0 (TID 91). 1685 bytes result sent to driver
[13:08:58,315] INFO  {TaskSetManager} Finished task 0.0 in stage 91.0 (TID 91) in 154 ms on localhost (1/1)
[13:08:58,316] INFO  {TaskSchedulerImpl} Removed TaskSet 91.0, whose tasks have all completed, from pool 
[13:08:58,316] INFO  {DAGScheduler} ResultStage 91 (sum at MyLinearRegressionImpl.scala:24) finished in 0.155 s
[13:08:58,316] INFO  {DAGScheduler} Job 89 finished: sum at MyLinearRegressionImpl.scala:24, took 0.159039 s
[13:08:58,318] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:58,318] INFO  {DAGScheduler} Got job 90 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:58,318] INFO  {DAGScheduler} Final stage: ResultStage 92 (count at MyLinearRegressionImpl.scala:26)
[13:08:58,318] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:58,318] INFO  {DAGScheduler} Missing parents: List()
[13:08:58,318] INFO  {DAGScheduler} Submitting ResultStage 92 (MapPartitionsRDD[106] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:58,320] INFO  {MemoryStore} Block broadcast_97 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:58,321] INFO  {MemoryStore} Block broadcast_97_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:58,321] INFO  {BlockManagerInfo} Added broadcast_97_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:58,322] INFO  {SparkContext} Created broadcast 97 from broadcast at DAGScheduler.scala:1012
[13:08:58,322] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[106] at map at MyLinearRegressionImpl.scala:36)
[13:08:58,322] INFO  {TaskSchedulerImpl} Adding task set 92.0 with 1 tasks
[13:08:58,323] INFO  {TaskSetManager} Starting task 0.0 in stage 92.0 (TID 92, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:58,323] INFO  {Executor} Running task 0.0 in stage 92.0 (TID 92)
[13:08:58,327] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:58,481] INFO  {Executor} Finished task 0.0 in stage 92.0 (TID 92). 1683 bytes result sent to driver
[13:08:58,482] INFO  {TaskSetManager} Finished task 0.0 in stage 92.0 (TID 92) in 160 ms on localhost (1/1)
[13:08:58,482] INFO  {TaskSchedulerImpl} Removed TaskSet 92.0, whose tasks have all completed, from pool 
[13:08:58,482] INFO  {DAGScheduler} ResultStage 92 (count at MyLinearRegressionImpl.scala:26) finished in 0.160 s
[13:08:58,483] INFO  {DAGScheduler} Job 90 finished: count at MyLinearRegressionImpl.scala:26, took 0.164818 s
[13:08:58,486] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:58,487] INFO  {DAGScheduler} Got job 91 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:58,487] INFO  {DAGScheduler} Final stage: ResultStage 93 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:58,487] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:58,487] INFO  {DAGScheduler} Missing parents: List()
[13:08:58,487] INFO  {DAGScheduler} Submitting ResultStage 93 (MapPartitionsRDD[108] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:58,490] INFO  {MemoryStore} Block broadcast_98 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:08:58,494] INFO  {MemoryStore} Block broadcast_98_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:58,494] INFO  {BlockManagerInfo} Added broadcast_98_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:58,494] INFO  {SparkContext} Created broadcast 98 from broadcast at DAGScheduler.scala:1012
[13:08:58,495] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[108] at map at MyLinearRegressionImpl.scala:54)
[13:08:58,495] INFO  {TaskSchedulerImpl} Adding task set 93.0 with 1 tasks
[13:08:58,495] INFO  {TaskSetManager} Starting task 0.0 in stage 93.0 (TID 93, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:58,495] INFO  {Executor} Running task 0.0 in stage 93.0 (TID 93)
[13:08:58,503] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:58,675] INFO  {Executor} Finished task 0.0 in stage 93.0 (TID 93). 2499 bytes result sent to driver
[13:08:58,676] INFO  {TaskSetManager} Finished task 0.0 in stage 93.0 (TID 93) in 181 ms on localhost (1/1)
[13:08:58,676] INFO  {TaskSchedulerImpl} Removed TaskSet 93.0, whose tasks have all completed, from pool 
[13:08:58,676] INFO  {DAGScheduler} ResultStage 93 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.181 s
[13:08:58,676] INFO  {DAGScheduler} Job 91 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.190375 s
[13:08:58,680] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:58,681] INFO  {DAGScheduler} Got job 92 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:58,681] INFO  {DAGScheduler} Final stage: ResultStage 94 (sum at MyLinearRegressionImpl.scala:24)
[13:08:58,681] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:58,681] INFO  {DAGScheduler} Missing parents: List()
[13:08:58,681] INFO  {DAGScheduler} Submitting ResultStage 94 (MapPartitionsRDD[110] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:58,683] INFO  {MemoryStore} Block broadcast_99 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:08:58,684] INFO  {MemoryStore} Block broadcast_99_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:08:58,684] INFO  {BlockManagerInfo} Added broadcast_99_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:58,684] INFO  {SparkContext} Created broadcast 99 from broadcast at DAGScheduler.scala:1012
[13:08:58,685] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[110] at map at MyLinearRegressionImpl.scala:22)
[13:08:58,685] INFO  {TaskSchedulerImpl} Adding task set 94.0 with 1 tasks
[13:08:58,685] INFO  {TaskSetManager} Starting task 0.0 in stage 94.0 (TID 94, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:58,686] INFO  {Executor} Running task 0.0 in stage 94.0 (TID 94)
[13:08:58,689] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:58,838] INFO  {Executor} Finished task 0.0 in stage 94.0 (TID 94). 1685 bytes result sent to driver
[13:08:58,839] INFO  {TaskSetManager} Finished task 0.0 in stage 94.0 (TID 94) in 154 ms on localhost (1/1)
[13:08:58,839] INFO  {TaskSchedulerImpl} Removed TaskSet 94.0, whose tasks have all completed, from pool 
[13:08:58,839] INFO  {DAGScheduler} ResultStage 94 (sum at MyLinearRegressionImpl.scala:24) finished in 0.154 s
[13:08:58,839] INFO  {DAGScheduler} Job 92 finished: sum at MyLinearRegressionImpl.scala:24, took 0.158538 s
[13:08:58,841] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:58,842] INFO  {DAGScheduler} Got job 93 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:58,842] INFO  {DAGScheduler} Final stage: ResultStage 95 (count at MyLinearRegressionImpl.scala:26)
[13:08:58,842] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:58,842] INFO  {DAGScheduler} Missing parents: List()
[13:08:58,842] INFO  {DAGScheduler} Submitting ResultStage 95 (MapPartitionsRDD[109] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:58,843] INFO  {MemoryStore} Block broadcast_100 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:08:58,846] INFO  {MemoryStore} Block broadcast_100_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:08:58,847] INFO  {BlockManagerInfo} Added broadcast_100_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:58,847] INFO  {SparkContext} Created broadcast 100 from broadcast at DAGScheduler.scala:1012
[13:08:58,847] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[109] at map at MyLinearRegressionImpl.scala:36)
[13:08:58,847] INFO  {TaskSchedulerImpl} Adding task set 95.0 with 1 tasks
[13:08:58,850] INFO  {TaskSetManager} Starting task 0.0 in stage 95.0 (TID 95, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:58,850] INFO  {Executor} Running task 0.0 in stage 95.0 (TID 95)
[13:08:58,854] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:58,914] INFO  {BlockManagerInfo} Removed broadcast_96_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:58,915] INFO  {BlockManagerInfo} Removed broadcast_99_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:58,915] INFO  {BlockManagerInfo} Removed broadcast_95_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:08:58,916] INFO  {BlockManagerInfo} Removed broadcast_97_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:08:58,917] INFO  {BlockManagerInfo} Removed broadcast_98_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:08:59,044] INFO  {Executor} Finished task 0.0 in stage 95.0 (TID 95). 1756 bytes result sent to driver
[13:08:59,044] INFO  {TaskSetManager} Finished task 0.0 in stage 95.0 (TID 95) in 196 ms on localhost (1/1)
[13:08:59,044] INFO  {TaskSchedulerImpl} Removed TaskSet 95.0, whose tasks have all completed, from pool 
[13:08:59,045] INFO  {DAGScheduler} ResultStage 95 (count at MyLinearRegressionImpl.scala:26) finished in 0.197 s
[13:08:59,045] INFO  {DAGScheduler} Job 93 finished: count at MyLinearRegressionImpl.scala:26, took 0.203371 s
[13:08:59,049] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:08:59,049] INFO  {DAGScheduler} Got job 94 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:08:59,049] INFO  {DAGScheduler} Final stage: ResultStage 96 (reduce at MyLinearRegressionImpl.scala:56)
[13:08:59,049] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:59,049] INFO  {DAGScheduler} Missing parents: List()
[13:08:59,050] INFO  {DAGScheduler} Submitting ResultStage 96 (MapPartitionsRDD[111] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:08:59,051] INFO  {MemoryStore} Block broadcast_101 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:08:59,053] INFO  {MemoryStore} Block broadcast_101_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:08:59,058] INFO  {BlockManagerInfo} Added broadcast_101_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:59,058] INFO  {SparkContext} Created broadcast 101 from broadcast at DAGScheduler.scala:1012
[13:08:59,058] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[111] at map at MyLinearRegressionImpl.scala:54)
[13:08:59,058] INFO  {TaskSchedulerImpl} Adding task set 96.0 with 1 tasks
[13:08:59,059] INFO  {TaskSetManager} Starting task 0.0 in stage 96.0 (TID 96, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:08:59,059] INFO  {Executor} Running task 0.0 in stage 96.0 (TID 96)
[13:08:59,063] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:59,330] INFO  {Executor} Finished task 0.0 in stage 96.0 (TID 96). 2499 bytes result sent to driver
[13:08:59,331] INFO  {TaskSetManager} Finished task 0.0 in stage 96.0 (TID 96) in 273 ms on localhost (1/1)
[13:08:59,331] INFO  {TaskSchedulerImpl} Removed TaskSet 96.0, whose tasks have all completed, from pool 
[13:08:59,331] INFO  {DAGScheduler} ResultStage 96 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.273 s
[13:08:59,331] INFO  {DAGScheduler} Job 94 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.282791 s
[13:08:59,339] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:08:59,340] INFO  {DAGScheduler} Got job 95 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:08:59,340] INFO  {DAGScheduler} Final stage: ResultStage 97 (sum at MyLinearRegressionImpl.scala:24)
[13:08:59,340] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:59,340] INFO  {DAGScheduler} Missing parents: List()
[13:08:59,340] INFO  {DAGScheduler} Submitting ResultStage 97 (MapPartitionsRDD[113] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:08:59,342] INFO  {MemoryStore} Block broadcast_102 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:08:59,344] INFO  {MemoryStore} Block broadcast_102_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:08:59,345] INFO  {BlockManagerInfo} Added broadcast_102_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:08:59,345] INFO  {SparkContext} Created broadcast 102 from broadcast at DAGScheduler.scala:1012
[13:08:59,345] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[113] at map at MyLinearRegressionImpl.scala:22)
[13:08:59,346] INFO  {TaskSchedulerImpl} Adding task set 97.0 with 1 tasks
[13:08:59,347] INFO  {TaskSetManager} Starting task 0.0 in stage 97.0 (TID 97, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:08:59,347] INFO  {Executor} Running task 0.0 in stage 97.0 (TID 97)
[13:08:59,354] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:08:59,708] INFO  {Executor} Finished task 0.0 in stage 97.0 (TID 97). 1685 bytes result sent to driver
[13:08:59,709] INFO  {TaskSetManager} Finished task 0.0 in stage 97.0 (TID 97) in 363 ms on localhost (1/1)
[13:08:59,709] INFO  {TaskSchedulerImpl} Removed TaskSet 97.0, whose tasks have all completed, from pool 
[13:08:59,709] INFO  {DAGScheduler} ResultStage 97 (sum at MyLinearRegressionImpl.scala:24) finished in 0.363 s
[13:08:59,710] INFO  {DAGScheduler} Job 95 finished: sum at MyLinearRegressionImpl.scala:24, took 0.370649 s
[13:08:59,713] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:08:59,714] INFO  {DAGScheduler} Got job 96 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:08:59,714] INFO  {DAGScheduler} Final stage: ResultStage 98 (count at MyLinearRegressionImpl.scala:26)
[13:08:59,714] INFO  {DAGScheduler} Parents of final stage: List()
[13:08:59,715] INFO  {DAGScheduler} Missing parents: List()
[13:08:59,715] INFO  {DAGScheduler} Submitting ResultStage 98 (MapPartitionsRDD[112] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:08:59,718] INFO  {MemoryStore} Block broadcast_103 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:08:59,720] INFO  {MemoryStore} Block broadcast_103_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:08:59,721] INFO  {BlockManagerInfo} Added broadcast_103_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:08:59,721] INFO  {SparkContext} Created broadcast 103 from broadcast at DAGScheduler.scala:1012
[13:08:59,722] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[112] at map at MyLinearRegressionImpl.scala:36)
[13:08:59,722] INFO  {TaskSchedulerImpl} Adding task set 98.0 with 1 tasks
[13:08:59,724] INFO  {TaskSetManager} Starting task 0.0 in stage 98.0 (TID 98, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:08:59,724] INFO  {Executor} Running task 0.0 in stage 98.0 (TID 98)
[13:08:59,731] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:00,105] INFO  {Executor} Finished task 0.0 in stage 98.0 (TID 98). 1683 bytes result sent to driver
[13:09:00,107] INFO  {TaskSetManager} Finished task 0.0 in stage 98.0 (TID 98) in 384 ms on localhost (1/1)
[13:09:00,107] INFO  {TaskSchedulerImpl} Removed TaskSet 98.0, whose tasks have all completed, from pool 
[13:09:00,107] INFO  {DAGScheduler} ResultStage 98 (count at MyLinearRegressionImpl.scala:26) finished in 0.385 s
[13:09:00,108] INFO  {DAGScheduler} Job 96 finished: count at MyLinearRegressionImpl.scala:26, took 0.394232 s
[13:09:00,113] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:00,114] INFO  {DAGScheduler} Got job 97 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:00,114] INFO  {DAGScheduler} Final stage: ResultStage 99 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:00,114] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:00,115] INFO  {DAGScheduler} Missing parents: List()
[13:09:00,115] INFO  {DAGScheduler} Submitting ResultStage 99 (MapPartitionsRDD[114] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:00,118] INFO  {MemoryStore} Block broadcast_104 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:00,120] INFO  {MemoryStore} Block broadcast_104_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:00,120] INFO  {BlockManagerInfo} Added broadcast_104_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:09:00,121] INFO  {SparkContext} Created broadcast 104 from broadcast at DAGScheduler.scala:1012
[13:09:00,122] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[114] at map at MyLinearRegressionImpl.scala:54)
[13:09:00,122] INFO  {TaskSchedulerImpl} Adding task set 99.0 with 1 tasks
[13:09:00,123] INFO  {TaskSetManager} Starting task 0.0 in stage 99.0 (TID 99, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:00,124] INFO  {Executor} Running task 0.0 in stage 99.0 (TID 99)
[13:09:00,132] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:00,412] INFO  {BlockManagerInfo} Removed broadcast_100_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:00,414] INFO  {BlockManagerInfo} Removed broadcast_101_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:00,415] INFO  {BlockManagerInfo} Removed broadcast_102_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:00,416] INFO  {BlockManagerInfo} Removed broadcast_103_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.9 MB)
[13:09:00,529] INFO  {Executor} Finished task 0.0 in stage 99.0 (TID 99). 2572 bytes result sent to driver
[13:09:00,530] INFO  {TaskSetManager} Finished task 0.0 in stage 99.0 (TID 99) in 408 ms on localhost (1/1)
[13:09:00,530] INFO  {TaskSchedulerImpl} Removed TaskSet 99.0, whose tasks have all completed, from pool 
[13:09:00,531] INFO  {DAGScheduler} ResultStage 99 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.409 s
[13:09:00,531] INFO  {DAGScheduler} Job 97 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.417294 s
[13:09:00,539] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:00,540] INFO  {DAGScheduler} Got job 98 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:00,540] INFO  {DAGScheduler} Final stage: ResultStage 100 (sum at MyLinearRegressionImpl.scala:24)
[13:09:00,540] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:00,540] INFO  {DAGScheduler} Missing parents: List()
[13:09:00,540] INFO  {DAGScheduler} Submitting ResultStage 100 (MapPartitionsRDD[116] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:00,544] INFO  {MemoryStore} Block broadcast_105 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:09:00,546] INFO  {MemoryStore} Block broadcast_105_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:09:00,547] INFO  {BlockManagerInfo} Added broadcast_105_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:09:00,548] INFO  {SparkContext} Created broadcast 105 from broadcast at DAGScheduler.scala:1012
[13:09:00,548] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[116] at map at MyLinearRegressionImpl.scala:22)
[13:09:00,548] INFO  {TaskSchedulerImpl} Adding task set 100.0 with 1 tasks
[13:09:00,549] INFO  {TaskSetManager} Starting task 0.0 in stage 100.0 (TID 100, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:00,549] INFO  {Executor} Running task 0.0 in stage 100.0 (TID 100)
[13:09:00,558] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:00,918] INFO  {Executor} Finished task 0.0 in stage 100.0 (TID 100). 1685 bytes result sent to driver
[13:09:00,919] INFO  {TaskSetManager} Finished task 0.0 in stage 100.0 (TID 100) in 371 ms on localhost (1/1)
[13:09:00,920] INFO  {TaskSchedulerImpl} Removed TaskSet 100.0, whose tasks have all completed, from pool 
[13:09:00,920] INFO  {DAGScheduler} ResultStage 100 (sum at MyLinearRegressionImpl.scala:24) finished in 0.372 s
[13:09:00,920] INFO  {DAGScheduler} Job 98 finished: sum at MyLinearRegressionImpl.scala:24, took 0.381312 s
[13:09:00,923] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:00,924] INFO  {DAGScheduler} Got job 99 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:00,924] INFO  {DAGScheduler} Final stage: ResultStage 101 (count at MyLinearRegressionImpl.scala:26)
[13:09:00,924] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:00,924] INFO  {DAGScheduler} Missing parents: List()
[13:09:00,925] INFO  {DAGScheduler} Submitting ResultStage 101 (MapPartitionsRDD[115] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:00,927] INFO  {MemoryStore} Block broadcast_106 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:00,929] INFO  {MemoryStore} Block broadcast_106_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:00,930] INFO  {BlockManagerInfo} Added broadcast_106_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:09:00,930] INFO  {SparkContext} Created broadcast 106 from broadcast at DAGScheduler.scala:1012
[13:09:00,930] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[115] at map at MyLinearRegressionImpl.scala:36)
[13:09:00,930] INFO  {TaskSchedulerImpl} Adding task set 101.0 with 1 tasks
[13:09:00,932] INFO  {TaskSetManager} Starting task 0.0 in stage 101.0 (TID 101, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:00,932] INFO  {Executor} Running task 0.0 in stage 101.0 (TID 101)
[13:09:00,939] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:01,300] INFO  {Executor} Finished task 0.0 in stage 101.0 (TID 101). 1683 bytes result sent to driver
[13:09:01,301] INFO  {TaskSetManager} Finished task 0.0 in stage 101.0 (TID 101) in 370 ms on localhost (1/1)
[13:09:01,301] INFO  {TaskSchedulerImpl} Removed TaskSet 101.0, whose tasks have all completed, from pool 
[13:09:01,301] INFO  {DAGScheduler} ResultStage 101 (count at MyLinearRegressionImpl.scala:26) finished in 0.370 s
[13:09:01,302] INFO  {DAGScheduler} Job 99 finished: count at MyLinearRegressionImpl.scala:26, took 0.378193 s
[13:09:01,307] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:01,307] INFO  {DAGScheduler} Got job 100 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:01,308] INFO  {DAGScheduler} Final stage: ResultStage 102 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:01,308] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:01,308] INFO  {DAGScheduler} Missing parents: List()
[13:09:01,308] INFO  {DAGScheduler} Submitting ResultStage 102 (MapPartitionsRDD[117] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:01,311] INFO  {MemoryStore} Block broadcast_107 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:01,313] INFO  {MemoryStore} Block broadcast_107_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:01,314] INFO  {BlockManagerInfo} Added broadcast_107_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:09:01,315] INFO  {SparkContext} Created broadcast 107 from broadcast at DAGScheduler.scala:1012
[13:09:01,315] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[117] at map at MyLinearRegressionImpl.scala:54)
[13:09:01,315] INFO  {TaskSchedulerImpl} Adding task set 102.0 with 1 tasks
[13:09:01,316] INFO  {TaskSetManager} Starting task 0.0 in stage 102.0 (TID 102, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:01,316] INFO  {Executor} Running task 0.0 in stage 102.0 (TID 102)
[13:09:01,326] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:01,742] INFO  {Executor} Finished task 0.0 in stage 102.0 (TID 102). 2499 bytes result sent to driver
[13:09:01,744] INFO  {TaskSetManager} Finished task 0.0 in stage 102.0 (TID 102) in 427 ms on localhost (1/1)
[13:09:01,744] INFO  {TaskSchedulerImpl} Removed TaskSet 102.0, whose tasks have all completed, from pool 
[13:09:01,744] INFO  {DAGScheduler} ResultStage 102 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.429 s
[13:09:01,745] INFO  {DAGScheduler} Job 100 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.438107 s
[13:09:01,758] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:01,759] INFO  {DAGScheduler} Got job 101 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:01,759] INFO  {DAGScheduler} Final stage: ResultStage 103 (sum at MyLinearRegressionImpl.scala:24)
[13:09:01,759] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:01,759] INFO  {DAGScheduler} Missing parents: List()
[13:09:01,760] INFO  {DAGScheduler} Submitting ResultStage 103 (MapPartitionsRDD[119] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:01,763] INFO  {MemoryStore} Block broadcast_108 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:01,772] INFO  {MemoryStore} Block broadcast_108_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:01,773] INFO  {BlockManagerInfo} Added broadcast_108_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:09:01,773] INFO  {SparkContext} Created broadcast 108 from broadcast at DAGScheduler.scala:1012
[13:09:01,774] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[119] at map at MyLinearRegressionImpl.scala:22)
[13:09:01,774] INFO  {TaskSchedulerImpl} Adding task set 103.0 with 1 tasks
[13:09:01,775] INFO  {TaskSetManager} Starting task 0.0 in stage 103.0 (TID 103, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:01,775] INFO  {Executor} Running task 0.0 in stage 103.0 (TID 103)
[13:09:01,783] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:02,232] INFO  {Executor} Finished task 0.0 in stage 103.0 (TID 103). 1685 bytes result sent to driver
[13:09:02,233] INFO  {TaskSetManager} Finished task 0.0 in stage 103.0 (TID 103) in 458 ms on localhost (1/1)
[13:09:02,234] INFO  {TaskSchedulerImpl} Removed TaskSet 103.0, whose tasks have all completed, from pool 
[13:09:02,234] INFO  {DAGScheduler} ResultStage 103 (sum at MyLinearRegressionImpl.scala:24) finished in 0.460 s
[13:09:02,234] INFO  {DAGScheduler} Job 101 finished: sum at MyLinearRegressionImpl.scala:24, took 0.476070 s
[13:09:02,237] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:02,238] INFO  {DAGScheduler} Got job 102 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:02,238] INFO  {DAGScheduler} Final stage: ResultStage 104 (count at MyLinearRegressionImpl.scala:26)
[13:09:02,238] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:02,238] INFO  {DAGScheduler} Missing parents: List()
[13:09:02,239] INFO  {DAGScheduler} Submitting ResultStage 104 (MapPartitionsRDD[118] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:02,241] INFO  {MemoryStore} Block broadcast_109 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:02,248] INFO  {MemoryStore} Block broadcast_109_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:02,248] INFO  {BlockManagerInfo} Removed broadcast_104_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:02,249] INFO  {BlockManagerInfo} Added broadcast_109_piece0 in memory on 192.168.0.103:41453 (size: 15.8 KB, free: 1128.8 MB)
[13:09:02,250] INFO  {SparkContext} Created broadcast 109 from broadcast at DAGScheduler.scala:1012
[13:09:02,250] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[118] at map at MyLinearRegressionImpl.scala:36)
[13:09:02,250] INFO  {TaskSchedulerImpl} Adding task set 104.0 with 1 tasks
[13:09:02,250] INFO  {BlockManagerInfo} Removed broadcast_105_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:02,252] INFO  {BlockManagerInfo} Removed broadcast_106_piece0 on 192.168.0.103:41453 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:02,252] INFO  {TaskSetManager} Starting task 0.0 in stage 104.0 (TID 104, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:02,253] INFO  {Executor} Running task 0.0 in stage 104.0 (TID 104)
[13:09:02,254] INFO  {BlockManagerInfo} Removed broadcast_107_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:02,256] INFO  {BlockManagerInfo} Removed broadcast_108_piece0 on 192.168.0.103:41453 in memory (size: 16.1 KB, free: 1128.9 MB)
[13:09:02,260] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:02,704] INFO  {Executor} Finished task 0.0 in stage 104.0 (TID 104). 1683 bytes result sent to driver
[13:09:02,705] INFO  {TaskSetManager} Finished task 0.0 in stage 104.0 (TID 104) in 454 ms on localhost (1/1)
[13:09:02,705] INFO  {TaskSchedulerImpl} Removed TaskSet 104.0, whose tasks have all completed, from pool 
[13:09:02,705] INFO  {DAGScheduler} ResultStage 104 (count at MyLinearRegressionImpl.scala:26) finished in 0.454 s
[13:09:02,706] INFO  {DAGScheduler} Job 102 finished: count at MyLinearRegressionImpl.scala:26, took 0.468137 s
[13:09:02,711] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:02,712] INFO  {DAGScheduler} Got job 103 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:02,712] INFO  {DAGScheduler} Final stage: ResultStage 105 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:02,712] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:02,712] INFO  {DAGScheduler} Missing parents: List()
[13:09:02,712] INFO  {DAGScheduler} Submitting ResultStage 105 (MapPartitionsRDD[120] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:02,714] INFO  {MemoryStore} Block broadcast_110 stored as values in memory (estimated size 45.8 KB, free 1128.6 MB)
[13:09:02,716] INFO  {MemoryStore} Block broadcast_110_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.6 MB)
[13:09:02,717] INFO  {BlockManagerInfo} Added broadcast_110_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:09:02,718] INFO  {SparkContext} Created broadcast 110 from broadcast at DAGScheduler.scala:1012
[13:09:02,718] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[120] at map at MyLinearRegressionImpl.scala:54)
[13:09:02,718] INFO  {TaskSchedulerImpl} Adding task set 105.0 with 1 tasks
[13:09:02,719] INFO  {TaskSetManager} Starting task 0.0 in stage 105.0 (TID 105, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:02,720] INFO  {Executor} Running task 0.0 in stage 105.0 (TID 105)
[13:09:02,727] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:03,087] INFO  {Executor} Finished task 0.0 in stage 105.0 (TID 105). 2499 bytes result sent to driver
[13:09:03,088] INFO  {TaskSetManager} Finished task 0.0 in stage 105.0 (TID 105) in 369 ms on localhost (1/1)
[13:09:03,088] INFO  {TaskSchedulerImpl} Removed TaskSet 105.0, whose tasks have all completed, from pool 
[13:09:03,089] INFO  {DAGScheduler} ResultStage 105 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.371 s
[13:09:03,089] INFO  {DAGScheduler} Job 103 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.378098 s
[13:09:03,096] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:03,097] INFO  {DAGScheduler} Got job 104 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:03,097] INFO  {DAGScheduler} Final stage: ResultStage 106 (sum at MyLinearRegressionImpl.scala:24)
[13:09:03,097] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:03,097] INFO  {DAGScheduler} Missing parents: List()
[13:09:03,098] INFO  {DAGScheduler} Submitting ResultStage 106 (MapPartitionsRDD[122] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:03,100] INFO  {MemoryStore} Block broadcast_111 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:03,102] INFO  {MemoryStore} Block broadcast_111_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:03,103] INFO  {BlockManagerInfo} Added broadcast_111_piece0 in memory on 192.168.0.103:41453 (size: 16.1 KB, free: 1128.8 MB)
[13:09:03,104] INFO  {SparkContext} Created broadcast 111 from broadcast at DAGScheduler.scala:1012
[13:09:03,104] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[122] at map at MyLinearRegressionImpl.scala:22)
[13:09:03,104] INFO  {TaskSchedulerImpl} Adding task set 106.0 with 1 tasks
[13:09:03,105] INFO  {TaskSetManager} Starting task 0.0 in stage 106.0 (TID 106, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:03,105] INFO  {Executor} Running task 0.0 in stage 106.0 (TID 106)
[13:09:03,112] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:03,407] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:09:03,415] INFO  {ServerConnector} Stopped ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:09:03,419] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[13:09:03,419] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[13:09:03,419] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[13:09:03,420] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[13:09:03,420] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[13:09:03,420] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[13:09:03,420] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[13:09:03,420] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[13:09:03,420] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[13:09:03,421] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[13:09:03,421] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[13:09:03,421] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[13:09:03,421] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[13:09:03,421] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[13:09:03,421] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[13:09:03,422] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[13:09:03,422] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[13:09:03,422] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[13:09:03,422] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[13:09:03,422] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[13:09:03,422] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[13:09:03,423] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[13:09:03,423] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[13:09:03,423] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[13:09:03,425] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:09:03,435] INFO  {DAGScheduler} Job 104 failed: sum at MyLinearRegressionImpl.scala:24, took 0.338329 s
[13:09:03,435] INFO  {DAGScheduler} ResultStage 106 (sum at MyLinearRegressionImpl.scala:24) failed in 0.330 s
[13:09:03,438] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@3f562b0)
[13:09:03,439] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(104,1511093343438,JobFailed(org.apache.spark.SparkException: Job 104 cancelled because SparkContext was shut down))
[13:09:03,451] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:09:03,471] INFO  {MemoryStore} MemoryStore cleared
[13:09:03,489] INFO  {BlockManager} BlockManager stopped
[13:09:03,490] ERROR {TaskContextImpl} Error in TaskCompletionListener
java.lang.IllegalStateException: Block broadcast_9 not found
	at org.apache.spark.storage.BlockInfoManager$$anonfun$1.apply(BlockInfoManager.scala:288)
	at org.apache.spark.storage.BlockInfoManager$$anonfun$1.apply(BlockInfoManager.scala:288)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:287)
	at org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:630)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$releaseLock$1.apply(TorrentBroadcast.scala:210)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$releaseLock$1.apply(TorrentBroadcast.scala:210)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:123)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:97)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:95)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:95)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[13:09:03,491] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:09:03,494] ERROR {TaskContextImpl} Error in TaskCompletionListener
java.lang.IllegalStateException: Block broadcast_111 not found
	at org.apache.spark.storage.BlockInfoManager$$anonfun$1.apply(BlockInfoManager.scala:288)
	at org.apache.spark.storage.BlockInfoManager$$anonfun$1.apply(BlockInfoManager.scala:288)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:287)
	at org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:630)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$releaseLock$1.apply(TorrentBroadcast.scala:210)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$releaseLock$1.apply(TorrentBroadcast.scala:210)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:123)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:97)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:95)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:95)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[13:09:03,499] ERROR {Executor} Exception in task 0.0 in stage 106.0 (TID 106)
java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:322)
	at scala.None$.get(Option.scala:320)
	at org.apache.spark.storage.BlockInfoManager.releaseAllLocksForTask(BlockInfoManager.scala:343)
	at org.apache.spark.storage.BlockManager.releaseAllLocksForTask(BlockManager.scala:646)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:281)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[13:09:03,501] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:09:03,511] INFO  {SparkContext} Successfully stopped SparkContext
[13:09:03,512] INFO  {ShutdownHookManager} Shutdown hook called
[13:09:03,514] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-4973a45c-5345-4a42-a071-b0ff7ad2c57e
[13:09:09,140] INFO  {SparkContext} Running Spark version 2.0.1
[13:09:09,699] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:09:09,989] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:09:09,990] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:09:10,152] INFO  {SecurityManager} Changing view acls to: victor
[13:09:10,153] INFO  {SecurityManager} Changing modify acls to: victor
[13:09:10,154] INFO  {SecurityManager} Changing view acls groups to: 
[13:09:10,156] INFO  {SecurityManager} Changing modify acls groups to: 
[13:09:10,157] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:09:11,200] INFO  {Utils} Successfully started service 'sparkDriver' on port 36903.
[13:09:11,327] INFO  {SparkEnv} Registering MapOutputTracker
[13:09:11,362] INFO  {SparkEnv} Registering BlockManagerMaster
[13:09:11,392] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-4a3a05c8-eeb3-4aff-97af-2a8a27005947
[13:09:11,449] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:09:11,587] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:09:11,814] INFO  {log} Logging initialized @4085ms
[13:09:12,154] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:09:12,189] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[13:09:12,189] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[13:09:12,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[13:09:12,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[13:09:12,191] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[13:09:12,191] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[13:09:12,191] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[13:09:12,192] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[13:09:12,192] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[13:09:12,193] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[13:09:12,193] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[13:09:12,194] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[13:09:12,195] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[13:09:12,195] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[13:09:12,196] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[13:09:12,196] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[13:09:12,196] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[13:09:12,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[13:09:12,197] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[13:09:12,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[13:09:12,211] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[13:09:12,212] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[13:09:12,213] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[13:09:12,214] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[13:09:12,225] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:09:12,225] INFO  {Server} Started @4500ms
[13:09:12,226] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:09:12,229] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:09:12,426] INFO  {Executor} Starting executor ID driver on host localhost
[13:09:12,473] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40629.
[13:09:12,475] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:40629
[13:09:12,478] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 40629)
[13:09:12,483] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:40629 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 40629)
[13:09:12,495] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 40629)
[13:09:12,867] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[13:09:12,969] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[13:09:12,971] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[13:09:12,974] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[13:09:12,976] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[13:09:12,982] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[13:09:13,016] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:09:16,055] INFO  {FileSourceStrategy} Pruning directories with: 
[13:09:16,058] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:09:16,062] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:09:16,063] INFO  {FileSourceStrategy} Pushed Filters: 
[13:09:16,310] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[13:09:16,370] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:09:16,372] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:40629 (size: 14.6 KB, free: 1128.9 MB)
[13:09:16,381] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:42
[13:09:16,385] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:09:16,993] INFO  {CodeGenerator} Code generated in 245.32865 ms
[13:09:17,113] INFO  {SparkContext} Starting job: show at Main.scala:42
[13:09:17,148] INFO  {DAGScheduler} Got job 0 (show at Main.scala:42) with 1 output partitions
[13:09:17,148] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:42)
[13:09:17,149] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:17,150] INFO  {DAGScheduler} Missing parents: List()
[13:09:17,156] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:42), which has no missing parents
[13:09:17,173] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[13:09:17,176] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1128.7 MB)
[13:09:17,176] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:40629 (size: 6.3 KB, free: 1128.9 MB)
[13:09:17,177] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:09:17,180] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:42)
[13:09:17,181] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:09:17,225] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5904 bytes)
[13:09:17,232] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:09:17,285] INFO  {CodeGenerator} Code generated in 15.780488 ms
[13:09:17,307] INFO  {CodeGenerator} Code generated in 8.721736 ms
[13:09:17,319] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:17,328] INFO  {CodeGenerator} Code generated in 7.242721 ms
[13:09:17,443] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2703 bytes result sent to driver
[13:09:17,451] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 247 ms on localhost (1/1)
[13:09:17,453] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:09:17,456] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:42) finished in 0.266 s
[13:09:17,462] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:42, took 0.348521 s
[13:09:17,484] INFO  {CodeGenerator} Code generated in 11.354492 ms
[13:09:17,520] INFO  {FileSourceStrategy} Pruning directories with: 
[13:09:17,521] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:09:17,521] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:09:17,521] INFO  {FileSourceStrategy} Pushed Filters: 
[13:09:17,527] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[13:09:17,539] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[13:09:17,539] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:40629 (size: 14.6 KB, free: 1128.9 MB)
[13:09:17,541] INFO  {SparkContext} Created broadcast 2 from foreach at Main.scala:45
[13:09:17,541] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:09:17,556] INFO  {FileSourceStrategy} Pruning directories with: 
[13:09:17,556] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:09:17,557] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:09:17,557] INFO  {FileSourceStrategy} Pushed Filters: 
[13:09:17,562] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[13:09:17,570] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[13:09:17,570] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:40629 (size: 14.6 KB, free: 1128.9 MB)
[13:09:17,572] INFO  {SparkContext} Created broadcast 3 from foreach at Main.scala:45
[13:09:17,572] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:09:17,596] INFO  {CodeGenerator} Code generated in 9.847916 ms
[13:09:17,629] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:40629 in memory (size: 6.3 KB, free: 1128.9 MB)
[13:09:17,632] INFO  {ContextCleaner} Cleaned accumulator 56
[13:09:17,635] INFO  {CodeGenerator} Code generated in 32.581347 ms
[13:09:17,678] INFO  {SparkContext} Starting job: foreach at Main.scala:45
[13:09:17,682] INFO  {DAGScheduler} Registering RDD 6 (foreach at Main.scala:45)
[13:09:17,682] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:45) with 1 output partitions
[13:09:17,682] INFO  {DAGScheduler} Final stage: ResultStage 2 (foreach at Main.scala:45)
[13:09:17,682] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 1)
[13:09:17,683] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 1)
[13:09:17,684] INFO  {DAGScheduler} Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at foreach at Main.scala:45), which has no missing parents
[13:09:17,693] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 15.0 KB, free 1128.5 MB)
[13:09:17,695] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.1 KB, free 1128.5 MB)
[13:09:17,696] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:40629 (size: 7.1 KB, free: 1128.9 MB)
[13:09:17,696] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[13:09:17,698] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at foreach at Main.scala:45)
[13:09:17,698] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:09:17,701] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[13:09:17,701] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:09:17,730] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:17,792] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2150 bytes result sent to driver
[13:09:17,796] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 96 ms on localhost (1/1)
[13:09:17,796] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:09:17,797] INFO  {DAGScheduler} ShuffleMapStage 1 (foreach at Main.scala:45) finished in 0.098 s
[13:09:17,797] INFO  {DAGScheduler} looking for newly runnable stages
[13:09:17,798] INFO  {DAGScheduler} running: Set()
[13:09:17,798] INFO  {DAGScheduler} waiting: Set(ResultStage 2)
[13:09:17,799] INFO  {DAGScheduler} failed: Set()
[13:09:17,801] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[10] at foreach at Main.scala:45), which has no missing parents
[13:09:17,816] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 13.8 KB, free 1128.4 MB)
[13:09:17,818] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.0 KB, free 1128.4 MB)
[13:09:17,818] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:40629 (size: 7.0 KB, free: 1128.8 MB)
[13:09:17,819] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[13:09:17,819] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at foreach at Main.scala:45)
[13:09:17,819] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:09:17,823] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5317 bytes)
[13:09:17,824] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:09:17,841] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:09:17,842] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[13:09:17,855] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 2222 bytes result sent to driver
[13:09:17,857] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 35 ms on localhost (1/1)
[13:09:17,857] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:09:17,857] INFO  {DAGScheduler} ResultStage 2 (foreach at Main.scala:45) finished in 0.036 s
[13:09:17,858] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:45, took 0.180159 s
[13:09:18,022] INFO  {ContextCleaner} Cleaned accumulator 63
[13:09:18,022] INFO  {ContextCleaner} Cleaned accumulator 64
[13:09:18,026] INFO  {ContextCleaner} Cleaned shuffle 0
[13:09:18,027] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:40629 in memory (size: 7.1 KB, free: 1128.9 MB)
[13:09:18,028] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:40629 in memory (size: 7.0 KB, free: 1128.9 MB)
[13:09:18,029] INFO  {ContextCleaner} Cleaned accumulator 62
[13:09:18,029] INFO  {ContextCleaner} Cleaned accumulator 61
[13:09:18,029] INFO  {ContextCleaner} Cleaned accumulator 60
[13:09:18,029] INFO  {ContextCleaner} Cleaned accumulator 59
[13:09:18,029] INFO  {ContextCleaner} Cleaned accumulator 58
[13:09:18,029] INFO  {ContextCleaner} Cleaned accumulator 57
[13:09:18,030] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:40629 in memory (size: 14.6 KB, free: 1128.9 MB)
[13:09:18,031] INFO  {ContextCleaner} Cleaned accumulator 55
[13:09:18,031] INFO  {ContextCleaner} Cleaned accumulator 54
[13:09:18,031] INFO  {ContextCleaner} Cleaned accumulator 53
[13:09:18,031] INFO  {ContextCleaner} Cleaned accumulator 52
[13:09:18,031] INFO  {ContextCleaner} Cleaned accumulator 51
[13:09:18,031] INFO  {ContextCleaner} Cleaned accumulator 50
[13:09:18,032] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:40629 in memory (size: 14.6 KB, free: 1128.9 MB)
[13:09:18,032] INFO  {ContextCleaner} Cleaned accumulator 5
[13:09:18,032] INFO  {ContextCleaner} Cleaned accumulator 4
[13:09:18,032] INFO  {ContextCleaner} Cleaned accumulator 3
[13:09:18,032] INFO  {ContextCleaner} Cleaned accumulator 2
[13:09:18,032] INFO  {ContextCleaner} Cleaned accumulator 1
[13:09:18,032] INFO  {ContextCleaner} Cleaned accumulator 0
[13:09:18,033] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 192.168.0.103:40629 in memory (size: 14.6 KB, free: 1128.9 MB)
[13:09:18,251] INFO  {FileSourceStrategy} Pruning directories with: 
[13:09:18,251] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:09:18,251] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:09:18,252] INFO  {FileSourceStrategy} Pushed Filters: 
[13:09:18,256] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[13:09:18,263] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:09:18,264] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:40629 (size: 14.6 KB, free: 1128.9 MB)
[13:09:18,265] INFO  {SparkContext} Created broadcast 6 from collect at PipelineBuilder.scala:59
[13:09:18,265] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:09:18,307] INFO  {CodeGenerator} Code generated in 13.517461 ms
[13:09:18,348] INFO  {CodeGenerator} Code generated in 31.761369 ms
[13:09:18,396] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[13:09:18,396] INFO  {DAGScheduler} Registering RDD 13 (collect at PipelineBuilder.scala:59)
[13:09:18,397] INFO  {DAGScheduler} Got job 2 (collect at PipelineBuilder.scala:59) with 1 output partitions
[13:09:18,397] INFO  {DAGScheduler} Final stage: ResultStage 4 (collect at PipelineBuilder.scala:59)
[13:09:18,397] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 3)
[13:09:18,397] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 3)
[13:09:18,398] INFO  {DAGScheduler} Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:09:18,401] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 29.5 KB, free 1128.7 MB)
[13:09:18,403] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.1 KB, free 1128.7 MB)
[13:09:18,404] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:40629 (size: 12.1 KB, free: 1128.9 MB)
[13:09:18,404] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[13:09:18,404] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at PipelineBuilder.scala:59)
[13:09:18,405] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[13:09:18,406] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[13:09:18,407] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[13:09:18,422] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:18,704] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 2406 bytes result sent to driver
[13:09:18,705] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 300 ms on localhost (1/1)
[13:09:18,706] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[13:09:18,707] INFO  {DAGScheduler} ShuffleMapStage 3 (collect at PipelineBuilder.scala:59) finished in 0.301 s
[13:09:18,707] INFO  {DAGScheduler} looking for newly runnable stages
[13:09:18,707] INFO  {DAGScheduler} running: Set()
[13:09:18,707] INFO  {DAGScheduler} waiting: Set(ResultStage 4)
[13:09:18,707] INFO  {DAGScheduler} failed: Set()
[13:09:18,707] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[16] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:09:18,710] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[13:09:18,714] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[13:09:18,714] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:40629 (size: 3.9 KB, free: 1128.9 MB)
[13:09:18,715] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[13:09:18,716] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at collect at PipelineBuilder.scala:59)
[13:09:18,716] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[13:09:18,717] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, ANY, 5317 bytes)
[13:09:18,718] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[13:09:18,721] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:09:18,721] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[13:09:18,724] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1868 bytes result sent to driver
[13:09:18,725] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 9 ms on localhost (1/1)
[13:09:18,725] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[13:09:18,725] INFO  {DAGScheduler} ResultStage 4 (collect at PipelineBuilder.scala:59) finished in 0.007 s
[13:09:18,726] INFO  {DAGScheduler} Job 2 finished: collect at PipelineBuilder.scala:59, took 0.329998 s
[13:09:18,747] INFO  {CodeGenerator} Code generated in 6.939876 ms
[13:09:18,932] INFO  {FileSourceStrategy} Pruning directories with: 
[13:09:18,932] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:09:18,933] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:09:18,933] INFO  {FileSourceStrategy} Pushed Filters: 
[13:09:18,938] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[13:09:19,054] INFO  {BlockManagerInfo} Removed broadcast_8_piece0 on 192.168.0.103:40629 in memory (size: 3.9 KB, free: 1128.9 MB)
[13:09:19,055] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[13:09:19,055] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:40629 in memory (size: 12.1 KB, free: 1128.9 MB)
[13:09:19,055] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:40629 (size: 14.6 KB, free: 1128.9 MB)
[13:09:19,056] INFO  {BlockManagerInfo} Removed broadcast_6_piece0 on 192.168.0.103:40629 in memory (size: 14.6 KB, free: 1128.9 MB)
[13:09:19,056] INFO  {ContextCleaner} Cleaned accumulator 153
[13:09:19,056] INFO  {ContextCleaner} Cleaned accumulator 154
[13:09:19,056] INFO  {SparkContext} Created broadcast 9 from rdd at MyLinearRegressionImpl.scala:92
[13:09:19,056] INFO  {ContextCleaner} Cleaned accumulator 155
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 156
[13:09:19,057] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 157
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 158
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 159
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 160
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 161
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 162
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 163
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 164
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 165
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 166
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 167
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 168
[13:09:19,057] INFO  {ContextCleaner} Cleaned accumulator 169
[13:09:19,058] INFO  {ContextCleaner} Cleaned shuffle 1
[13:09:19,149] INFO  {CodeGenerator} Code generated in 70.801292 ms
[13:09:19,177] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:63
[13:09:19,178] INFO  {DAGScheduler} Got job 3 (count at MyLinearRegressionImpl.scala:63) with 1 output partitions
[13:09:19,178] INFO  {DAGScheduler} Final stage: ResultStage 5 (count at MyLinearRegressionImpl.scala:63)
[13:09:19,178] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:19,179] INFO  {DAGScheduler} Missing parents: List()
[13:09:19,179] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[21] at map at MyLinearRegressionImpl.scala:92), which has no missing parents
[13:09:19,186] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 44.0 KB, free 1128.7 MB)
[13:09:19,188] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.9 KB, free 1128.7 MB)
[13:09:19,188] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:40629 (size: 14.9 KB, free: 1128.9 MB)
[13:09:19,189] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[13:09:19,189] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at map at MyLinearRegressionImpl.scala:92)
[13:09:19,189] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[13:09:19,191] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:19,192] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[13:09:19,221] INFO  {CodeGenerator} Code generated in 10.649536 ms
[13:09:19,223] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:19,535] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1770 bytes result sent to driver
[13:09:19,536] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 346 ms on localhost (1/1)
[13:09:19,536] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[13:09:19,536] INFO  {DAGScheduler} ResultStage 5 (count at MyLinearRegressionImpl.scala:63) finished in 0.346 s
[13:09:19,536] INFO  {DAGScheduler} Job 3 finished: count at MyLinearRegressionImpl.scala:63, took 0.358878 s
[13:09:19,547] INFO  {SparkContext} Starting job: take at MyLinearRegressionImpl.scala:64
[13:09:19,548] INFO  {DAGScheduler} Got job 4 (take at MyLinearRegressionImpl.scala:64) with 1 output partitions
[13:09:19,548] INFO  {DAGScheduler} Final stage: ResultStage 6 (take at MyLinearRegressionImpl.scala:64)
[13:09:19,548] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:19,548] INFO  {DAGScheduler} Missing parents: List()
[13:09:19,548] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at map at MyLinearRegressionImpl.scala:92), which has no missing parents
[13:09:19,551] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 44.2 KB, free 1128.7 MB)
[13:09:19,554] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1128.6 MB)
[13:09:19,554] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:40629 (size: 15.0 KB, free: 1128.9 MB)
[13:09:19,555] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[13:09:19,555] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at map at MyLinearRegressionImpl.scala:92)
[13:09:19,555] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[13:09:19,557] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:19,558] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[13:09:19,565] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:19,580] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2677 bytes result sent to driver
[13:09:19,581] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 25 ms on localhost (1/1)
[13:09:19,582] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[13:09:19,582] INFO  {DAGScheduler} ResultStage 6 (take at MyLinearRegressionImpl.scala:64) finished in 0.026 s
[13:09:19,582] INFO  {DAGScheduler} Job 4 finished: take at MyLinearRegressionImpl.scala:64, took 0.035333 s
[13:09:19,633] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:19,634] INFO  {DAGScheduler} Got job 5 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:19,634] INFO  {DAGScheduler} Final stage: ResultStage 7 (sum at MyLinearRegressionImpl.scala:24)
[13:09:19,634] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:19,634] INFO  {DAGScheduler} Missing parents: List()
[13:09:19,635] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[23] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:19,637] INFO  {MemoryStore} Block broadcast_12 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:09:19,754] INFO  {MemoryStore} Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.3 KB, free 1128.6 MB)
[13:09:19,754] INFO  {BlockManagerInfo} Removed broadcast_11_piece0 on 192.168.0.103:40629 in memory (size: 15.0 KB, free: 1128.9 MB)
[13:09:19,755] INFO  {BlockManagerInfo} Added broadcast_12_piece0 in memory on 192.168.0.103:40629 (size: 15.3 KB, free: 1128.9 MB)
[13:09:19,755] INFO  {SparkContext} Created broadcast 12 from broadcast at DAGScheduler.scala:1012
[13:09:19,756] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at map at MyLinearRegressionImpl.scala:22)
[13:09:19,756] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[13:09:19,756] INFO  {BlockManagerInfo} Removed broadcast_10_piece0 on 192.168.0.103:40629 in memory (size: 14.9 KB, free: 1128.9 MB)
[13:09:19,758] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5956 bytes)
[13:09:19,759] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[13:09:19,769] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:20,207] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1685 bytes result sent to driver
[13:09:20,209] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 453 ms on localhost (1/1)
[13:09:20,209] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[13:09:20,210] INFO  {DAGScheduler} ResultStage 7 (sum at MyLinearRegressionImpl.scala:24) finished in 0.454 s
[13:09:20,211] INFO  {DAGScheduler} Job 5 finished: sum at MyLinearRegressionImpl.scala:24, took 0.577601 s
[13:09:20,218] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:20,220] INFO  {DAGScheduler} Got job 6 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:20,220] INFO  {DAGScheduler} Final stage: ResultStage 8 (count at MyLinearRegressionImpl.scala:26)
[13:09:20,220] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:20,221] INFO  {DAGScheduler} Missing parents: List()
[13:09:20,221] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[22] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:20,228] INFO  {MemoryStore} Block broadcast_13 stored as values in memory (estimated size 45.0 KB, free 1128.7 MB)
[13:09:20,232] INFO  {MemoryStore} Block broadcast_13_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1128.6 MB)
[13:09:20,233] INFO  {BlockManagerInfo} Added broadcast_13_piece0 in memory on 192.168.0.103:40629 (size: 15.1 KB, free: 1128.9 MB)
[13:09:20,234] INFO  {SparkContext} Created broadcast 13 from broadcast at DAGScheduler.scala:1012
[13:09:20,234] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[22] at map at MyLinearRegressionImpl.scala:36)
[13:09:20,234] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[13:09:20,238] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:20,239] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[13:09:20,258] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:20,681] INFO  {BlockManagerInfo} Removed broadcast_12_piece0 on 192.168.0.103:40629 in memory (size: 15.3 KB, free: 1128.9 MB)
[13:09:21,011] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 1843 bytes result sent to driver
[13:09:21,012] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 776 ms on localhost (1/1)
[13:09:21,013] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[13:09:21,014] INFO  {DAGScheduler} ResultStage 8 (count at MyLinearRegressionImpl.scala:26) finished in 0.779 s
[13:09:21,014] INFO  {DAGScheduler} Job 6 finished: count at MyLinearRegressionImpl.scala:26, took 0.796069 s
[13:09:21,035] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:21,037] INFO  {DAGScheduler} Got job 7 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:21,037] INFO  {DAGScheduler} Final stage: ResultStage 9 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:21,037] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:21,037] INFO  {DAGScheduler} Missing parents: List()
[13:09:21,038] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[24] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:21,044] INFO  {MemoryStore} Block broadcast_14 stored as values in memory (estimated size 45.8 KB, free 1128.7 MB)
[13:09:21,046] INFO  {MemoryStore} Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.4 KB, free 1128.6 MB)
[13:09:21,047] INFO  {BlockManagerInfo} Added broadcast_14_piece0 in memory on 192.168.0.103:40629 (size: 15.4 KB, free: 1128.9 MB)
[13:09:21,048] INFO  {SparkContext} Created broadcast 14 from broadcast at DAGScheduler.scala:1012
[13:09:21,048] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[24] at map at MyLinearRegressionImpl.scala:54)
[13:09:21,048] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[13:09:21,051] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5959 bytes)
[13:09:21,051] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[13:09:21,067] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:21,520] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 2499 bytes result sent to driver
[13:09:21,522] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 472 ms on localhost (1/1)
[13:09:21,522] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[13:09:21,523] INFO  {DAGScheduler} ResultStage 9 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.473 s
[13:09:21,524] INFO  {DAGScheduler} Job 7 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.488579 s
[13:09:21,538] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:21,539] INFO  {DAGScheduler} Got job 8 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:21,540] INFO  {DAGScheduler} Final stage: ResultStage 10 (sum at MyLinearRegressionImpl.scala:24)
[13:09:21,540] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:21,540] INFO  {DAGScheduler} Missing parents: List()
[13:09:21,541] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[26] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:21,546] INFO  {MemoryStore} Block broadcast_15 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:09:21,549] INFO  {MemoryStore} Block broadcast_15_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.6 MB)
[13:09:21,549] INFO  {BlockManagerInfo} Added broadcast_15_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:21,550] INFO  {SparkContext} Created broadcast 15 from broadcast at DAGScheduler.scala:1012
[13:09:21,551] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at map at MyLinearRegressionImpl.scala:22)
[13:09:21,551] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[13:09:21,554] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5956 bytes)
[13:09:21,554] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[13:09:21,568] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:21,851] INFO  {BlockManagerInfo} Removed broadcast_14_piece0 on 192.168.0.103:40629 in memory (size: 15.4 KB, free: 1128.9 MB)
[13:09:22,002] INFO  {Executor} Finished task 0.0 in stage 10.0 (TID 10). 1758 bytes result sent to driver
[13:09:22,004] INFO  {TaskSetManager} Finished task 0.0 in stage 10.0 (TID 10) in 452 ms on localhost (1/1)
[13:09:22,004] INFO  {TaskSchedulerImpl} Removed TaskSet 10.0, whose tasks have all completed, from pool 
[13:09:22,005] INFO  {DAGScheduler} ResultStage 10 (sum at MyLinearRegressionImpl.scala:24) finished in 0.454 s
[13:09:22,006] INFO  {DAGScheduler} Job 8 finished: sum at MyLinearRegressionImpl.scala:24, took 0.467599 s
[13:09:22,012] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:22,013] INFO  {DAGScheduler} Got job 9 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:22,013] INFO  {DAGScheduler} Final stage: ResultStage 11 (count at MyLinearRegressionImpl.scala:26)
[13:09:22,013] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:22,014] INFO  {DAGScheduler} Missing parents: List()
[13:09:22,014] INFO  {DAGScheduler} Submitting ResultStage 11 (MapPartitionsRDD[25] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:22,018] INFO  {MemoryStore} Block broadcast_16 stored as values in memory (estimated size 45.0 KB, free 1128.6 MB)
[13:09:22,020] INFO  {MemoryStore} Block broadcast_16_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.6 MB)
[13:09:22,021] INFO  {BlockManagerInfo} Added broadcast_16_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:22,022] INFO  {SparkContext} Created broadcast 16 from broadcast at DAGScheduler.scala:1012
[13:09:22,023] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[25] at map at MyLinearRegressionImpl.scala:36)
[13:09:22,023] INFO  {TaskSchedulerImpl} Adding task set 11.0 with 1 tasks
[13:09:22,025] INFO  {TaskSetManager} Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:22,026] INFO  {Executor} Running task 0.0 in stage 11.0 (TID 11)
[13:09:22,043] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:22,435] INFO  {Executor} Finished task 0.0 in stage 11.0 (TID 11). 1683 bytes result sent to driver
[13:09:22,437] INFO  {TaskSetManager} Finished task 0.0 in stage 11.0 (TID 11) in 414 ms on localhost (1/1)
[13:09:22,438] INFO  {TaskSchedulerImpl} Removed TaskSet 11.0, whose tasks have all completed, from pool 
[13:09:22,438] INFO  {DAGScheduler} ResultStage 11 (count at MyLinearRegressionImpl.scala:26) finished in 0.415 s
[13:09:22,439] INFO  {DAGScheduler} Job 9 finished: count at MyLinearRegressionImpl.scala:26, took 0.426885 s
[13:09:22,446] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:22,447] INFO  {DAGScheduler} Got job 10 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:22,447] INFO  {DAGScheduler} Final stage: ResultStage 12 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:22,447] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:22,448] INFO  {DAGScheduler} Missing parents: List()
[13:09:22,448] INFO  {DAGScheduler} Submitting ResultStage 12 (MapPartitionsRDD[27] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:22,451] INFO  {MemoryStore} Block broadcast_17 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:22,454] INFO  {MemoryStore} Block broadcast_17_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:22,455] INFO  {BlockManagerInfo} Added broadcast_17_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:22,455] INFO  {SparkContext} Created broadcast 17 from broadcast at DAGScheduler.scala:1012
[13:09:22,456] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[27] at map at MyLinearRegressionImpl.scala:54)
[13:09:22,456] INFO  {TaskSchedulerImpl} Adding task set 12.0 with 1 tasks
[13:09:22,458] INFO  {TaskSetManager} Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5959 bytes)
[13:09:22,459] INFO  {Executor} Running task 0.0 in stage 12.0 (TID 12)
[13:09:22,470] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:22,785] INFO  {BlockManagerInfo} Removed broadcast_16_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:22,835] INFO  {Executor} Finished task 0.0 in stage 12.0 (TID 12). 2572 bytes result sent to driver
[13:09:22,837] INFO  {TaskSetManager} Finished task 0.0 in stage 12.0 (TID 12) in 380 ms on localhost (1/1)
[13:09:22,837] INFO  {TaskSchedulerImpl} Removed TaskSet 12.0, whose tasks have all completed, from pool 
[13:09:22,838] INFO  {DAGScheduler} ResultStage 12 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.382 s
[13:09:22,839] INFO  {DAGScheduler} Job 10 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.392570 s
[13:09:22,852] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:22,853] INFO  {DAGScheduler} Got job 11 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:22,853] INFO  {DAGScheduler} Final stage: ResultStage 13 (sum at MyLinearRegressionImpl.scala:24)
[13:09:22,854] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:22,854] INFO  {DAGScheduler} Missing parents: List()
[13:09:22,855] INFO  {DAGScheduler} Submitting ResultStage 13 (MapPartitionsRDD[29] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:22,858] INFO  {MemoryStore} Block broadcast_18 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:22,860] INFO  {MemoryStore} Block broadcast_18_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:22,861] INFO  {BlockManagerInfo} Added broadcast_18_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:22,862] INFO  {SparkContext} Created broadcast 18 from broadcast at DAGScheduler.scala:1012
[13:09:22,862] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[29] at map at MyLinearRegressionImpl.scala:22)
[13:09:22,862] INFO  {TaskSchedulerImpl} Adding task set 13.0 with 1 tasks
[13:09:22,865] INFO  {TaskSetManager} Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5956 bytes)
[13:09:22,865] INFO  {Executor} Running task 0.0 in stage 13.0 (TID 13)
[13:09:22,875] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:23,216] INFO  {Executor} Finished task 0.0 in stage 13.0 (TID 13). 1685 bytes result sent to driver
[13:09:23,217] INFO  {TaskSetManager} Finished task 0.0 in stage 13.0 (TID 13) in 354 ms on localhost (1/1)
[13:09:23,217] INFO  {TaskSchedulerImpl} Removed TaskSet 13.0, whose tasks have all completed, from pool 
[13:09:23,218] INFO  {DAGScheduler} ResultStage 13 (sum at MyLinearRegressionImpl.scala:24) finished in 0.355 s
[13:09:23,219] INFO  {DAGScheduler} Job 11 finished: sum at MyLinearRegressionImpl.scala:24, took 0.366060 s
[13:09:23,225] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:23,226] INFO  {DAGScheduler} Got job 12 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:23,226] INFO  {DAGScheduler} Final stage: ResultStage 14 (count at MyLinearRegressionImpl.scala:26)
[13:09:23,226] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:23,227] INFO  {DAGScheduler} Missing parents: List()
[13:09:23,227] INFO  {DAGScheduler} Submitting ResultStage 14 (MapPartitionsRDD[28] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:23,230] INFO  {MemoryStore} Block broadcast_19 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:23,233] INFO  {MemoryStore} Block broadcast_19_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:23,234] INFO  {BlockManagerInfo} Added broadcast_19_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:23,235] INFO  {SparkContext} Created broadcast 19 from broadcast at DAGScheduler.scala:1012
[13:09:23,235] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[28] at map at MyLinearRegressionImpl.scala:36)
[13:09:23,235] INFO  {TaskSchedulerImpl} Adding task set 14.0 with 1 tasks
[13:09:23,237] INFO  {TaskSetManager} Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:23,238] INFO  {Executor} Running task 0.0 in stage 14.0 (TID 14)
[13:09:23,248] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:23,582] INFO  {Executor} Finished task 0.0 in stage 14.0 (TID 14). 1683 bytes result sent to driver
[13:09:23,584] INFO  {TaskSetManager} Finished task 0.0 in stage 14.0 (TID 14) in 348 ms on localhost (1/1)
[13:09:23,584] INFO  {TaskSchedulerImpl} Removed TaskSet 14.0, whose tasks have all completed, from pool 
[13:09:23,585] INFO  {DAGScheduler} ResultStage 14 (count at MyLinearRegressionImpl.scala:26) finished in 0.349 s
[13:09:23,586] INFO  {DAGScheduler} Job 12 finished: count at MyLinearRegressionImpl.scala:26, took 0.360753 s
[13:09:23,592] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:23,593] INFO  {DAGScheduler} Got job 13 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:23,593] INFO  {DAGScheduler} Final stage: ResultStage 15 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:23,593] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:23,593] INFO  {DAGScheduler} Missing parents: List()
[13:09:23,594] INFO  {DAGScheduler} Submitting ResultStage 15 (MapPartitionsRDD[30] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:23,598] INFO  {MemoryStore} Block broadcast_20 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:23,601] INFO  {MemoryStore} Block broadcast_20_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:23,602] INFO  {BlockManagerInfo} Added broadcast_20_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:23,602] INFO  {SparkContext} Created broadcast 20 from broadcast at DAGScheduler.scala:1012
[13:09:23,603] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[30] at map at MyLinearRegressionImpl.scala:54)
[13:09:23,603] INFO  {TaskSchedulerImpl} Adding task set 15.0 with 1 tasks
[13:09:23,607] INFO  {TaskSetManager} Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, PROCESS_LOCAL, 5959 bytes)
[13:09:23,608] INFO  {Executor} Running task 0.0 in stage 15.0 (TID 15)
[13:09:23,620] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:23,890] INFO  {BlockManagerInfo} Removed broadcast_19_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:23,892] INFO  {BlockManagerInfo} Removed broadcast_18_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:23,895] INFO  {BlockManagerInfo} Removed broadcast_17_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:24,037] INFO  {Executor} Finished task 0.0 in stage 15.0 (TID 15). 2659 bytes result sent to driver
[13:09:24,039] INFO  {TaskSetManager} Finished task 0.0 in stage 15.0 (TID 15) in 435 ms on localhost (1/1)
[13:09:24,040] INFO  {TaskSchedulerImpl} Removed TaskSet 15.0, whose tasks have all completed, from pool 
[13:09:24,040] INFO  {DAGScheduler} ResultStage 15 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.437 s
[13:09:24,041] INFO  {DAGScheduler} Job 13 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.448455 s
[13:09:24,054] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:24,055] INFO  {DAGScheduler} Got job 14 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:24,055] INFO  {DAGScheduler} Final stage: ResultStage 16 (sum at MyLinearRegressionImpl.scala:24)
[13:09:24,055] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:24,056] INFO  {DAGScheduler} Missing parents: List()
[13:09:24,057] INFO  {DAGScheduler} Submitting ResultStage 16 (MapPartitionsRDD[32] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:24,061] INFO  {MemoryStore} Block broadcast_21 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:24,063] INFO  {MemoryStore} Block broadcast_21_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:24,064] INFO  {BlockManagerInfo} Added broadcast_21_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:24,065] INFO  {SparkContext} Created broadcast 21 from broadcast at DAGScheduler.scala:1012
[13:09:24,065] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[32] at map at MyLinearRegressionImpl.scala:22)
[13:09:24,066] INFO  {TaskSchedulerImpl} Adding task set 16.0 with 1 tasks
[13:09:24,068] INFO  {TaskSetManager} Starting task 0.0 in stage 16.0 (TID 16, localhost, partition 0, PROCESS_LOCAL, 5956 bytes)
[13:09:24,069] INFO  {Executor} Running task 0.0 in stage 16.0 (TID 16)
[13:09:24,081] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:24,418] INFO  {Executor} Finished task 0.0 in stage 16.0 (TID 16). 1685 bytes result sent to driver
[13:09:24,420] INFO  {TaskSetManager} Finished task 0.0 in stage 16.0 (TID 16) in 353 ms on localhost (1/1)
[13:09:24,420] INFO  {TaskSchedulerImpl} Removed TaskSet 16.0, whose tasks have all completed, from pool 
[13:09:24,420] INFO  {DAGScheduler} ResultStage 16 (sum at MyLinearRegressionImpl.scala:24) finished in 0.354 s
[13:09:24,421] INFO  {DAGScheduler} Job 14 finished: sum at MyLinearRegressionImpl.scala:24, took 0.366760 s
[13:09:24,427] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:24,429] INFO  {DAGScheduler} Got job 15 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:24,429] INFO  {DAGScheduler} Final stage: ResultStage 17 (count at MyLinearRegressionImpl.scala:26)
[13:09:24,429] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:24,429] INFO  {DAGScheduler} Missing parents: List()
[13:09:24,430] INFO  {DAGScheduler} Submitting ResultStage 17 (MapPartitionsRDD[31] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:24,433] INFO  {MemoryStore} Block broadcast_22 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:24,435] INFO  {MemoryStore} Block broadcast_22_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:24,436] INFO  {BlockManagerInfo} Added broadcast_22_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:24,437] INFO  {SparkContext} Created broadcast 22 from broadcast at DAGScheduler.scala:1012
[13:09:24,437] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[31] at map at MyLinearRegressionImpl.scala:36)
[13:09:24,437] INFO  {TaskSchedulerImpl} Adding task set 17.0 with 1 tasks
[13:09:24,440] INFO  {TaskSetManager} Starting task 0.0 in stage 17.0 (TID 17, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:24,440] INFO  {Executor} Running task 0.0 in stage 17.0 (TID 17)
[13:09:24,454] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:24,697] INFO  {Executor} Finished task 0.0 in stage 17.0 (TID 17). 1683 bytes result sent to driver
[13:09:24,698] INFO  {TaskSetManager} Finished task 0.0 in stage 17.0 (TID 17) in 260 ms on localhost (1/1)
[13:09:24,698] INFO  {TaskSchedulerImpl} Removed TaskSet 17.0, whose tasks have all completed, from pool 
[13:09:24,698] INFO  {DAGScheduler} ResultStage 17 (count at MyLinearRegressionImpl.scala:26) finished in 0.260 s
[13:09:24,699] INFO  {DAGScheduler} Job 15 finished: count at MyLinearRegressionImpl.scala:26, took 0.270986 s
[13:09:24,704] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:24,704] INFO  {DAGScheduler} Got job 16 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:24,704] INFO  {DAGScheduler} Final stage: ResultStage 18 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:24,704] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:24,705] INFO  {DAGScheduler} Missing parents: List()
[13:09:24,705] INFO  {DAGScheduler} Submitting ResultStage 18 (MapPartitionsRDD[33] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:24,707] INFO  {MemoryStore} Block broadcast_23 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:24,709] INFO  {MemoryStore} Block broadcast_23_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:24,709] INFO  {BlockManagerInfo} Added broadcast_23_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:24,710] INFO  {SparkContext} Created broadcast 23 from broadcast at DAGScheduler.scala:1012
[13:09:24,710] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[33] at map at MyLinearRegressionImpl.scala:54)
[13:09:24,710] INFO  {TaskSchedulerImpl} Adding task set 18.0 with 1 tasks
[13:09:24,712] INFO  {TaskSetManager} Starting task 0.0 in stage 18.0 (TID 18, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:24,712] INFO  {Executor} Running task 0.0 in stage 18.0 (TID 18)
[13:09:24,719] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:24,762] INFO  {BlockManagerInfo} Removed broadcast_22_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:24,763] INFO  {BlockManagerInfo} Removed broadcast_20_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:24,763] INFO  {BlockManagerInfo} Removed broadcast_21_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:24,862] INFO  {Executor} Finished task 0.0 in stage 18.0 (TID 18). 2572 bytes result sent to driver
[13:09:24,862] INFO  {TaskSetManager} Finished task 0.0 in stage 18.0 (TID 18) in 151 ms on localhost (1/1)
[13:09:24,863] INFO  {TaskSchedulerImpl} Removed TaskSet 18.0, whose tasks have all completed, from pool 
[13:09:24,863] INFO  {DAGScheduler} ResultStage 18 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.153 s
[13:09:24,863] INFO  {DAGScheduler} Job 16 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.159261 s
[13:09:24,867] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:24,868] INFO  {DAGScheduler} Got job 17 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:24,868] INFO  {DAGScheduler} Final stage: ResultStage 19 (sum at MyLinearRegressionImpl.scala:24)
[13:09:24,868] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:24,868] INFO  {DAGScheduler} Missing parents: List()
[13:09:24,868] INFO  {DAGScheduler} Submitting ResultStage 19 (MapPartitionsRDD[35] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:24,870] INFO  {MemoryStore} Block broadcast_24 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:24,871] INFO  {MemoryStore} Block broadcast_24_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:24,871] INFO  {BlockManagerInfo} Added broadcast_24_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:24,872] INFO  {SparkContext} Created broadcast 24 from broadcast at DAGScheduler.scala:1012
[13:09:24,872] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[35] at map at MyLinearRegressionImpl.scala:22)
[13:09:24,872] INFO  {TaskSchedulerImpl} Adding task set 19.0 with 1 tasks
[13:09:24,873] INFO  {TaskSetManager} Starting task 0.0 in stage 19.0 (TID 19, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:24,874] INFO  {Executor} Running task 0.0 in stage 19.0 (TID 19)
[13:09:24,878] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:25,018] INFO  {Executor} Finished task 0.0 in stage 19.0 (TID 19). 1685 bytes result sent to driver
[13:09:25,019] INFO  {TaskSetManager} Finished task 0.0 in stage 19.0 (TID 19) in 147 ms on localhost (1/1)
[13:09:25,019] INFO  {TaskSchedulerImpl} Removed TaskSet 19.0, whose tasks have all completed, from pool 
[13:09:25,019] INFO  {DAGScheduler} ResultStage 19 (sum at MyLinearRegressionImpl.scala:24) finished in 0.147 s
[13:09:25,019] INFO  {DAGScheduler} Job 17 finished: sum at MyLinearRegressionImpl.scala:24, took 0.151910 s
[13:09:25,022] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:25,023] INFO  {DAGScheduler} Got job 18 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:25,023] INFO  {DAGScheduler} Final stage: ResultStage 20 (count at MyLinearRegressionImpl.scala:26)
[13:09:25,023] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:25,023] INFO  {DAGScheduler} Missing parents: List()
[13:09:25,023] INFO  {DAGScheduler} Submitting ResultStage 20 (MapPartitionsRDD[34] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:25,025] INFO  {MemoryStore} Block broadcast_25 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:25,027] INFO  {MemoryStore} Block broadcast_25_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:25,027] INFO  {BlockManagerInfo} Added broadcast_25_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:25,027] INFO  {SparkContext} Created broadcast 25 from broadcast at DAGScheduler.scala:1012
[13:09:25,028] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[34] at map at MyLinearRegressionImpl.scala:36)
[13:09:25,028] INFO  {TaskSchedulerImpl} Adding task set 20.0 with 1 tasks
[13:09:25,029] INFO  {TaskSetManager} Starting task 0.0 in stage 20.0 (TID 20, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:25,029] INFO  {Executor} Running task 0.0 in stage 20.0 (TID 20)
[13:09:25,034] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:25,168] INFO  {Executor} Finished task 0.0 in stage 20.0 (TID 20). 1683 bytes result sent to driver
[13:09:25,169] INFO  {TaskSetManager} Finished task 0.0 in stage 20.0 (TID 20) in 141 ms on localhost (1/1)
[13:09:25,169] INFO  {TaskSchedulerImpl} Removed TaskSet 20.0, whose tasks have all completed, from pool 
[13:09:25,169] INFO  {DAGScheduler} ResultStage 20 (count at MyLinearRegressionImpl.scala:26) finished in 0.141 s
[13:09:25,170] INFO  {DAGScheduler} Job 18 finished: count at MyLinearRegressionImpl.scala:26, took 0.147349 s
[13:09:25,174] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:25,174] INFO  {DAGScheduler} Got job 19 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:25,174] INFO  {DAGScheduler} Final stage: ResultStage 21 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:25,175] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:25,175] INFO  {DAGScheduler} Missing parents: List()
[13:09:25,175] INFO  {DAGScheduler} Submitting ResultStage 21 (MapPartitionsRDD[36] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:25,177] INFO  {MemoryStore} Block broadcast_26 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:25,180] INFO  {MemoryStore} Block broadcast_26_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:25,180] INFO  {BlockManagerInfo} Added broadcast_26_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:25,181] INFO  {SparkContext} Created broadcast 26 from broadcast at DAGScheduler.scala:1012
[13:09:25,181] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[36] at map at MyLinearRegressionImpl.scala:54)
[13:09:25,181] INFO  {TaskSchedulerImpl} Adding task set 21.0 with 1 tasks
[13:09:25,183] INFO  {TaskSetManager} Starting task 0.0 in stage 21.0 (TID 21, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:25,183] INFO  {Executor} Running task 0.0 in stage 21.0 (TID 21)
[13:09:25,188] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:25,259] INFO  {BlockManagerInfo} Removed broadcast_23_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:25,260] INFO  {BlockManagerInfo} Removed broadcast_24_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:25,261] INFO  {BlockManagerInfo} Removed broadcast_25_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:25,351] INFO  {Executor} Finished task 0.0 in stage 21.0 (TID 21). 2572 bytes result sent to driver
[13:09:25,352] INFO  {TaskSetManager} Finished task 0.0 in stage 21.0 (TID 21) in 171 ms on localhost (1/1)
[13:09:25,352] INFO  {TaskSchedulerImpl} Removed TaskSet 21.0, whose tasks have all completed, from pool 
[13:09:25,352] INFO  {DAGScheduler} ResultStage 21 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.171 s
[13:09:25,352] INFO  {DAGScheduler} Job 19 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.178574 s
[13:09:25,357] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:25,357] INFO  {DAGScheduler} Got job 20 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:25,357] INFO  {DAGScheduler} Final stage: ResultStage 22 (sum at MyLinearRegressionImpl.scala:24)
[13:09:25,357] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:25,358] INFO  {DAGScheduler} Missing parents: List()
[13:09:25,358] INFO  {DAGScheduler} Submitting ResultStage 22 (MapPartitionsRDD[38] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:25,359] INFO  {MemoryStore} Block broadcast_27 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:25,360] INFO  {MemoryStore} Block broadcast_27_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:25,361] INFO  {BlockManagerInfo} Added broadcast_27_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:25,361] INFO  {SparkContext} Created broadcast 27 from broadcast at DAGScheduler.scala:1012
[13:09:25,361] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[38] at map at MyLinearRegressionImpl.scala:22)
[13:09:25,361] INFO  {TaskSchedulerImpl} Adding task set 22.0 with 1 tasks
[13:09:25,363] INFO  {TaskSetManager} Starting task 0.0 in stage 22.0 (TID 22, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:25,363] INFO  {Executor} Running task 0.0 in stage 22.0 (TID 22)
[13:09:25,367] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:25,499] INFO  {Executor} Finished task 0.0 in stage 22.0 (TID 22). 1685 bytes result sent to driver
[13:09:25,500] INFO  {TaskSetManager} Finished task 0.0 in stage 22.0 (TID 22) in 138 ms on localhost (1/1)
[13:09:25,500] INFO  {TaskSchedulerImpl} Removed TaskSet 22.0, whose tasks have all completed, from pool 
[13:09:25,500] INFO  {DAGScheduler} ResultStage 22 (sum at MyLinearRegressionImpl.scala:24) finished in 0.138 s
[13:09:25,500] INFO  {DAGScheduler} Job 20 finished: sum at MyLinearRegressionImpl.scala:24, took 0.143539 s
[13:09:25,504] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:25,505] INFO  {DAGScheduler} Got job 21 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:25,505] INFO  {DAGScheduler} Final stage: ResultStage 23 (count at MyLinearRegressionImpl.scala:26)
[13:09:25,505] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:25,505] INFO  {DAGScheduler} Missing parents: List()
[13:09:25,506] INFO  {DAGScheduler} Submitting ResultStage 23 (MapPartitionsRDD[37] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:25,507] INFO  {MemoryStore} Block broadcast_28 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:25,509] INFO  {MemoryStore} Block broadcast_28_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:25,509] INFO  {BlockManagerInfo} Added broadcast_28_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:25,510] INFO  {SparkContext} Created broadcast 28 from broadcast at DAGScheduler.scala:1012
[13:09:25,511] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[37] at map at MyLinearRegressionImpl.scala:36)
[13:09:25,511] INFO  {TaskSchedulerImpl} Adding task set 23.0 with 1 tasks
[13:09:25,512] INFO  {TaskSetManager} Starting task 0.0 in stage 23.0 (TID 23, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:25,513] INFO  {Executor} Running task 0.0 in stage 23.0 (TID 23)
[13:09:25,518] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:25,652] INFO  {Executor} Finished task 0.0 in stage 23.0 (TID 23). 1683 bytes result sent to driver
[13:09:25,652] INFO  {TaskSetManager} Finished task 0.0 in stage 23.0 (TID 23) in 140 ms on localhost (1/1)
[13:09:25,653] INFO  {TaskSchedulerImpl} Removed TaskSet 23.0, whose tasks have all completed, from pool 
[13:09:25,653] INFO  {DAGScheduler} ResultStage 23 (count at MyLinearRegressionImpl.scala:26) finished in 0.142 s
[13:09:25,653] INFO  {DAGScheduler} Job 21 finished: count at MyLinearRegressionImpl.scala:26, took 0.148726 s
[13:09:25,658] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:25,658] INFO  {DAGScheduler} Got job 22 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:25,658] INFO  {DAGScheduler} Final stage: ResultStage 24 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:25,659] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:25,659] INFO  {DAGScheduler} Missing parents: List()
[13:09:25,659] INFO  {DAGScheduler} Submitting ResultStage 24 (MapPartitionsRDD[39] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:25,661] INFO  {MemoryStore} Block broadcast_29 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:25,662] INFO  {MemoryStore} Block broadcast_29_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:25,663] INFO  {BlockManagerInfo} Added broadcast_29_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:25,663] INFO  {SparkContext} Created broadcast 29 from broadcast at DAGScheduler.scala:1012
[13:09:25,663] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[39] at map at MyLinearRegressionImpl.scala:54)
[13:09:25,663] INFO  {TaskSchedulerImpl} Adding task set 24.0 with 1 tasks
[13:09:25,665] INFO  {TaskSetManager} Starting task 0.0 in stage 24.0 (TID 24, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:25,665] INFO  {Executor} Running task 0.0 in stage 24.0 (TID 24)
[13:09:25,672] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:25,740] INFO  {BlockManagerInfo} Removed broadcast_28_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:25,741] INFO  {BlockManagerInfo} Removed broadcast_26_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:25,742] INFO  {BlockManagerInfo} Removed broadcast_27_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:25,816] INFO  {Executor} Finished task 0.0 in stage 24.0 (TID 24). 2572 bytes result sent to driver
[13:09:25,817] INFO  {TaskSetManager} Finished task 0.0 in stage 24.0 (TID 24) in 153 ms on localhost (1/1)
[13:09:25,817] INFO  {TaskSchedulerImpl} Removed TaskSet 24.0, whose tasks have all completed, from pool 
[13:09:25,817] INFO  {DAGScheduler} ResultStage 24 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.153 s
[13:09:25,818] INFO  {DAGScheduler} Job 22 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.159896 s
[13:09:25,824] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:25,824] INFO  {DAGScheduler} Got job 23 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:25,824] INFO  {DAGScheduler} Final stage: ResultStage 25 (sum at MyLinearRegressionImpl.scala:24)
[13:09:25,824] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:25,824] INFO  {DAGScheduler} Missing parents: List()
[13:09:25,825] INFO  {DAGScheduler} Submitting ResultStage 25 (MapPartitionsRDD[41] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:25,828] INFO  {MemoryStore} Block broadcast_30 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:25,830] INFO  {MemoryStore} Block broadcast_30_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:25,831] INFO  {BlockManagerInfo} Added broadcast_30_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:25,831] INFO  {SparkContext} Created broadcast 30 from broadcast at DAGScheduler.scala:1012
[13:09:25,831] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[41] at map at MyLinearRegressionImpl.scala:22)
[13:09:25,831] INFO  {TaskSchedulerImpl} Adding task set 25.0 with 1 tasks
[13:09:25,832] INFO  {TaskSetManager} Starting task 0.0 in stage 25.0 (TID 25, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:25,833] INFO  {Executor} Running task 0.0 in stage 25.0 (TID 25)
[13:09:25,837] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:25,972] INFO  {Executor} Finished task 0.0 in stage 25.0 (TID 25). 1685 bytes result sent to driver
[13:09:25,973] INFO  {TaskSetManager} Finished task 0.0 in stage 25.0 (TID 25) in 141 ms on localhost (1/1)
[13:09:25,973] INFO  {TaskSchedulerImpl} Removed TaskSet 25.0, whose tasks have all completed, from pool 
[13:09:25,973] INFO  {DAGScheduler} ResultStage 25 (sum at MyLinearRegressionImpl.scala:24) finished in 0.142 s
[13:09:25,974] INFO  {DAGScheduler} Job 23 finished: sum at MyLinearRegressionImpl.scala:24, took 0.149960 s
[13:09:25,977] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:25,977] INFO  {DAGScheduler} Got job 24 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:25,978] INFO  {DAGScheduler} Final stage: ResultStage 26 (count at MyLinearRegressionImpl.scala:26)
[13:09:25,978] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:25,978] INFO  {DAGScheduler} Missing parents: List()
[13:09:25,978] INFO  {DAGScheduler} Submitting ResultStage 26 (MapPartitionsRDD[40] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:25,980] INFO  {MemoryStore} Block broadcast_31 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:25,982] INFO  {MemoryStore} Block broadcast_31_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:25,982] INFO  {BlockManagerInfo} Added broadcast_31_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:25,983] INFO  {SparkContext} Created broadcast 31 from broadcast at DAGScheduler.scala:1012
[13:09:25,983] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[40] at map at MyLinearRegressionImpl.scala:36)
[13:09:25,983] INFO  {TaskSchedulerImpl} Adding task set 26.0 with 1 tasks
[13:09:25,985] INFO  {TaskSetManager} Starting task 0.0 in stage 26.0 (TID 26, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:25,985] INFO  {Executor} Running task 0.0 in stage 26.0 (TID 26)
[13:09:25,989] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:26,124] INFO  {Executor} Finished task 0.0 in stage 26.0 (TID 26). 1683 bytes result sent to driver
[13:09:26,125] INFO  {TaskSetManager} Finished task 0.0 in stage 26.0 (TID 26) in 142 ms on localhost (1/1)
[13:09:26,125] INFO  {TaskSchedulerImpl} Removed TaskSet 26.0, whose tasks have all completed, from pool 
[13:09:26,125] INFO  {DAGScheduler} ResultStage 26 (count at MyLinearRegressionImpl.scala:26) finished in 0.142 s
[13:09:26,125] INFO  {DAGScheduler} Job 24 finished: count at MyLinearRegressionImpl.scala:26, took 0.148456 s
[13:09:26,129] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:26,130] INFO  {DAGScheduler} Got job 25 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:26,130] INFO  {DAGScheduler} Final stage: ResultStage 27 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:26,130] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:26,130] INFO  {DAGScheduler} Missing parents: List()
[13:09:26,130] INFO  {DAGScheduler} Submitting ResultStage 27 (MapPartitionsRDD[42] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:26,133] INFO  {MemoryStore} Block broadcast_32 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:26,135] INFO  {MemoryStore} Block broadcast_32_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:26,135] INFO  {BlockManagerInfo} Added broadcast_32_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:26,135] INFO  {SparkContext} Created broadcast 32 from broadcast at DAGScheduler.scala:1012
[13:09:26,136] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[42] at map at MyLinearRegressionImpl.scala:54)
[13:09:26,136] INFO  {TaskSchedulerImpl} Adding task set 27.0 with 1 tasks
[13:09:26,137] INFO  {TaskSetManager} Starting task 0.0 in stage 27.0 (TID 27, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:26,138] INFO  {Executor} Running task 0.0 in stage 27.0 (TID 27)
[13:09:26,144] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:26,274] INFO  {BlockManagerInfo} Removed broadcast_29_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:26,275] INFO  {BlockManagerInfo} Removed broadcast_30_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:26,276] INFO  {BlockManagerInfo} Removed broadcast_31_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:26,299] INFO  {Executor} Finished task 0.0 in stage 27.0 (TID 27). 2572 bytes result sent to driver
[13:09:26,300] INFO  {TaskSetManager} Finished task 0.0 in stage 27.0 (TID 27) in 164 ms on localhost (1/1)
[13:09:26,300] INFO  {TaskSchedulerImpl} Removed TaskSet 27.0, whose tasks have all completed, from pool 
[13:09:26,301] INFO  {DAGScheduler} ResultStage 27 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.164 s
[13:09:26,301] INFO  {DAGScheduler} Job 25 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.171661 s
[13:09:26,308] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:26,309] INFO  {DAGScheduler} Got job 26 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:26,309] INFO  {DAGScheduler} Final stage: ResultStage 28 (sum at MyLinearRegressionImpl.scala:24)
[13:09:26,309] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:26,309] INFO  {DAGScheduler} Missing parents: List()
[13:09:26,309] INFO  {DAGScheduler} Submitting ResultStage 28 (MapPartitionsRDD[44] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:26,312] INFO  {MemoryStore} Block broadcast_33 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:26,313] INFO  {MemoryStore} Block broadcast_33_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:26,314] INFO  {BlockManagerInfo} Added broadcast_33_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:26,314] INFO  {SparkContext} Created broadcast 33 from broadcast at DAGScheduler.scala:1012
[13:09:26,314] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[44] at map at MyLinearRegressionImpl.scala:22)
[13:09:26,314] INFO  {TaskSchedulerImpl} Adding task set 28.0 with 1 tasks
[13:09:26,316] INFO  {TaskSetManager} Starting task 0.0 in stage 28.0 (TID 28, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:26,316] INFO  {Executor} Running task 0.0 in stage 28.0 (TID 28)
[13:09:26,321] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:26,453] INFO  {Executor} Finished task 0.0 in stage 28.0 (TID 28). 1685 bytes result sent to driver
[13:09:26,454] INFO  {TaskSetManager} Finished task 0.0 in stage 28.0 (TID 28) in 139 ms on localhost (1/1)
[13:09:26,454] INFO  {TaskSchedulerImpl} Removed TaskSet 28.0, whose tasks have all completed, from pool 
[13:09:26,454] INFO  {DAGScheduler} ResultStage 28 (sum at MyLinearRegressionImpl.scala:24) finished in 0.139 s
[13:09:26,455] INFO  {DAGScheduler} Job 26 finished: sum at MyLinearRegressionImpl.scala:24, took 0.146836 s
[13:09:26,457] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:26,457] INFO  {DAGScheduler} Got job 27 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:26,457] INFO  {DAGScheduler} Final stage: ResultStage 29 (count at MyLinearRegressionImpl.scala:26)
[13:09:26,457] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:26,458] INFO  {DAGScheduler} Missing parents: List()
[13:09:26,458] INFO  {DAGScheduler} Submitting ResultStage 29 (MapPartitionsRDD[43] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:26,459] INFO  {MemoryStore} Block broadcast_34 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:26,461] INFO  {MemoryStore} Block broadcast_34_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:26,461] INFO  {BlockManagerInfo} Added broadcast_34_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:26,462] INFO  {SparkContext} Created broadcast 34 from broadcast at DAGScheduler.scala:1012
[13:09:26,462] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[43] at map at MyLinearRegressionImpl.scala:36)
[13:09:26,462] INFO  {TaskSchedulerImpl} Adding task set 29.0 with 1 tasks
[13:09:26,463] INFO  {TaskSetManager} Starting task 0.0 in stage 29.0 (TID 29, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:26,463] INFO  {Executor} Running task 0.0 in stage 29.0 (TID 29)
[13:09:26,468] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:26,604] INFO  {Executor} Finished task 0.0 in stage 29.0 (TID 29). 1683 bytes result sent to driver
[13:09:26,605] INFO  {TaskSetManager} Finished task 0.0 in stage 29.0 (TID 29) in 143 ms on localhost (1/1)
[13:09:26,605] INFO  {TaskSchedulerImpl} Removed TaskSet 29.0, whose tasks have all completed, from pool 
[13:09:26,605] INFO  {DAGScheduler} ResultStage 29 (count at MyLinearRegressionImpl.scala:26) finished in 0.143 s
[13:09:26,606] INFO  {DAGScheduler} Job 27 finished: count at MyLinearRegressionImpl.scala:26, took 0.148967 s
[13:09:26,609] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:26,610] INFO  {DAGScheduler} Got job 28 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:26,610] INFO  {DAGScheduler} Final stage: ResultStage 30 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:26,610] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:26,611] INFO  {DAGScheduler} Missing parents: List()
[13:09:26,611] INFO  {DAGScheduler} Submitting ResultStage 30 (MapPartitionsRDD[45] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:26,613] INFO  {MemoryStore} Block broadcast_35 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:26,614] INFO  {MemoryStore} Block broadcast_35_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:26,615] INFO  {BlockManagerInfo} Added broadcast_35_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:26,615] INFO  {SparkContext} Created broadcast 35 from broadcast at DAGScheduler.scala:1012
[13:09:26,616] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[45] at map at MyLinearRegressionImpl.scala:54)
[13:09:26,616] INFO  {TaskSchedulerImpl} Adding task set 30.0 with 1 tasks
[13:09:26,617] INFO  {TaskSetManager} Starting task 0.0 in stage 30.0 (TID 30, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:26,617] INFO  {Executor} Running task 0.0 in stage 30.0 (TID 30)
[13:09:26,622] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:26,759] INFO  {Executor} Finished task 0.0 in stage 30.0 (TID 30). 2499 bytes result sent to driver
[13:09:26,760] INFO  {TaskSetManager} Finished task 0.0 in stage 30.0 (TID 30) in 144 ms on localhost (1/1)
[13:09:26,760] INFO  {TaskSchedulerImpl} Removed TaskSet 30.0, whose tasks have all completed, from pool 
[13:09:26,761] INFO  {DAGScheduler} ResultStage 30 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.144 s
[13:09:26,761] INFO  {DAGScheduler} Job 28 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.151295 s
[13:09:26,766] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:26,767] INFO  {DAGScheduler} Got job 29 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:26,767] INFO  {DAGScheduler} Final stage: ResultStage 31 (sum at MyLinearRegressionImpl.scala:24)
[13:09:26,767] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:26,768] INFO  {DAGScheduler} Missing parents: List()
[13:09:26,768] INFO  {DAGScheduler} Submitting ResultStage 31 (MapPartitionsRDD[47] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:26,770] INFO  {MemoryStore} Block broadcast_36 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:26,772] INFO  {MemoryStore} Block broadcast_36_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:26,772] INFO  {BlockManagerInfo} Added broadcast_36_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:26,773] INFO  {SparkContext} Created broadcast 36 from broadcast at DAGScheduler.scala:1012
[13:09:26,773] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[47] at map at MyLinearRegressionImpl.scala:22)
[13:09:26,773] INFO  {TaskSchedulerImpl} Adding task set 31.0 with 1 tasks
[13:09:26,774] INFO  {TaskSetManager} Starting task 0.0 in stage 31.0 (TID 31, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:26,774] INFO  {Executor} Running task 0.0 in stage 31.0 (TID 31)
[13:09:26,782] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:26,815] INFO  {BlockManagerInfo} Removed broadcast_33_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:26,815] INFO  {BlockManagerInfo} Removed broadcast_34_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:26,816] INFO  {BlockManagerInfo} Removed broadcast_35_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:26,817] INFO  {BlockManagerInfo} Removed broadcast_32_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:26,925] INFO  {Executor} Finished task 0.0 in stage 31.0 (TID 31). 1758 bytes result sent to driver
[13:09:26,926] INFO  {TaskSetManager} Finished task 0.0 in stage 31.0 (TID 31) in 153 ms on localhost (1/1)
[13:09:26,926] INFO  {TaskSchedulerImpl} Removed TaskSet 31.0, whose tasks have all completed, from pool 
[13:09:26,927] INFO  {DAGScheduler} ResultStage 31 (sum at MyLinearRegressionImpl.scala:24) finished in 0.154 s
[13:09:26,927] INFO  {DAGScheduler} Job 29 finished: sum at MyLinearRegressionImpl.scala:24, took 0.160468 s
[13:09:26,929] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:26,929] INFO  {DAGScheduler} Got job 30 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:26,929] INFO  {DAGScheduler} Final stage: ResultStage 32 (count at MyLinearRegressionImpl.scala:26)
[13:09:26,929] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:26,929] INFO  {DAGScheduler} Missing parents: List()
[13:09:26,930] INFO  {DAGScheduler} Submitting ResultStage 32 (MapPartitionsRDD[46] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:26,931] INFO  {MemoryStore} Block broadcast_37 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:26,932] INFO  {MemoryStore} Block broadcast_37_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:26,933] INFO  {BlockManagerInfo} Added broadcast_37_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:26,933] INFO  {SparkContext} Created broadcast 37 from broadcast at DAGScheduler.scala:1012
[13:09:26,933] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[46] at map at MyLinearRegressionImpl.scala:36)
[13:09:26,933] INFO  {TaskSchedulerImpl} Adding task set 32.0 with 1 tasks
[13:09:26,934] INFO  {TaskSetManager} Starting task 0.0 in stage 32.0 (TID 32, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:26,934] INFO  {Executor} Running task 0.0 in stage 32.0 (TID 32)
[13:09:26,939] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:27,074] INFO  {Executor} Finished task 0.0 in stage 32.0 (TID 32). 1683 bytes result sent to driver
[13:09:27,074] INFO  {TaskSetManager} Finished task 0.0 in stage 32.0 (TID 32) in 140 ms on localhost (1/1)
[13:09:27,074] INFO  {TaskSchedulerImpl} Removed TaskSet 32.0, whose tasks have all completed, from pool 
[13:09:27,075] INFO  {DAGScheduler} ResultStage 32 (count at MyLinearRegressionImpl.scala:26) finished in 0.141 s
[13:09:27,075] INFO  {DAGScheduler} Job 30 finished: count at MyLinearRegressionImpl.scala:26, took 0.145912 s
[13:09:27,077] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:27,078] INFO  {DAGScheduler} Got job 31 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:27,078] INFO  {DAGScheduler} Final stage: ResultStage 33 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:27,078] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:27,078] INFO  {DAGScheduler} Missing parents: List()
[13:09:27,078] INFO  {DAGScheduler} Submitting ResultStage 33 (MapPartitionsRDD[48] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:27,080] INFO  {MemoryStore} Block broadcast_38 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:27,081] INFO  {MemoryStore} Block broadcast_38_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:27,081] INFO  {BlockManagerInfo} Added broadcast_38_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:27,082] INFO  {SparkContext} Created broadcast 38 from broadcast at DAGScheduler.scala:1012
[13:09:27,082] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[48] at map at MyLinearRegressionImpl.scala:54)
[13:09:27,082] INFO  {TaskSchedulerImpl} Adding task set 33.0 with 1 tasks
[13:09:27,083] INFO  {TaskSetManager} Starting task 0.0 in stage 33.0 (TID 33, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:27,083] INFO  {Executor} Running task 0.0 in stage 33.0 (TID 33)
[13:09:27,087] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:27,221] INFO  {Executor} Finished task 0.0 in stage 33.0 (TID 33). 2499 bytes result sent to driver
[13:09:27,221] INFO  {TaskSetManager} Finished task 0.0 in stage 33.0 (TID 33) in 139 ms on localhost (1/1)
[13:09:27,221] INFO  {TaskSchedulerImpl} Removed TaskSet 33.0, whose tasks have all completed, from pool 
[13:09:27,222] INFO  {DAGScheduler} ResultStage 33 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.140 s
[13:09:27,222] INFO  {DAGScheduler} Job 31 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.144309 s
[13:09:27,228] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:27,228] INFO  {DAGScheduler} Got job 32 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:27,228] INFO  {DAGScheduler} Final stage: ResultStage 34 (sum at MyLinearRegressionImpl.scala:24)
[13:09:27,228] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:27,229] INFO  {DAGScheduler} Missing parents: List()
[13:09:27,229] INFO  {DAGScheduler} Submitting ResultStage 34 (MapPartitionsRDD[50] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:27,230] INFO  {MemoryStore} Block broadcast_39 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:27,231] INFO  {MemoryStore} Block broadcast_39_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.4 MB)
[13:09:27,232] INFO  {BlockManagerInfo} Added broadcast_39_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:27,232] INFO  {SparkContext} Created broadcast 39 from broadcast at DAGScheduler.scala:1012
[13:09:27,232] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[50] at map at MyLinearRegressionImpl.scala:22)
[13:09:27,232] INFO  {TaskSchedulerImpl} Adding task set 34.0 with 1 tasks
[13:09:27,233] INFO  {TaskSetManager} Starting task 0.0 in stage 34.0 (TID 34, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:27,234] INFO  {Executor} Running task 0.0 in stage 34.0 (TID 34)
[13:09:27,240] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:27,384] INFO  {BlockManagerInfo} Removed broadcast_36_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:27,385] INFO  {BlockManagerInfo} Removed broadcast_37_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:27,386] INFO  {BlockManagerInfo} Removed broadcast_38_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:27,405] INFO  {Executor} Finished task 0.0 in stage 34.0 (TID 34). 1758 bytes result sent to driver
[13:09:27,406] INFO  {TaskSetManager} Finished task 0.0 in stage 34.0 (TID 34) in 173 ms on localhost (1/1)
[13:09:27,406] INFO  {TaskSchedulerImpl} Removed TaskSet 34.0, whose tasks have all completed, from pool 
[13:09:27,406] INFO  {DAGScheduler} ResultStage 34 (sum at MyLinearRegressionImpl.scala:24) finished in 0.173 s
[13:09:27,407] INFO  {DAGScheduler} Job 32 finished: sum at MyLinearRegressionImpl.scala:24, took 0.178739 s
[13:09:27,409] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:27,410] INFO  {DAGScheduler} Got job 33 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:27,410] INFO  {DAGScheduler} Final stage: ResultStage 35 (count at MyLinearRegressionImpl.scala:26)
[13:09:27,410] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:27,410] INFO  {DAGScheduler} Missing parents: List()
[13:09:27,410] INFO  {DAGScheduler} Submitting ResultStage 35 (MapPartitionsRDD[49] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:27,413] INFO  {MemoryStore} Block broadcast_40 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:27,415] INFO  {MemoryStore} Block broadcast_40_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:27,415] INFO  {BlockManagerInfo} Added broadcast_40_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:27,416] INFO  {SparkContext} Created broadcast 40 from broadcast at DAGScheduler.scala:1012
[13:09:27,416] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[49] at map at MyLinearRegressionImpl.scala:36)
[13:09:27,416] INFO  {TaskSchedulerImpl} Adding task set 35.0 with 1 tasks
[13:09:27,417] INFO  {TaskSetManager} Starting task 0.0 in stage 35.0 (TID 35, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:27,417] INFO  {Executor} Running task 0.0 in stage 35.0 (TID 35)
[13:09:27,421] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:27,557] INFO  {Executor} Finished task 0.0 in stage 35.0 (TID 35). 1683 bytes result sent to driver
[13:09:27,558] INFO  {TaskSetManager} Finished task 0.0 in stage 35.0 (TID 35) in 142 ms on localhost (1/1)
[13:09:27,559] INFO  {TaskSchedulerImpl} Removed TaskSet 35.0, whose tasks have all completed, from pool 
[13:09:27,559] INFO  {DAGScheduler} ResultStage 35 (count at MyLinearRegressionImpl.scala:26) finished in 0.143 s
[13:09:27,559] INFO  {DAGScheduler} Job 33 finished: count at MyLinearRegressionImpl.scala:26, took 0.149736 s
[13:09:27,562] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:27,562] INFO  {DAGScheduler} Got job 34 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:27,562] INFO  {DAGScheduler} Final stage: ResultStage 36 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:27,562] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:27,562] INFO  {DAGScheduler} Missing parents: List()
[13:09:27,563] INFO  {DAGScheduler} Submitting ResultStage 36 (MapPartitionsRDD[51] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:27,565] INFO  {MemoryStore} Block broadcast_41 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:27,566] INFO  {MemoryStore} Block broadcast_41_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:27,567] INFO  {BlockManagerInfo} Added broadcast_41_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:27,567] INFO  {SparkContext} Created broadcast 41 from broadcast at DAGScheduler.scala:1012
[13:09:27,567] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[51] at map at MyLinearRegressionImpl.scala:54)
[13:09:27,567] INFO  {TaskSchedulerImpl} Adding task set 36.0 with 1 tasks
[13:09:27,569] INFO  {TaskSetManager} Starting task 0.0 in stage 36.0 (TID 36, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:27,569] INFO  {Executor} Running task 0.0 in stage 36.0 (TID 36)
[13:09:27,575] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:27,717] INFO  {Executor} Finished task 0.0 in stage 36.0 (TID 36). 2499 bytes result sent to driver
[13:09:27,718] INFO  {TaskSetManager} Finished task 0.0 in stage 36.0 (TID 36) in 150 ms on localhost (1/1)
[13:09:27,718] INFO  {TaskSchedulerImpl} Removed TaskSet 36.0, whose tasks have all completed, from pool 
[13:09:27,718] INFO  {DAGScheduler} ResultStage 36 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.150 s
[13:09:27,718] INFO  {DAGScheduler} Job 34 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.156438 s
[13:09:27,724] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:27,725] INFO  {DAGScheduler} Got job 35 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:27,725] INFO  {DAGScheduler} Final stage: ResultStage 37 (sum at MyLinearRegressionImpl.scala:24)
[13:09:27,725] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:27,725] INFO  {DAGScheduler} Missing parents: List()
[13:09:27,725] INFO  {DAGScheduler} Submitting ResultStage 37 (MapPartitionsRDD[53] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:27,727] INFO  {MemoryStore} Block broadcast_42 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:27,728] INFO  {MemoryStore} Block broadcast_42_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.4 MB)
[13:09:27,728] INFO  {BlockManagerInfo} Added broadcast_42_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:27,729] INFO  {SparkContext} Created broadcast 42 from broadcast at DAGScheduler.scala:1012
[13:09:27,729] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[53] at map at MyLinearRegressionImpl.scala:22)
[13:09:27,729] INFO  {TaskSchedulerImpl} Adding task set 37.0 with 1 tasks
[13:09:27,730] INFO  {TaskSetManager} Starting task 0.0 in stage 37.0 (TID 37, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:27,730] INFO  {Executor} Running task 0.0 in stage 37.0 (TID 37)
[13:09:27,734] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:27,869] INFO  {Executor} Finished task 0.0 in stage 37.0 (TID 37). 1685 bytes result sent to driver
[13:09:27,869] INFO  {TaskSetManager} Finished task 0.0 in stage 37.0 (TID 37) in 140 ms on localhost (1/1)
[13:09:27,869] INFO  {TaskSchedulerImpl} Removed TaskSet 37.0, whose tasks have all completed, from pool 
[13:09:27,869] INFO  {DAGScheduler} ResultStage 37 (sum at MyLinearRegressionImpl.scala:24) finished in 0.140 s
[13:09:27,870] INFO  {DAGScheduler} Job 35 finished: sum at MyLinearRegressionImpl.scala:24, took 0.145532 s
[13:09:27,872] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:27,872] INFO  {DAGScheduler} Got job 36 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:27,872] INFO  {DAGScheduler} Final stage: ResultStage 38 (count at MyLinearRegressionImpl.scala:26)
[13:09:27,872] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:27,872] INFO  {DAGScheduler} Missing parents: List()
[13:09:27,872] INFO  {DAGScheduler} Submitting ResultStage 38 (MapPartitionsRDD[52] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:27,874] INFO  {MemoryStore} Block broadcast_43 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:27,875] INFO  {MemoryStore} Block broadcast_43_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:27,875] INFO  {BlockManagerInfo} Added broadcast_43_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:27,875] INFO  {SparkContext} Created broadcast 43 from broadcast at DAGScheduler.scala:1012
[13:09:27,875] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[52] at map at MyLinearRegressionImpl.scala:36)
[13:09:27,876] INFO  {TaskSchedulerImpl} Adding task set 38.0 with 1 tasks
[13:09:27,876] INFO  {TaskSetManager} Starting task 0.0 in stage 38.0 (TID 38, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:27,877] INFO  {Executor} Running task 0.0 in stage 38.0 (TID 38)
[13:09:27,881] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:27,952] INFO  {BlockManagerInfo} Removed broadcast_39_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:27,953] INFO  {BlockManagerInfo} Removed broadcast_40_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:27,954] INFO  {BlockManagerInfo} Removed broadcast_41_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:27,954] INFO  {BlockManagerInfo} Removed broadcast_42_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:28,022] INFO  {Executor} Finished task 0.0 in stage 38.0 (TID 38). 1756 bytes result sent to driver
[13:09:28,023] INFO  {TaskSetManager} Finished task 0.0 in stage 38.0 (TID 38) in 147 ms on localhost (1/1)
[13:09:28,023] INFO  {TaskSchedulerImpl} Removed TaskSet 38.0, whose tasks have all completed, from pool 
[13:09:28,023] INFO  {DAGScheduler} ResultStage 38 (count at MyLinearRegressionImpl.scala:26) finished in 0.147 s
[13:09:28,024] INFO  {DAGScheduler} Job 36 finished: count at MyLinearRegressionImpl.scala:26, took 0.152064 s
[13:09:28,028] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:28,029] INFO  {DAGScheduler} Got job 37 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:28,029] INFO  {DAGScheduler} Final stage: ResultStage 39 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:28,029] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:28,030] INFO  {DAGScheduler} Missing parents: List()
[13:09:28,030] INFO  {DAGScheduler} Submitting ResultStage 39 (MapPartitionsRDD[54] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:28,033] INFO  {MemoryStore} Block broadcast_44 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:28,035] INFO  {MemoryStore} Block broadcast_44_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:28,035] INFO  {BlockManagerInfo} Added broadcast_44_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:28,036] INFO  {SparkContext} Created broadcast 44 from broadcast at DAGScheduler.scala:1012
[13:09:28,036] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[54] at map at MyLinearRegressionImpl.scala:54)
[13:09:28,036] INFO  {TaskSchedulerImpl} Adding task set 39.0 with 1 tasks
[13:09:28,038] INFO  {TaskSetManager} Starting task 0.0 in stage 39.0 (TID 39, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:28,038] INFO  {Executor} Running task 0.0 in stage 39.0 (TID 39)
[13:09:28,043] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:28,182] INFO  {Executor} Finished task 0.0 in stage 39.0 (TID 39). 2499 bytes result sent to driver
[13:09:28,182] INFO  {TaskSetManager} Finished task 0.0 in stage 39.0 (TID 39) in 146 ms on localhost (1/1)
[13:09:28,182] INFO  {TaskSchedulerImpl} Removed TaskSet 39.0, whose tasks have all completed, from pool 
[13:09:28,183] INFO  {DAGScheduler} ResultStage 39 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.147 s
[13:09:28,183] INFO  {DAGScheduler} Job 37 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.154586 s
[13:09:28,188] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:28,189] INFO  {DAGScheduler} Got job 38 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:28,189] INFO  {DAGScheduler} Final stage: ResultStage 40 (sum at MyLinearRegressionImpl.scala:24)
[13:09:28,189] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:28,189] INFO  {DAGScheduler} Missing parents: List()
[13:09:28,189] INFO  {DAGScheduler} Submitting ResultStage 40 (MapPartitionsRDD[56] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:28,191] INFO  {MemoryStore} Block broadcast_45 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:28,192] INFO  {MemoryStore} Block broadcast_45_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:28,192] INFO  {BlockManagerInfo} Added broadcast_45_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:28,193] INFO  {SparkContext} Created broadcast 45 from broadcast at DAGScheduler.scala:1012
[13:09:28,193] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[56] at map at MyLinearRegressionImpl.scala:22)
[13:09:28,193] INFO  {TaskSchedulerImpl} Adding task set 40.0 with 1 tasks
[13:09:28,194] INFO  {TaskSetManager} Starting task 0.0 in stage 40.0 (TID 40, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:28,194] INFO  {Executor} Running task 0.0 in stage 40.0 (TID 40)
[13:09:28,198] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:28,330] INFO  {Executor} Finished task 0.0 in stage 40.0 (TID 40). 1685 bytes result sent to driver
[13:09:28,330] INFO  {TaskSetManager} Finished task 0.0 in stage 40.0 (TID 40) in 137 ms on localhost (1/1)
[13:09:28,330] INFO  {TaskSchedulerImpl} Removed TaskSet 40.0, whose tasks have all completed, from pool 
[13:09:28,331] INFO  {DAGScheduler} ResultStage 40 (sum at MyLinearRegressionImpl.scala:24) finished in 0.138 s
[13:09:28,331] INFO  {DAGScheduler} Job 38 finished: sum at MyLinearRegressionImpl.scala:24, took 0.142710 s
[13:09:28,333] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:28,333] INFO  {DAGScheduler} Got job 39 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:28,333] INFO  {DAGScheduler} Final stage: ResultStage 41 (count at MyLinearRegressionImpl.scala:26)
[13:09:28,333] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:28,333] INFO  {DAGScheduler} Missing parents: List()
[13:09:28,334] INFO  {DAGScheduler} Submitting ResultStage 41 (MapPartitionsRDD[55] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:28,336] INFO  {MemoryStore} Block broadcast_46 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:28,338] INFO  {MemoryStore} Block broadcast_46_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:28,338] INFO  {BlockManagerInfo} Added broadcast_46_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:28,339] INFO  {SparkContext} Created broadcast 46 from broadcast at DAGScheduler.scala:1012
[13:09:28,339] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[55] at map at MyLinearRegressionImpl.scala:36)
[13:09:28,339] INFO  {TaskSchedulerImpl} Adding task set 41.0 with 1 tasks
[13:09:28,340] INFO  {TaskSetManager} Starting task 0.0 in stage 41.0 (TID 41, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:28,340] INFO  {Executor} Running task 0.0 in stage 41.0 (TID 41)
[13:09:28,343] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:28,475] INFO  {Executor} Finished task 0.0 in stage 41.0 (TID 41). 1683 bytes result sent to driver
[13:09:28,476] INFO  {TaskSetManager} Finished task 0.0 in stage 41.0 (TID 41) in 137 ms on localhost (1/1)
[13:09:28,476] INFO  {TaskSchedulerImpl} Removed TaskSet 41.0, whose tasks have all completed, from pool 
[13:09:28,476] INFO  {DAGScheduler} ResultStage 41 (count at MyLinearRegressionImpl.scala:26) finished in 0.137 s
[13:09:28,477] INFO  {DAGScheduler} Job 39 finished: count at MyLinearRegressionImpl.scala:26, took 0.143903 s
[13:09:28,480] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:28,481] INFO  {DAGScheduler} Got job 40 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:28,481] INFO  {DAGScheduler} Final stage: ResultStage 42 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:28,481] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:28,481] INFO  {DAGScheduler} Missing parents: List()
[13:09:28,482] INFO  {DAGScheduler} Submitting ResultStage 42 (MapPartitionsRDD[57] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:28,484] INFO  {MemoryStore} Block broadcast_47 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:28,486] INFO  {MemoryStore} Block broadcast_47_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:28,486] INFO  {BlockManagerInfo} Added broadcast_47_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:28,486] INFO  {SparkContext} Created broadcast 47 from broadcast at DAGScheduler.scala:1012
[13:09:28,487] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[57] at map at MyLinearRegressionImpl.scala:54)
[13:09:28,487] INFO  {TaskSchedulerImpl} Adding task set 42.0 with 1 tasks
[13:09:28,487] INFO  {TaskSetManager} Starting task 0.0 in stage 42.0 (TID 42, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:28,488] INFO  {Executor} Running task 0.0 in stage 42.0 (TID 42)
[13:09:28,492] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:28,542] INFO  {BlockManagerInfo} Removed broadcast_45_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:28,543] INFO  {BlockManagerInfo} Removed broadcast_44_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:28,544] INFO  {BlockManagerInfo} Removed broadcast_46_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:28,544] INFO  {BlockManagerInfo} Removed broadcast_43_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:28,642] INFO  {Executor} Finished task 0.0 in stage 42.0 (TID 42). 2572 bytes result sent to driver
[13:09:28,643] INFO  {TaskSetManager} Finished task 0.0 in stage 42.0 (TID 42) in 156 ms on localhost (1/1)
[13:09:28,643] INFO  {TaskSchedulerImpl} Removed TaskSet 42.0, whose tasks have all completed, from pool 
[13:09:28,644] INFO  {DAGScheduler} ResultStage 42 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.156 s
[13:09:28,644] INFO  {DAGScheduler} Job 40 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.163287 s
[13:09:28,649] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:28,650] INFO  {DAGScheduler} Got job 41 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:28,650] INFO  {DAGScheduler} Final stage: ResultStage 43 (sum at MyLinearRegressionImpl.scala:24)
[13:09:28,650] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:28,650] INFO  {DAGScheduler} Missing parents: List()
[13:09:28,651] INFO  {DAGScheduler} Submitting ResultStage 43 (MapPartitionsRDD[59] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:28,653] INFO  {MemoryStore} Block broadcast_48 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:28,655] INFO  {MemoryStore} Block broadcast_48_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:28,655] INFO  {BlockManagerInfo} Added broadcast_48_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:28,656] INFO  {SparkContext} Created broadcast 48 from broadcast at DAGScheduler.scala:1012
[13:09:28,656] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[59] at map at MyLinearRegressionImpl.scala:22)
[13:09:28,656] INFO  {TaskSchedulerImpl} Adding task set 43.0 with 1 tasks
[13:09:28,657] INFO  {TaskSetManager} Starting task 0.0 in stage 43.0 (TID 43, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:28,657] INFO  {Executor} Running task 0.0 in stage 43.0 (TID 43)
[13:09:28,660] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:28,797] INFO  {Executor} Finished task 0.0 in stage 43.0 (TID 43). 1685 bytes result sent to driver
[13:09:28,798] INFO  {TaskSetManager} Finished task 0.0 in stage 43.0 (TID 43) in 142 ms on localhost (1/1)
[13:09:28,798] INFO  {TaskSchedulerImpl} Removed TaskSet 43.0, whose tasks have all completed, from pool 
[13:09:28,798] INFO  {DAGScheduler} ResultStage 43 (sum at MyLinearRegressionImpl.scala:24) finished in 0.142 s
[13:09:28,799] INFO  {DAGScheduler} Job 41 finished: sum at MyLinearRegressionImpl.scala:24, took 0.149158 s
[13:09:28,802] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:28,803] INFO  {DAGScheduler} Got job 42 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:28,803] INFO  {DAGScheduler} Final stage: ResultStage 44 (count at MyLinearRegressionImpl.scala:26)
[13:09:28,803] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:28,803] INFO  {DAGScheduler} Missing parents: List()
[13:09:28,803] INFO  {DAGScheduler} Submitting ResultStage 44 (MapPartitionsRDD[58] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:28,805] INFO  {MemoryStore} Block broadcast_49 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:28,806] INFO  {MemoryStore} Block broadcast_49_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:28,807] INFO  {BlockManagerInfo} Added broadcast_49_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:28,807] INFO  {SparkContext} Created broadcast 49 from broadcast at DAGScheduler.scala:1012
[13:09:28,807] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[58] at map at MyLinearRegressionImpl.scala:36)
[13:09:28,807] INFO  {TaskSchedulerImpl} Adding task set 44.0 with 1 tasks
[13:09:28,808] INFO  {TaskSetManager} Starting task 0.0 in stage 44.0 (TID 44, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:28,808] INFO  {Executor} Running task 0.0 in stage 44.0 (TID 44)
[13:09:28,813] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:28,949] INFO  {Executor} Finished task 0.0 in stage 44.0 (TID 44). 1683 bytes result sent to driver
[13:09:28,950] INFO  {TaskSetManager} Finished task 0.0 in stage 44.0 (TID 44) in 142 ms on localhost (1/1)
[13:09:28,950] INFO  {TaskSchedulerImpl} Removed TaskSet 44.0, whose tasks have all completed, from pool 
[13:09:28,950] INFO  {DAGScheduler} ResultStage 44 (count at MyLinearRegressionImpl.scala:26) finished in 0.142 s
[13:09:28,950] INFO  {DAGScheduler} Job 42 finished: count at MyLinearRegressionImpl.scala:26, took 0.148042 s
[13:09:28,954] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:28,954] INFO  {DAGScheduler} Got job 43 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:28,955] INFO  {DAGScheduler} Final stage: ResultStage 45 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:28,955] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:28,955] INFO  {DAGScheduler} Missing parents: List()
[13:09:28,955] INFO  {DAGScheduler} Submitting ResultStage 45 (MapPartitionsRDD[60] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:28,956] INFO  {MemoryStore} Block broadcast_50 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:28,957] INFO  {MemoryStore} Block broadcast_50_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:28,957] INFO  {BlockManagerInfo} Added broadcast_50_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:28,958] INFO  {SparkContext} Created broadcast 50 from broadcast at DAGScheduler.scala:1012
[13:09:28,958] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[60] at map at MyLinearRegressionImpl.scala:54)
[13:09:28,958] INFO  {TaskSchedulerImpl} Adding task set 45.0 with 1 tasks
[13:09:28,959] INFO  {TaskSetManager} Starting task 0.0 in stage 45.0 (TID 45, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:28,959] INFO  {Executor} Running task 0.0 in stage 45.0 (TID 45)
[13:09:28,964] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:29,100] INFO  {Executor} Finished task 0.0 in stage 45.0 (TID 45). 2499 bytes result sent to driver
[13:09:29,105] INFO  {TaskSetManager} Finished task 0.0 in stage 45.0 (TID 45) in 146 ms on localhost (1/1)
[13:09:29,105] INFO  {TaskSchedulerImpl} Removed TaskSet 45.0, whose tasks have all completed, from pool 
[13:09:29,105] INFO  {DAGScheduler} ResultStage 45 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.147 s
[13:09:29,105] INFO  {BlockManagerInfo} Removed broadcast_47_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:29,105] INFO  {DAGScheduler} Job 43 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.150981 s
[13:09:29,106] INFO  {BlockManagerInfo} Removed broadcast_48_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:29,107] INFO  {BlockManagerInfo} Removed broadcast_49_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:29,110] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:29,111] INFO  {DAGScheduler} Got job 44 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:29,111] INFO  {DAGScheduler} Final stage: ResultStage 46 (sum at MyLinearRegressionImpl.scala:24)
[13:09:29,111] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:29,111] INFO  {DAGScheduler} Missing parents: List()
[13:09:29,111] INFO  {DAGScheduler} Submitting ResultStage 46 (MapPartitionsRDD[62] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:29,113] INFO  {MemoryStore} Block broadcast_51 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:29,114] INFO  {MemoryStore} Block broadcast_51_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:29,114] INFO  {BlockManagerInfo} Added broadcast_51_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:29,115] INFO  {SparkContext} Created broadcast 51 from broadcast at DAGScheduler.scala:1012
[13:09:29,115] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[62] at map at MyLinearRegressionImpl.scala:22)
[13:09:29,115] INFO  {TaskSchedulerImpl} Adding task set 46.0 with 1 tasks
[13:09:29,116] INFO  {TaskSetManager} Starting task 0.0 in stage 46.0 (TID 46, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:29,116] INFO  {Executor} Running task 0.0 in stage 46.0 (TID 46)
[13:09:29,122] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:29,259] INFO  {Executor} Finished task 0.0 in stage 46.0 (TID 46). 1685 bytes result sent to driver
[13:09:29,260] INFO  {TaskSetManager} Finished task 0.0 in stage 46.0 (TID 46) in 145 ms on localhost (1/1)
[13:09:29,260] INFO  {TaskSchedulerImpl} Removed TaskSet 46.0, whose tasks have all completed, from pool 
[13:09:29,260] INFO  {DAGScheduler} ResultStage 46 (sum at MyLinearRegressionImpl.scala:24) finished in 0.145 s
[13:09:29,261] INFO  {DAGScheduler} Job 44 finished: sum at MyLinearRegressionImpl.scala:24, took 0.150282 s
[13:09:29,263] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:29,264] INFO  {DAGScheduler} Got job 45 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:29,264] INFO  {DAGScheduler} Final stage: ResultStage 47 (count at MyLinearRegressionImpl.scala:26)
[13:09:29,264] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:29,264] INFO  {DAGScheduler} Missing parents: List()
[13:09:29,264] INFO  {DAGScheduler} Submitting ResultStage 47 (MapPartitionsRDD[61] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:29,266] INFO  {MemoryStore} Block broadcast_52 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:29,267] INFO  {MemoryStore} Block broadcast_52_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:29,267] INFO  {BlockManagerInfo} Added broadcast_52_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:29,268] INFO  {SparkContext} Created broadcast 52 from broadcast at DAGScheduler.scala:1012
[13:09:29,268] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[61] at map at MyLinearRegressionImpl.scala:36)
[13:09:29,268] INFO  {TaskSchedulerImpl} Adding task set 47.0 with 1 tasks
[13:09:29,269] INFO  {TaskSetManager} Starting task 0.0 in stage 47.0 (TID 47, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:29,269] INFO  {Executor} Running task 0.0 in stage 47.0 (TID 47)
[13:09:29,273] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:29,409] INFO  {Executor} Finished task 0.0 in stage 47.0 (TID 47). 1683 bytes result sent to driver
[13:09:29,410] INFO  {TaskSetManager} Finished task 0.0 in stage 47.0 (TID 47) in 141 ms on localhost (1/1)
[13:09:29,410] INFO  {TaskSchedulerImpl} Removed TaskSet 47.0, whose tasks have all completed, from pool 
[13:09:29,410] INFO  {DAGScheduler} ResultStage 47 (count at MyLinearRegressionImpl.scala:26) finished in 0.142 s
[13:09:29,410] INFO  {DAGScheduler} Job 45 finished: count at MyLinearRegressionImpl.scala:26, took 0.147334 s
[13:09:29,414] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:29,414] INFO  {DAGScheduler} Got job 46 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:29,414] INFO  {DAGScheduler} Final stage: ResultStage 48 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:29,414] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:29,414] INFO  {DAGScheduler} Missing parents: List()
[13:09:29,415] INFO  {DAGScheduler} Submitting ResultStage 48 (MapPartitionsRDD[63] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:29,416] INFO  {MemoryStore} Block broadcast_53 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:29,417] INFO  {MemoryStore} Block broadcast_53_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:29,418] INFO  {BlockManagerInfo} Added broadcast_53_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:29,418] INFO  {SparkContext} Created broadcast 53 from broadcast at DAGScheduler.scala:1012
[13:09:29,418] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[63] at map at MyLinearRegressionImpl.scala:54)
[13:09:29,418] INFO  {TaskSchedulerImpl} Adding task set 48.0 with 1 tasks
[13:09:29,419] INFO  {TaskSetManager} Starting task 0.0 in stage 48.0 (TID 48, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:29,419] INFO  {Executor} Running task 0.0 in stage 48.0 (TID 48)
[13:09:29,423] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:29,562] INFO  {Executor} Finished task 0.0 in stage 48.0 (TID 48). 2586 bytes result sent to driver
[13:09:29,562] INFO  {TaskSetManager} Finished task 0.0 in stage 48.0 (TID 48) in 143 ms on localhost (1/1)
[13:09:29,562] INFO  {TaskSchedulerImpl} Removed TaskSet 48.0, whose tasks have all completed, from pool 
[13:09:29,563] INFO  {DAGScheduler} ResultStage 48 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.143 s
[13:09:29,563] INFO  {DAGScheduler} Job 46 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.148952 s
[13:09:29,568] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:29,568] INFO  {DAGScheduler} Got job 47 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:29,569] INFO  {DAGScheduler} Final stage: ResultStage 49 (sum at MyLinearRegressionImpl.scala:24)
[13:09:29,569] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:29,569] INFO  {DAGScheduler} Missing parents: List()
[13:09:29,569] INFO  {DAGScheduler} Submitting ResultStage 49 (MapPartitionsRDD[65] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:29,570] INFO  {MemoryStore} Block broadcast_54 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:29,571] INFO  {MemoryStore} Block broadcast_54_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:29,572] INFO  {BlockManagerInfo} Added broadcast_54_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:29,572] INFO  {SparkContext} Created broadcast 54 from broadcast at DAGScheduler.scala:1012
[13:09:29,572] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[65] at map at MyLinearRegressionImpl.scala:22)
[13:09:29,572] INFO  {TaskSchedulerImpl} Adding task set 49.0 with 1 tasks
[13:09:29,573] INFO  {TaskSetManager} Starting task 0.0 in stage 49.0 (TID 49, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:29,573] INFO  {Executor} Running task 0.0 in stage 49.0 (TID 49)
[13:09:29,577] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:29,707] INFO  {BlockManagerInfo} Removed broadcast_52_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:29,708] INFO  {BlockManagerInfo} Removed broadcast_53_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:29,709] INFO  {BlockManagerInfo} Removed broadcast_50_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:29,710] INFO  {BlockManagerInfo} Removed broadcast_51_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:29,720] INFO  {Executor} Finished task 0.0 in stage 49.0 (TID 49). 1758 bytes result sent to driver
[13:09:29,721] INFO  {TaskSetManager} Finished task 0.0 in stage 49.0 (TID 49) in 148 ms on localhost (1/1)
[13:09:29,721] INFO  {TaskSchedulerImpl} Removed TaskSet 49.0, whose tasks have all completed, from pool 
[13:09:29,721] INFO  {DAGScheduler} ResultStage 49 (sum at MyLinearRegressionImpl.scala:24) finished in 0.149 s
[13:09:29,721] INFO  {DAGScheduler} Job 47 finished: sum at MyLinearRegressionImpl.scala:24, took 0.153257 s
[13:09:29,723] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:29,724] INFO  {DAGScheduler} Got job 48 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:29,724] INFO  {DAGScheduler} Final stage: ResultStage 50 (count at MyLinearRegressionImpl.scala:26)
[13:09:29,724] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:29,724] INFO  {DAGScheduler} Missing parents: List()
[13:09:29,724] INFO  {DAGScheduler} Submitting ResultStage 50 (MapPartitionsRDD[64] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:29,725] INFO  {MemoryStore} Block broadcast_55 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:29,727] INFO  {MemoryStore} Block broadcast_55_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:29,727] INFO  {BlockManagerInfo} Added broadcast_55_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:29,727] INFO  {SparkContext} Created broadcast 55 from broadcast at DAGScheduler.scala:1012
[13:09:29,728] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[64] at map at MyLinearRegressionImpl.scala:36)
[13:09:29,728] INFO  {TaskSchedulerImpl} Adding task set 50.0 with 1 tasks
[13:09:29,728] INFO  {TaskSetManager} Starting task 0.0 in stage 50.0 (TID 50, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:29,728] INFO  {Executor} Running task 0.0 in stage 50.0 (TID 50)
[13:09:29,732] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:29,865] INFO  {Executor} Finished task 0.0 in stage 50.0 (TID 50). 1683 bytes result sent to driver
[13:09:29,866] INFO  {TaskSetManager} Finished task 0.0 in stage 50.0 (TID 50) in 138 ms on localhost (1/1)
[13:09:29,866] INFO  {TaskSchedulerImpl} Removed TaskSet 50.0, whose tasks have all completed, from pool 
[13:09:29,866] INFO  {DAGScheduler} ResultStage 50 (count at MyLinearRegressionImpl.scala:26) finished in 0.138 s
[13:09:29,867] INFO  {DAGScheduler} Job 48 finished: count at MyLinearRegressionImpl.scala:26, took 0.143351 s
[13:09:29,870] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:29,871] INFO  {DAGScheduler} Got job 49 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:29,871] INFO  {DAGScheduler} Final stage: ResultStage 51 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:29,871] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:29,871] INFO  {DAGScheduler} Missing parents: List()
[13:09:29,871] INFO  {DAGScheduler} Submitting ResultStage 51 (MapPartitionsRDD[66] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:29,873] INFO  {MemoryStore} Block broadcast_56 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:29,875] INFO  {MemoryStore} Block broadcast_56_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:29,875] INFO  {BlockManagerInfo} Added broadcast_56_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:29,876] INFO  {SparkContext} Created broadcast 56 from broadcast at DAGScheduler.scala:1012
[13:09:29,876] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[66] at map at MyLinearRegressionImpl.scala:54)
[13:09:29,876] INFO  {TaskSchedulerImpl} Adding task set 51.0 with 1 tasks
[13:09:29,877] INFO  {TaskSetManager} Starting task 0.0 in stage 51.0 (TID 51, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:29,877] INFO  {Executor} Running task 0.0 in stage 51.0 (TID 51)
[13:09:29,882] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:30,027] INFO  {Executor} Finished task 0.0 in stage 51.0 (TID 51). 2499 bytes result sent to driver
[13:09:30,027] INFO  {TaskSetManager} Finished task 0.0 in stage 51.0 (TID 51) in 151 ms on localhost (1/1)
[13:09:30,027] INFO  {TaskSchedulerImpl} Removed TaskSet 51.0, whose tasks have all completed, from pool 
[13:09:30,028] INFO  {DAGScheduler} ResultStage 51 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.151 s
[13:09:30,028] INFO  {DAGScheduler} Job 49 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.157841 s
[13:09:30,033] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:30,033] INFO  {DAGScheduler} Got job 50 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:30,034] INFO  {DAGScheduler} Final stage: ResultStage 52 (sum at MyLinearRegressionImpl.scala:24)
[13:09:30,034] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:30,034] INFO  {DAGScheduler} Missing parents: List()
[13:09:30,034] INFO  {DAGScheduler} Submitting ResultStage 52 (MapPartitionsRDD[68] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:30,035] INFO  {MemoryStore} Block broadcast_57 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:30,037] INFO  {MemoryStore} Block broadcast_57_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.4 MB)
[13:09:30,037] INFO  {BlockManagerInfo} Added broadcast_57_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:30,038] INFO  {SparkContext} Created broadcast 57 from broadcast at DAGScheduler.scala:1012
[13:09:30,038] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[68] at map at MyLinearRegressionImpl.scala:22)
[13:09:30,038] INFO  {TaskSchedulerImpl} Adding task set 52.0 with 1 tasks
[13:09:30,039] INFO  {TaskSetManager} Starting task 0.0 in stage 52.0 (TID 52, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:30,039] INFO  {Executor} Running task 0.0 in stage 52.0 (TID 52)
[13:09:30,043] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:30,177] INFO  {Executor} Finished task 0.0 in stage 52.0 (TID 52). 1685 bytes result sent to driver
[13:09:30,177] INFO  {TaskSetManager} Finished task 0.0 in stage 52.0 (TID 52) in 139 ms on localhost (1/1)
[13:09:30,178] INFO  {TaskSchedulerImpl} Removed TaskSet 52.0, whose tasks have all completed, from pool 
[13:09:30,178] INFO  {DAGScheduler} ResultStage 52 (sum at MyLinearRegressionImpl.scala:24) finished in 0.140 s
[13:09:30,178] INFO  {DAGScheduler} Job 50 finished: sum at MyLinearRegressionImpl.scala:24, took 0.145047 s
[13:09:30,180] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:30,181] INFO  {DAGScheduler} Got job 51 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:30,181] INFO  {DAGScheduler} Final stage: ResultStage 53 (count at MyLinearRegressionImpl.scala:26)
[13:09:30,181] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:30,181] INFO  {DAGScheduler} Missing parents: List()
[13:09:30,181] INFO  {DAGScheduler} Submitting ResultStage 53 (MapPartitionsRDD[67] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:30,183] INFO  {MemoryStore} Block broadcast_58 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:30,185] INFO  {MemoryStore} Block broadcast_58_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:30,185] INFO  {BlockManagerInfo} Added broadcast_58_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:30,186] INFO  {SparkContext} Created broadcast 58 from broadcast at DAGScheduler.scala:1012
[13:09:30,186] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[67] at map at MyLinearRegressionImpl.scala:36)
[13:09:30,186] INFO  {TaskSchedulerImpl} Adding task set 53.0 with 1 tasks
[13:09:30,187] INFO  {TaskSetManager} Starting task 0.0 in stage 53.0 (TID 53, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:30,187] INFO  {Executor} Running task 0.0 in stage 53.0 (TID 53)
[13:09:30,191] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:30,301] INFO  {BlockManagerInfo} Removed broadcast_57_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:30,302] INFO  {BlockManagerInfo} Removed broadcast_54_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:30,303] INFO  {BlockManagerInfo} Removed broadcast_55_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:30,303] INFO  {BlockManagerInfo} Removed broadcast_56_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:30,327] INFO  {Executor} Finished task 0.0 in stage 53.0 (TID 53). 1756 bytes result sent to driver
[13:09:30,328] INFO  {TaskSetManager} Finished task 0.0 in stage 53.0 (TID 53) in 142 ms on localhost (1/1)
[13:09:30,328] INFO  {TaskSchedulerImpl} Removed TaskSet 53.0, whose tasks have all completed, from pool 
[13:09:30,328] INFO  {DAGScheduler} ResultStage 53 (count at MyLinearRegressionImpl.scala:26) finished in 0.142 s
[13:09:30,328] INFO  {DAGScheduler} Job 51 finished: count at MyLinearRegressionImpl.scala:26, took 0.147485 s
[13:09:30,330] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:30,331] INFO  {DAGScheduler} Got job 52 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:30,331] INFO  {DAGScheduler} Final stage: ResultStage 54 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:30,331] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:30,331] INFO  {DAGScheduler} Missing parents: List()
[13:09:30,331] INFO  {DAGScheduler} Submitting ResultStage 54 (MapPartitionsRDD[69] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:30,332] INFO  {MemoryStore} Block broadcast_59 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:30,333] INFO  {MemoryStore} Block broadcast_59_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:30,334] INFO  {BlockManagerInfo} Added broadcast_59_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:30,334] INFO  {SparkContext} Created broadcast 59 from broadcast at DAGScheduler.scala:1012
[13:09:30,334] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[69] at map at MyLinearRegressionImpl.scala:54)
[13:09:30,334] INFO  {TaskSchedulerImpl} Adding task set 54.0 with 1 tasks
[13:09:30,335] INFO  {TaskSetManager} Starting task 0.0 in stage 54.0 (TID 54, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:30,335] INFO  {Executor} Running task 0.0 in stage 54.0 (TID 54)
[13:09:30,340] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:30,472] INFO  {Executor} Finished task 0.0 in stage 54.0 (TID 54). 2499 bytes result sent to driver
[13:09:30,472] INFO  {TaskSetManager} Finished task 0.0 in stage 54.0 (TID 54) in 137 ms on localhost (1/1)
[13:09:30,472] INFO  {TaskSchedulerImpl} Removed TaskSet 54.0, whose tasks have all completed, from pool 
[13:09:30,473] INFO  {DAGScheduler} ResultStage 54 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.139 s
[13:09:30,473] INFO  {DAGScheduler} Job 52 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.142312 s
[13:09:30,479] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:30,480] INFO  {DAGScheduler} Got job 53 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:30,480] INFO  {DAGScheduler} Final stage: ResultStage 55 (sum at MyLinearRegressionImpl.scala:24)
[13:09:30,480] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:30,480] INFO  {DAGScheduler} Missing parents: List()
[13:09:30,480] INFO  {DAGScheduler} Submitting ResultStage 55 (MapPartitionsRDD[71] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:30,481] INFO  {MemoryStore} Block broadcast_60 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:30,483] INFO  {MemoryStore} Block broadcast_60_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:30,483] INFO  {BlockManagerInfo} Added broadcast_60_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:30,484] INFO  {SparkContext} Created broadcast 60 from broadcast at DAGScheduler.scala:1012
[13:09:30,484] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[71] at map at MyLinearRegressionImpl.scala:22)
[13:09:30,484] INFO  {TaskSchedulerImpl} Adding task set 55.0 with 1 tasks
[13:09:30,485] INFO  {TaskSetManager} Starting task 0.0 in stage 55.0 (TID 55, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:30,485] INFO  {Executor} Running task 0.0 in stage 55.0 (TID 55)
[13:09:30,490] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:30,622] INFO  {Executor} Finished task 0.0 in stage 55.0 (TID 55). 1685 bytes result sent to driver
[13:09:30,623] INFO  {TaskSetManager} Finished task 0.0 in stage 55.0 (TID 55) in 138 ms on localhost (1/1)
[13:09:30,623] INFO  {TaskSchedulerImpl} Removed TaskSet 55.0, whose tasks have all completed, from pool 
[13:09:30,623] INFO  {DAGScheduler} ResultStage 55 (sum at MyLinearRegressionImpl.scala:24) finished in 0.139 s
[13:09:30,623] INFO  {DAGScheduler} Job 53 finished: sum at MyLinearRegressionImpl.scala:24, took 0.144355 s
[13:09:30,626] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:30,626] INFO  {DAGScheduler} Got job 54 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:30,626] INFO  {DAGScheduler} Final stage: ResultStage 56 (count at MyLinearRegressionImpl.scala:26)
[13:09:30,626] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:30,627] INFO  {DAGScheduler} Missing parents: List()
[13:09:30,627] INFO  {DAGScheduler} Submitting ResultStage 56 (MapPartitionsRDD[70] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:30,629] INFO  {MemoryStore} Block broadcast_61 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:30,630] INFO  {MemoryStore} Block broadcast_61_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:30,630] INFO  {BlockManagerInfo} Added broadcast_61_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:30,631] INFO  {SparkContext} Created broadcast 61 from broadcast at DAGScheduler.scala:1012
[13:09:30,631] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[70] at map at MyLinearRegressionImpl.scala:36)
[13:09:30,631] INFO  {TaskSchedulerImpl} Adding task set 56.0 with 1 tasks
[13:09:30,632] INFO  {TaskSetManager} Starting task 0.0 in stage 56.0 (TID 56, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:30,632] INFO  {Executor} Running task 0.0 in stage 56.0 (TID 56)
[13:09:30,636] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:30,772] INFO  {Executor} Finished task 0.0 in stage 56.0 (TID 56). 1683 bytes result sent to driver
[13:09:30,772] INFO  {TaskSetManager} Finished task 0.0 in stage 56.0 (TID 56) in 140 ms on localhost (1/1)
[13:09:30,772] INFO  {TaskSchedulerImpl} Removed TaskSet 56.0, whose tasks have all completed, from pool 
[13:09:30,773] INFO  {DAGScheduler} ResultStage 56 (count at MyLinearRegressionImpl.scala:26) finished in 0.141 s
[13:09:30,773] INFO  {DAGScheduler} Job 54 finished: count at MyLinearRegressionImpl.scala:26, took 0.146841 s
[13:09:30,776] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:30,777] INFO  {DAGScheduler} Got job 55 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:30,777] INFO  {DAGScheduler} Final stage: ResultStage 57 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:30,777] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:30,777] INFO  {DAGScheduler} Missing parents: List()
[13:09:30,777] INFO  {DAGScheduler} Submitting ResultStage 57 (MapPartitionsRDD[72] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:30,779] INFO  {MemoryStore} Block broadcast_62 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:30,780] INFO  {MemoryStore} Block broadcast_62_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:30,781] INFO  {BlockManagerInfo} Added broadcast_62_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:30,781] INFO  {SparkContext} Created broadcast 62 from broadcast at DAGScheduler.scala:1012
[13:09:30,781] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[72] at map at MyLinearRegressionImpl.scala:54)
[13:09:30,781] INFO  {TaskSchedulerImpl} Adding task set 57.0 with 1 tasks
[13:09:30,782] INFO  {TaskSetManager} Starting task 0.0 in stage 57.0 (TID 57, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:30,782] INFO  {Executor} Running task 0.0 in stage 57.0 (TID 57)
[13:09:30,786] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:30,908] INFO  {BlockManagerInfo} Removed broadcast_60_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:30,910] INFO  {BlockManagerInfo} Removed broadcast_61_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:30,911] INFO  {BlockManagerInfo} Removed broadcast_58_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:30,912] INFO  {BlockManagerInfo} Removed broadcast_59_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:30,936] INFO  {Executor} Finished task 0.0 in stage 57.0 (TID 57). 2572 bytes result sent to driver
[13:09:30,937] INFO  {TaskSetManager} Finished task 0.0 in stage 57.0 (TID 57) in 155 ms on localhost (1/1)
[13:09:30,937] INFO  {TaskSchedulerImpl} Removed TaskSet 57.0, whose tasks have all completed, from pool 
[13:09:30,937] INFO  {DAGScheduler} ResultStage 57 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.155 s
[13:09:30,937] INFO  {DAGScheduler} Job 55 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.161002 s
[13:09:30,941] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:30,941] INFO  {DAGScheduler} Got job 56 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:30,941] INFO  {DAGScheduler} Final stage: ResultStage 58 (sum at MyLinearRegressionImpl.scala:24)
[13:09:30,941] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:30,941] INFO  {DAGScheduler} Missing parents: List()
[13:09:30,941] INFO  {DAGScheduler} Submitting ResultStage 58 (MapPartitionsRDD[74] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:30,943] INFO  {MemoryStore} Block broadcast_63 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:30,944] INFO  {MemoryStore} Block broadcast_63_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:30,944] INFO  {BlockManagerInfo} Added broadcast_63_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:30,945] INFO  {SparkContext} Created broadcast 63 from broadcast at DAGScheduler.scala:1012
[13:09:30,945] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[74] at map at MyLinearRegressionImpl.scala:22)
[13:09:30,945] INFO  {TaskSchedulerImpl} Adding task set 58.0 with 1 tasks
[13:09:30,946] INFO  {TaskSetManager} Starting task 0.0 in stage 58.0 (TID 58, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:30,946] INFO  {Executor} Running task 0.0 in stage 58.0 (TID 58)
[13:09:30,951] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:31,093] INFO  {Executor} Finished task 0.0 in stage 58.0 (TID 58). 1685 bytes result sent to driver
[13:09:31,094] INFO  {TaskSetManager} Finished task 0.0 in stage 58.0 (TID 58) in 149 ms on localhost (1/1)
[13:09:31,094] INFO  {TaskSchedulerImpl} Removed TaskSet 58.0, whose tasks have all completed, from pool 
[13:09:31,095] INFO  {DAGScheduler} ResultStage 58 (sum at MyLinearRegressionImpl.scala:24) finished in 0.149 s
[13:09:31,095] INFO  {DAGScheduler} Job 56 finished: sum at MyLinearRegressionImpl.scala:24, took 0.153927 s
[13:09:31,097] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:31,098] INFO  {DAGScheduler} Got job 57 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:31,098] INFO  {DAGScheduler} Final stage: ResultStage 59 (count at MyLinearRegressionImpl.scala:26)
[13:09:31,098] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:31,098] INFO  {DAGScheduler} Missing parents: List()
[13:09:31,098] INFO  {DAGScheduler} Submitting ResultStage 59 (MapPartitionsRDD[73] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:31,100] INFO  {MemoryStore} Block broadcast_64 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:31,101] INFO  {MemoryStore} Block broadcast_64_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:31,102] INFO  {BlockManagerInfo} Added broadcast_64_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:31,102] INFO  {SparkContext} Created broadcast 64 from broadcast at DAGScheduler.scala:1012
[13:09:31,102] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[73] at map at MyLinearRegressionImpl.scala:36)
[13:09:31,102] INFO  {TaskSchedulerImpl} Adding task set 59.0 with 1 tasks
[13:09:31,103] INFO  {TaskSetManager} Starting task 0.0 in stage 59.0 (TID 59, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:31,103] INFO  {Executor} Running task 0.0 in stage 59.0 (TID 59)
[13:09:31,108] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:31,238] INFO  {Executor} Finished task 0.0 in stage 59.0 (TID 59). 1683 bytes result sent to driver
[13:09:31,238] INFO  {TaskSetManager} Finished task 0.0 in stage 59.0 (TID 59) in 135 ms on localhost (1/1)
[13:09:31,238] INFO  {TaskSchedulerImpl} Removed TaskSet 59.0, whose tasks have all completed, from pool 
[13:09:31,239] INFO  {DAGScheduler} ResultStage 59 (count at MyLinearRegressionImpl.scala:26) finished in 0.137 s
[13:09:31,239] INFO  {DAGScheduler} Job 57 finished: count at MyLinearRegressionImpl.scala:26, took 0.141387 s
[13:09:31,242] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:31,242] INFO  {DAGScheduler} Got job 58 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:31,242] INFO  {DAGScheduler} Final stage: ResultStage 60 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:31,242] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:31,242] INFO  {DAGScheduler} Missing parents: List()
[13:09:31,243] INFO  {DAGScheduler} Submitting ResultStage 60 (MapPartitionsRDD[75] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:31,244] INFO  {MemoryStore} Block broadcast_65 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:31,245] INFO  {MemoryStore} Block broadcast_65_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:31,246] INFO  {BlockManagerInfo} Added broadcast_65_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:31,246] INFO  {SparkContext} Created broadcast 65 from broadcast at DAGScheduler.scala:1012
[13:09:31,247] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[75] at map at MyLinearRegressionImpl.scala:54)
[13:09:31,247] INFO  {TaskSchedulerImpl} Adding task set 60.0 with 1 tasks
[13:09:31,247] INFO  {TaskSetManager} Starting task 0.0 in stage 60.0 (TID 60, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:31,248] INFO  {Executor} Running task 0.0 in stage 60.0 (TID 60)
[13:09:31,252] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:31,388] INFO  {Executor} Finished task 0.0 in stage 60.0 (TID 60). 2499 bytes result sent to driver
[13:09:31,389] INFO  {TaskSetManager} Finished task 0.0 in stage 60.0 (TID 60) in 142 ms on localhost (1/1)
[13:09:31,389] INFO  {TaskSchedulerImpl} Removed TaskSet 60.0, whose tasks have all completed, from pool 
[13:09:31,389] INFO  {DAGScheduler} ResultStage 60 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.142 s
[13:09:31,389] INFO  {DAGScheduler} Job 58 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.147436 s
[13:09:31,393] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:31,394] INFO  {DAGScheduler} Got job 59 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:31,394] INFO  {DAGScheduler} Final stage: ResultStage 61 (sum at MyLinearRegressionImpl.scala:24)
[13:09:31,394] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:31,394] INFO  {DAGScheduler} Missing parents: List()
[13:09:31,394] INFO  {DAGScheduler} Submitting ResultStage 61 (MapPartitionsRDD[77] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:31,396] INFO  {MemoryStore} Block broadcast_66 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:31,397] INFO  {MemoryStore} Block broadcast_66_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:31,397] INFO  {BlockManagerInfo} Added broadcast_66_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:31,397] INFO  {SparkContext} Created broadcast 66 from broadcast at DAGScheduler.scala:1012
[13:09:31,397] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[77] at map at MyLinearRegressionImpl.scala:22)
[13:09:31,397] INFO  {TaskSchedulerImpl} Adding task set 61.0 with 1 tasks
[13:09:31,398] INFO  {TaskSetManager} Starting task 0.0 in stage 61.0 (TID 61, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:31,398] INFO  {Executor} Running task 0.0 in stage 61.0 (TID 61)
[13:09:31,402] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:31,512] INFO  {BlockManagerInfo} Removed broadcast_62_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:31,513] INFO  {BlockManagerInfo} Removed broadcast_63_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:31,514] INFO  {BlockManagerInfo} Removed broadcast_65_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:31,514] INFO  {BlockManagerInfo} Removed broadcast_64_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:31,539] INFO  {Executor} Finished task 0.0 in stage 61.0 (TID 61). 1758 bytes result sent to driver
[13:09:31,540] INFO  {TaskSetManager} Finished task 0.0 in stage 61.0 (TID 61) in 141 ms on localhost (1/1)
[13:09:31,540] INFO  {TaskSchedulerImpl} Removed TaskSet 61.0, whose tasks have all completed, from pool 
[13:09:31,540] INFO  {DAGScheduler} ResultStage 61 (sum at MyLinearRegressionImpl.scala:24) finished in 0.142 s
[13:09:31,540] INFO  {DAGScheduler} Job 59 finished: sum at MyLinearRegressionImpl.scala:24, took 0.146480 s
[13:09:31,542] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:31,543] INFO  {DAGScheduler} Got job 60 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:31,543] INFO  {DAGScheduler} Final stage: ResultStage 62 (count at MyLinearRegressionImpl.scala:26)
[13:09:31,543] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:31,543] INFO  {DAGScheduler} Missing parents: List()
[13:09:31,543] INFO  {DAGScheduler} Submitting ResultStage 62 (MapPartitionsRDD[76] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:31,545] INFO  {MemoryStore} Block broadcast_67 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:31,546] INFO  {MemoryStore} Block broadcast_67_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:31,546] INFO  {BlockManagerInfo} Added broadcast_67_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:31,547] INFO  {SparkContext} Created broadcast 67 from broadcast at DAGScheduler.scala:1012
[13:09:31,547] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[76] at map at MyLinearRegressionImpl.scala:36)
[13:09:31,547] INFO  {TaskSchedulerImpl} Adding task set 62.0 with 1 tasks
[13:09:31,548] INFO  {TaskSetManager} Starting task 0.0 in stage 62.0 (TID 62, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:31,548] INFO  {Executor} Running task 0.0 in stage 62.0 (TID 62)
[13:09:31,551] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:31,682] INFO  {Executor} Finished task 0.0 in stage 62.0 (TID 62). 1683 bytes result sent to driver
[13:09:31,683] INFO  {TaskSetManager} Finished task 0.0 in stage 62.0 (TID 62) in 136 ms on localhost (1/1)
[13:09:31,683] INFO  {TaskSchedulerImpl} Removed TaskSet 62.0, whose tasks have all completed, from pool 
[13:09:31,684] INFO  {DAGScheduler} ResultStage 62 (count at MyLinearRegressionImpl.scala:26) finished in 0.136 s
[13:09:31,684] INFO  {DAGScheduler} Job 60 finished: count at MyLinearRegressionImpl.scala:26, took 0.141631 s
[13:09:31,688] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:31,688] INFO  {DAGScheduler} Got job 61 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:31,688] INFO  {DAGScheduler} Final stage: ResultStage 63 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:31,688] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:31,689] INFO  {DAGScheduler} Missing parents: List()
[13:09:31,689] INFO  {DAGScheduler} Submitting ResultStage 63 (MapPartitionsRDD[78] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:31,691] INFO  {MemoryStore} Block broadcast_68 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:31,692] INFO  {MemoryStore} Block broadcast_68_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:31,693] INFO  {BlockManagerInfo} Added broadcast_68_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:31,693] INFO  {SparkContext} Created broadcast 68 from broadcast at DAGScheduler.scala:1012
[13:09:31,693] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[78] at map at MyLinearRegressionImpl.scala:54)
[13:09:31,693] INFO  {TaskSchedulerImpl} Adding task set 63.0 with 1 tasks
[13:09:31,694] INFO  {TaskSetManager} Starting task 0.0 in stage 63.0 (TID 63, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:31,695] INFO  {Executor} Running task 0.0 in stage 63.0 (TID 63)
[13:09:31,698] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:31,837] INFO  {Executor} Finished task 0.0 in stage 63.0 (TID 63). 2499 bytes result sent to driver
[13:09:31,837] INFO  {TaskSetManager} Finished task 0.0 in stage 63.0 (TID 63) in 143 ms on localhost (1/1)
[13:09:31,837] INFO  {TaskSchedulerImpl} Removed TaskSet 63.0, whose tasks have all completed, from pool 
[13:09:31,838] INFO  {DAGScheduler} ResultStage 63 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.144 s
[13:09:31,838] INFO  {DAGScheduler} Job 61 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.150032 s
[13:09:31,844] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:31,845] INFO  {DAGScheduler} Got job 62 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:31,845] INFO  {DAGScheduler} Final stage: ResultStage 64 (sum at MyLinearRegressionImpl.scala:24)
[13:09:31,845] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:31,845] INFO  {DAGScheduler} Missing parents: List()
[13:09:31,845] INFO  {DAGScheduler} Submitting ResultStage 64 (MapPartitionsRDD[80] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:31,848] INFO  {MemoryStore} Block broadcast_69 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:31,850] INFO  {MemoryStore} Block broadcast_69_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.4 MB)
[13:09:31,850] INFO  {BlockManagerInfo} Added broadcast_69_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:31,851] INFO  {SparkContext} Created broadcast 69 from broadcast at DAGScheduler.scala:1012
[13:09:31,851] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[80] at map at MyLinearRegressionImpl.scala:22)
[13:09:31,851] INFO  {TaskSchedulerImpl} Adding task set 64.0 with 1 tasks
[13:09:31,852] INFO  {TaskSetManager} Starting task 0.0 in stage 64.0 (TID 64, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:31,852] INFO  {Executor} Running task 0.0 in stage 64.0 (TID 64)
[13:09:31,856] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:31,995] INFO  {Executor} Finished task 0.0 in stage 64.0 (TID 64). 1685 bytes result sent to driver
[13:09:31,996] INFO  {TaskSetManager} Finished task 0.0 in stage 64.0 (TID 64) in 145 ms on localhost (1/1)
[13:09:31,996] INFO  {TaskSchedulerImpl} Removed TaskSet 64.0, whose tasks have all completed, from pool 
[13:09:31,996] INFO  {DAGScheduler} ResultStage 64 (sum at MyLinearRegressionImpl.scala:24) finished in 0.145 s
[13:09:31,996] INFO  {DAGScheduler} Job 62 finished: sum at MyLinearRegressionImpl.scala:24, took 0.151608 s
[13:09:31,998] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:31,998] INFO  {DAGScheduler} Got job 63 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:31,998] INFO  {DAGScheduler} Final stage: ResultStage 65 (count at MyLinearRegressionImpl.scala:26)
[13:09:31,998] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:31,998] INFO  {DAGScheduler} Missing parents: List()
[13:09:31,999] INFO  {DAGScheduler} Submitting ResultStage 65 (MapPartitionsRDD[79] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:32,000] INFO  {MemoryStore} Block broadcast_70 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:32,001] INFO  {MemoryStore} Block broadcast_70_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:32,001] INFO  {BlockManagerInfo} Added broadcast_70_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:32,001] INFO  {SparkContext} Created broadcast 70 from broadcast at DAGScheduler.scala:1012
[13:09:32,002] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[79] at map at MyLinearRegressionImpl.scala:36)
[13:09:32,002] INFO  {TaskSchedulerImpl} Adding task set 65.0 with 1 tasks
[13:09:32,002] INFO  {TaskSetManager} Starting task 0.0 in stage 65.0 (TID 65, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:32,003] INFO  {Executor} Running task 0.0 in stage 65.0 (TID 65)
[13:09:32,006] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:32,133] INFO  {BlockManagerInfo} Removed broadcast_66_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:32,135] INFO  {BlockManagerInfo} Removed broadcast_67_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:32,135] INFO  {BlockManagerInfo} Removed broadcast_68_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:32,136] INFO  {BlockManagerInfo} Removed broadcast_69_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:32,146] INFO  {Executor} Finished task 0.0 in stage 65.0 (TID 65). 1756 bytes result sent to driver
[13:09:32,147] INFO  {TaskSetManager} Finished task 0.0 in stage 65.0 (TID 65) in 145 ms on localhost (1/1)
[13:09:32,147] INFO  {TaskSchedulerImpl} Removed TaskSet 65.0, whose tasks have all completed, from pool 
[13:09:32,147] INFO  {DAGScheduler} ResultStage 65 (count at MyLinearRegressionImpl.scala:26) finished in 0.145 s
[13:09:32,147] INFO  {DAGScheduler} Job 63 finished: count at MyLinearRegressionImpl.scala:26, took 0.149621 s
[13:09:32,150] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:32,150] INFO  {DAGScheduler} Got job 64 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:32,150] INFO  {DAGScheduler} Final stage: ResultStage 66 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:32,150] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:32,150] INFO  {DAGScheduler} Missing parents: List()
[13:09:32,151] INFO  {DAGScheduler} Submitting ResultStage 66 (MapPartitionsRDD[81] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:32,152] INFO  {MemoryStore} Block broadcast_71 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:32,153] INFO  {MemoryStore} Block broadcast_71_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:32,153] INFO  {BlockManagerInfo} Added broadcast_71_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:32,153] INFO  {SparkContext} Created broadcast 71 from broadcast at DAGScheduler.scala:1012
[13:09:32,154] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[81] at map at MyLinearRegressionImpl.scala:54)
[13:09:32,154] INFO  {TaskSchedulerImpl} Adding task set 66.0 with 1 tasks
[13:09:32,154] INFO  {TaskSetManager} Starting task 0.0 in stage 66.0 (TID 66, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:32,155] INFO  {Executor} Running task 0.0 in stage 66.0 (TID 66)
[13:09:32,159] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:32,298] INFO  {Executor} Finished task 0.0 in stage 66.0 (TID 66). 2499 bytes result sent to driver
[13:09:32,298] INFO  {TaskSetManager} Finished task 0.0 in stage 66.0 (TID 66) in 144 ms on localhost (1/1)
[13:09:32,298] INFO  {TaskSchedulerImpl} Removed TaskSet 66.0, whose tasks have all completed, from pool 
[13:09:32,299] INFO  {DAGScheduler} ResultStage 66 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.143 s
[13:09:32,299] INFO  {DAGScheduler} Job 64 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.148853 s
[13:09:32,303] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:32,303] INFO  {DAGScheduler} Got job 65 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:32,303] INFO  {DAGScheduler} Final stage: ResultStage 67 (sum at MyLinearRegressionImpl.scala:24)
[13:09:32,303] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:32,303] INFO  {DAGScheduler} Missing parents: List()
[13:09:32,304] INFO  {DAGScheduler} Submitting ResultStage 67 (MapPartitionsRDD[83] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:32,305] INFO  {MemoryStore} Block broadcast_72 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:32,307] INFO  {MemoryStore} Block broadcast_72_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:32,307] INFO  {BlockManagerInfo} Added broadcast_72_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:32,308] INFO  {SparkContext} Created broadcast 72 from broadcast at DAGScheduler.scala:1012
[13:09:32,308] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[83] at map at MyLinearRegressionImpl.scala:22)
[13:09:32,308] INFO  {TaskSchedulerImpl} Adding task set 67.0 with 1 tasks
[13:09:32,309] INFO  {TaskSetManager} Starting task 0.0 in stage 67.0 (TID 67, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:32,309] INFO  {Executor} Running task 0.0 in stage 67.0 (TID 67)
[13:09:32,313] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:32,449] INFO  {Executor} Finished task 0.0 in stage 67.0 (TID 67). 1685 bytes result sent to driver
[13:09:32,450] INFO  {TaskSetManager} Finished task 0.0 in stage 67.0 (TID 67) in 142 ms on localhost (1/1)
[13:09:32,450] INFO  {TaskSchedulerImpl} Removed TaskSet 67.0, whose tasks have all completed, from pool 
[13:09:32,450] INFO  {DAGScheduler} ResultStage 67 (sum at MyLinearRegressionImpl.scala:24) finished in 0.142 s
[13:09:32,450] INFO  {DAGScheduler} Job 65 finished: sum at MyLinearRegressionImpl.scala:24, took 0.147719 s
[13:09:32,453] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:32,453] INFO  {DAGScheduler} Got job 66 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:32,453] INFO  {DAGScheduler} Final stage: ResultStage 68 (count at MyLinearRegressionImpl.scala:26)
[13:09:32,453] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:32,453] INFO  {DAGScheduler} Missing parents: List()
[13:09:32,454] INFO  {DAGScheduler} Submitting ResultStage 68 (MapPartitionsRDD[82] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:32,455] INFO  {MemoryStore} Block broadcast_73 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:32,457] INFO  {MemoryStore} Block broadcast_73_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:32,457] INFO  {BlockManagerInfo} Added broadcast_73_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:32,457] INFO  {SparkContext} Created broadcast 73 from broadcast at DAGScheduler.scala:1012
[13:09:32,457] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[82] at map at MyLinearRegressionImpl.scala:36)
[13:09:32,457] INFO  {TaskSchedulerImpl} Adding task set 68.0 with 1 tasks
[13:09:32,458] INFO  {TaskSetManager} Starting task 0.0 in stage 68.0 (TID 68, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:32,458] INFO  {Executor} Running task 0.0 in stage 68.0 (TID 68)
[13:09:32,462] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:32,594] INFO  {Executor} Finished task 0.0 in stage 68.0 (TID 68). 1683 bytes result sent to driver
[13:09:32,594] INFO  {TaskSetManager} Finished task 0.0 in stage 68.0 (TID 68) in 136 ms on localhost (1/1)
[13:09:32,594] INFO  {TaskSchedulerImpl} Removed TaskSet 68.0, whose tasks have all completed, from pool 
[13:09:32,595] INFO  {DAGScheduler} ResultStage 68 (count at MyLinearRegressionImpl.scala:26) finished in 0.137 s
[13:09:32,595] INFO  {DAGScheduler} Job 66 finished: count at MyLinearRegressionImpl.scala:26, took 0.142021 s
[13:09:32,598] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:32,599] INFO  {DAGScheduler} Got job 67 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:32,599] INFO  {DAGScheduler} Final stage: ResultStage 69 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:32,599] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:32,599] INFO  {DAGScheduler} Missing parents: List()
[13:09:32,599] INFO  {DAGScheduler} Submitting ResultStage 69 (MapPartitionsRDD[84] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:32,601] INFO  {MemoryStore} Block broadcast_74 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:32,602] INFO  {MemoryStore} Block broadcast_74_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:32,602] INFO  {BlockManagerInfo} Added broadcast_74_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:32,603] INFO  {SparkContext} Created broadcast 74 from broadcast at DAGScheduler.scala:1012
[13:09:32,603] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[84] at map at MyLinearRegressionImpl.scala:54)
[13:09:32,603] INFO  {TaskSchedulerImpl} Adding task set 69.0 with 1 tasks
[13:09:32,604] INFO  {TaskSetManager} Starting task 0.0 in stage 69.0 (TID 69, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:32,604] INFO  {Executor} Running task 0.0 in stage 69.0 (TID 69)
[13:09:32,609] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:32,747] INFO  {BlockManagerInfo} Removed broadcast_71_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:32,747] INFO  {BlockManagerInfo} Removed broadcast_73_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:32,748] INFO  {BlockManagerInfo} Removed broadcast_72_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:32,749] INFO  {BlockManagerInfo} Removed broadcast_70_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:32,750] INFO  {Executor} Finished task 0.0 in stage 69.0 (TID 69). 2572 bytes result sent to driver
[13:09:32,750] INFO  {TaskSetManager} Finished task 0.0 in stage 69.0 (TID 69) in 146 ms on localhost (1/1)
[13:09:32,750] INFO  {TaskSchedulerImpl} Removed TaskSet 69.0, whose tasks have all completed, from pool 
[13:09:32,750] INFO  {DAGScheduler} ResultStage 69 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.147 s
[13:09:32,751] INFO  {DAGScheduler} Job 67 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.152372 s
[13:09:32,754] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:32,755] INFO  {DAGScheduler} Got job 68 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:32,755] INFO  {DAGScheduler} Final stage: ResultStage 70 (sum at MyLinearRegressionImpl.scala:24)
[13:09:32,755] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:32,755] INFO  {DAGScheduler} Missing parents: List()
[13:09:32,755] INFO  {DAGScheduler} Submitting ResultStage 70 (MapPartitionsRDD[86] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:32,756] INFO  {MemoryStore} Block broadcast_75 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:32,758] INFO  {MemoryStore} Block broadcast_75_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:32,758] INFO  {BlockManagerInfo} Added broadcast_75_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:32,759] INFO  {SparkContext} Created broadcast 75 from broadcast at DAGScheduler.scala:1012
[13:09:32,759] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[86] at map at MyLinearRegressionImpl.scala:22)
[13:09:32,759] INFO  {TaskSchedulerImpl} Adding task set 70.0 with 1 tasks
[13:09:32,761] INFO  {TaskSetManager} Starting task 0.0 in stage 70.0 (TID 70, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:32,762] INFO  {Executor} Running task 0.0 in stage 70.0 (TID 70)
[13:09:32,765] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:32,897] INFO  {Executor} Finished task 0.0 in stage 70.0 (TID 70). 1685 bytes result sent to driver
[13:09:32,899] INFO  {TaskSetManager} Finished task 0.0 in stage 70.0 (TID 70) in 138 ms on localhost (1/1)
[13:09:32,899] INFO  {TaskSchedulerImpl} Removed TaskSet 70.0, whose tasks have all completed, from pool 
[13:09:32,899] INFO  {DAGScheduler} ResultStage 70 (sum at MyLinearRegressionImpl.scala:24) finished in 0.139 s
[13:09:32,899] INFO  {DAGScheduler} Job 68 finished: sum at MyLinearRegressionImpl.scala:24, took 0.144825 s
[13:09:32,902] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:32,902] INFO  {DAGScheduler} Got job 69 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:32,902] INFO  {DAGScheduler} Final stage: ResultStage 71 (count at MyLinearRegressionImpl.scala:26)
[13:09:32,902] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:32,903] INFO  {DAGScheduler} Missing parents: List()
[13:09:32,903] INFO  {DAGScheduler} Submitting ResultStage 71 (MapPartitionsRDD[85] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:32,905] INFO  {MemoryStore} Block broadcast_76 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:32,906] INFO  {MemoryStore} Block broadcast_76_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:32,907] INFO  {BlockManagerInfo} Added broadcast_76_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:32,907] INFO  {SparkContext} Created broadcast 76 from broadcast at DAGScheduler.scala:1012
[13:09:32,907] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[85] at map at MyLinearRegressionImpl.scala:36)
[13:09:32,907] INFO  {TaskSchedulerImpl} Adding task set 71.0 with 1 tasks
[13:09:32,908] INFO  {TaskSetManager} Starting task 0.0 in stage 71.0 (TID 71, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:32,908] INFO  {Executor} Running task 0.0 in stage 71.0 (TID 71)
[13:09:32,916] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:33,050] INFO  {Executor} Finished task 0.0 in stage 71.0 (TID 71). 1683 bytes result sent to driver
[13:09:33,051] INFO  {TaskSetManager} Finished task 0.0 in stage 71.0 (TID 71) in 143 ms on localhost (1/1)
[13:09:33,051] INFO  {TaskSchedulerImpl} Removed TaskSet 71.0, whose tasks have all completed, from pool 
[13:09:33,051] INFO  {DAGScheduler} ResultStage 71 (count at MyLinearRegressionImpl.scala:26) finished in 0.143 s
[13:09:33,051] INFO  {DAGScheduler} Job 69 finished: count at MyLinearRegressionImpl.scala:26, took 0.149225 s
[13:09:33,054] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:33,055] INFO  {DAGScheduler} Got job 70 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:33,055] INFO  {DAGScheduler} Final stage: ResultStage 72 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:33,055] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:33,055] INFO  {DAGScheduler} Missing parents: List()
[13:09:33,055] INFO  {DAGScheduler} Submitting ResultStage 72 (MapPartitionsRDD[87] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:33,057] INFO  {MemoryStore} Block broadcast_77 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:33,058] INFO  {MemoryStore} Block broadcast_77_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:33,058] INFO  {BlockManagerInfo} Added broadcast_77_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:33,059] INFO  {SparkContext} Created broadcast 77 from broadcast at DAGScheduler.scala:1012
[13:09:33,059] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[87] at map at MyLinearRegressionImpl.scala:54)
[13:09:33,059] INFO  {TaskSchedulerImpl} Adding task set 72.0 with 1 tasks
[13:09:33,060] INFO  {TaskSetManager} Starting task 0.0 in stage 72.0 (TID 72, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:33,060] INFO  {Executor} Running task 0.0 in stage 72.0 (TID 72)
[13:09:33,064] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:33,199] INFO  {Executor} Finished task 0.0 in stage 72.0 (TID 72). 2499 bytes result sent to driver
[13:09:33,200] INFO  {TaskSetManager} Finished task 0.0 in stage 72.0 (TID 72) in 141 ms on localhost (1/1)
[13:09:33,200] INFO  {TaskSchedulerImpl} Removed TaskSet 72.0, whose tasks have all completed, from pool 
[13:09:33,200] INFO  {DAGScheduler} ResultStage 72 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.141 s
[13:09:33,200] INFO  {DAGScheduler} Job 70 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.145962 s
[13:09:33,204] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:33,204] INFO  {DAGScheduler} Got job 71 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:33,205] INFO  {DAGScheduler} Final stage: ResultStage 73 (sum at MyLinearRegressionImpl.scala:24)
[13:09:33,205] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:33,205] INFO  {DAGScheduler} Missing parents: List()
[13:09:33,205] INFO  {DAGScheduler} Submitting ResultStage 73 (MapPartitionsRDD[89] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:33,206] INFO  {MemoryStore} Block broadcast_78 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:33,207] INFO  {MemoryStore} Block broadcast_78_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:33,207] INFO  {BlockManagerInfo} Added broadcast_78_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:33,207] INFO  {SparkContext} Created broadcast 78 from broadcast at DAGScheduler.scala:1012
[13:09:33,207] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[89] at map at MyLinearRegressionImpl.scala:22)
[13:09:33,207] INFO  {TaskSchedulerImpl} Adding task set 73.0 with 1 tasks
[13:09:33,208] INFO  {TaskSetManager} Starting task 0.0 in stage 73.0 (TID 73, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:33,208] INFO  {Executor} Running task 0.0 in stage 73.0 (TID 73)
[13:09:33,212] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:33,342] INFO  {Executor} Finished task 0.0 in stage 73.0 (TID 73). 1685 bytes result sent to driver
[13:09:33,343] INFO  {TaskSetManager} Finished task 0.0 in stage 73.0 (TID 73) in 135 ms on localhost (1/1)
[13:09:33,343] INFO  {TaskSchedulerImpl} Removed TaskSet 73.0, whose tasks have all completed, from pool 
[13:09:33,343] INFO  {DAGScheduler} ResultStage 73 (sum at MyLinearRegressionImpl.scala:24) finished in 0.135 s
[13:09:33,343] INFO  {DAGScheduler} Job 71 finished: sum at MyLinearRegressionImpl.scala:24, took 0.139206 s
[13:09:33,346] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:33,346] INFO  {DAGScheduler} Got job 72 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:33,346] INFO  {DAGScheduler} Final stage: ResultStage 74 (count at MyLinearRegressionImpl.scala:26)
[13:09:33,346] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:33,346] INFO  {DAGScheduler} Missing parents: List()
[13:09:33,347] INFO  {DAGScheduler} Submitting ResultStage 74 (MapPartitionsRDD[88] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:33,348] INFO  {MemoryStore} Block broadcast_79 stored as values in memory (estimated size 45.0 KB, free 1128.3 MB)
[13:09:33,349] INFO  {MemoryStore} Block broadcast_79_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:33,350] INFO  {BlockManagerInfo} Added broadcast_79_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:33,350] INFO  {SparkContext} Created broadcast 79 from broadcast at DAGScheduler.scala:1012
[13:09:33,350] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[88] at map at MyLinearRegressionImpl.scala:36)
[13:09:33,351] INFO  {TaskSchedulerImpl} Adding task set 74.0 with 1 tasks
[13:09:33,351] INFO  {TaskSetManager} Starting task 0.0 in stage 74.0 (TID 74, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:33,352] INFO  {Executor} Running task 0.0 in stage 74.0 (TID 74)
[13:09:33,355] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:33,391] INFO  {BlockManagerInfo} Removed broadcast_77_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:33,392] INFO  {BlockManagerInfo} Removed broadcast_78_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:33,393] INFO  {BlockManagerInfo} Removed broadcast_74_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:33,394] INFO  {BlockManagerInfo} Removed broadcast_75_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:33,394] INFO  {BlockManagerInfo} Removed broadcast_76_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:33,498] INFO  {Executor} Finished task 0.0 in stage 74.0 (TID 74). 1756 bytes result sent to driver
[13:09:33,499] INFO  {TaskSetManager} Finished task 0.0 in stage 74.0 (TID 74) in 147 ms on localhost (1/1)
[13:09:33,499] INFO  {TaskSchedulerImpl} Removed TaskSet 74.0, whose tasks have all completed, from pool 
[13:09:33,499] INFO  {DAGScheduler} ResultStage 74 (count at MyLinearRegressionImpl.scala:26) finished in 0.148 s
[13:09:33,499] INFO  {DAGScheduler} Job 72 finished: count at MyLinearRegressionImpl.scala:26, took 0.153200 s
[13:09:33,503] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:33,503] INFO  {DAGScheduler} Got job 73 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:33,503] INFO  {DAGScheduler} Final stage: ResultStage 75 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:33,503] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:33,504] INFO  {DAGScheduler} Missing parents: List()
[13:09:33,504] INFO  {DAGScheduler} Submitting ResultStage 75 (MapPartitionsRDD[90] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:33,505] INFO  {MemoryStore} Block broadcast_80 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:33,507] INFO  {MemoryStore} Block broadcast_80_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:33,507] INFO  {BlockManagerInfo} Added broadcast_80_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:33,508] INFO  {SparkContext} Created broadcast 80 from broadcast at DAGScheduler.scala:1012
[13:09:33,508] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[90] at map at MyLinearRegressionImpl.scala:54)
[13:09:33,508] INFO  {TaskSchedulerImpl} Adding task set 75.0 with 1 tasks
[13:09:33,509] INFO  {TaskSetManager} Starting task 0.0 in stage 75.0 (TID 75, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:33,509] INFO  {Executor} Running task 0.0 in stage 75.0 (TID 75)
[13:09:33,512] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:33,645] INFO  {Executor} Finished task 0.0 in stage 75.0 (TID 75). 2499 bytes result sent to driver
[13:09:33,645] INFO  {TaskSetManager} Finished task 0.0 in stage 75.0 (TID 75) in 137 ms on localhost (1/1)
[13:09:33,646] INFO  {TaskSchedulerImpl} Removed TaskSet 75.0, whose tasks have all completed, from pool 
[13:09:33,646] INFO  {DAGScheduler} ResultStage 75 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.138 s
[13:09:33,646] INFO  {DAGScheduler} Job 73 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.143050 s
[13:09:33,651] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:33,652] INFO  {DAGScheduler} Got job 74 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:33,652] INFO  {DAGScheduler} Final stage: ResultStage 76 (sum at MyLinearRegressionImpl.scala:24)
[13:09:33,652] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:33,652] INFO  {DAGScheduler} Missing parents: List()
[13:09:33,652] INFO  {DAGScheduler} Submitting ResultStage 76 (MapPartitionsRDD[92] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:33,653] INFO  {MemoryStore} Block broadcast_81 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:33,656] INFO  {MemoryStore} Block broadcast_81_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:33,656] INFO  {BlockManagerInfo} Added broadcast_81_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:33,657] INFO  {SparkContext} Created broadcast 81 from broadcast at DAGScheduler.scala:1012
[13:09:33,657] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[92] at map at MyLinearRegressionImpl.scala:22)
[13:09:33,657] INFO  {TaskSchedulerImpl} Adding task set 76.0 with 1 tasks
[13:09:33,658] INFO  {TaskSetManager} Starting task 0.0 in stage 76.0 (TID 76, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:33,658] INFO  {Executor} Running task 0.0 in stage 76.0 (TID 76)
[13:09:33,661] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:33,800] INFO  {Executor} Finished task 0.0 in stage 76.0 (TID 76). 1685 bytes result sent to driver
[13:09:33,800] INFO  {TaskSetManager} Finished task 0.0 in stage 76.0 (TID 76) in 143 ms on localhost (1/1)
[13:09:33,800] INFO  {TaskSchedulerImpl} Removed TaskSet 76.0, whose tasks have all completed, from pool 
[13:09:33,800] INFO  {DAGScheduler} ResultStage 76 (sum at MyLinearRegressionImpl.scala:24) finished in 0.143 s
[13:09:33,801] INFO  {DAGScheduler} Job 74 finished: sum at MyLinearRegressionImpl.scala:24, took 0.149557 s
[13:09:33,803] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:33,803] INFO  {DAGScheduler} Got job 75 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:33,803] INFO  {DAGScheduler} Final stage: ResultStage 77 (count at MyLinearRegressionImpl.scala:26)
[13:09:33,803] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:33,804] INFO  {DAGScheduler} Missing parents: List()
[13:09:33,804] INFO  {DAGScheduler} Submitting ResultStage 77 (MapPartitionsRDD[91] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:33,805] INFO  {MemoryStore} Block broadcast_82 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:33,807] INFO  {MemoryStore} Block broadcast_82_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:33,807] INFO  {BlockManagerInfo} Added broadcast_82_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:33,808] INFO  {SparkContext} Created broadcast 82 from broadcast at DAGScheduler.scala:1012
[13:09:33,808] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[91] at map at MyLinearRegressionImpl.scala:36)
[13:09:33,808] INFO  {TaskSchedulerImpl} Adding task set 77.0 with 1 tasks
[13:09:33,809] INFO  {TaskSetManager} Starting task 0.0 in stage 77.0 (TID 77, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:33,809] INFO  {Executor} Running task 0.0 in stage 77.0 (TID 77)
[13:09:33,813] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:33,944] INFO  {Executor} Finished task 0.0 in stage 77.0 (TID 77). 1683 bytes result sent to driver
[13:09:33,945] INFO  {TaskSetManager} Finished task 0.0 in stage 77.0 (TID 77) in 137 ms on localhost (1/1)
[13:09:33,945] INFO  {TaskSchedulerImpl} Removed TaskSet 77.0, whose tasks have all completed, from pool 
[13:09:33,945] INFO  {DAGScheduler} ResultStage 77 (count at MyLinearRegressionImpl.scala:26) finished in 0.137 s
[13:09:33,945] INFO  {DAGScheduler} Job 75 finished: count at MyLinearRegressionImpl.scala:26, took 0.142404 s
[13:09:33,948] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:33,949] INFO  {DAGScheduler} Got job 76 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:33,949] INFO  {DAGScheduler} Final stage: ResultStage 78 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:33,949] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:33,949] INFO  {DAGScheduler} Missing parents: List()
[13:09:33,949] INFO  {DAGScheduler} Submitting ResultStage 78 (MapPartitionsRDD[93] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:33,952] INFO  {MemoryStore} Block broadcast_83 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:33,953] INFO  {MemoryStore} Block broadcast_83_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:33,954] INFO  {BlockManagerInfo} Added broadcast_83_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:33,954] INFO  {SparkContext} Created broadcast 83 from broadcast at DAGScheduler.scala:1012
[13:09:33,954] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[93] at map at MyLinearRegressionImpl.scala:54)
[13:09:33,955] INFO  {TaskSchedulerImpl} Adding task set 78.0 with 1 tasks
[13:09:33,956] INFO  {TaskSetManager} Starting task 0.0 in stage 78.0 (TID 78, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:33,956] INFO  {Executor} Running task 0.0 in stage 78.0 (TID 78)
[13:09:33,961] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:34,014] INFO  {BlockManagerInfo} Removed broadcast_81_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:34,015] INFO  {BlockManagerInfo} Removed broadcast_79_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:34,015] INFO  {BlockManagerInfo} Removed broadcast_82_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:34,016] INFO  {BlockManagerInfo} Removed broadcast_80_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:34,101] INFO  {Executor} Finished task 0.0 in stage 78.0 (TID 78). 2572 bytes result sent to driver
[13:09:34,102] INFO  {TaskSetManager} Finished task 0.0 in stage 78.0 (TID 78) in 147 ms on localhost (1/1)
[13:09:34,102] INFO  {TaskSchedulerImpl} Removed TaskSet 78.0, whose tasks have all completed, from pool 
[13:09:34,102] INFO  {DAGScheduler} ResultStage 78 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.147 s
[13:09:34,102] INFO  {DAGScheduler} Job 76 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.153664 s
[13:09:34,107] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:34,107] INFO  {DAGScheduler} Got job 77 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:34,108] INFO  {DAGScheduler} Final stage: ResultStage 79 (sum at MyLinearRegressionImpl.scala:24)
[13:09:34,108] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:34,108] INFO  {DAGScheduler} Missing parents: List()
[13:09:34,108] INFO  {DAGScheduler} Submitting ResultStage 79 (MapPartitionsRDD[95] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:34,109] INFO  {MemoryStore} Block broadcast_84 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:34,111] INFO  {MemoryStore} Block broadcast_84_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:34,111] INFO  {BlockManagerInfo} Added broadcast_84_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:34,111] INFO  {SparkContext} Created broadcast 84 from broadcast at DAGScheduler.scala:1012
[13:09:34,112] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[95] at map at MyLinearRegressionImpl.scala:22)
[13:09:34,112] INFO  {TaskSchedulerImpl} Adding task set 79.0 with 1 tasks
[13:09:34,112] INFO  {TaskSetManager} Starting task 0.0 in stage 79.0 (TID 79, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:34,113] INFO  {Executor} Running task 0.0 in stage 79.0 (TID 79)
[13:09:34,118] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:34,255] INFO  {Executor} Finished task 0.0 in stage 79.0 (TID 79). 1685 bytes result sent to driver
[13:09:34,256] INFO  {TaskSetManager} Finished task 0.0 in stage 79.0 (TID 79) in 144 ms on localhost (1/1)
[13:09:34,256] INFO  {TaskSchedulerImpl} Removed TaskSet 79.0, whose tasks have all completed, from pool 
[13:09:34,256] INFO  {DAGScheduler} ResultStage 79 (sum at MyLinearRegressionImpl.scala:24) finished in 0.144 s
[13:09:34,256] INFO  {DAGScheduler} Job 77 finished: sum at MyLinearRegressionImpl.scala:24, took 0.149174 s
[13:09:34,258] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:34,259] INFO  {DAGScheduler} Got job 78 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:34,259] INFO  {DAGScheduler} Final stage: ResultStage 80 (count at MyLinearRegressionImpl.scala:26)
[13:09:34,259] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:34,259] INFO  {DAGScheduler} Missing parents: List()
[13:09:34,259] INFO  {DAGScheduler} Submitting ResultStage 80 (MapPartitionsRDD[94] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:34,261] INFO  {MemoryStore} Block broadcast_85 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:34,262] INFO  {MemoryStore} Block broadcast_85_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:34,262] INFO  {BlockManagerInfo} Added broadcast_85_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:34,263] INFO  {SparkContext} Created broadcast 85 from broadcast at DAGScheduler.scala:1012
[13:09:34,263] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[94] at map at MyLinearRegressionImpl.scala:36)
[13:09:34,263] INFO  {TaskSchedulerImpl} Adding task set 80.0 with 1 tasks
[13:09:34,264] INFO  {TaskSetManager} Starting task 0.0 in stage 80.0 (TID 80, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:34,264] INFO  {Executor} Running task 0.0 in stage 80.0 (TID 80)
[13:09:34,267] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:34,396] INFO  {Executor} Finished task 0.0 in stage 80.0 (TID 80). 1683 bytes result sent to driver
[13:09:34,396] INFO  {TaskSetManager} Finished task 0.0 in stage 80.0 (TID 80) in 133 ms on localhost (1/1)
[13:09:34,396] INFO  {TaskSchedulerImpl} Removed TaskSet 80.0, whose tasks have all completed, from pool 
[13:09:34,397] INFO  {DAGScheduler} ResultStage 80 (count at MyLinearRegressionImpl.scala:26) finished in 0.134 s
[13:09:34,397] INFO  {DAGScheduler} Job 78 finished: count at MyLinearRegressionImpl.scala:26, took 0.138477 s
[13:09:34,400] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:34,400] INFO  {DAGScheduler} Got job 79 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:34,401] INFO  {DAGScheduler} Final stage: ResultStage 81 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:34,401] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:34,401] INFO  {DAGScheduler} Missing parents: List()
[13:09:34,401] INFO  {DAGScheduler} Submitting ResultStage 81 (MapPartitionsRDD[96] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:34,403] INFO  {MemoryStore} Block broadcast_86 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:34,404] INFO  {MemoryStore} Block broadcast_86_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:34,404] INFO  {BlockManagerInfo} Added broadcast_86_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:34,405] INFO  {SparkContext} Created broadcast 86 from broadcast at DAGScheduler.scala:1012
[13:09:34,405] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[96] at map at MyLinearRegressionImpl.scala:54)
[13:09:34,405] INFO  {TaskSchedulerImpl} Adding task set 81.0 with 1 tasks
[13:09:34,406] INFO  {TaskSetManager} Starting task 0.0 in stage 81.0 (TID 81, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:34,406] INFO  {Executor} Running task 0.0 in stage 81.0 (TID 81)
[13:09:34,409] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:34,549] INFO  {Executor} Finished task 0.0 in stage 81.0 (TID 81). 2499 bytes result sent to driver
[13:09:34,550] INFO  {TaskSetManager} Finished task 0.0 in stage 81.0 (TID 81) in 145 ms on localhost (1/1)
[13:09:34,550] INFO  {TaskSchedulerImpl} Removed TaskSet 81.0, whose tasks have all completed, from pool 
[13:09:34,550] INFO  {DAGScheduler} ResultStage 81 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.145 s
[13:09:34,550] INFO  {DAGScheduler} Job 79 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.150068 s
[13:09:34,555] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:34,556] INFO  {DAGScheduler} Got job 80 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:34,556] INFO  {DAGScheduler} Final stage: ResultStage 82 (sum at MyLinearRegressionImpl.scala:24)
[13:09:34,556] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:34,556] INFO  {DAGScheduler} Missing parents: List()
[13:09:34,556] INFO  {DAGScheduler} Submitting ResultStage 82 (MapPartitionsRDD[98] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:34,558] INFO  {MemoryStore} Block broadcast_87 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:34,559] INFO  {MemoryStore} Block broadcast_87_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:34,560] INFO  {BlockManagerInfo} Added broadcast_87_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:34,560] INFO  {SparkContext} Created broadcast 87 from broadcast at DAGScheduler.scala:1012
[13:09:34,560] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[98] at map at MyLinearRegressionImpl.scala:22)
[13:09:34,560] INFO  {TaskSchedulerImpl} Adding task set 82.0 with 1 tasks
[13:09:34,561] INFO  {TaskSetManager} Starting task 0.0 in stage 82.0 (TID 82, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:34,561] INFO  {Executor} Running task 0.0 in stage 82.0 (TID 82)
[13:09:34,566] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:34,647] INFO  {BlockManagerInfo} Removed broadcast_85_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:34,648] INFO  {BlockManagerInfo} Removed broadcast_83_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:34,649] INFO  {BlockManagerInfo} Removed broadcast_84_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:34,649] INFO  {BlockManagerInfo} Removed broadcast_86_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:34,708] INFO  {Executor} Finished task 0.0 in stage 82.0 (TID 82). 1758 bytes result sent to driver
[13:09:34,708] INFO  {TaskSetManager} Finished task 0.0 in stage 82.0 (TID 82) in 147 ms on localhost (1/1)
[13:09:34,708] INFO  {TaskSchedulerImpl} Removed TaskSet 82.0, whose tasks have all completed, from pool 
[13:09:34,709] INFO  {DAGScheduler} ResultStage 82 (sum at MyLinearRegressionImpl.scala:24) finished in 0.148 s
[13:09:34,709] INFO  {DAGScheduler} Job 80 finished: sum at MyLinearRegressionImpl.scala:24, took 0.153593 s
[13:09:34,710] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:34,711] INFO  {DAGScheduler} Got job 81 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:34,711] INFO  {DAGScheduler} Final stage: ResultStage 83 (count at MyLinearRegressionImpl.scala:26)
[13:09:34,711] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:34,711] INFO  {DAGScheduler} Missing parents: List()
[13:09:34,711] INFO  {DAGScheduler} Submitting ResultStage 83 (MapPartitionsRDD[97] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:34,713] INFO  {MemoryStore} Block broadcast_88 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:34,714] INFO  {MemoryStore} Block broadcast_88_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:34,714] INFO  {BlockManagerInfo} Added broadcast_88_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:34,715] INFO  {SparkContext} Created broadcast 88 from broadcast at DAGScheduler.scala:1012
[13:09:34,715] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[97] at map at MyLinearRegressionImpl.scala:36)
[13:09:34,715] INFO  {TaskSchedulerImpl} Adding task set 83.0 with 1 tasks
[13:09:34,715] INFO  {TaskSetManager} Starting task 0.0 in stage 83.0 (TID 83, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:34,716] INFO  {Executor} Running task 0.0 in stage 83.0 (TID 83)
[13:09:34,719] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:34,856] INFO  {Executor} Finished task 0.0 in stage 83.0 (TID 83). 1683 bytes result sent to driver
[13:09:34,857] INFO  {TaskSetManager} Finished task 0.0 in stage 83.0 (TID 83) in 142 ms on localhost (1/1)
[13:09:34,857] INFO  {TaskSchedulerImpl} Removed TaskSet 83.0, whose tasks have all completed, from pool 
[13:09:34,857] INFO  {DAGScheduler} ResultStage 83 (count at MyLinearRegressionImpl.scala:26) finished in 0.142 s
[13:09:34,858] INFO  {DAGScheduler} Job 81 finished: count at MyLinearRegressionImpl.scala:26, took 0.146974 s
[13:09:34,860] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:34,861] INFO  {DAGScheduler} Got job 82 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:34,861] INFO  {DAGScheduler} Final stage: ResultStage 84 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:34,861] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:34,861] INFO  {DAGScheduler} Missing parents: List()
[13:09:34,861] INFO  {DAGScheduler} Submitting ResultStage 84 (MapPartitionsRDD[99] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:34,863] INFO  {MemoryStore} Block broadcast_89 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:34,865] INFO  {MemoryStore} Block broadcast_89_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:34,865] INFO  {BlockManagerInfo} Added broadcast_89_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:34,865] INFO  {SparkContext} Created broadcast 89 from broadcast at DAGScheduler.scala:1012
[13:09:34,865] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[99] at map at MyLinearRegressionImpl.scala:54)
[13:09:34,866] INFO  {TaskSchedulerImpl} Adding task set 84.0 with 1 tasks
[13:09:34,866] INFO  {TaskSetManager} Starting task 0.0 in stage 84.0 (TID 84, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:34,866] INFO  {Executor} Running task 0.0 in stage 84.0 (TID 84)
[13:09:34,870] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:35,014] INFO  {Executor} Finished task 0.0 in stage 84.0 (TID 84). 2499 bytes result sent to driver
[13:09:35,015] INFO  {TaskSetManager} Finished task 0.0 in stage 84.0 (TID 84) in 149 ms on localhost (1/1)
[13:09:35,015] INFO  {TaskSchedulerImpl} Removed TaskSet 84.0, whose tasks have all completed, from pool 
[13:09:35,015] INFO  {DAGScheduler} ResultStage 84 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.149 s
[13:09:35,015] INFO  {DAGScheduler} Job 82 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.155467 s
[13:09:35,021] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:35,021] INFO  {DAGScheduler} Got job 83 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:35,021] INFO  {DAGScheduler} Final stage: ResultStage 85 (sum at MyLinearRegressionImpl.scala:24)
[13:09:35,021] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:35,021] INFO  {DAGScheduler} Missing parents: List()
[13:09:35,022] INFO  {DAGScheduler} Submitting ResultStage 85 (MapPartitionsRDD[101] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:35,023] INFO  {MemoryStore} Block broadcast_90 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:35,025] INFO  {MemoryStore} Block broadcast_90_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.4 MB)
[13:09:35,025] INFO  {BlockManagerInfo} Added broadcast_90_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:35,025] INFO  {SparkContext} Created broadcast 90 from broadcast at DAGScheduler.scala:1012
[13:09:35,025] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[101] at map at MyLinearRegressionImpl.scala:22)
[13:09:35,026] INFO  {TaskSchedulerImpl} Adding task set 85.0 with 1 tasks
[13:09:35,027] INFO  {TaskSetManager} Starting task 0.0 in stage 85.0 (TID 85, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:35,027] INFO  {Executor} Running task 0.0 in stage 85.0 (TID 85)
[13:09:35,030] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:35,168] INFO  {Executor} Finished task 0.0 in stage 85.0 (TID 85). 1685 bytes result sent to driver
[13:09:35,169] INFO  {TaskSetManager} Finished task 0.0 in stage 85.0 (TID 85) in 142 ms on localhost (1/1)
[13:09:35,169] INFO  {TaskSchedulerImpl} Removed TaskSet 85.0, whose tasks have all completed, from pool 
[13:09:35,169] INFO  {DAGScheduler} ResultStage 85 (sum at MyLinearRegressionImpl.scala:24) finished in 0.143 s
[13:09:35,169] INFO  {DAGScheduler} Job 83 finished: sum at MyLinearRegressionImpl.scala:24, took 0.148220 s
[13:09:35,171] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:35,172] INFO  {DAGScheduler} Got job 84 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:35,172] INFO  {DAGScheduler} Final stage: ResultStage 86 (count at MyLinearRegressionImpl.scala:26)
[13:09:35,172] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:35,172] INFO  {DAGScheduler} Missing parents: List()
[13:09:35,172] INFO  {DAGScheduler} Submitting ResultStage 86 (MapPartitionsRDD[100] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:35,173] INFO  {MemoryStore} Block broadcast_91 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:35,175] INFO  {MemoryStore} Block broadcast_91_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:35,175] INFO  {BlockManagerInfo} Added broadcast_91_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:35,176] INFO  {SparkContext} Created broadcast 91 from broadcast at DAGScheduler.scala:1012
[13:09:35,176] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[100] at map at MyLinearRegressionImpl.scala:36)
[13:09:35,176] INFO  {TaskSchedulerImpl} Adding task set 86.0 with 1 tasks
[13:09:35,177] INFO  {TaskSetManager} Starting task 0.0 in stage 86.0 (TID 86, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:35,177] INFO  {Executor} Running task 0.0 in stage 86.0 (TID 86)
[13:09:35,182] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:35,300] INFO  {BlockManagerInfo} Removed broadcast_87_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:35,302] INFO  {BlockManagerInfo} Removed broadcast_88_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:35,303] INFO  {BlockManagerInfo} Removed broadcast_89_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:35,305] INFO  {BlockManagerInfo} Removed broadcast_90_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:35,327] INFO  {Executor} Finished task 0.0 in stage 86.0 (TID 86). 1756 bytes result sent to driver
[13:09:35,327] INFO  {TaskSetManager} Finished task 0.0 in stage 86.0 (TID 86) in 151 ms on localhost (1/1)
[13:09:35,327] INFO  {TaskSchedulerImpl} Removed TaskSet 86.0, whose tasks have all completed, from pool 
[13:09:35,328] INFO  {DAGScheduler} ResultStage 86 (count at MyLinearRegressionImpl.scala:26) finished in 0.152 s
[13:09:35,328] INFO  {DAGScheduler} Job 84 finished: count at MyLinearRegressionImpl.scala:26, took 0.156618 s
[13:09:35,331] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:35,332] INFO  {DAGScheduler} Got job 85 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:35,332] INFO  {DAGScheduler} Final stage: ResultStage 87 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:35,332] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:35,332] INFO  {DAGScheduler} Missing parents: List()
[13:09:35,332] INFO  {DAGScheduler} Submitting ResultStage 87 (MapPartitionsRDD[102] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:35,333] INFO  {MemoryStore} Block broadcast_92 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:35,335] INFO  {MemoryStore} Block broadcast_92_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:35,335] INFO  {BlockManagerInfo} Added broadcast_92_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:35,335] INFO  {SparkContext} Created broadcast 92 from broadcast at DAGScheduler.scala:1012
[13:09:35,336] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[102] at map at MyLinearRegressionImpl.scala:54)
[13:09:35,336] INFO  {TaskSchedulerImpl} Adding task set 87.0 with 1 tasks
[13:09:35,336] INFO  {TaskSetManager} Starting task 0.0 in stage 87.0 (TID 87, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:35,337] INFO  {Executor} Running task 0.0 in stage 87.0 (TID 87)
[13:09:35,340] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:35,474] INFO  {Executor} Finished task 0.0 in stage 87.0 (TID 87). 2586 bytes result sent to driver
[13:09:35,474] INFO  {TaskSetManager} Finished task 0.0 in stage 87.0 (TID 87) in 138 ms on localhost (1/1)
[13:09:35,475] INFO  {TaskSchedulerImpl} Removed TaskSet 87.0, whose tasks have all completed, from pool 
[13:09:35,475] INFO  {DAGScheduler} ResultStage 87 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.139 s
[13:09:35,475] INFO  {DAGScheduler} Job 85 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.143677 s
[13:09:35,479] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:35,480] INFO  {DAGScheduler} Got job 86 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:35,480] INFO  {DAGScheduler} Final stage: ResultStage 88 (sum at MyLinearRegressionImpl.scala:24)
[13:09:35,480] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:35,480] INFO  {DAGScheduler} Missing parents: List()
[13:09:35,480] INFO  {DAGScheduler} Submitting ResultStage 88 (MapPartitionsRDD[104] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:35,482] INFO  {MemoryStore} Block broadcast_93 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:35,483] INFO  {MemoryStore} Block broadcast_93_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:35,484] INFO  {BlockManagerInfo} Added broadcast_93_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:35,484] INFO  {SparkContext} Created broadcast 93 from broadcast at DAGScheduler.scala:1012
[13:09:35,484] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[104] at map at MyLinearRegressionImpl.scala:22)
[13:09:35,484] INFO  {TaskSchedulerImpl} Adding task set 88.0 with 1 tasks
[13:09:35,485] INFO  {TaskSetManager} Starting task 0.0 in stage 88.0 (TID 88, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:35,486] INFO  {Executor} Running task 0.0 in stage 88.0 (TID 88)
[13:09:35,490] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:35,624] INFO  {Executor} Finished task 0.0 in stage 88.0 (TID 88). 1685 bytes result sent to driver
[13:09:35,624] INFO  {TaskSetManager} Finished task 0.0 in stage 88.0 (TID 88) in 139 ms on localhost (1/1)
[13:09:35,624] INFO  {TaskSchedulerImpl} Removed TaskSet 88.0, whose tasks have all completed, from pool 
[13:09:35,624] INFO  {DAGScheduler} ResultStage 88 (sum at MyLinearRegressionImpl.scala:24) finished in 0.139 s
[13:09:35,625] INFO  {DAGScheduler} Job 86 finished: sum at MyLinearRegressionImpl.scala:24, took 0.145587 s
[13:09:35,627] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:35,628] INFO  {DAGScheduler} Got job 87 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:35,628] INFO  {DAGScheduler} Final stage: ResultStage 89 (count at MyLinearRegressionImpl.scala:26)
[13:09:35,628] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:35,628] INFO  {DAGScheduler} Missing parents: List()
[13:09:35,628] INFO  {DAGScheduler} Submitting ResultStage 89 (MapPartitionsRDD[103] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:35,629] INFO  {MemoryStore} Block broadcast_94 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:35,631] INFO  {MemoryStore} Block broadcast_94_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:35,631] INFO  {BlockManagerInfo} Added broadcast_94_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:35,631] INFO  {SparkContext} Created broadcast 94 from broadcast at DAGScheduler.scala:1012
[13:09:35,631] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[103] at map at MyLinearRegressionImpl.scala:36)
[13:09:35,631] INFO  {TaskSchedulerImpl} Adding task set 89.0 with 1 tasks
[13:09:35,632] INFO  {TaskSetManager} Starting task 0.0 in stage 89.0 (TID 89, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:35,632] INFO  {Executor} Running task 0.0 in stage 89.0 (TID 89)
[13:09:35,637] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:35,774] INFO  {Executor} Finished task 0.0 in stage 89.0 (TID 89). 1683 bytes result sent to driver
[13:09:35,774] INFO  {TaskSetManager} Finished task 0.0 in stage 89.0 (TID 89) in 142 ms on localhost (1/1)
[13:09:35,774] INFO  {TaskSchedulerImpl} Removed TaskSet 89.0, whose tasks have all completed, from pool 
[13:09:35,775] INFO  {DAGScheduler} ResultStage 89 (count at MyLinearRegressionImpl.scala:26) finished in 0.143 s
[13:09:35,775] INFO  {DAGScheduler} Job 87 finished: count at MyLinearRegressionImpl.scala:26, took 0.147577 s
[13:09:35,778] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:35,778] INFO  {DAGScheduler} Got job 88 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:35,778] INFO  {DAGScheduler} Final stage: ResultStage 90 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:35,778] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:35,778] INFO  {DAGScheduler} Missing parents: List()
[13:09:35,779] INFO  {DAGScheduler} Submitting ResultStage 90 (MapPartitionsRDD[105] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:35,780] INFO  {MemoryStore} Block broadcast_95 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:35,781] INFO  {MemoryStore} Block broadcast_95_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:35,781] INFO  {BlockManagerInfo} Added broadcast_95_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:35,781] INFO  {SparkContext} Created broadcast 95 from broadcast at DAGScheduler.scala:1012
[13:09:35,781] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[105] at map at MyLinearRegressionImpl.scala:54)
[13:09:35,781] INFO  {TaskSchedulerImpl} Adding task set 90.0 with 1 tasks
[13:09:35,782] INFO  {TaskSetManager} Starting task 0.0 in stage 90.0 (TID 90, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:35,782] INFO  {Executor} Running task 0.0 in stage 90.0 (TID 90)
[13:09:35,787] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:35,928] INFO  {Executor} Finished task 0.0 in stage 90.0 (TID 90). 2499 bytes result sent to driver
[13:09:35,929] INFO  {TaskSetManager} Finished task 0.0 in stage 90.0 (TID 90) in 147 ms on localhost (1/1)
[13:09:35,929] INFO  {TaskSchedulerImpl} Removed TaskSet 90.0, whose tasks have all completed, from pool 
[13:09:35,929] INFO  {DAGScheduler} ResultStage 90 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.147 s
[13:09:35,930] INFO  {DAGScheduler} Job 88 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.151587 s
[13:09:35,934] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:35,935] INFO  {DAGScheduler} Got job 89 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:35,935] INFO  {DAGScheduler} Final stage: ResultStage 91 (sum at MyLinearRegressionImpl.scala:24)
[13:09:35,935] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:35,935] INFO  {DAGScheduler} Missing parents: List()
[13:09:35,935] INFO  {DAGScheduler} Submitting ResultStage 91 (MapPartitionsRDD[107] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:35,937] INFO  {MemoryStore} Block broadcast_96 stored as values in memory (estimated size 45.5 KB, free 1128.3 MB)
[13:09:35,938] INFO  {MemoryStore} Block broadcast_96_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:35,938] INFO  {BlockManagerInfo} Added broadcast_96_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:35,939] INFO  {SparkContext} Created broadcast 96 from broadcast at DAGScheduler.scala:1012
[13:09:35,939] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[107] at map at MyLinearRegressionImpl.scala:22)
[13:09:35,939] INFO  {TaskSchedulerImpl} Adding task set 91.0 with 1 tasks
[13:09:35,940] INFO  {TaskSetManager} Starting task 0.0 in stage 91.0 (TID 91, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:35,940] INFO  {Executor} Running task 0.0 in stage 91.0 (TID 91)
[13:09:35,945] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:35,972] INFO  {BlockManagerInfo} Removed broadcast_91_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:35,972] INFO  {BlockManagerInfo} Removed broadcast_92_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:35,973] INFO  {BlockManagerInfo} Removed broadcast_93_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:35,973] INFO  {BlockManagerInfo} Removed broadcast_94_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:35,974] INFO  {BlockManagerInfo} Removed broadcast_95_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:36,088] INFO  {Executor} Finished task 0.0 in stage 91.0 (TID 91). 1758 bytes result sent to driver
[13:09:36,088] INFO  {TaskSetManager} Finished task 0.0 in stage 91.0 (TID 91) in 149 ms on localhost (1/1)
[13:09:36,089] INFO  {TaskSchedulerImpl} Removed TaskSet 91.0, whose tasks have all completed, from pool 
[13:09:36,089] INFO  {DAGScheduler} ResultStage 91 (sum at MyLinearRegressionImpl.scala:24) finished in 0.150 s
[13:09:36,089] INFO  {DAGScheduler} Job 89 finished: sum at MyLinearRegressionImpl.scala:24, took 0.154679 s
[13:09:36,091] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:36,092] INFO  {DAGScheduler} Got job 90 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:36,092] INFO  {DAGScheduler} Final stage: ResultStage 92 (count at MyLinearRegressionImpl.scala:26)
[13:09:36,092] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:36,092] INFO  {DAGScheduler} Missing parents: List()
[13:09:36,092] INFO  {DAGScheduler} Submitting ResultStage 92 (MapPartitionsRDD[106] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:36,093] INFO  {MemoryStore} Block broadcast_97 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:36,095] INFO  {MemoryStore} Block broadcast_97_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:36,095] INFO  {BlockManagerInfo} Added broadcast_97_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:36,095] INFO  {SparkContext} Created broadcast 97 from broadcast at DAGScheduler.scala:1012
[13:09:36,096] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[106] at map at MyLinearRegressionImpl.scala:36)
[13:09:36,096] INFO  {TaskSchedulerImpl} Adding task set 92.0 with 1 tasks
[13:09:36,097] INFO  {TaskSetManager} Starting task 0.0 in stage 92.0 (TID 92, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:36,097] INFO  {Executor} Running task 0.0 in stage 92.0 (TID 92)
[13:09:36,100] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:36,239] INFO  {Executor} Finished task 0.0 in stage 92.0 (TID 92). 1770 bytes result sent to driver
[13:09:36,239] INFO  {TaskSetManager} Finished task 0.0 in stage 92.0 (TID 92) in 143 ms on localhost (1/1)
[13:09:36,239] INFO  {TaskSchedulerImpl} Removed TaskSet 92.0, whose tasks have all completed, from pool 
[13:09:36,239] INFO  {DAGScheduler} ResultStage 92 (count at MyLinearRegressionImpl.scala:26) finished in 0.143 s
[13:09:36,240] INFO  {DAGScheduler} Job 90 finished: count at MyLinearRegressionImpl.scala:26, took 0.148540 s
[13:09:36,242] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:36,242] INFO  {DAGScheduler} Got job 91 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:36,242] INFO  {DAGScheduler} Final stage: ResultStage 93 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:36,242] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:36,242] INFO  {DAGScheduler} Missing parents: List()
[13:09:36,243] INFO  {DAGScheduler} Submitting ResultStage 93 (MapPartitionsRDD[108] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:36,244] INFO  {MemoryStore} Block broadcast_98 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:36,246] INFO  {MemoryStore} Block broadcast_98_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:36,246] INFO  {BlockManagerInfo} Added broadcast_98_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:36,246] INFO  {SparkContext} Created broadcast 98 from broadcast at DAGScheduler.scala:1012
[13:09:36,246] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[108] at map at MyLinearRegressionImpl.scala:54)
[13:09:36,247] INFO  {TaskSchedulerImpl} Adding task set 93.0 with 1 tasks
[13:09:36,247] INFO  {TaskSetManager} Starting task 0.0 in stage 93.0 (TID 93, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:36,247] INFO  {Executor} Running task 0.0 in stage 93.0 (TID 93)
[13:09:36,251] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:36,392] INFO  {Executor} Finished task 0.0 in stage 93.0 (TID 93). 2586 bytes result sent to driver
[13:09:36,393] INFO  {TaskSetManager} Finished task 0.0 in stage 93.0 (TID 93) in 146 ms on localhost (1/1)
[13:09:36,393] INFO  {TaskSchedulerImpl} Removed TaskSet 93.0, whose tasks have all completed, from pool 
[13:09:36,393] INFO  {DAGScheduler} ResultStage 93 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.146 s
[13:09:36,393] INFO  {DAGScheduler} Job 91 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.151376 s
[13:09:36,397] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:36,397] INFO  {DAGScheduler} Got job 92 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:36,397] INFO  {DAGScheduler} Final stage: ResultStage 94 (sum at MyLinearRegressionImpl.scala:24)
[13:09:36,397] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:36,397] INFO  {DAGScheduler} Missing parents: List()
[13:09:36,398] INFO  {DAGScheduler} Submitting ResultStage 94 (MapPartitionsRDD[110] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:36,399] INFO  {MemoryStore} Block broadcast_99 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:36,400] INFO  {MemoryStore} Block broadcast_99_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.4 MB)
[13:09:36,400] INFO  {BlockManagerInfo} Added broadcast_99_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:36,400] INFO  {SparkContext} Created broadcast 99 from broadcast at DAGScheduler.scala:1012
[13:09:36,400] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[110] at map at MyLinearRegressionImpl.scala:22)
[13:09:36,400] INFO  {TaskSchedulerImpl} Adding task set 94.0 with 1 tasks
[13:09:36,401] INFO  {TaskSetManager} Starting task 0.0 in stage 94.0 (TID 94, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:36,401] INFO  {Executor} Running task 0.0 in stage 94.0 (TID 94)
[13:09:36,404] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:36,544] INFO  {Executor} Finished task 0.0 in stage 94.0 (TID 94). 1685 bytes result sent to driver
[13:09:36,544] INFO  {TaskSetManager} Finished task 0.0 in stage 94.0 (TID 94) in 143 ms on localhost (1/1)
[13:09:36,545] INFO  {TaskSchedulerImpl} Removed TaskSet 94.0, whose tasks have all completed, from pool 
[13:09:36,545] INFO  {DAGScheduler} ResultStage 94 (sum at MyLinearRegressionImpl.scala:24) finished in 0.144 s
[13:09:36,545] INFO  {DAGScheduler} Job 92 finished: sum at MyLinearRegressionImpl.scala:24, took 0.148055 s
[13:09:36,547] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:36,548] INFO  {DAGScheduler} Got job 93 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:36,548] INFO  {DAGScheduler} Final stage: ResultStage 95 (count at MyLinearRegressionImpl.scala:26)
[13:09:36,548] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:36,548] INFO  {DAGScheduler} Missing parents: List()
[13:09:36,548] INFO  {DAGScheduler} Submitting ResultStage 95 (MapPartitionsRDD[109] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:36,549] INFO  {MemoryStore} Block broadcast_100 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:36,550] INFO  {MemoryStore} Block broadcast_100_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:36,550] INFO  {BlockManagerInfo} Added broadcast_100_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:36,551] INFO  {SparkContext} Created broadcast 100 from broadcast at DAGScheduler.scala:1012
[13:09:36,551] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[109] at map at MyLinearRegressionImpl.scala:36)
[13:09:36,551] INFO  {TaskSchedulerImpl} Adding task set 95.0 with 1 tasks
[13:09:36,552] INFO  {TaskSetManager} Starting task 0.0 in stage 95.0 (TID 95, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:36,552] INFO  {Executor} Running task 0.0 in stage 95.0 (TID 95)
[13:09:36,555] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:36,621] INFO  {BlockManagerInfo} Removed broadcast_97_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:36,622] INFO  {BlockManagerInfo} Removed broadcast_98_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:36,623] INFO  {BlockManagerInfo} Removed broadcast_96_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:36,623] INFO  {BlockManagerInfo} Removed broadcast_99_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:36,690] INFO  {Executor} Finished task 0.0 in stage 95.0 (TID 95). 1756 bytes result sent to driver
[13:09:36,691] INFO  {TaskSetManager} Finished task 0.0 in stage 95.0 (TID 95) in 140 ms on localhost (1/1)
[13:09:36,691] INFO  {TaskSchedulerImpl} Removed TaskSet 95.0, whose tasks have all completed, from pool 
[13:09:36,691] INFO  {DAGScheduler} ResultStage 95 (count at MyLinearRegressionImpl.scala:26) finished in 0.140 s
[13:09:36,692] INFO  {DAGScheduler} Job 93 finished: count at MyLinearRegressionImpl.scala:26, took 0.144330 s
[13:09:36,694] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:36,695] INFO  {DAGScheduler} Got job 94 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:36,695] INFO  {DAGScheduler} Final stage: ResultStage 96 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:36,695] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:36,695] INFO  {DAGScheduler} Missing parents: List()
[13:09:36,695] INFO  {DAGScheduler} Submitting ResultStage 96 (MapPartitionsRDD[111] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:36,696] INFO  {MemoryStore} Block broadcast_101 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:36,697] INFO  {MemoryStore} Block broadcast_101_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:36,697] INFO  {BlockManagerInfo} Added broadcast_101_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:36,698] INFO  {SparkContext} Created broadcast 101 from broadcast at DAGScheduler.scala:1012
[13:09:36,698] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[111] at map at MyLinearRegressionImpl.scala:54)
[13:09:36,698] INFO  {TaskSchedulerImpl} Adding task set 96.0 with 1 tasks
[13:09:36,699] INFO  {TaskSetManager} Starting task 0.0 in stage 96.0 (TID 96, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:36,699] INFO  {Executor} Running task 0.0 in stage 96.0 (TID 96)
[13:09:36,703] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:36,844] INFO  {Executor} Finished task 0.0 in stage 96.0 (TID 96). 2499 bytes result sent to driver
[13:09:36,845] INFO  {TaskSetManager} Finished task 0.0 in stage 96.0 (TID 96) in 147 ms on localhost (1/1)
[13:09:36,845] INFO  {TaskSchedulerImpl} Removed TaskSet 96.0, whose tasks have all completed, from pool 
[13:09:36,845] INFO  {DAGScheduler} ResultStage 96 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.147 s
[13:09:36,845] INFO  {DAGScheduler} Job 94 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.151192 s
[13:09:36,850] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:36,850] INFO  {DAGScheduler} Got job 95 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:36,850] INFO  {DAGScheduler} Final stage: ResultStage 97 (sum at MyLinearRegressionImpl.scala:24)
[13:09:36,850] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:36,851] INFO  {DAGScheduler} Missing parents: List()
[13:09:36,851] INFO  {DAGScheduler} Submitting ResultStage 97 (MapPartitionsRDD[113] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:36,852] INFO  {MemoryStore} Block broadcast_102 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:36,854] INFO  {MemoryStore} Block broadcast_102_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:36,854] INFO  {BlockManagerInfo} Added broadcast_102_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:36,854] INFO  {SparkContext} Created broadcast 102 from broadcast at DAGScheduler.scala:1012
[13:09:36,855] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[113] at map at MyLinearRegressionImpl.scala:22)
[13:09:36,855] INFO  {TaskSchedulerImpl} Adding task set 97.0 with 1 tasks
[13:09:36,856] INFO  {TaskSetManager} Starting task 0.0 in stage 97.0 (TID 97, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:36,856] INFO  {Executor} Running task 0.0 in stage 97.0 (TID 97)
[13:09:36,859] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:36,998] INFO  {Executor} Finished task 0.0 in stage 97.0 (TID 97). 1685 bytes result sent to driver
[13:09:36,999] INFO  {TaskSetManager} Finished task 0.0 in stage 97.0 (TID 97) in 144 ms on localhost (1/1)
[13:09:36,999] INFO  {TaskSchedulerImpl} Removed TaskSet 97.0, whose tasks have all completed, from pool 
[13:09:36,999] INFO  {DAGScheduler} ResultStage 97 (sum at MyLinearRegressionImpl.scala:24) finished in 0.144 s
[13:09:36,999] INFO  {DAGScheduler} Job 95 finished: sum at MyLinearRegressionImpl.scala:24, took 0.149127 s
[13:09:37,001] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:37,001] INFO  {DAGScheduler} Got job 96 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:37,001] INFO  {DAGScheduler} Final stage: ResultStage 98 (count at MyLinearRegressionImpl.scala:26)
[13:09:37,001] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:37,001] INFO  {DAGScheduler} Missing parents: List()
[13:09:37,001] INFO  {DAGScheduler} Submitting ResultStage 98 (MapPartitionsRDD[112] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:37,002] INFO  {MemoryStore} Block broadcast_103 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:37,003] INFO  {MemoryStore} Block broadcast_103_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:37,004] INFO  {BlockManagerInfo} Added broadcast_103_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:37,004] INFO  {SparkContext} Created broadcast 103 from broadcast at DAGScheduler.scala:1012
[13:09:37,004] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[112] at map at MyLinearRegressionImpl.scala:36)
[13:09:37,004] INFO  {TaskSchedulerImpl} Adding task set 98.0 with 1 tasks
[13:09:37,005] INFO  {TaskSetManager} Starting task 0.0 in stage 98.0 (TID 98, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:37,005] INFO  {Executor} Running task 0.0 in stage 98.0 (TID 98)
[13:09:37,008] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:37,140] INFO  {Executor} Finished task 0.0 in stage 98.0 (TID 98). 1683 bytes result sent to driver
[13:09:37,140] INFO  {TaskSetManager} Finished task 0.0 in stage 98.0 (TID 98) in 136 ms on localhost (1/1)
[13:09:37,140] INFO  {TaskSchedulerImpl} Removed TaskSet 98.0, whose tasks have all completed, from pool 
[13:09:37,141] INFO  {DAGScheduler} ResultStage 98 (count at MyLinearRegressionImpl.scala:26) finished in 0.137 s
[13:09:37,141] INFO  {DAGScheduler} Job 96 finished: count at MyLinearRegressionImpl.scala:26, took 0.140077 s
[13:09:37,144] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:37,144] INFO  {DAGScheduler} Got job 97 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:37,144] INFO  {DAGScheduler} Final stage: ResultStage 99 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:37,144] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:37,144] INFO  {DAGScheduler} Missing parents: List()
[13:09:37,145] INFO  {DAGScheduler} Submitting ResultStage 99 (MapPartitionsRDD[114] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:37,146] INFO  {MemoryStore} Block broadcast_104 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:37,147] INFO  {MemoryStore} Block broadcast_104_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:37,148] INFO  {BlockManagerInfo} Added broadcast_104_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:37,148] INFO  {SparkContext} Created broadcast 104 from broadcast at DAGScheduler.scala:1012
[13:09:37,148] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[114] at map at MyLinearRegressionImpl.scala:54)
[13:09:37,148] INFO  {TaskSchedulerImpl} Adding task set 99.0 with 1 tasks
[13:09:37,149] INFO  {TaskSetManager} Starting task 0.0 in stage 99.0 (TID 99, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:37,149] INFO  {Executor} Running task 0.0 in stage 99.0 (TID 99)
[13:09:37,153] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:37,277] INFO  {BlockManagerInfo} Removed broadcast_100_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:37,278] INFO  {BlockManagerInfo} Removed broadcast_101_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:37,279] INFO  {BlockManagerInfo} Removed broadcast_102_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:37,279] INFO  {BlockManagerInfo} Removed broadcast_103_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:37,299] INFO  {Executor} Finished task 0.0 in stage 99.0 (TID 99). 2572 bytes result sent to driver
[13:09:37,299] INFO  {TaskSetManager} Finished task 0.0 in stage 99.0 (TID 99) in 151 ms on localhost (1/1)
[13:09:37,299] INFO  {TaskSchedulerImpl} Removed TaskSet 99.0, whose tasks have all completed, from pool 
[13:09:37,299] INFO  {DAGScheduler} ResultStage 99 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.151 s
[13:09:37,300] INFO  {DAGScheduler} Job 97 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.155842 s
[13:09:37,305] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:37,305] INFO  {DAGScheduler} Got job 98 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:37,305] INFO  {DAGScheduler} Final stage: ResultStage 100 (sum at MyLinearRegressionImpl.scala:24)
[13:09:37,305] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:37,306] INFO  {DAGScheduler} Missing parents: List()
[13:09:37,306] INFO  {DAGScheduler} Submitting ResultStage 100 (MapPartitionsRDD[116] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:37,308] INFO  {MemoryStore} Block broadcast_105 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:37,309] INFO  {MemoryStore} Block broadcast_105_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:37,309] INFO  {BlockManagerInfo} Added broadcast_105_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:37,310] INFO  {SparkContext} Created broadcast 105 from broadcast at DAGScheduler.scala:1012
[13:09:37,310] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[116] at map at MyLinearRegressionImpl.scala:22)
[13:09:37,310] INFO  {TaskSchedulerImpl} Adding task set 100.0 with 1 tasks
[13:09:37,311] INFO  {TaskSetManager} Starting task 0.0 in stage 100.0 (TID 100, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:37,311] INFO  {Executor} Running task 0.0 in stage 100.0 (TID 100)
[13:09:37,315] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:37,447] INFO  {Executor} Finished task 0.0 in stage 100.0 (TID 100). 1685 bytes result sent to driver
[13:09:37,448] INFO  {TaskSetManager} Finished task 0.0 in stage 100.0 (TID 100) in 138 ms on localhost (1/1)
[13:09:37,448] INFO  {TaskSchedulerImpl} Removed TaskSet 100.0, whose tasks have all completed, from pool 
[13:09:37,448] INFO  {DAGScheduler} ResultStage 100 (sum at MyLinearRegressionImpl.scala:24) finished in 0.138 s
[13:09:37,449] INFO  {DAGScheduler} Job 98 finished: sum at MyLinearRegressionImpl.scala:24, took 0.143689 s
[13:09:37,451] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:37,451] INFO  {DAGScheduler} Got job 99 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:37,451] INFO  {DAGScheduler} Final stage: ResultStage 101 (count at MyLinearRegressionImpl.scala:26)
[13:09:37,451] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:37,451] INFO  {DAGScheduler} Missing parents: List()
[13:09:37,452] INFO  {DAGScheduler} Submitting ResultStage 101 (MapPartitionsRDD[115] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:37,453] INFO  {MemoryStore} Block broadcast_106 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:37,454] INFO  {MemoryStore} Block broadcast_106_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:37,455] INFO  {BlockManagerInfo} Added broadcast_106_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:37,455] INFO  {SparkContext} Created broadcast 106 from broadcast at DAGScheduler.scala:1012
[13:09:37,455] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[115] at map at MyLinearRegressionImpl.scala:36)
[13:09:37,455] INFO  {TaskSchedulerImpl} Adding task set 101.0 with 1 tasks
[13:09:37,456] INFO  {TaskSetManager} Starting task 0.0 in stage 101.0 (TID 101, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:37,456] INFO  {Executor} Running task 0.0 in stage 101.0 (TID 101)
[13:09:37,460] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:37,596] INFO  {Executor} Finished task 0.0 in stage 101.0 (TID 101). 1683 bytes result sent to driver
[13:09:37,597] INFO  {TaskSetManager} Finished task 0.0 in stage 101.0 (TID 101) in 141 ms on localhost (1/1)
[13:09:37,597] INFO  {TaskSchedulerImpl} Removed TaskSet 101.0, whose tasks have all completed, from pool 
[13:09:37,597] INFO  {DAGScheduler} ResultStage 101 (count at MyLinearRegressionImpl.scala:26) finished in 0.141 s
[13:09:37,597] INFO  {DAGScheduler} Job 99 finished: count at MyLinearRegressionImpl.scala:26, took 0.146511 s
[13:09:37,600] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:37,601] INFO  {DAGScheduler} Got job 100 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:37,601] INFO  {DAGScheduler} Final stage: ResultStage 102 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:37,601] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:37,601] INFO  {DAGScheduler} Missing parents: List()
[13:09:37,601] INFO  {DAGScheduler} Submitting ResultStage 102 (MapPartitionsRDD[117] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:37,603] INFO  {MemoryStore} Block broadcast_107 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:37,604] INFO  {MemoryStore} Block broadcast_107_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:37,605] INFO  {BlockManagerInfo} Added broadcast_107_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:37,605] INFO  {SparkContext} Created broadcast 107 from broadcast at DAGScheduler.scala:1012
[13:09:37,605] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[117] at map at MyLinearRegressionImpl.scala:54)
[13:09:37,605] INFO  {TaskSchedulerImpl} Adding task set 102.0 with 1 tasks
[13:09:37,606] INFO  {TaskSetManager} Starting task 0.0 in stage 102.0 (TID 102, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:37,606] INFO  {Executor} Running task 0.0 in stage 102.0 (TID 102)
[13:09:37,609] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:37,749] INFO  {Executor} Finished task 0.0 in stage 102.0 (TID 102). 2586 bytes result sent to driver
[13:09:37,749] INFO  {TaskSetManager} Finished task 0.0 in stage 102.0 (TID 102) in 143 ms on localhost (1/1)
[13:09:37,750] INFO  {TaskSchedulerImpl} Removed TaskSet 102.0, whose tasks have all completed, from pool 
[13:09:37,750] INFO  {DAGScheduler} ResultStage 102 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.145 s
[13:09:37,750] INFO  {DAGScheduler} Job 100 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.149787 s
[13:09:37,753] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:37,754] INFO  {DAGScheduler} Got job 101 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:37,754] INFO  {DAGScheduler} Final stage: ResultStage 103 (sum at MyLinearRegressionImpl.scala:24)
[13:09:37,754] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:37,754] INFO  {DAGScheduler} Missing parents: List()
[13:09:37,754] INFO  {DAGScheduler} Submitting ResultStage 103 (MapPartitionsRDD[119] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:37,756] INFO  {MemoryStore} Block broadcast_108 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:37,758] INFO  {MemoryStore} Block broadcast_108_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:37,758] INFO  {BlockManagerInfo} Added broadcast_108_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:37,758] INFO  {SparkContext} Created broadcast 108 from broadcast at DAGScheduler.scala:1012
[13:09:37,758] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[119] at map at MyLinearRegressionImpl.scala:22)
[13:09:37,758] INFO  {TaskSchedulerImpl} Adding task set 103.0 with 1 tasks
[13:09:37,759] INFO  {TaskSetManager} Starting task 0.0 in stage 103.0 (TID 103, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:37,759] INFO  {Executor} Running task 0.0 in stage 103.0 (TID 103)
[13:09:37,763] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:37,906] INFO  {Executor} Finished task 0.0 in stage 103.0 (TID 103). 1685 bytes result sent to driver
[13:09:37,907] INFO  {TaskSetManager} Finished task 0.0 in stage 103.0 (TID 103) in 148 ms on localhost (1/1)
[13:09:37,907] INFO  {TaskSchedulerImpl} Removed TaskSet 103.0, whose tasks have all completed, from pool 
[13:09:37,907] INFO  {DAGScheduler} ResultStage 103 (sum at MyLinearRegressionImpl.scala:24) finished in 0.148 s
[13:09:37,907] INFO  {DAGScheduler} Job 101 finished: sum at MyLinearRegressionImpl.scala:24, took 0.153347 s
[13:09:37,908] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:37,909] INFO  {DAGScheduler} Got job 102 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:37,910] INFO  {DAGScheduler} Final stage: ResultStage 104 (count at MyLinearRegressionImpl.scala:26)
[13:09:37,910] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:37,910] INFO  {DAGScheduler} Missing parents: List()
[13:09:37,910] INFO  {DAGScheduler} Submitting ResultStage 104 (MapPartitionsRDD[118] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:37,912] INFO  {MemoryStore} Block broadcast_109 stored as values in memory (estimated size 45.0 KB, free 1128.3 MB)
[13:09:37,915] INFO  {MemoryStore} Block broadcast_109_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:37,915] INFO  {BlockManagerInfo} Added broadcast_109_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:37,915] INFO  {SparkContext} Created broadcast 109 from broadcast at DAGScheduler.scala:1012
[13:09:37,915] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[118] at map at MyLinearRegressionImpl.scala:36)
[13:09:37,916] INFO  {TaskSchedulerImpl} Adding task set 104.0 with 1 tasks
[13:09:37,916] INFO  {TaskSetManager} Starting task 0.0 in stage 104.0 (TID 104, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:37,916] INFO  {Executor} Running task 0.0 in stage 104.0 (TID 104)
[13:09:37,921] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:37,969] INFO  {BlockManagerInfo} Removed broadcast_105_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:37,970] INFO  {BlockManagerInfo} Removed broadcast_106_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:37,971] INFO  {BlockManagerInfo} Removed broadcast_108_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:37,973] INFO  {BlockManagerInfo} Removed broadcast_104_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:37,974] INFO  {BlockManagerInfo} Removed broadcast_107_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:38,069] INFO  {Executor} Finished task 0.0 in stage 104.0 (TID 104). 1756 bytes result sent to driver
[13:09:38,070] INFO  {TaskSetManager} Finished task 0.0 in stage 104.0 (TID 104) in 154 ms on localhost (1/1)
[13:09:38,070] INFO  {TaskSchedulerImpl} Removed TaskSet 104.0, whose tasks have all completed, from pool 
[13:09:38,070] INFO  {DAGScheduler} ResultStage 104 (count at MyLinearRegressionImpl.scala:26) finished in 0.154 s
[13:09:38,070] INFO  {DAGScheduler} Job 102 finished: count at MyLinearRegressionImpl.scala:26, took 0.161709 s
[13:09:38,073] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:38,073] INFO  {DAGScheduler} Got job 103 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:38,073] INFO  {DAGScheduler} Final stage: ResultStage 105 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:38,073] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:38,074] INFO  {DAGScheduler} Missing parents: List()
[13:09:38,074] INFO  {DAGScheduler} Submitting ResultStage 105 (MapPartitionsRDD[120] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:38,075] INFO  {MemoryStore} Block broadcast_110 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:38,076] INFO  {MemoryStore} Block broadcast_110_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:38,076] INFO  {BlockManagerInfo} Added broadcast_110_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:38,077] INFO  {SparkContext} Created broadcast 110 from broadcast at DAGScheduler.scala:1012
[13:09:38,077] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[120] at map at MyLinearRegressionImpl.scala:54)
[13:09:38,077] INFO  {TaskSchedulerImpl} Adding task set 105.0 with 1 tasks
[13:09:38,078] INFO  {TaskSetManager} Starting task 0.0 in stage 105.0 (TID 105, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:38,078] INFO  {Executor} Running task 0.0 in stage 105.0 (TID 105)
[13:09:38,081] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:38,219] INFO  {Executor} Finished task 0.0 in stage 105.0 (TID 105). 2586 bytes result sent to driver
[13:09:38,219] INFO  {TaskSetManager} Finished task 0.0 in stage 105.0 (TID 105) in 142 ms on localhost (1/1)
[13:09:38,219] INFO  {TaskSchedulerImpl} Removed TaskSet 105.0, whose tasks have all completed, from pool 
[13:09:38,220] INFO  {DAGScheduler} ResultStage 105 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.143 s
[13:09:38,220] INFO  {DAGScheduler} Job 103 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.146808 s
[13:09:38,225] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:38,225] INFO  {DAGScheduler} Got job 104 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:38,225] INFO  {DAGScheduler} Final stage: ResultStage 106 (sum at MyLinearRegressionImpl.scala:24)
[13:09:38,226] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:38,226] INFO  {DAGScheduler} Missing parents: List()
[13:09:38,226] INFO  {DAGScheduler} Submitting ResultStage 106 (MapPartitionsRDD[122] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:38,227] INFO  {MemoryStore} Block broadcast_111 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:38,229] INFO  {MemoryStore} Block broadcast_111_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:38,229] INFO  {BlockManagerInfo} Added broadcast_111_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:38,230] INFO  {SparkContext} Created broadcast 111 from broadcast at DAGScheduler.scala:1012
[13:09:38,230] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[122] at map at MyLinearRegressionImpl.scala:22)
[13:09:38,230] INFO  {TaskSchedulerImpl} Adding task set 106.0 with 1 tasks
[13:09:38,231] INFO  {TaskSetManager} Starting task 0.0 in stage 106.0 (TID 106, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:38,231] INFO  {Executor} Running task 0.0 in stage 106.0 (TID 106)
[13:09:38,234] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:38,370] INFO  {Executor} Finished task 0.0 in stage 106.0 (TID 106). 1685 bytes result sent to driver
[13:09:38,370] INFO  {TaskSetManager} Finished task 0.0 in stage 106.0 (TID 106) in 140 ms on localhost (1/1)
[13:09:38,370] INFO  {TaskSchedulerImpl} Removed TaskSet 106.0, whose tasks have all completed, from pool 
[13:09:38,370] INFO  {DAGScheduler} ResultStage 106 (sum at MyLinearRegressionImpl.scala:24) finished in 0.140 s
[13:09:38,370] INFO  {DAGScheduler} Job 104 finished: sum at MyLinearRegressionImpl.scala:24, took 0.145509 s
[13:09:38,372] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:38,373] INFO  {DAGScheduler} Got job 105 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:38,373] INFO  {DAGScheduler} Final stage: ResultStage 107 (count at MyLinearRegressionImpl.scala:26)
[13:09:38,373] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:38,373] INFO  {DAGScheduler} Missing parents: List()
[13:09:38,373] INFO  {DAGScheduler} Submitting ResultStage 107 (MapPartitionsRDD[121] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:38,374] INFO  {MemoryStore} Block broadcast_112 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:38,376] INFO  {MemoryStore} Block broadcast_112_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:38,376] INFO  {BlockManagerInfo} Added broadcast_112_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:38,376] INFO  {SparkContext} Created broadcast 112 from broadcast at DAGScheduler.scala:1012
[13:09:38,376] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[121] at map at MyLinearRegressionImpl.scala:36)
[13:09:38,376] INFO  {TaskSchedulerImpl} Adding task set 107.0 with 1 tasks
[13:09:38,377] INFO  {TaskSetManager} Starting task 0.0 in stage 107.0 (TID 107, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:38,377] INFO  {Executor} Running task 0.0 in stage 107.0 (TID 107)
[13:09:38,381] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:38,514] INFO  {Executor} Finished task 0.0 in stage 107.0 (TID 107). 1683 bytes result sent to driver
[13:09:38,514] INFO  {TaskSetManager} Finished task 0.0 in stage 107.0 (TID 107) in 137 ms on localhost (1/1)
[13:09:38,514] INFO  {TaskSchedulerImpl} Removed TaskSet 107.0, whose tasks have all completed, from pool 
[13:09:38,514] INFO  {DAGScheduler} ResultStage 107 (count at MyLinearRegressionImpl.scala:26) finished in 0.138 s
[13:09:38,514] INFO  {DAGScheduler} Job 105 finished: count at MyLinearRegressionImpl.scala:26, took 0.141830 s
[13:09:38,516] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:38,517] INFO  {DAGScheduler} Got job 106 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:38,517] INFO  {DAGScheduler} Final stage: ResultStage 108 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:38,517] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:38,517] INFO  {DAGScheduler} Missing parents: List()
[13:09:38,517] INFO  {DAGScheduler} Submitting ResultStage 108 (MapPartitionsRDD[123] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:38,518] INFO  {MemoryStore} Block broadcast_113 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:38,519] INFO  {MemoryStore} Block broadcast_113_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:38,519] INFO  {BlockManagerInfo} Added broadcast_113_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:38,520] INFO  {SparkContext} Created broadcast 113 from broadcast at DAGScheduler.scala:1012
[13:09:38,520] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[123] at map at MyLinearRegressionImpl.scala:54)
[13:09:38,520] INFO  {TaskSchedulerImpl} Adding task set 108.0 with 1 tasks
[13:09:38,521] INFO  {TaskSetManager} Starting task 0.0 in stage 108.0 (TID 108, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:38,522] INFO  {Executor} Running task 0.0 in stage 108.0 (TID 108)
[13:09:38,526] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:38,625] INFO  {BlockManagerInfo} Removed broadcast_109_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:38,625] INFO  {BlockManagerInfo} Removed broadcast_110_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:38,626] INFO  {BlockManagerInfo} Removed broadcast_111_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:38,627] INFO  {BlockManagerInfo} Removed broadcast_112_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:38,667] INFO  {Executor} Finished task 0.0 in stage 108.0 (TID 108). 2572 bytes result sent to driver
[13:09:38,667] INFO  {TaskSetManager} Finished task 0.0 in stage 108.0 (TID 108) in 146 ms on localhost (1/1)
[13:09:38,667] INFO  {TaskSchedulerImpl} Removed TaskSet 108.0, whose tasks have all completed, from pool 
[13:09:38,668] INFO  {DAGScheduler} ResultStage 108 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.148 s
[13:09:38,668] INFO  {DAGScheduler} Job 106 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.151235 s
[13:09:38,673] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:38,673] INFO  {DAGScheduler} Got job 107 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:38,673] INFO  {DAGScheduler} Final stage: ResultStage 109 (sum at MyLinearRegressionImpl.scala:24)
[13:09:38,673] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:38,673] INFO  {DAGScheduler} Missing parents: List()
[13:09:38,674] INFO  {DAGScheduler} Submitting ResultStage 109 (MapPartitionsRDD[125] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:38,675] INFO  {MemoryStore} Block broadcast_114 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:38,676] INFO  {MemoryStore} Block broadcast_114_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:38,676] INFO  {BlockManagerInfo} Added broadcast_114_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:38,677] INFO  {SparkContext} Created broadcast 114 from broadcast at DAGScheduler.scala:1012
[13:09:38,677] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[125] at map at MyLinearRegressionImpl.scala:22)
[13:09:38,677] INFO  {TaskSchedulerImpl} Adding task set 109.0 with 1 tasks
[13:09:38,678] INFO  {TaskSetManager} Starting task 0.0 in stage 109.0 (TID 109, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:38,678] INFO  {Executor} Running task 0.0 in stage 109.0 (TID 109)
[13:09:38,683] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:38,824] INFO  {Executor} Finished task 0.0 in stage 109.0 (TID 109). 1685 bytes result sent to driver
[13:09:38,824] INFO  {TaskSetManager} Finished task 0.0 in stage 109.0 (TID 109) in 147 ms on localhost (1/1)
[13:09:38,824] INFO  {TaskSchedulerImpl} Removed TaskSet 109.0, whose tasks have all completed, from pool 
[13:09:38,825] INFO  {DAGScheduler} ResultStage 109 (sum at MyLinearRegressionImpl.scala:24) finished in 0.148 s
[13:09:38,825] INFO  {DAGScheduler} Job 107 finished: sum at MyLinearRegressionImpl.scala:24, took 0.151997 s
[13:09:38,827] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:38,827] INFO  {DAGScheduler} Got job 108 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:38,827] INFO  {DAGScheduler} Final stage: ResultStage 110 (count at MyLinearRegressionImpl.scala:26)
[13:09:38,828] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:38,828] INFO  {DAGScheduler} Missing parents: List()
[13:09:38,828] INFO  {DAGScheduler} Submitting ResultStage 110 (MapPartitionsRDD[124] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:38,829] INFO  {MemoryStore} Block broadcast_115 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:38,831] INFO  {MemoryStore} Block broadcast_115_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:38,831] INFO  {BlockManagerInfo} Added broadcast_115_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:38,832] INFO  {SparkContext} Created broadcast 115 from broadcast at DAGScheduler.scala:1012
[13:09:38,832] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[124] at map at MyLinearRegressionImpl.scala:36)
[13:09:38,832] INFO  {TaskSchedulerImpl} Adding task set 110.0 with 1 tasks
[13:09:38,833] INFO  {TaskSetManager} Starting task 0.0 in stage 110.0 (TID 110, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:38,833] INFO  {Executor} Running task 0.0 in stage 110.0 (TID 110)
[13:09:38,836] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:38,973] INFO  {Executor} Finished task 0.0 in stage 110.0 (TID 110). 1683 bytes result sent to driver
[13:09:38,973] INFO  {TaskSetManager} Finished task 0.0 in stage 110.0 (TID 110) in 141 ms on localhost (1/1)
[13:09:38,973] INFO  {TaskSchedulerImpl} Removed TaskSet 110.0, whose tasks have all completed, from pool 
[13:09:38,973] INFO  {DAGScheduler} ResultStage 110 (count at MyLinearRegressionImpl.scala:26) finished in 0.141 s
[13:09:38,974] INFO  {DAGScheduler} Job 108 finished: count at MyLinearRegressionImpl.scala:26, took 0.146699 s
[13:09:38,976] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:38,976] INFO  {DAGScheduler} Got job 109 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:38,976] INFO  {DAGScheduler} Final stage: ResultStage 111 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:38,976] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:38,976] INFO  {DAGScheduler} Missing parents: List()
[13:09:38,977] INFO  {DAGScheduler} Submitting ResultStage 111 (MapPartitionsRDD[126] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:38,978] INFO  {MemoryStore} Block broadcast_116 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:38,980] INFO  {MemoryStore} Block broadcast_116_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:38,980] INFO  {BlockManagerInfo} Added broadcast_116_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:38,980] INFO  {SparkContext} Created broadcast 116 from broadcast at DAGScheduler.scala:1012
[13:09:38,980] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[126] at map at MyLinearRegressionImpl.scala:54)
[13:09:38,980] INFO  {TaskSchedulerImpl} Adding task set 111.0 with 1 tasks
[13:09:38,981] INFO  {TaskSetManager} Starting task 0.0 in stage 111.0 (TID 111, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:38,981] INFO  {Executor} Running task 0.0 in stage 111.0 (TID 111)
[13:09:38,986] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:39,123] INFO  {Executor} Finished task 0.0 in stage 111.0 (TID 111). 2499 bytes result sent to driver
[13:09:39,124] INFO  {TaskSetManager} Finished task 0.0 in stage 111.0 (TID 111) in 143 ms on localhost (1/1)
[13:09:39,124] INFO  {TaskSchedulerImpl} Removed TaskSet 111.0, whose tasks have all completed, from pool 
[13:09:39,124] INFO  {DAGScheduler} ResultStage 111 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.143 s
[13:09:39,124] INFO  {DAGScheduler} Job 109 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.148555 s
[13:09:39,128] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:39,128] INFO  {DAGScheduler} Got job 110 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:39,128] INFO  {DAGScheduler} Final stage: ResultStage 112 (sum at MyLinearRegressionImpl.scala:24)
[13:09:39,128] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:39,128] INFO  {DAGScheduler} Missing parents: List()
[13:09:39,129] INFO  {DAGScheduler} Submitting ResultStage 112 (MapPartitionsRDD[128] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:39,130] INFO  {MemoryStore} Block broadcast_117 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:39,132] INFO  {MemoryStore} Block broadcast_117_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:39,132] INFO  {BlockManagerInfo} Added broadcast_117_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:39,133] INFO  {SparkContext} Created broadcast 117 from broadcast at DAGScheduler.scala:1012
[13:09:39,133] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[128] at map at MyLinearRegressionImpl.scala:22)
[13:09:39,133] INFO  {TaskSchedulerImpl} Adding task set 112.0 with 1 tasks
[13:09:39,135] INFO  {TaskSetManager} Starting task 0.0 in stage 112.0 (TID 112, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:39,135] INFO  {Executor} Running task 0.0 in stage 112.0 (TID 112)
[13:09:39,138] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:39,269] INFO  {Executor} Finished task 0.0 in stage 112.0 (TID 112). 1685 bytes result sent to driver
[13:09:39,270] INFO  {TaskSetManager} Finished task 0.0 in stage 112.0 (TID 112) in 136 ms on localhost (1/1)
[13:09:39,270] INFO  {TaskSchedulerImpl} Removed TaskSet 112.0, whose tasks have all completed, from pool 
[13:09:39,270] INFO  {DAGScheduler} ResultStage 112 (sum at MyLinearRegressionImpl.scala:24) finished in 0.136 s
[13:09:39,270] INFO  {DAGScheduler} Job 110 finished: sum at MyLinearRegressionImpl.scala:24, took 0.142601 s
[13:09:39,272] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:39,273] INFO  {DAGScheduler} Got job 111 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:39,273] INFO  {DAGScheduler} Final stage: ResultStage 113 (count at MyLinearRegressionImpl.scala:26)
[13:09:39,273] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:39,273] INFO  {DAGScheduler} Missing parents: List()
[13:09:39,273] INFO  {DAGScheduler} Submitting ResultStage 113 (MapPartitionsRDD[127] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:39,274] INFO  {MemoryStore} Block broadcast_118 stored as values in memory (estimated size 45.0 KB, free 1128.3 MB)
[13:09:39,275] INFO  {MemoryStore} Block broadcast_118_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:39,276] INFO  {BlockManagerInfo} Added broadcast_118_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:39,276] INFO  {SparkContext} Created broadcast 118 from broadcast at DAGScheduler.scala:1012
[13:09:39,276] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[127] at map at MyLinearRegressionImpl.scala:36)
[13:09:39,276] INFO  {TaskSchedulerImpl} Adding task set 113.0 with 1 tasks
[13:09:39,277] INFO  {TaskSetManager} Starting task 0.0 in stage 113.0 (TID 113, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:39,277] INFO  {Executor} Running task 0.0 in stage 113.0 (TID 113)
[13:09:39,282] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:39,313] INFO  {BlockManagerInfo} Removed broadcast_116_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:39,314] INFO  {BlockManagerInfo} Removed broadcast_113_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:39,315] INFO  {BlockManagerInfo} Removed broadcast_114_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:39,316] INFO  {BlockManagerInfo} Removed broadcast_115_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:39,317] INFO  {BlockManagerInfo} Removed broadcast_117_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:39,422] INFO  {Executor} Finished task 0.0 in stage 113.0 (TID 113). 1756 bytes result sent to driver
[13:09:39,422] INFO  {TaskSetManager} Finished task 0.0 in stage 113.0 (TID 113) in 146 ms on localhost (1/1)
[13:09:39,423] INFO  {TaskSchedulerImpl} Removed TaskSet 113.0, whose tasks have all completed, from pool 
[13:09:39,423] INFO  {DAGScheduler} ResultStage 113 (count at MyLinearRegressionImpl.scala:26) finished in 0.147 s
[13:09:39,423] INFO  {DAGScheduler} Job 111 finished: count at MyLinearRegressionImpl.scala:26, took 0.150415 s
[13:09:39,426] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:39,426] INFO  {DAGScheduler} Got job 112 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:39,426] INFO  {DAGScheduler} Final stage: ResultStage 114 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:39,426] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:39,427] INFO  {DAGScheduler} Missing parents: List()
[13:09:39,427] INFO  {DAGScheduler} Submitting ResultStage 114 (MapPartitionsRDD[129] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:39,428] INFO  {MemoryStore} Block broadcast_119 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:39,430] INFO  {MemoryStore} Block broadcast_119_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:39,430] INFO  {BlockManagerInfo} Added broadcast_119_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:39,430] INFO  {SparkContext} Created broadcast 119 from broadcast at DAGScheduler.scala:1012
[13:09:39,431] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[129] at map at MyLinearRegressionImpl.scala:54)
[13:09:39,431] INFO  {TaskSchedulerImpl} Adding task set 114.0 with 1 tasks
[13:09:39,431] INFO  {TaskSetManager} Starting task 0.0 in stage 114.0 (TID 114, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:39,432] INFO  {Executor} Running task 0.0 in stage 114.0 (TID 114)
[13:09:39,437] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:39,587] INFO  {Executor} Finished task 0.0 in stage 114.0 (TID 114). 2499 bytes result sent to driver
[13:09:39,588] INFO  {TaskSetManager} Finished task 0.0 in stage 114.0 (TID 114) in 157 ms on localhost (1/1)
[13:09:39,588] INFO  {TaskSchedulerImpl} Removed TaskSet 114.0, whose tasks have all completed, from pool 
[13:09:39,588] INFO  {DAGScheduler} ResultStage 114 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.157 s
[13:09:39,588] INFO  {DAGScheduler} Job 112 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.162129 s
[13:09:39,593] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:39,594] INFO  {DAGScheduler} Got job 113 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:39,594] INFO  {DAGScheduler} Final stage: ResultStage 115 (sum at MyLinearRegressionImpl.scala:24)
[13:09:39,594] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:39,594] INFO  {DAGScheduler} Missing parents: List()
[13:09:39,594] INFO  {DAGScheduler} Submitting ResultStage 115 (MapPartitionsRDD[131] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:39,596] INFO  {MemoryStore} Block broadcast_120 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:39,597] INFO  {MemoryStore} Block broadcast_120_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:39,597] INFO  {BlockManagerInfo} Added broadcast_120_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:39,598] INFO  {SparkContext} Created broadcast 120 from broadcast at DAGScheduler.scala:1012
[13:09:39,598] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[131] at map at MyLinearRegressionImpl.scala:22)
[13:09:39,598] INFO  {TaskSchedulerImpl} Adding task set 115.0 with 1 tasks
[13:09:39,599] INFO  {TaskSetManager} Starting task 0.0 in stage 115.0 (TID 115, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:39,599] INFO  {Executor} Running task 0.0 in stage 115.0 (TID 115)
[13:09:39,603] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:39,740] INFO  {Executor} Finished task 0.0 in stage 115.0 (TID 115). 1685 bytes result sent to driver
[13:09:39,740] INFO  {TaskSetManager} Finished task 0.0 in stage 115.0 (TID 115) in 142 ms on localhost (1/1)
[13:09:39,740] INFO  {TaskSchedulerImpl} Removed TaskSet 115.0, whose tasks have all completed, from pool 
[13:09:39,740] INFO  {DAGScheduler} ResultStage 115 (sum at MyLinearRegressionImpl.scala:24) finished in 0.142 s
[13:09:39,740] INFO  {DAGScheduler} Job 113 finished: sum at MyLinearRegressionImpl.scala:24, took 0.147443 s
[13:09:39,742] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:39,742] INFO  {DAGScheduler} Got job 114 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:39,742] INFO  {DAGScheduler} Final stage: ResultStage 116 (count at MyLinearRegressionImpl.scala:26)
[13:09:39,742] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:39,743] INFO  {DAGScheduler} Missing parents: List()
[13:09:39,743] INFO  {DAGScheduler} Submitting ResultStage 116 (MapPartitionsRDD[130] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:39,744] INFO  {MemoryStore} Block broadcast_121 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:39,746] INFO  {MemoryStore} Block broadcast_121_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:39,747] INFO  {BlockManagerInfo} Added broadcast_121_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:39,748] INFO  {SparkContext} Created broadcast 121 from broadcast at DAGScheduler.scala:1012
[13:09:39,748] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[130] at map at MyLinearRegressionImpl.scala:36)
[13:09:39,748] INFO  {TaskSchedulerImpl} Adding task set 116.0 with 1 tasks
[13:09:39,749] INFO  {TaskSetManager} Starting task 0.0 in stage 116.0 (TID 116, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:39,749] INFO  {Executor} Running task 0.0 in stage 116.0 (TID 116)
[13:09:39,752] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:39,886] INFO  {Executor} Finished task 0.0 in stage 116.0 (TID 116). 1683 bytes result sent to driver
[13:09:39,887] INFO  {TaskSetManager} Finished task 0.0 in stage 116.0 (TID 116) in 139 ms on localhost (1/1)
[13:09:39,888] INFO  {TaskSchedulerImpl} Removed TaskSet 116.0, whose tasks have all completed, from pool 
[13:09:39,888] INFO  {DAGScheduler} ResultStage 116 (count at MyLinearRegressionImpl.scala:26) finished in 0.140 s
[13:09:39,888] INFO  {DAGScheduler} Job 114 finished: count at MyLinearRegressionImpl.scala:26, took 0.146070 s
[13:09:39,892] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:39,893] INFO  {DAGScheduler} Got job 115 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:39,893] INFO  {DAGScheduler} Final stage: ResultStage 117 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:39,893] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:39,893] INFO  {DAGScheduler} Missing parents: List()
[13:09:39,893] INFO  {DAGScheduler} Submitting ResultStage 117 (MapPartitionsRDD[132] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:39,898] INFO  {MemoryStore} Block broadcast_122 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:39,901] INFO  {MemoryStore} Block broadcast_122_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:39,901] INFO  {BlockManagerInfo} Added broadcast_122_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:39,901] INFO  {SparkContext} Created broadcast 122 from broadcast at DAGScheduler.scala:1012
[13:09:39,902] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[132] at map at MyLinearRegressionImpl.scala:54)
[13:09:39,902] INFO  {TaskSchedulerImpl} Adding task set 117.0 with 1 tasks
[13:09:39,903] INFO  {TaskSetManager} Starting task 0.0 in stage 117.0 (TID 117, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:39,904] INFO  {Executor} Running task 0.0 in stage 117.0 (TID 117)
[13:09:39,910] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:40,012] INFO  {BlockManagerInfo} Removed broadcast_121_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:40,013] INFO  {BlockManagerInfo} Removed broadcast_118_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:40,013] INFO  {BlockManagerInfo} Removed broadcast_119_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:40,014] INFO  {BlockManagerInfo} Removed broadcast_120_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:40,054] INFO  {Executor} Finished task 0.0 in stage 117.0 (TID 117). 2572 bytes result sent to driver
[13:09:40,055] INFO  {TaskSetManager} Finished task 0.0 in stage 117.0 (TID 117) in 153 ms on localhost (1/1)
[13:09:40,055] INFO  {TaskSchedulerImpl} Removed TaskSet 117.0, whose tasks have all completed, from pool 
[13:09:40,055] INFO  {DAGScheduler} ResultStage 117 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.153 s
[13:09:40,055] INFO  {DAGScheduler} Job 115 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.163026 s
[13:09:40,059] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:40,059] INFO  {DAGScheduler} Got job 116 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:40,059] INFO  {DAGScheduler} Final stage: ResultStage 118 (sum at MyLinearRegressionImpl.scala:24)
[13:09:40,059] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:40,060] INFO  {DAGScheduler} Missing parents: List()
[13:09:40,060] INFO  {DAGScheduler} Submitting ResultStage 118 (MapPartitionsRDD[134] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:40,061] INFO  {MemoryStore} Block broadcast_123 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:40,062] INFO  {MemoryStore} Block broadcast_123_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:40,063] INFO  {BlockManagerInfo} Added broadcast_123_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:40,063] INFO  {SparkContext} Created broadcast 123 from broadcast at DAGScheduler.scala:1012
[13:09:40,063] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[134] at map at MyLinearRegressionImpl.scala:22)
[13:09:40,063] INFO  {TaskSchedulerImpl} Adding task set 118.0 with 1 tasks
[13:09:40,064] INFO  {TaskSetManager} Starting task 0.0 in stage 118.0 (TID 118, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:40,064] INFO  {Executor} Running task 0.0 in stage 118.0 (TID 118)
[13:09:40,067] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:40,205] INFO  {Executor} Finished task 0.0 in stage 118.0 (TID 118). 1685 bytes result sent to driver
[13:09:40,206] INFO  {TaskSetManager} Finished task 0.0 in stage 118.0 (TID 118) in 142 ms on localhost (1/1)
[13:09:40,206] INFO  {TaskSchedulerImpl} Removed TaskSet 118.0, whose tasks have all completed, from pool 
[13:09:40,206] INFO  {DAGScheduler} ResultStage 118 (sum at MyLinearRegressionImpl.scala:24) finished in 0.143 s
[13:09:40,206] INFO  {DAGScheduler} Job 116 finished: sum at MyLinearRegressionImpl.scala:24, took 0.147007 s
[13:09:40,208] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:40,209] INFO  {DAGScheduler} Got job 117 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:40,209] INFO  {DAGScheduler} Final stage: ResultStage 119 (count at MyLinearRegressionImpl.scala:26)
[13:09:40,209] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:40,209] INFO  {DAGScheduler} Missing parents: List()
[13:09:40,209] INFO  {DAGScheduler} Submitting ResultStage 119 (MapPartitionsRDD[133] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:40,210] INFO  {MemoryStore} Block broadcast_124 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:40,212] INFO  {MemoryStore} Block broadcast_124_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:40,212] INFO  {BlockManagerInfo} Added broadcast_124_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:40,212] INFO  {SparkContext} Created broadcast 124 from broadcast at DAGScheduler.scala:1012
[13:09:40,212] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[133] at map at MyLinearRegressionImpl.scala:36)
[13:09:40,213] INFO  {TaskSchedulerImpl} Adding task set 119.0 with 1 tasks
[13:09:40,213] INFO  {TaskSetManager} Starting task 0.0 in stage 119.0 (TID 119, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:40,214] INFO  {Executor} Running task 0.0 in stage 119.0 (TID 119)
[13:09:40,217] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:40,353] INFO  {Executor} Finished task 0.0 in stage 119.0 (TID 119). 1683 bytes result sent to driver
[13:09:40,354] INFO  {TaskSetManager} Finished task 0.0 in stage 119.0 (TID 119) in 141 ms on localhost (1/1)
[13:09:40,354] INFO  {TaskSchedulerImpl} Removed TaskSet 119.0, whose tasks have all completed, from pool 
[13:09:40,354] INFO  {DAGScheduler} ResultStage 119 (count at MyLinearRegressionImpl.scala:26) finished in 0.141 s
[13:09:40,354] INFO  {DAGScheduler} Job 117 finished: count at MyLinearRegressionImpl.scala:26, took 0.146225 s
[13:09:40,357] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:40,358] INFO  {DAGScheduler} Got job 118 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:40,358] INFO  {DAGScheduler} Final stage: ResultStage 120 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:40,358] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:40,358] INFO  {DAGScheduler} Missing parents: List()
[13:09:40,358] INFO  {DAGScheduler} Submitting ResultStage 120 (MapPartitionsRDD[135] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:40,360] INFO  {MemoryStore} Block broadcast_125 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:40,361] INFO  {MemoryStore} Block broadcast_125_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:40,361] INFO  {BlockManagerInfo} Added broadcast_125_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:40,362] INFO  {SparkContext} Created broadcast 125 from broadcast at DAGScheduler.scala:1012
[13:09:40,362] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[135] at map at MyLinearRegressionImpl.scala:54)
[13:09:40,362] INFO  {TaskSchedulerImpl} Adding task set 120.0 with 1 tasks
[13:09:40,363] INFO  {TaskSetManager} Starting task 0.0 in stage 120.0 (TID 120, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:40,363] INFO  {Executor} Running task 0.0 in stage 120.0 (TID 120)
[13:09:40,366] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:40,504] INFO  {Executor} Finished task 0.0 in stage 120.0 (TID 120). 2499 bytes result sent to driver
[13:09:40,504] INFO  {TaskSetManager} Finished task 0.0 in stage 120.0 (TID 120) in 142 ms on localhost (1/1)
[13:09:40,505] INFO  {TaskSchedulerImpl} Removed TaskSet 120.0, whose tasks have all completed, from pool 
[13:09:40,505] INFO  {DAGScheduler} ResultStage 120 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.143 s
[13:09:40,505] INFO  {DAGScheduler} Job 118 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.147729 s
[13:09:40,513] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:40,514] INFO  {DAGScheduler} Got job 119 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:40,514] INFO  {DAGScheduler} Final stage: ResultStage 121 (sum at MyLinearRegressionImpl.scala:24)
[13:09:40,514] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:40,514] INFO  {DAGScheduler} Missing parents: List()
[13:09:40,515] INFO  {DAGScheduler} Submitting ResultStage 121 (MapPartitionsRDD[137] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:40,517] INFO  {MemoryStore} Block broadcast_126 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:40,519] INFO  {MemoryStore} Block broadcast_126_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:40,520] INFO  {BlockManagerInfo} Added broadcast_126_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:40,520] INFO  {SparkContext} Created broadcast 126 from broadcast at DAGScheduler.scala:1012
[13:09:40,520] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[137] at map at MyLinearRegressionImpl.scala:22)
[13:09:40,520] INFO  {TaskSchedulerImpl} Adding task set 121.0 with 1 tasks
[13:09:40,522] INFO  {TaskSetManager} Starting task 0.0 in stage 121.0 (TID 121, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:40,522] INFO  {Executor} Running task 0.0 in stage 121.0 (TID 121)
[13:09:40,529] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:40,856] INFO  {Executor} Finished task 0.0 in stage 121.0 (TID 121). 1685 bytes result sent to driver
[13:09:40,857] INFO  {TaskSetManager} Finished task 0.0 in stage 121.0 (TID 121) in 336 ms on localhost (1/1)
[13:09:40,857] INFO  {TaskSchedulerImpl} Removed TaskSet 121.0, whose tasks have all completed, from pool 
[13:09:40,857] INFO  {DAGScheduler} ResultStage 121 (sum at MyLinearRegressionImpl.scala:24) finished in 0.336 s
[13:09:40,858] INFO  {DAGScheduler} Job 119 finished: sum at MyLinearRegressionImpl.scala:24, took 0.344790 s
[13:09:40,861] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:40,862] INFO  {DAGScheduler} Got job 120 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:40,862] INFO  {DAGScheduler} Final stage: ResultStage 122 (count at MyLinearRegressionImpl.scala:26)
[13:09:40,862] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:40,862] INFO  {DAGScheduler} Missing parents: List()
[13:09:40,863] INFO  {DAGScheduler} Submitting ResultStage 122 (MapPartitionsRDD[136] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:40,865] INFO  {MemoryStore} Block broadcast_127 stored as values in memory (estimated size 45.0 KB, free 1128.3 MB)
[13:09:40,867] INFO  {MemoryStore} Block broadcast_127_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:40,868] INFO  {BlockManagerInfo} Added broadcast_127_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:40,869] INFO  {SparkContext} Created broadcast 127 from broadcast at DAGScheduler.scala:1012
[13:09:40,869] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[136] at map at MyLinearRegressionImpl.scala:36)
[13:09:40,869] INFO  {TaskSchedulerImpl} Adding task set 122.0 with 1 tasks
[13:09:40,870] INFO  {TaskSetManager} Starting task 0.0 in stage 122.0 (TID 122, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:40,870] INFO  {Executor} Running task 0.0 in stage 122.0 (TID 122)
[13:09:40,877] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:40,958] INFO  {BlockManagerInfo} Removed broadcast_123_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:40,960] INFO  {BlockManagerInfo} Removed broadcast_125_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:40,961] INFO  {BlockManagerInfo} Removed broadcast_126_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:40,962] INFO  {BlockManagerInfo} Removed broadcast_122_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:40,964] INFO  {BlockManagerInfo} Removed broadcast_124_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:41,218] INFO  {Executor} Finished task 0.0 in stage 122.0 (TID 122). 1756 bytes result sent to driver
[13:09:41,219] INFO  {TaskSetManager} Finished task 0.0 in stage 122.0 (TID 122) in 350 ms on localhost (1/1)
[13:09:41,219] INFO  {TaskSchedulerImpl} Removed TaskSet 122.0, whose tasks have all completed, from pool 
[13:09:41,220] INFO  {DAGScheduler} ResultStage 122 (count at MyLinearRegressionImpl.scala:26) finished in 0.351 s
[13:09:41,220] INFO  {DAGScheduler} Job 120 finished: count at MyLinearRegressionImpl.scala:26, took 0.358582 s
[13:09:41,225] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:41,226] INFO  {DAGScheduler} Got job 121 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:41,226] INFO  {DAGScheduler} Final stage: ResultStage 123 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:41,226] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:41,226] INFO  {DAGScheduler} Missing parents: List()
[13:09:41,227] INFO  {DAGScheduler} Submitting ResultStage 123 (MapPartitionsRDD[138] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:41,229] INFO  {MemoryStore} Block broadcast_128 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:41,231] INFO  {MemoryStore} Block broadcast_128_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:41,231] INFO  {BlockManagerInfo} Added broadcast_128_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:41,232] INFO  {SparkContext} Created broadcast 128 from broadcast at DAGScheduler.scala:1012
[13:09:41,232] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[138] at map at MyLinearRegressionImpl.scala:54)
[13:09:41,232] INFO  {TaskSchedulerImpl} Adding task set 123.0 with 1 tasks
[13:09:41,233] INFO  {TaskSetManager} Starting task 0.0 in stage 123.0 (TID 123, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:41,234] INFO  {Executor} Running task 0.0 in stage 123.0 (TID 123)
[13:09:41,241] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:41,579] INFO  {Executor} Finished task 0.0 in stage 123.0 (TID 123). 2499 bytes result sent to driver
[13:09:41,580] INFO  {TaskSetManager} Finished task 0.0 in stage 123.0 (TID 123) in 347 ms on localhost (1/1)
[13:09:41,580] INFO  {TaskSchedulerImpl} Removed TaskSet 123.0, whose tasks have all completed, from pool 
[13:09:41,581] INFO  {DAGScheduler} ResultStage 123 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.349 s
[13:09:41,581] INFO  {DAGScheduler} Job 121 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.355700 s
[13:09:41,588] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:41,589] INFO  {DAGScheduler} Got job 122 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:41,589] INFO  {DAGScheduler} Final stage: ResultStage 124 (sum at MyLinearRegressionImpl.scala:24)
[13:09:41,589] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:41,589] INFO  {DAGScheduler} Missing parents: List()
[13:09:41,591] INFO  {DAGScheduler} Submitting ResultStage 124 (MapPartitionsRDD[140] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:41,593] INFO  {MemoryStore} Block broadcast_129 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:41,595] INFO  {MemoryStore} Block broadcast_129_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:41,595] INFO  {BlockManagerInfo} Added broadcast_129_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:41,596] INFO  {SparkContext} Created broadcast 129 from broadcast at DAGScheduler.scala:1012
[13:09:41,596] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 124 (MapPartitionsRDD[140] at map at MyLinearRegressionImpl.scala:22)
[13:09:41,596] INFO  {TaskSchedulerImpl} Adding task set 124.0 with 1 tasks
[13:09:41,597] INFO  {TaskSetManager} Starting task 0.0 in stage 124.0 (TID 124, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:41,598] INFO  {Executor} Running task 0.0 in stage 124.0 (TID 124)
[13:09:41,605] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:41,939] INFO  {Executor} Finished task 0.0 in stage 124.0 (TID 124). 1685 bytes result sent to driver
[13:09:41,939] INFO  {TaskSetManager} Finished task 0.0 in stage 124.0 (TID 124) in 342 ms on localhost (1/1)
[13:09:41,940] INFO  {TaskSchedulerImpl} Removed TaskSet 124.0, whose tasks have all completed, from pool 
[13:09:41,940] INFO  {DAGScheduler} ResultStage 124 (sum at MyLinearRegressionImpl.scala:24) finished in 0.343 s
[13:09:41,940] INFO  {DAGScheduler} Job 122 finished: sum at MyLinearRegressionImpl.scala:24, took 0.351712 s
[13:09:41,944] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:41,944] INFO  {DAGScheduler} Got job 123 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:41,944] INFO  {DAGScheduler} Final stage: ResultStage 125 (count at MyLinearRegressionImpl.scala:26)
[13:09:41,944] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:41,945] INFO  {DAGScheduler} Missing parents: List()
[13:09:41,945] INFO  {DAGScheduler} Submitting ResultStage 125 (MapPartitionsRDD[139] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:41,947] INFO  {MemoryStore} Block broadcast_130 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:41,949] INFO  {MemoryStore} Block broadcast_130_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:41,950] INFO  {BlockManagerInfo} Added broadcast_130_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:41,950] INFO  {SparkContext} Created broadcast 130 from broadcast at DAGScheduler.scala:1012
[13:09:41,951] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[139] at map at MyLinearRegressionImpl.scala:36)
[13:09:41,951] INFO  {TaskSchedulerImpl} Adding task set 125.0 with 1 tasks
[13:09:41,952] INFO  {TaskSetManager} Starting task 0.0 in stage 125.0 (TID 125, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:41,952] INFO  {Executor} Running task 0.0 in stage 125.0 (TID 125)
[13:09:41,959] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:42,289] INFO  {Executor} Finished task 0.0 in stage 125.0 (TID 125). 1683 bytes result sent to driver
[13:09:42,290] INFO  {TaskSetManager} Finished task 0.0 in stage 125.0 (TID 125) in 339 ms on localhost (1/1)
[13:09:42,290] INFO  {TaskSchedulerImpl} Removed TaskSet 125.0, whose tasks have all completed, from pool 
[13:09:42,291] INFO  {DAGScheduler} ResultStage 125 (count at MyLinearRegressionImpl.scala:26) finished in 0.340 s
[13:09:42,291] INFO  {DAGScheduler} Job 123 finished: count at MyLinearRegressionImpl.scala:26, took 0.347385 s
[13:09:42,316] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:42,317] INFO  {DAGScheduler} Got job 124 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:42,317] INFO  {DAGScheduler} Final stage: ResultStage 126 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:42,317] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:42,317] INFO  {DAGScheduler} Missing parents: List()
[13:09:42,318] INFO  {DAGScheduler} Submitting ResultStage 126 (MapPartitionsRDD[141] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:42,321] INFO  {MemoryStore} Block broadcast_131 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:42,324] INFO  {MemoryStore} Block broadcast_131_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:42,324] INFO  {BlockManagerInfo} Added broadcast_131_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:42,325] INFO  {SparkContext} Created broadcast 131 from broadcast at DAGScheduler.scala:1012
[13:09:42,326] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[141] at map at MyLinearRegressionImpl.scala:54)
[13:09:42,326] INFO  {TaskSchedulerImpl} Adding task set 126.0 with 1 tasks
[13:09:42,327] INFO  {TaskSetManager} Starting task 0.0 in stage 126.0 (TID 126, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:42,328] INFO  {Executor} Running task 0.0 in stage 126.0 (TID 126)
[13:09:42,339] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:42,847] INFO  {BlockManagerInfo} Removed broadcast_127_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:42,855] INFO  {BlockManagerInfo} Removed broadcast_128_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:42,858] INFO  {BlockManagerInfo} Removed broadcast_129_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:42,867] INFO  {BlockManagerInfo} Removed broadcast_130_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:42,968] INFO  {Executor} Finished task 0.0 in stage 126.0 (TID 126). 2572 bytes result sent to driver
[13:09:42,969] INFO  {TaskSetManager} Finished task 0.0 in stage 126.0 (TID 126) in 642 ms on localhost (1/1)
[13:09:42,969] INFO  {TaskSchedulerImpl} Removed TaskSet 126.0, whose tasks have all completed, from pool 
[13:09:42,972] INFO  {DAGScheduler} ResultStage 126 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.643 s
[13:09:42,973] INFO  {DAGScheduler} Job 124 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.657155 s
[13:09:42,991] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:43,002] INFO  {DAGScheduler} Got job 125 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:43,002] INFO  {DAGScheduler} Final stage: ResultStage 127 (sum at MyLinearRegressionImpl.scala:24)
[13:09:43,003] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:43,003] INFO  {DAGScheduler} Missing parents: List()
[13:09:43,003] INFO  {DAGScheduler} Submitting ResultStage 127 (MapPartitionsRDD[143] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:43,008] INFO  {MemoryStore} Block broadcast_132 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:43,010] INFO  {MemoryStore} Block broadcast_132_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:43,011] INFO  {BlockManagerInfo} Added broadcast_132_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:43,012] INFO  {SparkContext} Created broadcast 132 from broadcast at DAGScheduler.scala:1012
[13:09:43,012] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[143] at map at MyLinearRegressionImpl.scala:22)
[13:09:43,012] INFO  {TaskSchedulerImpl} Adding task set 127.0 with 1 tasks
[13:09:43,014] INFO  {TaskSetManager} Starting task 0.0 in stage 127.0 (TID 127, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:43,014] INFO  {Executor} Running task 0.0 in stage 127.0 (TID 127)
[13:09:43,024] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:43,523] INFO  {Executor} Finished task 0.0 in stage 127.0 (TID 127). 1685 bytes result sent to driver
[13:09:43,524] INFO  {TaskSetManager} Finished task 0.0 in stage 127.0 (TID 127) in 511 ms on localhost (1/1)
[13:09:43,524] INFO  {TaskSchedulerImpl} Removed TaskSet 127.0, whose tasks have all completed, from pool 
[13:09:43,524] INFO  {DAGScheduler} ResultStage 127 (sum at MyLinearRegressionImpl.scala:24) finished in 0.510 s
[13:09:43,525] INFO  {DAGScheduler} Job 125 finished: sum at MyLinearRegressionImpl.scala:24, took 0.533727 s
[13:09:43,530] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:43,531] INFO  {DAGScheduler} Got job 126 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:43,531] INFO  {DAGScheduler} Final stage: ResultStage 128 (count at MyLinearRegressionImpl.scala:26)
[13:09:43,531] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:43,531] INFO  {DAGScheduler} Missing parents: List()
[13:09:43,531] INFO  {DAGScheduler} Submitting ResultStage 128 (MapPartitionsRDD[142] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:43,534] INFO  {MemoryStore} Block broadcast_133 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:43,536] INFO  {MemoryStore} Block broadcast_133_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:43,536] INFO  {BlockManagerInfo} Added broadcast_133_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:43,537] INFO  {SparkContext} Created broadcast 133 from broadcast at DAGScheduler.scala:1012
[13:09:43,537] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[142] at map at MyLinearRegressionImpl.scala:36)
[13:09:43,537] INFO  {TaskSchedulerImpl} Adding task set 128.0 with 1 tasks
[13:09:43,538] INFO  {TaskSetManager} Starting task 0.0 in stage 128.0 (TID 128, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:43,539] INFO  {Executor} Running task 0.0 in stage 128.0 (TID 128)
[13:09:43,546] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:44,086] INFO  {Executor} Finished task 0.0 in stage 128.0 (TID 128). 1683 bytes result sent to driver
[13:09:44,087] INFO  {TaskSetManager} Finished task 0.0 in stage 128.0 (TID 128) in 549 ms on localhost (1/1)
[13:09:44,088] INFO  {TaskSchedulerImpl} Removed TaskSet 128.0, whose tasks have all completed, from pool 
[13:09:44,088] INFO  {DAGScheduler} ResultStage 128 (count at MyLinearRegressionImpl.scala:26) finished in 0.551 s
[13:09:44,089] INFO  {DAGScheduler} Job 126 finished: count at MyLinearRegressionImpl.scala:26, took 0.558920 s
[13:09:44,107] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:44,109] INFO  {DAGScheduler} Got job 127 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:44,109] INFO  {DAGScheduler} Final stage: ResultStage 129 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:44,109] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:44,109] INFO  {DAGScheduler} Missing parents: List()
[13:09:44,110] INFO  {DAGScheduler} Submitting ResultStage 129 (MapPartitionsRDD[144] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:44,114] INFO  {MemoryStore} Block broadcast_134 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:44,117] INFO  {MemoryStore} Block broadcast_134_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:44,117] INFO  {BlockManagerInfo} Added broadcast_134_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:44,118] INFO  {SparkContext} Created broadcast 134 from broadcast at DAGScheduler.scala:1012
[13:09:44,118] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[144] at map at MyLinearRegressionImpl.scala:54)
[13:09:44,118] INFO  {TaskSchedulerImpl} Adding task set 129.0 with 1 tasks
[13:09:44,120] INFO  {TaskSetManager} Starting task 0.0 in stage 129.0 (TID 129, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:44,121] INFO  {Executor} Running task 0.0 in stage 129.0 (TID 129)
[13:09:44,130] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:44,494] INFO  {Executor} Finished task 0.0 in stage 129.0 (TID 129). 2499 bytes result sent to driver
[13:09:44,495] INFO  {TaskSetManager} Finished task 0.0 in stage 129.0 (TID 129) in 375 ms on localhost (1/1)
[13:09:44,496] INFO  {TaskSchedulerImpl} Removed TaskSet 129.0, whose tasks have all completed, from pool 
[13:09:44,496] INFO  {DAGScheduler} ResultStage 129 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.375 s
[13:09:44,496] INFO  {DAGScheduler} Job 127 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.389055 s
[13:09:44,507] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:44,511] INFO  {DAGScheduler} Got job 128 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:44,511] INFO  {DAGScheduler} Final stage: ResultStage 130 (sum at MyLinearRegressionImpl.scala:24)
[13:09:44,511] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:44,511] INFO  {DAGScheduler} Missing parents: List()
[13:09:44,511] INFO  {DAGScheduler} Submitting ResultStage 130 (MapPartitionsRDD[146] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:44,514] INFO  {MemoryStore} Block broadcast_135 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:44,516] INFO  {MemoryStore} Block broadcast_135_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:44,517] INFO  {BlockManagerInfo} Added broadcast_135_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:44,518] INFO  {SparkContext} Created broadcast 135 from broadcast at DAGScheduler.scala:1012
[13:09:44,518] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[146] at map at MyLinearRegressionImpl.scala:22)
[13:09:44,518] INFO  {TaskSchedulerImpl} Adding task set 130.0 with 1 tasks
[13:09:44,519] INFO  {TaskSetManager} Starting task 0.0 in stage 130.0 (TID 130, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:44,520] INFO  {Executor} Running task 0.0 in stage 130.0 (TID 130)
[13:09:44,531] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:44,947] INFO  {Executor} Finished task 0.0 in stage 130.0 (TID 130). 1685 bytes result sent to driver
[13:09:44,948] INFO  {TaskSetManager} Finished task 0.0 in stage 130.0 (TID 130) in 429 ms on localhost (1/1)
[13:09:44,949] INFO  {TaskSchedulerImpl} Removed TaskSet 130.0, whose tasks have all completed, from pool 
[13:09:44,949] INFO  {DAGScheduler} ResultStage 130 (sum at MyLinearRegressionImpl.scala:24) finished in 0.429 s
[13:09:44,950] INFO  {DAGScheduler} Job 128 finished: sum at MyLinearRegressionImpl.scala:24, took 0.442888 s
[13:09:44,954] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:44,956] INFO  {DAGScheduler} Got job 129 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:44,956] INFO  {DAGScheduler} Final stage: ResultStage 131 (count at MyLinearRegressionImpl.scala:26)
[13:09:44,956] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:44,956] INFO  {DAGScheduler} Missing parents: List()
[13:09:44,956] INFO  {DAGScheduler} Submitting ResultStage 131 (MapPartitionsRDD[145] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:44,960] INFO  {MemoryStore} Block broadcast_136 stored as values in memory (estimated size 45.0 KB, free 1128.3 MB)
[13:09:44,963] INFO  {MemoryStore} Block broadcast_136_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:44,964] INFO  {BlockManagerInfo} Added broadcast_136_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:44,965] INFO  {SparkContext} Created broadcast 136 from broadcast at DAGScheduler.scala:1012
[13:09:44,965] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[145] at map at MyLinearRegressionImpl.scala:36)
[13:09:44,965] INFO  {TaskSchedulerImpl} Adding task set 131.0 with 1 tasks
[13:09:44,966] INFO  {TaskSetManager} Starting task 0.0 in stage 131.0 (TID 131, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:44,966] INFO  {Executor} Running task 0.0 in stage 131.0 (TID 131)
[13:09:44,977] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:45,129] INFO  {BlockManagerInfo} Removed broadcast_131_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:45,130] INFO  {BlockManagerInfo} Removed broadcast_132_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:45,132] INFO  {BlockManagerInfo} Removed broadcast_133_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:45,133] INFO  {BlockManagerInfo} Removed broadcast_134_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:45,136] INFO  {BlockManagerInfo} Removed broadcast_135_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:45,356] INFO  {Executor} Finished task 0.0 in stage 131.0 (TID 131). 1756 bytes result sent to driver
[13:09:45,357] INFO  {TaskSetManager} Finished task 0.0 in stage 131.0 (TID 131) in 392 ms on localhost (1/1)
[13:09:45,357] INFO  {TaskSchedulerImpl} Removed TaskSet 131.0, whose tasks have all completed, from pool 
[13:09:45,357] INFO  {DAGScheduler} ResultStage 131 (count at MyLinearRegressionImpl.scala:26) finished in 0.392 s
[13:09:45,358] INFO  {DAGScheduler} Job 129 finished: count at MyLinearRegressionImpl.scala:26, took 0.403288 s
[13:09:45,365] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:45,367] INFO  {DAGScheduler} Got job 130 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:45,367] INFO  {DAGScheduler} Final stage: ResultStage 132 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:45,367] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:45,367] INFO  {DAGScheduler} Missing parents: List()
[13:09:45,368] INFO  {DAGScheduler} Submitting ResultStage 132 (MapPartitionsRDD[147] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:45,371] INFO  {MemoryStore} Block broadcast_137 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:45,373] INFO  {MemoryStore} Block broadcast_137_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:45,374] INFO  {BlockManagerInfo} Added broadcast_137_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:45,374] INFO  {SparkContext} Created broadcast 137 from broadcast at DAGScheduler.scala:1012
[13:09:45,375] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[147] at map at MyLinearRegressionImpl.scala:54)
[13:09:45,375] INFO  {TaskSchedulerImpl} Adding task set 132.0 with 1 tasks
[13:09:45,376] INFO  {TaskSetManager} Starting task 0.0 in stage 132.0 (TID 132, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:45,376] INFO  {Executor} Running task 0.0 in stage 132.0 (TID 132)
[13:09:45,386] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:45,781] INFO  {Executor} Finished task 0.0 in stage 132.0 (TID 132). 2499 bytes result sent to driver
[13:09:45,783] INFO  {TaskSetManager} Finished task 0.0 in stage 132.0 (TID 132) in 407 ms on localhost (1/1)
[13:09:45,783] INFO  {TaskSchedulerImpl} Removed TaskSet 132.0, whose tasks have all completed, from pool 
[13:09:45,783] INFO  {DAGScheduler} ResultStage 132 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.408 s
[13:09:45,784] INFO  {DAGScheduler} Job 130 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.419046 s
[13:09:45,795] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:45,796] INFO  {DAGScheduler} Got job 131 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:45,796] INFO  {DAGScheduler} Final stage: ResultStage 133 (sum at MyLinearRegressionImpl.scala:24)
[13:09:45,797] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:45,797] INFO  {DAGScheduler} Missing parents: List()
[13:09:45,797] INFO  {DAGScheduler} Submitting ResultStage 133 (MapPartitionsRDD[149] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:45,801] INFO  {MemoryStore} Block broadcast_138 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:45,803] INFO  {MemoryStore} Block broadcast_138_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:45,804] INFO  {BlockManagerInfo} Added broadcast_138_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:45,805] INFO  {SparkContext} Created broadcast 138 from broadcast at DAGScheduler.scala:1012
[13:09:45,805] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[149] at map at MyLinearRegressionImpl.scala:22)
[13:09:45,805] INFO  {TaskSchedulerImpl} Adding task set 133.0 with 1 tasks
[13:09:45,807] INFO  {TaskSetManager} Starting task 0.0 in stage 133.0 (TID 133, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:45,807] INFO  {Executor} Running task 0.0 in stage 133.0 (TID 133)
[13:09:45,828] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:46,456] INFO  {Executor} Finished task 0.0 in stage 133.0 (TID 133). 1772 bytes result sent to driver
[13:09:46,459] INFO  {TaskSetManager} Finished task 0.0 in stage 133.0 (TID 133) in 653 ms on localhost (1/1)
[13:09:46,459] INFO  {TaskSchedulerImpl} Removed TaskSet 133.0, whose tasks have all completed, from pool 
[13:09:46,464] INFO  {DAGScheduler} ResultStage 133 (sum at MyLinearRegressionImpl.scala:24) finished in 0.651 s
[13:09:46,464] INFO  {DAGScheduler} Job 131 finished: sum at MyLinearRegressionImpl.scala:24, took 0.668908 s
[13:09:46,469] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:46,470] INFO  {DAGScheduler} Got job 132 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:46,470] INFO  {DAGScheduler} Final stage: ResultStage 134 (count at MyLinearRegressionImpl.scala:26)
[13:09:46,470] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:46,470] INFO  {DAGScheduler} Missing parents: List()
[13:09:46,470] INFO  {DAGScheduler} Submitting ResultStage 134 (MapPartitionsRDD[148] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:46,473] INFO  {MemoryStore} Block broadcast_139 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:46,475] INFO  {MemoryStore} Block broadcast_139_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:46,480] INFO  {BlockManagerInfo} Added broadcast_139_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:46,482] INFO  {SparkContext} Created broadcast 139 from broadcast at DAGScheduler.scala:1012
[13:09:46,482] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[148] at map at MyLinearRegressionImpl.scala:36)
[13:09:46,482] INFO  {TaskSchedulerImpl} Adding task set 134.0 with 1 tasks
[13:09:46,483] INFO  {TaskSetManager} Starting task 0.0 in stage 134.0 (TID 134, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:46,484] INFO  {Executor} Running task 0.0 in stage 134.0 (TID 134)
[13:09:46,493] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:46,893] INFO  {Executor} Finished task 0.0 in stage 134.0 (TID 134). 1683 bytes result sent to driver
[13:09:46,894] INFO  {TaskSetManager} Finished task 0.0 in stage 134.0 (TID 134) in 411 ms on localhost (1/1)
[13:09:46,894] INFO  {TaskSchedulerImpl} Removed TaskSet 134.0, whose tasks have all completed, from pool 
[13:09:46,895] INFO  {DAGScheduler} ResultStage 134 (count at MyLinearRegressionImpl.scala:26) finished in 0.412 s
[13:09:46,895] INFO  {DAGScheduler} Job 132 finished: count at MyLinearRegressionImpl.scala:26, took 0.426073 s
[13:09:46,900] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:46,901] INFO  {DAGScheduler} Got job 133 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:46,901] INFO  {DAGScheduler} Final stage: ResultStage 135 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:46,901] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:46,901] INFO  {DAGScheduler} Missing parents: List()
[13:09:46,902] INFO  {DAGScheduler} Submitting ResultStage 135 (MapPartitionsRDD[150] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:46,904] INFO  {MemoryStore} Block broadcast_140 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:46,906] INFO  {MemoryStore} Block broadcast_140_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:46,906] INFO  {BlockManagerInfo} Added broadcast_140_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:46,907] INFO  {SparkContext} Created broadcast 140 from broadcast at DAGScheduler.scala:1012
[13:09:46,907] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[150] at map at MyLinearRegressionImpl.scala:54)
[13:09:46,907] INFO  {TaskSchedulerImpl} Adding task set 135.0 with 1 tasks
[13:09:46,909] INFO  {TaskSetManager} Starting task 0.0 in stage 135.0 (TID 135, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:46,909] INFO  {Executor} Running task 0.0 in stage 135.0 (TID 135)
[13:09:46,917] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:47,379] INFO  {Executor} Finished task 0.0 in stage 135.0 (TID 135). 2499 bytes result sent to driver
[13:09:47,380] INFO  {TaskSetManager} Finished task 0.0 in stage 135.0 (TID 135) in 472 ms on localhost (1/1)
[13:09:47,380] INFO  {TaskSchedulerImpl} Removed TaskSet 135.0, whose tasks have all completed, from pool 
[13:09:47,380] INFO  {DAGScheduler} ResultStage 135 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.472 s
[13:09:47,381] INFO  {DAGScheduler} Job 133 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.480451 s
[13:09:47,389] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:47,390] INFO  {DAGScheduler} Got job 134 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:47,390] INFO  {DAGScheduler} Final stage: ResultStage 136 (sum at MyLinearRegressionImpl.scala:24)
[13:09:47,390] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:47,390] INFO  {DAGScheduler} Missing parents: List()
[13:09:47,390] INFO  {DAGScheduler} Submitting ResultStage 136 (MapPartitionsRDD[152] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:47,392] INFO  {MemoryStore} Block broadcast_141 stored as values in memory (estimated size 45.5 KB, free 1128.3 MB)
[13:09:47,400] INFO  {BlockManagerInfo} Removed broadcast_139_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:47,400] INFO  {MemoryStore} Block broadcast_141_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:47,401] INFO  {BlockManagerInfo} Added broadcast_141_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:47,401] INFO  {SparkContext} Created broadcast 141 from broadcast at DAGScheduler.scala:1012
[13:09:47,401] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[152] at map at MyLinearRegressionImpl.scala:22)
[13:09:47,401] INFO  {TaskSchedulerImpl} Adding task set 136.0 with 1 tasks
[13:09:47,402] INFO  {BlockManagerInfo} Removed broadcast_140_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:47,403] INFO  {TaskSetManager} Starting task 0.0 in stage 136.0 (TID 136, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:47,403] INFO  {Executor} Running task 0.0 in stage 136.0 (TID 136)
[13:09:47,403] INFO  {BlockManagerInfo} Removed broadcast_136_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:47,404] INFO  {BlockManagerInfo} Removed broadcast_137_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:47,405] INFO  {BlockManagerInfo} Removed broadcast_138_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:47,412] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:47,829] INFO  {Executor} Finished task 0.0 in stage 136.0 (TID 136). 1685 bytes result sent to driver
[13:09:47,830] INFO  {TaskSetManager} Finished task 0.0 in stage 136.0 (TID 136) in 427 ms on localhost (1/1)
[13:09:47,830] INFO  {TaskSchedulerImpl} Removed TaskSet 136.0, whose tasks have all completed, from pool 
[13:09:47,830] INFO  {DAGScheduler} ResultStage 136 (sum at MyLinearRegressionImpl.scala:24) finished in 0.428 s
[13:09:47,830] INFO  {DAGScheduler} Job 134 finished: sum at MyLinearRegressionImpl.scala:24, took 0.441054 s
[13:09:47,834] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:47,835] INFO  {DAGScheduler} Got job 135 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:47,835] INFO  {DAGScheduler} Final stage: ResultStage 137 (count at MyLinearRegressionImpl.scala:26)
[13:09:47,835] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:47,835] INFO  {DAGScheduler} Missing parents: List()
[13:09:47,835] INFO  {DAGScheduler} Submitting ResultStage 137 (MapPartitionsRDD[151] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:47,838] INFO  {MemoryStore} Block broadcast_142 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:47,839] INFO  {MemoryStore} Block broadcast_142_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:47,840] INFO  {BlockManagerInfo} Added broadcast_142_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:47,840] INFO  {SparkContext} Created broadcast 142 from broadcast at DAGScheduler.scala:1012
[13:09:47,840] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 137 (MapPartitionsRDD[151] at map at MyLinearRegressionImpl.scala:36)
[13:09:47,841] INFO  {TaskSchedulerImpl} Adding task set 137.0 with 1 tasks
[13:09:47,842] INFO  {TaskSetManager} Starting task 0.0 in stage 137.0 (TID 137, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:47,842] INFO  {Executor} Running task 0.0 in stage 137.0 (TID 137)
[13:09:47,849] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:48,173] INFO  {Executor} Finished task 0.0 in stage 137.0 (TID 137). 1683 bytes result sent to driver
[13:09:48,174] INFO  {TaskSetManager} Finished task 0.0 in stage 137.0 (TID 137) in 333 ms on localhost (1/1)
[13:09:48,174] INFO  {TaskSchedulerImpl} Removed TaskSet 137.0, whose tasks have all completed, from pool 
[13:09:48,174] INFO  {DAGScheduler} ResultStage 137 (count at MyLinearRegressionImpl.scala:26) finished in 0.333 s
[13:09:48,175] INFO  {DAGScheduler} Job 135 finished: count at MyLinearRegressionImpl.scala:26, took 0.340399 s
[13:09:48,179] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:48,180] INFO  {DAGScheduler} Got job 136 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:48,180] INFO  {DAGScheduler} Final stage: ResultStage 138 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:48,180] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:48,180] INFO  {DAGScheduler} Missing parents: List()
[13:09:48,180] INFO  {DAGScheduler} Submitting ResultStage 138 (MapPartitionsRDD[153] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:48,182] INFO  {MemoryStore} Block broadcast_143 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:48,184] INFO  {MemoryStore} Block broadcast_143_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:48,184] INFO  {BlockManagerInfo} Added broadcast_143_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:48,185] INFO  {SparkContext} Created broadcast 143 from broadcast at DAGScheduler.scala:1012
[13:09:48,185] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[153] at map at MyLinearRegressionImpl.scala:54)
[13:09:48,185] INFO  {TaskSchedulerImpl} Adding task set 138.0 with 1 tasks
[13:09:48,186] INFO  {TaskSetManager} Starting task 0.0 in stage 138.0 (TID 138, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:48,187] INFO  {Executor} Running task 0.0 in stage 138.0 (TID 138)
[13:09:48,193] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:48,503] INFO  {Executor} Finished task 0.0 in stage 138.0 (TID 138). 2499 bytes result sent to driver
[13:09:48,504] INFO  {TaskSetManager} Finished task 0.0 in stage 138.0 (TID 138) in 318 ms on localhost (1/1)
[13:09:48,504] INFO  {TaskSchedulerImpl} Removed TaskSet 138.0, whose tasks have all completed, from pool 
[13:09:48,504] INFO  {DAGScheduler} ResultStage 138 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.318 s
[13:09:48,505] INFO  {DAGScheduler} Job 136 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.325690 s
[13:09:48,509] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:48,509] INFO  {DAGScheduler} Got job 137 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:48,510] INFO  {DAGScheduler} Final stage: ResultStage 139 (sum at MyLinearRegressionImpl.scala:24)
[13:09:48,510] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:48,510] INFO  {DAGScheduler} Missing parents: List()
[13:09:48,510] INFO  {DAGScheduler} Submitting ResultStage 139 (MapPartitionsRDD[155] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:48,511] INFO  {MemoryStore} Block broadcast_144 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:48,513] INFO  {MemoryStore} Block broadcast_144_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.4 MB)
[13:09:48,513] INFO  {BlockManagerInfo} Added broadcast_144_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:48,513] INFO  {SparkContext} Created broadcast 144 from broadcast at DAGScheduler.scala:1012
[13:09:48,513] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[155] at map at MyLinearRegressionImpl.scala:22)
[13:09:48,513] INFO  {TaskSchedulerImpl} Adding task set 139.0 with 1 tasks
[13:09:48,514] INFO  {TaskSetManager} Starting task 0.0 in stage 139.0 (TID 139, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:48,514] INFO  {Executor} Running task 0.0 in stage 139.0 (TID 139)
[13:09:48,518] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:48,669] INFO  {Executor} Finished task 0.0 in stage 139.0 (TID 139). 1685 bytes result sent to driver
[13:09:48,669] INFO  {TaskSetManager} Finished task 0.0 in stage 139.0 (TID 139) in 155 ms on localhost (1/1)
[13:09:48,670] INFO  {TaskSchedulerImpl} Removed TaskSet 139.0, whose tasks have all completed, from pool 
[13:09:48,670] INFO  {DAGScheduler} ResultStage 139 (sum at MyLinearRegressionImpl.scala:24) finished in 0.156 s
[13:09:48,670] INFO  {DAGScheduler} Job 137 finished: sum at MyLinearRegressionImpl.scala:24, took 0.160810 s
[13:09:48,671] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:48,672] INFO  {DAGScheduler} Got job 138 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:48,672] INFO  {DAGScheduler} Final stage: ResultStage 140 (count at MyLinearRegressionImpl.scala:26)
[13:09:48,672] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:48,672] INFO  {DAGScheduler} Missing parents: List()
[13:09:48,672] INFO  {DAGScheduler} Submitting ResultStage 140 (MapPartitionsRDD[154] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:48,673] INFO  {MemoryStore} Block broadcast_145 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:48,674] INFO  {MemoryStore} Block broadcast_145_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:48,674] INFO  {BlockManagerInfo} Added broadcast_145_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:48,674] INFO  {SparkContext} Created broadcast 145 from broadcast at DAGScheduler.scala:1012
[13:09:48,674] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 140 (MapPartitionsRDD[154] at map at MyLinearRegressionImpl.scala:36)
[13:09:48,674] INFO  {TaskSchedulerImpl} Adding task set 140.0 with 1 tasks
[13:09:48,675] INFO  {TaskSetManager} Starting task 0.0 in stage 140.0 (TID 140, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:48,675] INFO  {Executor} Running task 0.0 in stage 140.0 (TID 140)
[13:09:48,678] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:48,789] INFO  {BlockManagerInfo} Removed broadcast_141_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:48,800] INFO  {BlockManagerInfo} Removed broadcast_142_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:48,801] INFO  {BlockManagerInfo} Removed broadcast_143_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:48,801] INFO  {BlockManagerInfo} Removed broadcast_144_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:48,828] INFO  {Executor} Finished task 0.0 in stage 140.0 (TID 140). 1756 bytes result sent to driver
[13:09:48,828] INFO  {TaskSetManager} Finished task 0.0 in stage 140.0 (TID 140) in 153 ms on localhost (1/1)
[13:09:48,828] INFO  {TaskSchedulerImpl} Removed TaskSet 140.0, whose tasks have all completed, from pool 
[13:09:48,828] INFO  {DAGScheduler} ResultStage 140 (count at MyLinearRegressionImpl.scala:26) finished in 0.154 s
[13:09:48,828] INFO  {DAGScheduler} Job 138 finished: count at MyLinearRegressionImpl.scala:26, took 0.157083 s
[13:09:48,830] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:48,831] INFO  {DAGScheduler} Got job 139 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:48,831] INFO  {DAGScheduler} Final stage: ResultStage 141 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:48,831] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:48,831] INFO  {DAGScheduler} Missing parents: List()
[13:09:48,831] INFO  {DAGScheduler} Submitting ResultStage 141 (MapPartitionsRDD[156] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:48,832] INFO  {MemoryStore} Block broadcast_146 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:48,833] INFO  {MemoryStore} Block broadcast_146_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:48,834] INFO  {BlockManagerInfo} Added broadcast_146_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:48,834] INFO  {SparkContext} Created broadcast 146 from broadcast at DAGScheduler.scala:1012
[13:09:48,834] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[156] at map at MyLinearRegressionImpl.scala:54)
[13:09:48,834] INFO  {TaskSchedulerImpl} Adding task set 141.0 with 1 tasks
[13:09:48,835] INFO  {TaskSetManager} Starting task 0.0 in stage 141.0 (TID 141, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:48,835] INFO  {Executor} Running task 0.0 in stage 141.0 (TID 141)
[13:09:48,840] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:49,058] INFO  {Executor} Finished task 0.0 in stage 141.0 (TID 141). 2499 bytes result sent to driver
[13:09:49,059] INFO  {TaskSetManager} Finished task 0.0 in stage 141.0 (TID 141) in 225 ms on localhost (1/1)
[13:09:49,059] INFO  {TaskSchedulerImpl} Removed TaskSet 141.0, whose tasks have all completed, from pool 
[13:09:49,060] INFO  {DAGScheduler} ResultStage 141 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.225 s
[13:09:49,060] INFO  {DAGScheduler} Job 139 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.229305 s
[13:09:49,065] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:49,066] INFO  {DAGScheduler} Got job 140 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:49,066] INFO  {DAGScheduler} Final stage: ResultStage 142 (sum at MyLinearRegressionImpl.scala:24)
[13:09:49,066] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:49,066] INFO  {DAGScheduler} Missing parents: List()
[13:09:49,066] INFO  {DAGScheduler} Submitting ResultStage 142 (MapPartitionsRDD[158] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:49,067] INFO  {MemoryStore} Block broadcast_147 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:49,069] INFO  {MemoryStore} Block broadcast_147_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:49,069] INFO  {BlockManagerInfo} Added broadcast_147_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:49,070] INFO  {SparkContext} Created broadcast 147 from broadcast at DAGScheduler.scala:1012
[13:09:49,070] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 142 (MapPartitionsRDD[158] at map at MyLinearRegressionImpl.scala:22)
[13:09:49,070] INFO  {TaskSchedulerImpl} Adding task set 142.0 with 1 tasks
[13:09:49,071] INFO  {TaskSetManager} Starting task 0.0 in stage 142.0 (TID 142, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:49,071] INFO  {Executor} Running task 0.0 in stage 142.0 (TID 142)
[13:09:49,076] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:49,325] INFO  {Executor} Finished task 0.0 in stage 142.0 (TID 142). 1685 bytes result sent to driver
[13:09:49,326] INFO  {TaskSetManager} Finished task 0.0 in stage 142.0 (TID 142) in 256 ms on localhost (1/1)
[13:09:49,326] INFO  {TaskSchedulerImpl} Removed TaskSet 142.0, whose tasks have all completed, from pool 
[13:09:49,326] INFO  {DAGScheduler} ResultStage 142 (sum at MyLinearRegressionImpl.scala:24) finished in 0.255 s
[13:09:49,327] INFO  {DAGScheduler} Job 140 finished: sum at MyLinearRegressionImpl.scala:24, took 0.261701 s
[13:09:49,329] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:49,330] INFO  {DAGScheduler} Got job 141 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:49,330] INFO  {DAGScheduler} Final stage: ResultStage 143 (count at MyLinearRegressionImpl.scala:26)
[13:09:49,330] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:49,330] INFO  {DAGScheduler} Missing parents: List()
[13:09:49,330] INFO  {DAGScheduler} Submitting ResultStage 143 (MapPartitionsRDD[157] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:49,331] INFO  {MemoryStore} Block broadcast_148 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:49,333] INFO  {MemoryStore} Block broadcast_148_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.4 MB)
[13:09:49,333] INFO  {BlockManagerInfo} Added broadcast_148_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:49,333] INFO  {SparkContext} Created broadcast 148 from broadcast at DAGScheduler.scala:1012
[13:09:49,333] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 143 (MapPartitionsRDD[157] at map at MyLinearRegressionImpl.scala:36)
[13:09:49,333] INFO  {TaskSchedulerImpl} Adding task set 143.0 with 1 tasks
[13:09:49,334] INFO  {TaskSetManager} Starting task 0.0 in stage 143.0 (TID 143, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:49,334] INFO  {Executor} Running task 0.0 in stage 143.0 (TID 143)
[13:09:49,337] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:49,507] INFO  {Executor} Finished task 0.0 in stage 143.0 (TID 143). 1683 bytes result sent to driver
[13:09:49,508] INFO  {TaskSetManager} Finished task 0.0 in stage 143.0 (TID 143) in 174 ms on localhost (1/1)
[13:09:49,508] INFO  {TaskSchedulerImpl} Removed TaskSet 143.0, whose tasks have all completed, from pool 
[13:09:49,508] INFO  {DAGScheduler} ResultStage 143 (count at MyLinearRegressionImpl.scala:26) finished in 0.175 s
[13:09:49,508] INFO  {DAGScheduler} Job 141 finished: count at MyLinearRegressionImpl.scala:26, took 0.178897 s
[13:09:49,510] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:49,511] INFO  {DAGScheduler} Got job 142 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:49,511] INFO  {DAGScheduler} Final stage: ResultStage 144 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:49,511] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:49,511] INFO  {DAGScheduler} Missing parents: List()
[13:09:49,511] INFO  {DAGScheduler} Submitting ResultStage 144 (MapPartitionsRDD[159] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:49,512] INFO  {MemoryStore} Block broadcast_149 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:49,514] INFO  {MemoryStore} Block broadcast_149_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:49,514] INFO  {BlockManagerInfo} Added broadcast_149_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:49,514] INFO  {SparkContext} Created broadcast 149 from broadcast at DAGScheduler.scala:1012
[13:09:49,514] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[159] at map at MyLinearRegressionImpl.scala:54)
[13:09:49,514] INFO  {TaskSchedulerImpl} Adding task set 144.0 with 1 tasks
[13:09:49,515] INFO  {TaskSetManager} Starting task 0.0 in stage 144.0 (TID 144, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:49,515] INFO  {Executor} Running task 0.0 in stage 144.0 (TID 144)
[13:09:49,518] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:49,657] INFO  {Executor} Finished task 0.0 in stage 144.0 (TID 144). 2499 bytes result sent to driver
[13:09:49,658] INFO  {TaskSetManager} Finished task 0.0 in stage 144.0 (TID 144) in 143 ms on localhost (1/1)
[13:09:49,658] INFO  {TaskSchedulerImpl} Removed TaskSet 144.0, whose tasks have all completed, from pool 
[13:09:49,658] INFO  {DAGScheduler} ResultStage 144 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.143 s
[13:09:49,658] INFO  {DAGScheduler} Job 142 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.147679 s
[13:09:49,662] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:49,662] INFO  {DAGScheduler} Got job 143 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:49,662] INFO  {DAGScheduler} Final stage: ResultStage 145 (sum at MyLinearRegressionImpl.scala:24)
[13:09:49,662] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:49,662] INFO  {DAGScheduler} Missing parents: List()
[13:09:49,663] INFO  {DAGScheduler} Submitting ResultStage 145 (MapPartitionsRDD[161] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:49,664] INFO  {MemoryStore} Block broadcast_150 stored as values in memory (estimated size 45.5 KB, free 1128.3 MB)
[13:09:49,665] INFO  {MemoryStore} Block broadcast_150_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:49,666] INFO  {BlockManagerInfo} Added broadcast_150_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:49,666] INFO  {SparkContext} Created broadcast 150 from broadcast at DAGScheduler.scala:1012
[13:09:49,666] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[161] at map at MyLinearRegressionImpl.scala:22)
[13:09:49,666] INFO  {TaskSchedulerImpl} Adding task set 145.0 with 1 tasks
[13:09:49,667] INFO  {TaskSetManager} Starting task 0.0 in stage 145.0 (TID 145, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:49,667] INFO  {Executor} Running task 0.0 in stage 145.0 (TID 145)
[13:09:49,670] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:49,741] INFO  {BlockManagerInfo} Removed broadcast_145_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:49,742] INFO  {BlockManagerInfo} Removed broadcast_146_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:49,743] INFO  {BlockManagerInfo} Removed broadcast_147_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:49,744] INFO  {BlockManagerInfo} Removed broadcast_148_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:49,745] INFO  {BlockManagerInfo} Removed broadcast_149_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:49,818] INFO  {Executor} Finished task 0.0 in stage 145.0 (TID 145). 1758 bytes result sent to driver
[13:09:49,819] INFO  {TaskSetManager} Finished task 0.0 in stage 145.0 (TID 145) in 153 ms on localhost (1/1)
[13:09:49,819] INFO  {TaskSchedulerImpl} Removed TaskSet 145.0, whose tasks have all completed, from pool 
[13:09:49,819] INFO  {DAGScheduler} ResultStage 145 (sum at MyLinearRegressionImpl.scala:24) finished in 0.153 s
[13:09:49,819] INFO  {DAGScheduler} Job 143 finished: sum at MyLinearRegressionImpl.scala:24, took 0.157182 s
[13:09:49,821] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:49,822] INFO  {DAGScheduler} Got job 144 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:49,822] INFO  {DAGScheduler} Final stage: ResultStage 146 (count at MyLinearRegressionImpl.scala:26)
[13:09:49,822] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:49,822] INFO  {DAGScheduler} Missing parents: List()
[13:09:49,822] INFO  {DAGScheduler} Submitting ResultStage 146 (MapPartitionsRDD[160] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:49,823] INFO  {MemoryStore} Block broadcast_151 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:49,824] INFO  {MemoryStore} Block broadcast_151_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:49,824] INFO  {BlockManagerInfo} Added broadcast_151_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:49,825] INFO  {SparkContext} Created broadcast 151 from broadcast at DAGScheduler.scala:1012
[13:09:49,825] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 146 (MapPartitionsRDD[160] at map at MyLinearRegressionImpl.scala:36)
[13:09:49,825] INFO  {TaskSchedulerImpl} Adding task set 146.0 with 1 tasks
[13:09:49,826] INFO  {TaskSetManager} Starting task 0.0 in stage 146.0 (TID 146, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:49,826] INFO  {Executor} Running task 0.0 in stage 146.0 (TID 146)
[13:09:49,831] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:49,974] INFO  {Executor} Finished task 0.0 in stage 146.0 (TID 146). 1770 bytes result sent to driver
[13:09:49,974] INFO  {TaskSetManager} Finished task 0.0 in stage 146.0 (TID 146) in 149 ms on localhost (1/1)
[13:09:49,974] INFO  {TaskSchedulerImpl} Removed TaskSet 146.0, whose tasks have all completed, from pool 
[13:09:49,974] INFO  {DAGScheduler} ResultStage 146 (count at MyLinearRegressionImpl.scala:26) finished in 0.149 s
[13:09:49,975] INFO  {DAGScheduler} Job 144 finished: count at MyLinearRegressionImpl.scala:26, took 0.153262 s
[13:09:49,977] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:49,977] INFO  {DAGScheduler} Got job 145 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:49,977] INFO  {DAGScheduler} Final stage: ResultStage 147 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:49,977] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:49,977] INFO  {DAGScheduler} Missing parents: List()
[13:09:49,977] INFO  {DAGScheduler} Submitting ResultStage 147 (MapPartitionsRDD[162] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:49,978] INFO  {MemoryStore} Block broadcast_152 stored as values in memory (estimated size 45.8 KB, free 1128.5 MB)
[13:09:49,980] INFO  {MemoryStore} Block broadcast_152_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:09:49,980] INFO  {BlockManagerInfo} Added broadcast_152_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:49,980] INFO  {SparkContext} Created broadcast 152 from broadcast at DAGScheduler.scala:1012
[13:09:49,980] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[162] at map at MyLinearRegressionImpl.scala:54)
[13:09:49,980] INFO  {TaskSchedulerImpl} Adding task set 147.0 with 1 tasks
[13:09:49,981] INFO  {TaskSetManager} Starting task 0.0 in stage 147.0 (TID 147, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:49,981] INFO  {Executor} Running task 0.0 in stage 147.0 (TID 147)
[13:09:49,984] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:50,121] INFO  {Executor} Finished task 0.0 in stage 147.0 (TID 147). 2499 bytes result sent to driver
[13:09:50,122] INFO  {TaskSetManager} Finished task 0.0 in stage 147.0 (TID 147) in 141 ms on localhost (1/1)
[13:09:50,122] INFO  {TaskSchedulerImpl} Removed TaskSet 147.0, whose tasks have all completed, from pool 
[13:09:50,122] INFO  {DAGScheduler} ResultStage 147 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.142 s
[13:09:50,122] INFO  {DAGScheduler} Job 145 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.145448 s
[13:09:50,127] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:50,127] INFO  {DAGScheduler} Got job 146 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:50,127] INFO  {DAGScheduler} Final stage: ResultStage 148 (sum at MyLinearRegressionImpl.scala:24)
[13:09:50,127] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:50,127] INFO  {DAGScheduler} Missing parents: List()
[13:09:50,127] INFO  {DAGScheduler} Submitting ResultStage 148 (MapPartitionsRDD[164] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:50,129] INFO  {MemoryStore} Block broadcast_153 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:50,130] INFO  {MemoryStore} Block broadcast_153_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.4 MB)
[13:09:50,130] INFO  {BlockManagerInfo} Added broadcast_153_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:50,131] INFO  {SparkContext} Created broadcast 153 from broadcast at DAGScheduler.scala:1012
[13:09:50,131] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[164] at map at MyLinearRegressionImpl.scala:22)
[13:09:50,131] INFO  {TaskSchedulerImpl} Adding task set 148.0 with 1 tasks
[13:09:50,132] INFO  {TaskSetManager} Starting task 0.0 in stage 148.0 (TID 148, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:50,132] INFO  {Executor} Running task 0.0 in stage 148.0 (TID 148)
[13:09:50,136] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:50,274] INFO  {Executor} Finished task 0.0 in stage 148.0 (TID 148). 1685 bytes result sent to driver
[13:09:50,274] INFO  {TaskSetManager} Finished task 0.0 in stage 148.0 (TID 148) in 143 ms on localhost (1/1)
[13:09:50,274] INFO  {TaskSchedulerImpl} Removed TaskSet 148.0, whose tasks have all completed, from pool 
[13:09:50,275] INFO  {DAGScheduler} ResultStage 148 (sum at MyLinearRegressionImpl.scala:24) finished in 0.144 s
[13:09:50,275] INFO  {DAGScheduler} Job 146 finished: sum at MyLinearRegressionImpl.scala:24, took 0.148203 s
[13:09:50,277] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:50,277] INFO  {DAGScheduler} Got job 147 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:50,277] INFO  {DAGScheduler} Final stage: ResultStage 149 (count at MyLinearRegressionImpl.scala:26)
[13:09:50,277] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:50,277] INFO  {DAGScheduler} Missing parents: List()
[13:09:50,277] INFO  {DAGScheduler} Submitting ResultStage 149 (MapPartitionsRDD[163] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:50,279] INFO  {MemoryStore} Block broadcast_154 stored as values in memory (estimated size 45.0 KB, free 1128.4 MB)
[13:09:50,280] INFO  {MemoryStore} Block broadcast_154_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.3 MB)
[13:09:50,280] INFO  {BlockManagerInfo} Added broadcast_154_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:50,281] INFO  {SparkContext} Created broadcast 154 from broadcast at DAGScheduler.scala:1012
[13:09:50,281] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[163] at map at MyLinearRegressionImpl.scala:36)
[13:09:50,281] INFO  {TaskSchedulerImpl} Adding task set 149.0 with 1 tasks
[13:09:50,282] INFO  {TaskSetManager} Starting task 0.0 in stage 149.0 (TID 149, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:50,282] INFO  {Executor} Running task 0.0 in stage 149.0 (TID 149)
[13:09:50,285] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:50,420] INFO  {Executor} Finished task 0.0 in stage 149.0 (TID 149). 1683 bytes result sent to driver
[13:09:50,420] INFO  {TaskSetManager} Finished task 0.0 in stage 149.0 (TID 149) in 139 ms on localhost (1/1)
[13:09:50,420] INFO  {TaskSchedulerImpl} Removed TaskSet 149.0, whose tasks have all completed, from pool 
[13:09:50,420] INFO  {DAGScheduler} ResultStage 149 (count at MyLinearRegressionImpl.scala:26) finished in 0.139 s
[13:09:50,421] INFO  {DAGScheduler} Job 147 finished: count at MyLinearRegressionImpl.scala:26, took 0.143947 s
[13:09:50,423] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:50,423] INFO  {DAGScheduler} Got job 148 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:50,423] INFO  {DAGScheduler} Final stage: ResultStage 150 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:50,423] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:50,423] INFO  {DAGScheduler} Missing parents: List()
[13:09:50,424] INFO  {DAGScheduler} Submitting ResultStage 150 (MapPartitionsRDD[165] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:50,425] INFO  {MemoryStore} Block broadcast_155 stored as values in memory (estimated size 45.8 KB, free 1128.3 MB)
[13:09:50,427] INFO  {MemoryStore} Block broadcast_155_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.3 MB)
[13:09:50,427] INFO  {BlockManagerInfo} Added broadcast_155_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:50,428] INFO  {SparkContext} Created broadcast 155 from broadcast at DAGScheduler.scala:1012
[13:09:50,429] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[165] at map at MyLinearRegressionImpl.scala:54)
[13:09:50,429] INFO  {TaskSchedulerImpl} Adding task set 150.0 with 1 tasks
[13:09:50,429] INFO  {TaskSetManager} Starting task 0.0 in stage 150.0 (TID 150, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:50,429] INFO  {Executor} Running task 0.0 in stage 150.0 (TID 150)
[13:09:50,432] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:50,464] INFO  {BlockManagerInfo} Removed broadcast_151_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:50,465] INFO  {BlockManagerInfo} Removed broadcast_153_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:50,465] INFO  {BlockManagerInfo} Removed broadcast_150_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:50,466] INFO  {BlockManagerInfo} Removed broadcast_154_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:50,466] INFO  {BlockManagerInfo} Removed broadcast_152_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:50,572] INFO  {Executor} Finished task 0.0 in stage 150.0 (TID 150). 2572 bytes result sent to driver
[13:09:50,573] INFO  {TaskSetManager} Finished task 0.0 in stage 150.0 (TID 150) in 144 ms on localhost (1/1)
[13:09:50,573] INFO  {TaskSchedulerImpl} Removed TaskSet 150.0, whose tasks have all completed, from pool 
[13:09:50,573] INFO  {DAGScheduler} ResultStage 150 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.144 s
[13:09:50,573] INFO  {DAGScheduler} Job 148 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.150418 s
[13:09:50,578] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:50,578] INFO  {DAGScheduler} Got job 149 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:50,578] INFO  {DAGScheduler} Final stage: ResultStage 151 (sum at MyLinearRegressionImpl.scala:24)
[13:09:50,578] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:50,578] INFO  {DAGScheduler} Missing parents: List()
[13:09:50,579] INFO  {DAGScheduler} Submitting ResultStage 151 (MapPartitionsRDD[167] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:50,580] INFO  {MemoryStore} Block broadcast_156 stored as values in memory (estimated size 45.5 KB, free 1128.5 MB)
[13:09:50,582] INFO  {MemoryStore} Block broadcast_156_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.5 MB)
[13:09:50,582] INFO  {BlockManagerInfo} Added broadcast_156_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:50,582] INFO  {SparkContext} Created broadcast 156 from broadcast at DAGScheduler.scala:1012
[13:09:50,583] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 151 (MapPartitionsRDD[167] at map at MyLinearRegressionImpl.scala:22)
[13:09:50,583] INFO  {TaskSchedulerImpl} Adding task set 151.0 with 1 tasks
[13:09:50,583] INFO  {TaskSetManager} Starting task 0.0 in stage 151.0 (TID 151, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:50,584] INFO  {Executor} Running task 0.0 in stage 151.0 (TID 151)
[13:09:50,587] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:50,728] INFO  {Executor} Finished task 0.0 in stage 151.0 (TID 151). 1685 bytes result sent to driver
[13:09:50,729] INFO  {TaskSetManager} Finished task 0.0 in stage 151.0 (TID 151) in 145 ms on localhost (1/1)
[13:09:50,729] INFO  {TaskSchedulerImpl} Removed TaskSet 151.0, whose tasks have all completed, from pool 
[13:09:50,729] INFO  {DAGScheduler} ResultStage 151 (sum at MyLinearRegressionImpl.scala:24) finished in 0.146 s
[13:09:50,729] INFO  {DAGScheduler} Job 149 finished: sum at MyLinearRegressionImpl.scala:24, took 0.151018 s
[13:09:50,731] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:50,731] INFO  {DAGScheduler} Got job 150 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:50,731] INFO  {DAGScheduler} Final stage: ResultStage 152 (count at MyLinearRegressionImpl.scala:26)
[13:09:50,731] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:50,731] INFO  {DAGScheduler} Missing parents: List()
[13:09:50,731] INFO  {DAGScheduler} Submitting ResultStage 152 (MapPartitionsRDD[166] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:50,732] INFO  {MemoryStore} Block broadcast_157 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:50,734] INFO  {MemoryStore} Block broadcast_157_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:50,734] INFO  {BlockManagerInfo} Added broadcast_157_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:50,734] INFO  {SparkContext} Created broadcast 157 from broadcast at DAGScheduler.scala:1012
[13:09:50,734] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[166] at map at MyLinearRegressionImpl.scala:36)
[13:09:50,734] INFO  {TaskSchedulerImpl} Adding task set 152.0 with 1 tasks
[13:09:50,735] INFO  {TaskSetManager} Starting task 0.0 in stage 152.0 (TID 152, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:50,735] INFO  {Executor} Running task 0.0 in stage 152.0 (TID 152)
[13:09:50,738] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:50,876] INFO  {Executor} Finished task 0.0 in stage 152.0 (TID 152). 1683 bytes result sent to driver
[13:09:50,877] INFO  {TaskSetManager} Finished task 0.0 in stage 152.0 (TID 152) in 142 ms on localhost (1/1)
[13:09:50,877] INFO  {TaskSchedulerImpl} Removed TaskSet 152.0, whose tasks have all completed, from pool 
[13:09:50,877] INFO  {DAGScheduler} ResultStage 152 (count at MyLinearRegressionImpl.scala:26) finished in 0.142 s
[13:09:50,877] INFO  {DAGScheduler} Job 150 finished: count at MyLinearRegressionImpl.scala:26, took 0.146719 s
[13:09:50,880] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:09:50,880] INFO  {DAGScheduler} Got job 151 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:09:50,881] INFO  {DAGScheduler} Final stage: ResultStage 153 (reduce at MyLinearRegressionImpl.scala:56)
[13:09:50,881] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:50,881] INFO  {DAGScheduler} Missing parents: List()
[13:09:50,881] INFO  {DAGScheduler} Submitting ResultStage 153 (MapPartitionsRDD[168] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:09:50,882] INFO  {MemoryStore} Block broadcast_158 stored as values in memory (estimated size 45.8 KB, free 1128.4 MB)
[13:09:50,883] INFO  {MemoryStore} Block broadcast_158_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.4 MB)
[13:09:50,883] INFO  {BlockManagerInfo} Added broadcast_158_piece0 in memory on 192.168.0.103:40629 (size: 16.1 KB, free: 1128.8 MB)
[13:09:50,884] INFO  {SparkContext} Created broadcast 158 from broadcast at DAGScheduler.scala:1012
[13:09:50,884] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 153 (MapPartitionsRDD[168] at map at MyLinearRegressionImpl.scala:54)
[13:09:50,884] INFO  {TaskSchedulerImpl} Adding task set 153.0 with 1 tasks
[13:09:50,885] INFO  {TaskSetManager} Starting task 0.0 in stage 153.0 (TID 153, localhost, partition 0, PROCESS_LOCAL, 5960 bytes)
[13:09:50,885] INFO  {Executor} Running task 0.0 in stage 153.0 (TID 153)
[13:09:50,889] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:51,043] INFO  {Executor} Finished task 0.0 in stage 153.0 (TID 153). 2499 bytes result sent to driver
[13:09:51,044] INFO  {TaskSetManager} Finished task 0.0 in stage 153.0 (TID 153) in 160 ms on localhost (1/1)
[13:09:51,044] INFO  {TaskSchedulerImpl} Removed TaskSet 153.0, whose tasks have all completed, from pool 
[13:09:51,044] INFO  {DAGScheduler} ResultStage 153 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.160 s
[13:09:51,044] INFO  {DAGScheduler} Job 151 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.164019 s
[13:09:51,048] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:09:51,048] INFO  {DAGScheduler} Got job 152 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:09:51,048] INFO  {DAGScheduler} Final stage: ResultStage 154 (sum at MyLinearRegressionImpl.scala:24)
[13:09:51,048] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:51,048] INFO  {DAGScheduler} Missing parents: List()
[13:09:51,048] INFO  {DAGScheduler} Submitting ResultStage 154 (MapPartitionsRDD[170] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:09:51,049] INFO  {MemoryStore} Block broadcast_159 stored as values in memory (estimated size 45.5 KB, free 1128.4 MB)
[13:09:51,050] INFO  {MemoryStore} Block broadcast_159_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1128.3 MB)
[13:09:51,050] INFO  {BlockManagerInfo} Added broadcast_159_piece0 in memory on 192.168.0.103:40629 (size: 16.0 KB, free: 1128.8 MB)
[13:09:51,051] INFO  {SparkContext} Created broadcast 159 from broadcast at DAGScheduler.scala:1012
[13:09:51,051] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 154 (MapPartitionsRDD[170] at map at MyLinearRegressionImpl.scala:22)
[13:09:51,051] INFO  {TaskSchedulerImpl} Adding task set 154.0 with 1 tasks
[13:09:51,051] INFO  {TaskSetManager} Starting task 0.0 in stage 154.0 (TID 154, localhost, partition 0, PROCESS_LOCAL, 5957 bytes)
[13:09:51,051] INFO  {Executor} Running task 0.0 in stage 154.0 (TID 154)
[13:09:51,055] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:51,194] INFO  {BlockManagerInfo} Removed broadcast_155_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:51,195] INFO  {BlockManagerInfo} Removed broadcast_156_piece0 on 192.168.0.103:40629 in memory (size: 16.0 KB, free: 1128.8 MB)
[13:09:51,195] INFO  {BlockManagerInfo} Removed broadcast_157_piece0 on 192.168.0.103:40629 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:09:51,195] INFO  {Executor} Finished task 0.0 in stage 154.0 (TID 154). 1758 bytes result sent to driver
[13:09:51,195] INFO  {BlockManagerInfo} Removed broadcast_158_piece0 on 192.168.0.103:40629 in memory (size: 16.1 KB, free: 1128.8 MB)
[13:09:51,196] INFO  {TaskSetManager} Finished task 0.0 in stage 154.0 (TID 154) in 145 ms on localhost (1/1)
[13:09:51,196] INFO  {TaskSchedulerImpl} Removed TaskSet 154.0, whose tasks have all completed, from pool 
[13:09:51,196] INFO  {DAGScheduler} ResultStage 154 (sum at MyLinearRegressionImpl.scala:24) finished in 0.145 s
[13:09:51,196] INFO  {DAGScheduler} Job 152 finished: sum at MyLinearRegressionImpl.scala:24, took 0.148517 s
[13:09:51,198] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:09:51,198] INFO  {DAGScheduler} Got job 153 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:09:51,198] INFO  {DAGScheduler} Final stage: ResultStage 155 (count at MyLinearRegressionImpl.scala:26)
[13:09:51,198] INFO  {DAGScheduler} Parents of final stage: List()
[13:09:51,198] INFO  {DAGScheduler} Missing parents: List()
[13:09:51,198] INFO  {DAGScheduler} Submitting ResultStage 155 (MapPartitionsRDD[169] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:09:51,199] INFO  {MemoryStore} Block broadcast_160 stored as values in memory (estimated size 45.0 KB, free 1128.5 MB)
[13:09:51,201] INFO  {MemoryStore} Block broadcast_160_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.5 MB)
[13:09:51,201] INFO  {BlockManagerInfo} Added broadcast_160_piece0 in memory on 192.168.0.103:40629 (size: 15.8 KB, free: 1128.8 MB)
[13:09:51,201] INFO  {SparkContext} Created broadcast 160 from broadcast at DAGScheduler.scala:1012
[13:09:51,201] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 155 (MapPartitionsRDD[169] at map at MyLinearRegressionImpl.scala:36)
[13:09:51,201] INFO  {TaskSchedulerImpl} Adding task set 155.0 with 1 tasks
[13:09:51,202] INFO  {TaskSetManager} Starting task 0.0 in stage 155.0 (TID 155, localhost, partition 0, PROCESS_LOCAL, 5875 bytes)
[13:09:51,202] INFO  {Executor} Running task 0.0 in stage 155.0 (TID 155)
[13:09:51,205] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[13:09:51,228] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:09:51,233] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:09:51,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[13:09:51,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[13:09:51,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[13:09:51,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[13:09:51,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[13:09:51,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[13:09:51,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[13:09:51,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[13:09:51,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[13:09:51,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[13:09:51,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[13:09:51,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[13:09:51,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[13:09:51,238] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[13:09:51,238] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[13:09:51,238] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[13:09:51,238] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[13:09:51,238] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[13:09:51,238] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[13:09:51,238] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[13:09:51,238] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[13:09:51,239] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[13:09:51,239] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[13:09:51,239] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[13:09:51,241] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:09:51,247] INFO  {DAGScheduler} Job 153 failed: count at MyLinearRegressionImpl.scala:26, took 0.049689 s
[13:09:51,248] INFO  {DAGScheduler} ResultStage 155 (count at MyLinearRegressionImpl.scala:26) failed in 0.046 s
[13:09:51,249] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@78f4aa60)
[13:09:51,251] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(153,1511093391249,JobFailed(org.apache.spark.SparkException: Job 153 cancelled because SparkContext was shut down))
[13:09:51,255] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:09:51,264] INFO  {MemoryStore} MemoryStore cleared
[13:09:51,264] INFO  {BlockManager} BlockManager stopped
[13:09:51,264] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:09:51,267] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:09:51,268] INFO  {SparkContext} Successfully stopped SparkContext
[13:09:51,269] INFO  {ShutdownHookManager} Shutdown hook called
[13:09:51,269] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-af5f0053-a831-4c26-8957-eed7a7d0c657
[13:09:58,255] INFO  {SparkContext} Running Spark version 2.0.1
[13:09:58,848] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:09:59,094] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:09:59,096] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:09:59,277] INFO  {SecurityManager} Changing view acls to: victor
[13:09:59,279] INFO  {SecurityManager} Changing modify acls to: victor
[13:09:59,282] INFO  {SecurityManager} Changing view acls groups to: 
[13:09:59,285] INFO  {SecurityManager} Changing modify acls groups to: 
[13:09:59,287] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:10:00,126] INFO  {Utils} Successfully started service 'sparkDriver' on port 33997.
[13:10:00,162] INFO  {SparkEnv} Registering MapOutputTracker
[13:10:00,196] INFO  {SparkEnv} Registering BlockManagerMaster
[13:10:00,225] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-de7425d8-c2ed-4f58-a3c9-3b1b11ceaab6
[13:10:00,263] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:10:00,359] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:10:00,529] INFO  {log} Logging initialized @3779ms
[13:10:00,751] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:10:00,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[13:10:00,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[13:10:00,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[13:10:00,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[13:10:00,788] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[13:10:00,788] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[13:10:00,789] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[13:10:00,789] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[13:10:00,789] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[13:10:00,790] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[13:10:00,790] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[13:10:00,791] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[13:10:00,791] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[13:10:00,792] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[13:10:00,792] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[13:10:00,792] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[13:10:00,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[13:10:00,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[13:10:00,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[13:10:00,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[13:10:00,805] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[13:10:00,806] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[13:10:00,807] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[13:10:00,808] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[13:10:00,818] INFO  {ServerConnector} Started ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:10:00,819] INFO  {Server} Started @4071ms
[13:10:00,819] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:10:00,822] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:10:01,003] INFO  {Executor} Starting executor ID driver on host localhost
[13:10:01,048] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41017.
[13:10:01,049] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:41017
[13:10:01,052] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 41017)
[13:10:01,059] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:41017 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 41017)
[13:10:01,067] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 41017)
[13:10:01,417] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[13:10:02,575] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[13:10:02,687] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:10:02,692] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:41017 (size: 14.6 KB, free: 1128.9 MB)
[13:10:02,701] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:30
[13:10:05,765] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b7f06c7{/SQL,null,AVAILABLE}
[13:10:05,767] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@729c8063{/SQL/json,null,AVAILABLE}
[13:10:05,768] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31e739bf{/SQL/execution,null,AVAILABLE}
[13:10:05,769] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7743ec{/SQL/execution/json,null,AVAILABLE}
[13:10:05,773] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@316cda31{/static/sql,null,AVAILABLE}
[13:10:05,827] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:10:07,627] INFO  {CodeGenerator} Code generated in 373.373989 ms
[13:10:07,691] INFO  {FileInputFormat} Total input paths to process : 1
[13:10:07,692] INFO  {FileInputFormat} Total input paths to process : 1
[13:10:07,704] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[13:10:07,711] INFO  {SparkContext} Starting job: show at Main.scala:42
[13:10:07,725] INFO  {DAGScheduler} Got job 0 (show at Main.scala:42) with 1 output partitions
[13:10:07,725] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:42)
[13:10:07,726] INFO  {DAGScheduler} Parents of final stage: List()
[13:10:07,727] INFO  {DAGScheduler} Missing parents: List()
[13:10:07,732] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[7] at show at Main.scala:42), which has no missing parents
[13:10:07,749] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 14.3 KB, free 1128.7 MB)
[13:10:07,753] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1128.7 MB)
[13:10:07,754] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:41017 (size: 6.8 KB, free: 1128.9 MB)
[13:10:07,755] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:10:07,760] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at show at Main.scala:42)
[13:10:07,762] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:10:07,802] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5474 bytes)
[13:10:07,810] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:10:07,839] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[13:10:07,867] INFO  {CodeGenerator} Code generated in 14.191679 ms
[13:10:07,890] INFO  {CodeGenerator} Code generated in 17.46415 ms
[13:10:07,906] INFO  {CodeGenerator} Code generated in 8.097812 ms
[13:10:07,961] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[13:10:07,967] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[13:10:07,968] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[13:10:07,971] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[13:10:07,994] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 1674 bytes result sent to driver
[13:10:08,001] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 217 ms on localhost (1/1)
[13:10:08,002] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:10:08,006] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:42) finished in 0.235 s
[13:10:08,010] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:42, took 0.298887 s
[13:10:08,099] INFO  {CodeGenerator} Code generated in 10.42306 ms
[13:10:08,131] INFO  {CodeGenerator} Code generated in 26.056968 ms
[13:10:08,173] INFO  {SparkContext} Starting job: foreach at Main.scala:45
[13:10:08,177] INFO  {DAGScheduler} Registering RDD 10 (foreach at Main.scala:45)
[13:10:08,178] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:45) with 1 output partitions
[13:10:08,178] INFO  {DAGScheduler} Final stage: ResultStage 2 (foreach at Main.scala:45)
[13:10:08,178] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 1)
[13:10:08,178] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 1)
[13:10:08,180] INFO  {DAGScheduler} Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:45), which has no missing parents
[13:10:08,193] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 16.5 KB, free 1128.7 MB)
[13:10:08,195] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.7 KB, free 1128.7 MB)
[13:10:08,196] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:41017 (size: 7.7 KB, free: 1128.9 MB)
[13:10:08,197] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[13:10:08,198] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:45)
[13:10:08,198] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:10:08,202] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5548 bytes)
[13:10:08,203] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:10:08,212] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[13:10:08,279] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1881 bytes result sent to driver
[13:10:08,282] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 83 ms on localhost (1/1)
[13:10:08,282] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:10:08,283] INFO  {DAGScheduler} ShuffleMapStage 1 (foreach at Main.scala:45) finished in 0.084 s
[13:10:08,283] INFO  {DAGScheduler} looking for newly runnable stages
[13:10:08,284] INFO  {DAGScheduler} running: Set()
[13:10:08,284] INFO  {DAGScheduler} waiting: Set(ResultStage 2)
[13:10:08,285] INFO  {DAGScheduler} failed: Set()
[13:10:08,286] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[14] at foreach at Main.scala:45), which has no missing parents
[13:10:08,299] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 14.8 KB, free 1128.7 MB)
[13:10:08,302] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.4 KB, free 1128.7 MB)
[13:10:08,303] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:41017 (size: 7.4 KB, free: 1128.9 MB)
[13:10:08,304] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[13:10:08,304] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at foreach at Main.scala:45)
[13:10:08,304] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:10:08,306] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5317 bytes)
[13:10:08,307] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:10:08,324] INFO  {ShuffleBlockFetcherIterator} Getting 0 non-empty blocks out of 1 blocks
[13:10:08,326] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[13:10:08,352] INFO  {CodeGenerator} Code generated in 13.506953 ms
[13:10:08,360] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 2222 bytes result sent to driver
[13:10:08,363] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 57 ms on localhost (1/1)
[13:10:08,363] INFO  {DAGScheduler} ResultStage 2 (foreach at Main.scala:45) finished in 0.059 s
[13:10:08,363] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:10:08,364] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:45, took 0.189796 s
[13:10:08,585] INFO  {ContextCleaner} Cleaned accumulator 0
[13:10:08,585] INFO  {ContextCleaner} Cleaned accumulator 1
[13:10:08,585] INFO  {ContextCleaner} Cleaned accumulator 2
[13:10:08,585] INFO  {ContextCleaner} Cleaned accumulator 3
[13:10:08,585] INFO  {ContextCleaner} Cleaned accumulator 4
[13:10:08,585] INFO  {ContextCleaner} Cleaned accumulator 5
[13:10:08,606] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:41017 in memory (size: 6.8 KB, free: 1128.9 MB)
[13:10:08,609] INFO  {ContextCleaner} Cleaned accumulator 50
[13:10:08,610] INFO  {ContextCleaner} Cleaned accumulator 51
[13:10:08,610] INFO  {ContextCleaner} Cleaned accumulator 52
[13:10:08,610] INFO  {ContextCleaner} Cleaned accumulator 53
[13:10:08,610] INFO  {ContextCleaner} Cleaned accumulator 54
[13:10:08,610] INFO  {ContextCleaner} Cleaned accumulator 55
[13:10:08,610] INFO  {ContextCleaner} Cleaned accumulator 56
[13:10:08,610] INFO  {ContextCleaner} Cleaned accumulator 57
[13:10:08,610] INFO  {ContextCleaner} Cleaned accumulator 58
[13:10:08,611] INFO  {ContextCleaner} Cleaned accumulator 59
[13:10:08,611] INFO  {ContextCleaner} Cleaned accumulator 60
[13:10:08,611] INFO  {ContextCleaner} Cleaned accumulator 61
[13:10:08,611] INFO  {ContextCleaner} Cleaned accumulator 62
[13:10:08,611] INFO  {ContextCleaner} Cleaned accumulator 63
[13:10:08,611] INFO  {ContextCleaner} Cleaned accumulator 64
[13:10:08,616] INFO  {ContextCleaner} Cleaned shuffle 0
[13:10:08,619] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:41017 in memory (size: 7.7 KB, free: 1128.9 MB)
[13:10:08,621] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:41017 in memory (size: 7.4 KB, free: 1128.9 MB)
[13:10:08,801] INFO  {CodeGenerator} Code generated in 11.62672 ms
[13:10:08,840] INFO  {CodeGenerator} Code generated in 30.554505 ms
[13:10:08,891] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[13:10:08,892] INFO  {DAGScheduler} Registering RDD 17 (collect at PipelineBuilder.scala:59)
[13:10:08,892] INFO  {DAGScheduler} Got job 2 (collect at PipelineBuilder.scala:59) with 1 output partitions
[13:10:08,892] INFO  {DAGScheduler} Final stage: ResultStage 4 (collect at PipelineBuilder.scala:59)
[13:10:08,892] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 3)
[13:10:08,892] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 3)
[13:10:08,893] INFO  {DAGScheduler} Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:10:08,896] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 30.9 KB, free 1128.7 MB)
[13:10:08,898] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.7 KB, free 1128.7 MB)
[13:10:08,898] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:41017 (size: 12.7 KB, free: 1128.9 MB)
[13:10:08,899] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[13:10:08,899] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at PipelineBuilder.scala:59)
[13:10:08,899] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[13:10:08,901] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5548 bytes)
[13:10:08,901] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[13:10:08,913] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[13:10:08,959] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 2406 bytes result sent to driver
[13:10:08,961] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 62 ms on localhost (1/1)
[13:10:08,961] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[13:10:08,962] INFO  {DAGScheduler} ShuffleMapStage 3 (collect at PipelineBuilder.scala:59) finished in 0.063 s
[13:10:08,962] INFO  {DAGScheduler} looking for newly runnable stages
[13:10:08,962] INFO  {DAGScheduler} running: Set()
[13:10:08,962] INFO  {DAGScheduler} waiting: Set(ResultStage 4)
[13:10:08,962] INFO  {DAGScheduler} failed: Set()
[13:10:08,962] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:10:08,967] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[13:10:08,968] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[13:10:08,969] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:41017 (size: 3.9 KB, free: 1128.9 MB)
[13:10:08,969] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[13:10:08,969] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at PipelineBuilder.scala:59)
[13:10:08,969] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[13:10:08,973] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, ANY, 5317 bytes)
[13:10:08,973] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[13:10:08,976] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:10:08,976] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[13:10:08,988] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1867 bytes result sent to driver
[13:10:08,990] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 18 ms on localhost (1/1)
[13:10:08,991] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[13:10:08,991] INFO  {DAGScheduler} ResultStage 4 (collect at PipelineBuilder.scala:59) finished in 0.020 s
[13:10:08,992] INFO  {DAGScheduler} Job 2 finished: collect at PipelineBuilder.scala:59, took 0.100418 s
[13:10:09,005] INFO  {CodeGenerator} Code generated in 7.583077 ms
[13:10:09,228] INFO  {CodeGenerator} Code generated in 57.150161 ms
[13:10:09,247] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:63
[13:10:09,248] INFO  {DAGScheduler} Got job 3 (count at MyLinearRegressionImpl.scala:63) with 1 output partitions
[13:10:09,248] INFO  {DAGScheduler} Final stage: ResultStage 5 (count at MyLinearRegressionImpl.scala:63)
[13:10:09,248] INFO  {DAGScheduler} Parents of final stage: List()
[13:10:09,248] INFO  {DAGScheduler} Missing parents: List()
[13:10:09,249] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[25] at map at MyLinearRegressionImpl.scala:92), which has no missing parents
[13:10:09,259] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 45.1 KB, free 1128.7 MB)
[13:10:09,262] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.6 KB, free 1128.6 MB)
[13:10:09,262] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:41017 (size: 15.6 KB, free: 1128.9 MB)
[13:10:09,263] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[13:10:09,263] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at map at MyLinearRegressionImpl.scala:92)
[13:10:09,263] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[13:10:09,265] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5445 bytes)
[13:10:09,265] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[13:10:09,270] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[13:10:09,289] INFO  {CodeGenerator} Code generated in 7.593866 ms
[13:10:09,315] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1770 bytes result sent to driver
[13:10:09,316] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 51 ms on localhost (1/1)
[13:10:09,316] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[13:10:09,316] INFO  {DAGScheduler} ResultStage 5 (count at MyLinearRegressionImpl.scala:63) finished in 0.053 s
[13:10:09,317] INFO  {DAGScheduler} Job 3 finished: count at MyLinearRegressionImpl.scala:63, took 0.069501 s
[13:10:09,328] INFO  {SparkContext} Starting job: take at MyLinearRegressionImpl.scala:64
[13:10:09,329] INFO  {DAGScheduler} Got job 4 (take at MyLinearRegressionImpl.scala:64) with 1 output partitions
[13:10:09,329] INFO  {DAGScheduler} Final stage: ResultStage 6 (take at MyLinearRegressionImpl.scala:64)
[13:10:09,329] INFO  {DAGScheduler} Parents of final stage: List()
[13:10:09,329] INFO  {DAGScheduler} Missing parents: List()
[13:10:09,330] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[25] at map at MyLinearRegressionImpl.scala:92), which has no missing parents
[13:10:09,334] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 45.2 KB, free 1128.6 MB)
[13:10:09,336] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.7 KB, free 1128.6 MB)
[13:10:09,337] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:41017 (size: 15.7 KB, free: 1128.8 MB)
[13:10:09,337] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[13:10:09,338] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at map at MyLinearRegressionImpl.scala:92)
[13:10:09,338] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[13:10:09,340] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5527 bytes)
[13:10:09,340] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[13:10:09,346] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[13:10:09,380] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1661 bytes result sent to driver
[13:10:09,383] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 44 ms on localhost (1/1)
[13:10:09,383] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[13:10:09,384] INFO  {DAGScheduler} ResultStage 6 (take at MyLinearRegressionImpl.scala:64) finished in 0.046 s
[13:10:09,384] INFO  {DAGScheduler} Job 4 finished: take at MyLinearRegressionImpl.scala:64, took 0.056429 s
[13:10:09,389] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:10:09,402] INFO  {ServerConnector} Stopped ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:10:09,405] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[13:10:09,406] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[13:10:09,406] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[13:10:09,406] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[13:10:09,407] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[13:10:09,407] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[13:10:09,407] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[13:10:09,407] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[13:10:09,408] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[13:10:09,408] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[13:10:09,408] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[13:10:09,408] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[13:10:09,408] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[13:10:09,408] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[13:10:09,408] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[13:10:09,409] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[13:10:09,409] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[13:10:09,409] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[13:10:09,409] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[13:10:09,409] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[13:10:09,409] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[13:10:09,409] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[13:10:09,410] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[13:10:09,410] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[13:10:09,412] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:10:09,424] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:10:09,432] INFO  {MemoryStore} MemoryStore cleared
[13:10:09,433] INFO  {BlockManager} BlockManager stopped
[13:10:09,435] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:10:09,438] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:10:09,446] INFO  {SparkContext} Successfully stopped SparkContext
[13:10:09,447] INFO  {ShutdownHookManager} Shutdown hook called
[13:10:09,448] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-701698a7-c948-413a-aaf1-3aec48a36a79
[13:10:22,514] INFO  {SparkContext} Running Spark version 2.0.1
[13:10:22,735] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:10:22,852] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:10:22,853] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:10:22,953] INFO  {SecurityManager} Changing view acls to: victor
[13:10:22,954] INFO  {SecurityManager} Changing modify acls to: victor
[13:10:22,955] INFO  {SecurityManager} Changing view acls groups to: 
[13:10:22,956] INFO  {SecurityManager} Changing modify acls groups to: 
[13:10:22,957] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:10:23,337] INFO  {Utils} Successfully started service 'sparkDriver' on port 43021.
[13:10:23,356] INFO  {SparkEnv} Registering MapOutputTracker
[13:10:23,371] INFO  {SparkEnv} Registering BlockManagerMaster
[13:10:23,384] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-9d3033b0-d2f3-484f-9e14-efce085cf7dd
[13:10:23,400] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:10:23,459] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:10:23,642] INFO  {log} Logging initialized @1806ms
[13:10:23,867] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:10:23,901] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[13:10:23,901] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[13:10:23,902] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[13:10:23,902] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[13:10:23,903] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[13:10:23,903] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[13:10:23,904] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[13:10:23,904] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[13:10:23,904] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[13:10:23,905] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[13:10:23,905] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[13:10:23,906] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[13:10:23,906] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[13:10:23,907] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[13:10:23,907] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[13:10:23,907] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[13:10:23,908] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[13:10:23,908] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[13:10:23,909] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[13:10:23,909] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[13:10:23,920] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[13:10:23,921] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[13:10:23,923] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[13:10:23,924] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[13:10:23,939] INFO  {ServerConnector} Started ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:10:23,940] INFO  {Server} Started @2106ms
[13:10:23,940] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:10:23,943] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:10:24,110] INFO  {Executor} Starting executor ID driver on host localhost
[13:10:24,163] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46373.
[13:10:24,164] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:46373
[13:10:24,168] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 46373)
[13:10:24,173] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:46373 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 46373)
[13:10:24,181] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 46373)
[13:10:24,528] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[13:10:25,604] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[13:10:25,726] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:10:25,731] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:46373 (size: 14.6 KB, free: 1128.9 MB)
[13:10:25,738] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:30
[13:10:28,809] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b7f06c7{/SQL,null,AVAILABLE}
[13:10:28,810] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@729c8063{/SQL/json,null,AVAILABLE}
[13:10:28,811] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31e739bf{/SQL/execution,null,AVAILABLE}
[13:10:28,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7743ec{/SQL/execution/json,null,AVAILABLE}
[13:10:28,815] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@316cda31{/static/sql,null,AVAILABLE}
[13:10:28,869] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:10:30,230] INFO  {CodeGenerator} Code generated in 208.577801 ms
[13:10:30,358] INFO  {FileInputFormat} Total input paths to process : 2
[13:10:30,360] INFO  {FileInputFormat} Total input paths to process : 2
[13:10:30,373] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[13:10:30,381] INFO  {SparkContext} Starting job: show at Main.scala:42
[13:10:30,395] INFO  {DAGScheduler} Got job 0 (show at Main.scala:42) with 1 output partitions
[13:10:30,396] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:42)
[13:10:30,396] INFO  {DAGScheduler} Parents of final stage: List()
[13:10:30,397] INFO  {DAGScheduler} Missing parents: List()
[13:10:30,404] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[7] at show at Main.scala:42), which has no missing parents
[13:10:30,422] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 14.4 KB, free 1128.7 MB)
[13:10:30,424] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1128.7 MB)
[13:10:30,424] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:46373 (size: 6.8 KB, free: 1128.9 MB)
[13:10:30,425] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:10:30,428] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at show at Main.scala:42)
[13:10:30,430] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:10:30,472] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5523 bytes)
[13:10:30,478] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:10:30,516] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:10:30,537] INFO  {CodeGenerator} Code generated in 10.101601 ms
[13:10:30,557] INFO  {CodeGenerator} Code generated in 14.267845 ms
[13:10:30,571] INFO  {CodeGenerator} Code generated in 7.785587 ms
[13:10:30,616] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[13:10:30,622] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[13:10:30,623] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[13:10:30,626] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[13:10:30,962] INFO  {CodeGenerator} Code generated in 9.087218 ms
[13:10:31,658] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 929926 bytes result sent to driver
[13:10:31,669] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 1215 ms on localhost (1/1)
[13:10:31,671] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:10:31,675] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:42) finished in 1.236 s
[13:10:31,681] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:42, took 1.299356 s
[13:10:31,706] INFO  {CodeGenerator} Code generated in 10.453128 ms
[13:10:31,788] INFO  {CodeGenerator} Code generated in 9.131766 ms
[13:10:31,815] INFO  {CodeGenerator} Code generated in 21.752955 ms
[13:10:31,856] INFO  {SparkContext} Starting job: foreach at Main.scala:45
[13:10:31,859] INFO  {DAGScheduler} Registering RDD 10 (foreach at Main.scala:45)
[13:10:31,860] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:45) with 1 output partitions
[13:10:31,860] INFO  {DAGScheduler} Final stage: ResultStage 2 (foreach at Main.scala:45)
[13:10:31,860] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 1)
[13:10:31,860] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 1)
[13:10:31,861] INFO  {DAGScheduler} Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:45), which has no missing parents
[13:10:31,871] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 16.5 KB, free 1128.7 MB)
[13:10:31,873] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.7 KB, free 1128.7 MB)
[13:10:31,873] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:46373 (size: 7.7 KB, free: 1128.9 MB)
[13:10:31,874] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[13:10:31,876] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:45)
[13:10:31,876] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:10:31,880] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:10:31,880] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:10:31,895] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:10:32,187] INFO  {ContextCleaner} Cleaned accumulator 56
[13:10:32,462] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2223 bytes result sent to driver
[13:10:32,465] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 588 ms on localhost (1/1)
[13:10:32,466] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:10:32,467] INFO  {DAGScheduler} ShuffleMapStage 1 (foreach at Main.scala:45) finished in 0.590 s
[13:10:32,467] INFO  {DAGScheduler} looking for newly runnable stages
[13:10:32,468] INFO  {DAGScheduler} running: Set()
[13:10:32,468] INFO  {DAGScheduler} waiting: Set(ResultStage 2)
[13:10:32,469] INFO  {DAGScheduler} failed: Set()
[13:10:32,470] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[14] at foreach at Main.scala:45), which has no missing parents
[13:10:32,486] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 14.8 KB, free 1128.7 MB)
[13:10:32,488] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.4 KB, free 1128.7 MB)
[13:10:32,489] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:46373 (size: 7.4 KB, free: 1128.9 MB)
[13:10:32,489] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[13:10:32,490] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at foreach at Main.scala:45)
[13:10:32,490] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:10:32,494] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5317 bytes)
[13:10:32,494] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:10:32,516] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:10:32,517] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[13:10:32,567] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 2222 bytes result sent to driver
[13:10:32,569] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 77 ms on localhost (1/1)
[13:10:32,569] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:10:32,570] INFO  {DAGScheduler} ResultStage 2 (foreach at Main.scala:45) finished in 0.078 s
[13:10:32,570] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:45, took 0.714506 s
[13:10:32,782] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:46373 in memory (size: 7.4 KB, free: 1128.9 MB)
[13:10:32,843] INFO  {CodeGenerator} Code generated in 14.19036 ms
[13:10:32,889] INFO  {CodeGenerator} Code generated in 36.816503 ms
[13:10:32,946] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[13:10:32,947] INFO  {DAGScheduler} Registering RDD 17 (collect at PipelineBuilder.scala:59)
[13:10:32,947] INFO  {DAGScheduler} Got job 2 (collect at PipelineBuilder.scala:59) with 1 output partitions
[13:10:32,947] INFO  {DAGScheduler} Final stage: ResultStage 4 (collect at PipelineBuilder.scala:59)
[13:10:32,947] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 3)
[13:10:32,947] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 3)
[13:10:32,948] INFO  {DAGScheduler} Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:10:32,950] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 30.9 KB, free 1128.7 MB)
[13:10:32,952] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.6 KB, free 1128.7 MB)
[13:10:32,952] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:46373 (size: 12.6 KB, free: 1128.9 MB)
[13:10:32,953] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[13:10:32,953] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at PipelineBuilder.scala:59)
[13:10:32,953] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[13:10:32,955] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:10:32,956] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[13:10:32,967] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:10:33,995] INFO  {ContextCleaner} Cleaned accumulator 153
[13:10:34,442] ERROR {Executor} Exception in task 0.0 in stage 3.0 (TID 3)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "0.419193351817
2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more
[13:10:34,481] WARN  {TaskSetManager} Lost task 0.0 in stage 3.0 (TID 3, localhost): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "0.419193351817
2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more

[13:10:34,483] ERROR {TaskSetManager} Task 0 in stage 3.0 failed 1 times; aborting job
[13:10:34,484] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[13:10:34,491] INFO  {TaskSchedulerImpl} Cancelling stage 3
[13:10:34,493] INFO  {DAGScheduler} ShuffleMapStage 3 (collect at PipelineBuilder.scala:59) failed in 1.538 s
[13:10:34,494] INFO  {DAGScheduler} Job 2 failed: collect at PipelineBuilder.scala:59, took 1.548550 s
[13:10:34,504] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:10:34,512] INFO  {ServerConnector} Stopped ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:10:34,516] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[13:10:34,516] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[13:10:34,517] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[13:10:34,517] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[13:10:34,517] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[13:10:34,517] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[13:10:34,518] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[13:10:34,518] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[13:10:34,518] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[13:10:34,518] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[13:10:34,519] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[13:10:34,519] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[13:10:34,519] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[13:10:34,519] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[13:10:34,519] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[13:10:34,520] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[13:10:34,520] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[13:10:34,520] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[13:10:34,520] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[13:10:34,521] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[13:10:34,521] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[13:10:34,521] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[13:10:34,521] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[13:10:34,521] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[13:10:34,524] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:10:34,541] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:10:34,551] INFO  {MemoryStore} MemoryStore cleared
[13:10:34,552] INFO  {BlockManager} BlockManager stopped
[13:10:34,555] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:10:34,559] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:10:34,562] INFO  {SparkContext} Successfully stopped SparkContext
[13:10:34,563] INFO  {ShutdownHookManager} Shutdown hook called
[13:10:34,565] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-d94b9cf1-3350-46fa-a745-6ab0ef3b8327
[13:11:48,684] INFO  {SparkContext} Running Spark version 2.0.1
[13:11:48,934] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:11:49,049] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:11:49,050] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:11:49,146] INFO  {SecurityManager} Changing view acls to: victor
[13:11:49,147] INFO  {SecurityManager} Changing modify acls to: victor
[13:11:49,148] INFO  {SecurityManager} Changing view acls groups to: 
[13:11:49,148] INFO  {SecurityManager} Changing modify acls groups to: 
[13:11:49,149] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:11:49,807] INFO  {Utils} Successfully started service 'sparkDriver' on port 37765.
[13:11:49,849] INFO  {SparkEnv} Registering MapOutputTracker
[13:11:49,885] INFO  {SparkEnv} Registering BlockManagerMaster
[13:11:49,915] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-8691ad5d-62a8-4a7f-92bb-b13e5c7d32eb
[13:11:49,955] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:11:50,080] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:11:50,268] INFO  {log} Logging initialized @2220ms
[13:11:50,506] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:11:50,545] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@628c4ac0{/jobs,null,AVAILABLE}
[13:11:50,546] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7b84fcf8{/jobs/json,null,AVAILABLE}
[13:11:50,546] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30b19518{/jobs/job,null,AVAILABLE}
[13:11:50,548] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@363042d7{/jobs/job/json,null,AVAILABLE}
[13:11:50,549] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@366ac49b{/stages,null,AVAILABLE}
[13:11:50,550] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ad59d92{/stages/json,null,AVAILABLE}
[13:11:50,550] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56f0cc85{/stages/stage,null,AVAILABLE}
[13:11:50,551] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62e20a76{/stages/stage/json,null,AVAILABLE}
[13:11:50,552] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2cc44ad{/stages/pool,null,AVAILABLE}
[13:11:50,552] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@44b3606b{/stages/pool/json,null,AVAILABLE}
[13:11:50,553] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1477089c{/storage,null,AVAILABLE}
[13:11:50,554] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@663411de{/storage/json,null,AVAILABLE}
[13:11:50,554] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@63dd899{/storage/rdd,null,AVAILABLE}
[13:11:50,555] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59d2400d{/storage/rdd/json,null,AVAILABLE}
[13:11:50,555] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@75cd8043{/environment,null,AVAILABLE}
[13:11:50,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@33b1c5c5{/environment/json,null,AVAILABLE}
[13:11:50,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5b202a3a{/executors,null,AVAILABLE}
[13:11:50,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10b9db7b{/executors/json,null,AVAILABLE}
[13:11:50,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@9ef8eb7{/executors/threadDump,null,AVAILABLE}
[13:11:50,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@34cdeda2{/executors/threadDump/json,null,AVAILABLE}
[13:11:50,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ee660fb{/static,null,AVAILABLE}
[13:11:50,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@305a0c5f{/,null,AVAILABLE}
[13:11:50,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4535b6d5{/api,null,AVAILABLE}
[13:11:50,572] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1ecee32c{/stages/stage/kill,null,AVAILABLE}
[13:11:50,584] INFO  {ServerConnector} Started ServerConnector@2dd80673{HTTP/1.1}{0.0.0.0:4040}
[13:11:50,585] INFO  {Server} Started @2540ms
[13:11:50,585] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:11:50,590] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:11:50,775] INFO  {Executor} Starting executor ID driver on host localhost
[13:11:50,822] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33363.
[13:11:50,824] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:33363
[13:11:50,827] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 33363)
[13:11:50,834] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:33363 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 33363)
[13:11:50,843] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 33363)
[13:11:51,213] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[13:11:52,364] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[13:11:52,517] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:11:52,523] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:33363 (size: 14.6 KB, free: 1128.9 MB)
[13:11:52,534] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:30
[13:11:54,703] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b7f06c7{/SQL,null,AVAILABLE}
[13:11:54,704] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@729c8063{/SQL/json,null,AVAILABLE}
[13:11:54,704] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31e739bf{/SQL/execution,null,AVAILABLE}
[13:11:54,705] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7743ec{/SQL/execution/json,null,AVAILABLE}
[13:11:54,706] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@316cda31{/static/sql,null,AVAILABLE}
[13:11:54,730] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:11:55,541] INFO  {CodeGenerator} Code generated in 213.50391 ms
[13:11:55,608] INFO  {FileInputFormat} Total input paths to process : 2
[13:11:55,611] INFO  {FileInputFormat} Total input paths to process : 2
[13:11:55,642] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[13:11:55,653] INFO  {SparkContext} Starting job: show at Main.scala:42
[13:11:55,669] INFO  {DAGScheduler} Got job 0 (show at Main.scala:42) with 1 output partitions
[13:11:55,670] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:42)
[13:11:55,671] INFO  {DAGScheduler} Parents of final stage: List()
[13:11:55,672] INFO  {DAGScheduler} Missing parents: List()
[13:11:55,678] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[7] at show at Main.scala:42), which has no missing parents
[13:11:55,694] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 14.4 KB, free 1128.7 MB)
[13:11:55,696] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1128.7 MB)
[13:11:55,697] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:33363 (size: 6.8 KB, free: 1128.9 MB)
[13:11:55,698] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:11:55,704] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at show at Main.scala:42)
[13:11:55,706] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:11:55,749] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5523 bytes)
[13:11:55,754] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:11:55,784] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:11:55,806] INFO  {CodeGenerator} Code generated in 10.558613 ms
[13:11:55,828] INFO  {CodeGenerator} Code generated in 15.45759 ms
[13:11:55,842] INFO  {CodeGenerator} Code generated in 7.853306 ms
[13:11:55,885] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[13:11:55,890] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[13:11:55,891] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[13:11:55,894] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[13:11:56,136] INFO  {CodeGenerator} Code generated in 9.964465 ms
[13:11:56,431] INFO  {MemoryStore} Block taskresult_0 stored as bytes in memory (estimated size 1814.1 KB, free 1127.0 MB)
[13:11:56,432] INFO  {BlockManagerInfo} Added taskresult_0 in memory on 192.168.0.103:33363 (size: 1814.1 KB, free: 1127.1 MB)
[13:11:56,446] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 1857651 bytes result sent via BlockManager)
[13:11:56,567] INFO  {TransportClientFactory} Successfully created connection to /192.168.0.103:33363 after 62 ms (0 ms spent in bootstraps)
[13:11:56,698] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 952 ms on localhost (1/1)
[13:11:56,700] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:11:56,701] INFO  {BlockManagerInfo} Removed taskresult_0 on 192.168.0.103:33363 in memory (size: 1814.1 KB, free: 1128.9 MB)
[13:11:56,702] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:42) finished in 0.983 s
[13:11:56,707] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:42, took 1.053541 s
[13:11:56,738] INFO  {CodeGenerator} Code generated in 11.991705 ms
[13:11:56,836] INFO  {CodeGenerator} Code generated in 17.93023 ms
[13:11:56,865] INFO  {CodeGenerator} Code generated in 20.818914 ms
[13:11:56,897] INFO  {SparkContext} Starting job: foreach at Main.scala:45
[13:11:56,900] INFO  {DAGScheduler} Registering RDD 10 (foreach at Main.scala:45)
[13:11:56,901] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:45) with 1 output partitions
[13:11:56,901] INFO  {DAGScheduler} Final stage: ResultStage 2 (foreach at Main.scala:45)
[13:11:56,901] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 1)
[13:11:56,902] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 1)
[13:11:56,903] INFO  {DAGScheduler} Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:45), which has no missing parents
[13:11:57,029] INFO  {ContextCleaner} Cleaned accumulator 5
[13:11:57,031] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 16.5 KB, free 1128.7 MB)
[13:11:57,033] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.7 KB, free 1128.7 MB)
[13:11:57,034] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:33363 (size: 7.7 KB, free: 1128.9 MB)
[13:11:57,035] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[13:11:57,036] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:33363 in memory (size: 6.8 KB, free: 1128.9 MB)
[13:11:57,037] INFO  {ContextCleaner} Cleaned accumulator 56
[13:11:57,037] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:45)
[13:11:57,037] INFO  {ContextCleaner} Cleaned accumulator 4
[13:11:57,038] INFO  {ContextCleaner} Cleaned accumulator 3
[13:11:57,038] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:11:57,038] INFO  {ContextCleaner} Cleaned accumulator 2
[13:11:57,038] INFO  {ContextCleaner} Cleaned accumulator 1
[13:11:57,038] INFO  {ContextCleaner} Cleaned accumulator 0
[13:11:57,043] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:11:57,044] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:11:57,055] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:11:57,653] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2136 bytes result sent to driver
[13:11:57,657] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 618 ms on localhost (1/1)
[13:11:57,657] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:11:57,658] INFO  {DAGScheduler} ShuffleMapStage 1 (foreach at Main.scala:45) finished in 0.620 s
[13:11:57,659] INFO  {DAGScheduler} looking for newly runnable stages
[13:11:57,661] INFO  {DAGScheduler} running: Set()
[13:11:57,661] INFO  {DAGScheduler} waiting: Set(ResultStage 2)
[13:11:57,661] INFO  {DAGScheduler} failed: Set()
[13:11:57,663] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[14] at foreach at Main.scala:45), which has no missing parents
[13:11:57,675] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 14.8 KB, free 1128.7 MB)
[13:11:57,676] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.4 KB, free 1128.7 MB)
[13:11:57,677] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:33363 (size: 7.4 KB, free: 1128.9 MB)
[13:11:57,677] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[13:11:57,677] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at foreach at Main.scala:45)
[13:11:57,678] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:11:57,683] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5317 bytes)
[13:11:57,684] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:11:57,699] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:11:57,700] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[13:11:57,725] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 2135 bytes result sent to driver
[13:11:57,726] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 46 ms on localhost (1/1)
[13:11:57,726] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:11:57,727] INFO  {DAGScheduler} ResultStage 2 (foreach at Main.scala:45) finished in 0.047 s
[13:11:57,727] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:45, took 0.829999 s
[13:11:57,983] INFO  {CodeGenerator} Code generated in 27.189749 ms
[13:11:58,035] INFO  {CodeGenerator} Code generated in 37.472104 ms
[13:11:58,087] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[13:11:58,088] INFO  {DAGScheduler} Registering RDD 17 (collect at PipelineBuilder.scala:59)
[13:11:58,089] INFO  {DAGScheduler} Got job 2 (collect at PipelineBuilder.scala:59) with 1 output partitions
[13:11:58,089] INFO  {DAGScheduler} Final stage: ResultStage 4 (collect at PipelineBuilder.scala:59)
[13:11:58,089] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 3)
[13:11:58,089] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 3)
[13:11:58,090] INFO  {DAGScheduler} Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:11:58,094] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 30.9 KB, free 1128.7 MB)
[13:11:58,096] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.7 KB, free 1128.7 MB)
[13:11:58,096] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:33363 (size: 12.7 KB, free: 1128.9 MB)
[13:11:58,097] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[13:11:58,097] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at PipelineBuilder.scala:59)
[13:11:58,097] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[13:11:58,099] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:11:58,099] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[13:11:58,110] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:11:58,549] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:33363 in memory (size: 7.4 KB, free: 1128.9 MB)
[13:11:58,550] INFO  {ContextCleaner} Cleaned accumulator 153
[13:11:58,671] ERROR {Executor} Exception in task 0.0 in stage 3.0 (TID 3)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "0.419193351817
2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more
[13:11:58,689] WARN  {TaskSetManager} Lost task 0.0 in stage 3.0 (TID 3, localhost): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "0.419193351817
2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more

[13:11:58,690] ERROR {TaskSetManager} Task 0 in stage 3.0 failed 1 times; aborting job
[13:11:58,691] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[13:11:58,694] INFO  {TaskSchedulerImpl} Cancelling stage 3
[13:11:58,695] INFO  {DAGScheduler} ShuffleMapStage 3 (collect at PipelineBuilder.scala:59) failed in 0.596 s
[13:11:58,695] INFO  {DAGScheduler} Job 2 failed: collect at PipelineBuilder.scala:59, took 0.607925 s
[13:11:58,700] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:11:58,704] INFO  {ServerConnector} Stopped ServerConnector@2dd80673{HTTP/1.1}{0.0.0.0:4040}
[13:11:58,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1ecee32c{/stages/stage/kill,null,UNAVAILABLE}
[13:11:58,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4535b6d5{/api,null,UNAVAILABLE}
[13:11:58,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@305a0c5f{/,null,UNAVAILABLE}
[13:11:58,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6ee660fb{/static,null,UNAVAILABLE}
[13:11:58,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@34cdeda2{/executors/threadDump/json,null,UNAVAILABLE}
[13:11:58,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@9ef8eb7{/executors/threadDump,null,UNAVAILABLE}
[13:11:58,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10b9db7b{/executors/json,null,UNAVAILABLE}
[13:11:58,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5b202a3a{/executors,null,UNAVAILABLE}
[13:11:58,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@33b1c5c5{/environment/json,null,UNAVAILABLE}
[13:11:58,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@75cd8043{/environment,null,UNAVAILABLE}
[13:11:58,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59d2400d{/storage/rdd/json,null,UNAVAILABLE}
[13:11:58,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@63dd899{/storage/rdd,null,UNAVAILABLE}
[13:11:58,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@663411de{/storage/json,null,UNAVAILABLE}
[13:11:58,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1477089c{/storage,null,UNAVAILABLE}
[13:11:58,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@44b3606b{/stages/pool/json,null,UNAVAILABLE}
[13:11:58,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2cc44ad{/stages/pool,null,UNAVAILABLE}
[13:11:58,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@62e20a76{/stages/stage/json,null,UNAVAILABLE}
[13:11:58,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56f0cc85{/stages/stage,null,UNAVAILABLE}
[13:11:58,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6ad59d92{/stages/json,null,UNAVAILABLE}
[13:11:58,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@366ac49b{/stages,null,UNAVAILABLE}
[13:11:58,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@363042d7{/jobs/job/json,null,UNAVAILABLE}
[13:11:58,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@30b19518{/jobs/job,null,UNAVAILABLE}
[13:11:58,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7b84fcf8{/jobs/json,null,UNAVAILABLE}
[13:11:58,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@628c4ac0{/jobs,null,UNAVAILABLE}
[13:11:58,709] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:11:58,716] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:11:58,721] INFO  {MemoryStore} MemoryStore cleared
[13:11:58,722] INFO  {BlockManager} BlockManager stopped
[13:11:58,723] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:11:58,725] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:11:58,726] INFO  {SparkContext} Successfully stopped SparkContext
[13:11:58,727] INFO  {ShutdownHookManager} Shutdown hook called
[13:11:58,727] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-75bee0a6-645e-46f8-94b9-076af9d8a2eb
[13:13:15,744] INFO  {SparkContext} Running Spark version 2.0.1
[13:13:15,959] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:13:16,078] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:13:16,080] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:13:16,164] INFO  {SecurityManager} Changing view acls to: victor
[13:13:16,165] INFO  {SecurityManager} Changing modify acls to: victor
[13:13:16,165] INFO  {SecurityManager} Changing view acls groups to: 
[13:13:16,166] INFO  {SecurityManager} Changing modify acls groups to: 
[13:13:16,167] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:13:16,518] INFO  {Utils} Successfully started service 'sparkDriver' on port 36465.
[13:13:16,537] INFO  {SparkEnv} Registering MapOutputTracker
[13:13:16,557] INFO  {SparkEnv} Registering BlockManagerMaster
[13:13:16,569] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-d186d9a3-d924-4a99-ba1c-1f3e091b2207
[13:13:16,584] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:13:16,652] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:13:16,728] INFO  {log} Logging initialized @1609ms
[13:13:16,952] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:13:16,986] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[13:13:16,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[13:13:16,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[13:13:16,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[13:13:16,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[13:13:16,989] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[13:13:16,989] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[13:13:16,989] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[13:13:16,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[13:13:16,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[13:13:16,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[13:13:16,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[13:13:16,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[13:13:16,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[13:13:16,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[13:13:16,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[13:13:16,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[13:13:16,994] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[13:13:16,994] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[13:13:16,994] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[13:13:17,008] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[13:13:17,008] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[13:13:17,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[13:13:17,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[13:13:17,024] INFO  {ServerConnector} Started ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:13:17,025] INFO  {Server} Started @1907ms
[13:13:17,025] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:13:17,028] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:13:17,217] INFO  {Executor} Starting executor ID driver on host localhost
[13:13:17,268] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42719.
[13:13:17,270] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:42719
[13:13:17,273] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 42719)
[13:13:17,278] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:42719 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 42719)
[13:13:17,286] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 42719)
[13:13:17,630] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[13:13:18,698] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[13:13:18,805] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:13:18,809] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:42719 (size: 14.6 KB, free: 1128.9 MB)
[13:13:18,818] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:30
[13:13:22,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52b959df{/SQL,null,AVAILABLE}
[13:13:22,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@553d2579{/SQL/json,null,AVAILABLE}
[13:13:22,003] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1f7cec93{/SQL/execution,null,AVAILABLE}
[13:13:22,004] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3cdff901{/SQL/execution/json,null,AVAILABLE}
[13:13:22,007] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5c18d6d4{/static/sql,null,AVAILABLE}
[13:13:22,074] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:13:23,490] INFO  {CodeGenerator} Code generated in 217.875689 ms
[13:13:23,558] INFO  {FileInputFormat} Total input paths to process : 2
[13:13:23,561] INFO  {FileInputFormat} Total input paths to process : 2
[13:13:23,574] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[13:13:23,581] INFO  {SparkContext} Starting job: show at Main.scala:45
[13:13:23,596] INFO  {DAGScheduler} Got job 0 (show at Main.scala:45) with 1 output partitions
[13:13:23,596] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:45)
[13:13:23,596] INFO  {DAGScheduler} Parents of final stage: List()
[13:13:23,597] INFO  {DAGScheduler} Missing parents: List()
[13:13:23,604] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:45), which has no missing parents
[13:13:23,628] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 17.6 KB, free 1128.7 MB)
[13:13:23,630] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1128.7 MB)
[13:13:23,631] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:42719 (size: 8.1 KB, free: 1128.9 MB)
[13:13:23,632] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:13:23,635] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:45)
[13:13:23,636] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:13:23,671] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5523 bytes)
[13:13:23,677] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:13:23,708] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:13:23,732] INFO  {CodeGenerator} Code generated in 13.206691 ms
[13:13:23,761] INFO  {CodeGenerator} Code generated in 18.752331 ms
[13:13:23,773] INFO  {CodeGenerator} Code generated in 7.415175 ms
[13:13:23,815] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[13:13:23,820] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[13:13:23,821] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[13:13:23,824] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[13:13:24,142] INFO  {CodeGenerator} Code generated in 21.042886 ms
[13:13:24,814] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 953952 bytes result sent to driver
[13:13:24,827] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 1171 ms on localhost (1/1)
[13:13:24,828] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:13:24,832] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:45) finished in 1.187 s
[13:13:24,838] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:45, took 1.256523 s
[13:13:24,872] INFO  {CodeGenerator} Code generated in 19.385257 ms
[13:13:24,991] INFO  {CodeGenerator} Code generated in 13.280471 ms
[13:13:25,023] INFO  {CodeGenerator} Code generated in 25.442596 ms
[13:13:25,059] INFO  {SparkContext} Starting job: foreach at Main.scala:48
[13:13:25,062] INFO  {DAGScheduler} Registering RDD 11 (foreach at Main.scala:48)
[13:13:25,063] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:48) with 1 output partitions
[13:13:25,063] INFO  {DAGScheduler} Final stage: ResultStage 2 (foreach at Main.scala:48)
[13:13:25,063] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 1)
[13:13:25,063] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 1)
[13:13:25,065] INFO  {DAGScheduler} Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at foreach at Main.scala:48), which has no missing parents
[13:13:25,074] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 20.1 KB, free 1128.7 MB)
[13:13:25,076] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.9 KB, free 1128.7 MB)
[13:13:25,076] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:42719 (size: 8.9 KB, free: 1128.9 MB)
[13:13:25,077] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[13:13:25,079] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at foreach at Main.scala:48)
[13:13:25,079] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:13:25,082] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:13:25,083] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:13:25,094] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:13:25,319] INFO  {ContextCleaner} Cleaned accumulator 56
[13:13:25,668] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2223 bytes result sent to driver
[13:13:25,671] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 592 ms on localhost (1/1)
[13:13:25,671] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:13:25,673] INFO  {DAGScheduler} ShuffleMapStage 1 (foreach at Main.scala:48) finished in 0.593 s
[13:13:25,673] INFO  {DAGScheduler} looking for newly runnable stages
[13:13:25,674] INFO  {DAGScheduler} running: Set()
[13:13:25,675] INFO  {DAGScheduler} waiting: Set(ResultStage 2)
[13:13:25,675] INFO  {DAGScheduler} failed: Set()
[13:13:25,677] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[15] at foreach at Main.scala:48), which has no missing parents
[13:13:25,692] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 17.2 KB, free 1128.7 MB)
[13:13:25,693] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1128.7 MB)
[13:13:25,694] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:42719 (size: 8.5 KB, free: 1128.9 MB)
[13:13:25,695] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[13:13:25,695] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at foreach at Main.scala:48)
[13:13:25,695] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:13:25,700] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5317 bytes)
[13:13:25,700] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:13:25,719] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:13:25,721] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 7 ms
[13:13:25,757] INFO  {CodeGenerator} Code generated in 19.027597 ms
[13:13:25,776] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 2222 bytes result sent to driver
[13:13:25,778] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 79 ms on localhost (1/1)
[13:13:25,778] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:13:25,778] INFO  {DAGScheduler} ResultStage 2 (foreach at Main.scala:48) finished in 0.081 s
[13:13:25,779] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:48, took 0.719963 s
[13:13:25,807] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:13:25,811] INFO  {ServerConnector} Stopped ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[13:13:25,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[13:13:25,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[13:13:25,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[13:13:25,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[13:13:25,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[13:13:25,813] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[13:13:25,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[13:13:25,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[13:13:25,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[13:13:25,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[13:13:25,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[13:13:25,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[13:13:25,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[13:13:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[13:13:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[13:13:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[13:13:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[13:13:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[13:13:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[13:13:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[13:13:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[13:13:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[13:13:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[13:13:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[13:13:25,817] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:13:25,826] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:13:25,830] INFO  {MemoryStore} MemoryStore cleared
[13:13:25,831] INFO  {BlockManager} BlockManager stopped
[13:13:25,836] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:13:25,839] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:13:25,842] INFO  {SparkContext} Successfully stopped SparkContext
[13:13:25,843] INFO  {ShutdownHookManager} Shutdown hook called
[13:13:25,844] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-77baf8e6-1a48-4c6c-ab90-11517e8ef197
[13:13:42,576] INFO  {SparkContext} Running Spark version 2.0.1
[13:13:42,841] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:13:42,952] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:13:42,953] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:13:43,041] INFO  {SecurityManager} Changing view acls to: victor
[13:13:43,043] INFO  {SecurityManager} Changing modify acls to: victor
[13:13:43,044] INFO  {SecurityManager} Changing view acls groups to: 
[13:13:43,045] INFO  {SecurityManager} Changing modify acls groups to: 
[13:13:43,047] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:13:43,381] INFO  {Utils} Successfully started service 'sparkDriver' on port 38579.
[13:13:43,399] INFO  {SparkEnv} Registering MapOutputTracker
[13:13:43,413] INFO  {SparkEnv} Registering BlockManagerMaster
[13:13:43,424] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-d85b095b-2fc9-4ea1-8a46-6054b7cc3234
[13:13:43,439] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:13:43,482] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:13:43,557] INFO  {log} Logging initialized @1618ms
[13:13:43,660] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:13:43,675] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[13:13:43,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[13:13:43,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[13:13:43,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[13:13:43,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[13:13:43,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[13:13:43,676] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[13:13:43,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[13:13:43,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[13:13:43,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[13:13:43,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[13:13:43,677] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[13:13:43,678] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[13:13:43,678] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[13:13:43,678] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[13:13:43,678] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[13:13:43,678] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[13:13:43,678] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[13:13:43,679] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[13:13:43,679] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[13:13:43,684] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[13:13:43,684] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[13:13:43,685] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[13:13:43,685] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[13:13:43,689] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:13:43,689] INFO  {Server} Started @1751ms
[13:13:43,690] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:13:43,691] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:13:43,780] INFO  {Executor} Starting executor ID driver on host localhost
[13:13:43,800] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37163.
[13:13:43,801] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:37163
[13:13:43,802] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 37163)
[13:13:43,805] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:37163 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 37163)
[13:13:43,808] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 37163)
[13:13:43,963] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[13:13:44,493] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[13:13:44,557] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:13:44,559] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:37163 (size: 14.6 KB, free: 1128.9 MB)
[13:13:44,563] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:30
[13:13:45,933] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b7f06c7{/SQL,null,AVAILABLE}
[13:13:45,933] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@729c8063{/SQL/json,null,AVAILABLE}
[13:13:45,934] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31e739bf{/SQL/execution,null,AVAILABLE}
[13:13:45,935] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7743ec{/SQL/execution/json,null,AVAILABLE}
[13:13:45,936] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@316cda31{/static/sql,null,AVAILABLE}
[13:13:45,960] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:13:46,763] INFO  {CodeGenerator} Code generated in 204.644768 ms
[13:13:46,831] INFO  {FileInputFormat} Total input paths to process : 2
[13:13:46,834] INFO  {FileInputFormat} Total input paths to process : 2
[13:13:46,849] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[13:13:46,858] INFO  {SparkContext} Starting job: show at Main.scala:43
[13:13:46,873] INFO  {DAGScheduler} Got job 0 (show at Main.scala:43) with 1 output partitions
[13:13:46,873] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:43)
[13:13:46,873] INFO  {DAGScheduler} Parents of final stage: List()
[13:13:46,875] INFO  {DAGScheduler} Missing parents: List()
[13:13:46,879] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[7] at show at Main.scala:43), which has no missing parents
[13:13:46,895] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 14.4 KB, free 1128.7 MB)
[13:13:46,897] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 1128.7 MB)
[13:13:46,898] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:37163 (size: 6.8 KB, free: 1128.9 MB)
[13:13:46,898] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:13:46,902] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at show at Main.scala:43)
[13:13:46,904] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:13:46,948] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5523 bytes)
[13:13:46,955] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:13:46,988] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:13:47,013] INFO  {CodeGenerator} Code generated in 12.616213 ms
[13:13:47,041] INFO  {CodeGenerator} Code generated in 19.8076 ms
[13:13:47,057] INFO  {CodeGenerator} Code generated in 7.581905 ms
[13:13:47,101] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[13:13:47,108] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[13:13:47,109] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[13:13:47,111] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[13:13:47,472] INFO  {CodeGenerator} Code generated in 9.33005 ms
[13:13:47,934] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 929926 bytes result sent to driver
[13:13:47,945] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 1016 ms on localhost (1/1)
[13:13:47,947] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:13:47,952] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:43) finished in 1.034 s
[13:13:47,959] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:43, took 1.100709 s
[13:13:47,983] INFO  {CodeGenerator} Code generated in 10.154137 ms
[13:13:48,068] INFO  {CodeGenerator} Code generated in 9.470627 ms
[13:13:48,090] INFO  {CodeGenerator} Code generated in 17.32191 ms
[13:13:48,122] INFO  {SparkContext} Starting job: foreach at Main.scala:46
[13:13:48,125] INFO  {DAGScheduler} Registering RDD 10 (foreach at Main.scala:46)
[13:13:48,125] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:46) with 1 output partitions
[13:13:48,126] INFO  {DAGScheduler} Final stage: ResultStage 2 (foreach at Main.scala:46)
[13:13:48,126] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 1)
[13:13:48,126] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 1)
[13:13:48,127] INFO  {DAGScheduler} Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:46), which has no missing parents
[13:13:48,139] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 16.5 KB, free 1128.7 MB)
[13:13:48,142] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.7 KB, free 1128.7 MB)
[13:13:48,142] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:37163 (size: 7.7 KB, free: 1128.9 MB)
[13:13:48,143] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[13:13:48,145] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at foreach at Main.scala:46)
[13:13:48,145] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:13:48,148] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:13:48,149] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:13:48,160] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:13:48,345] INFO  {ContextCleaner} Cleaned accumulator 56
[13:13:49,219] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2223 bytes result sent to driver
[13:13:49,224] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 1078 ms on localhost (1/1)
[13:13:49,225] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:13:49,227] INFO  {DAGScheduler} ShuffleMapStage 1 (foreach at Main.scala:46) finished in 1.080 s
[13:13:49,227] INFO  {DAGScheduler} looking for newly runnable stages
[13:13:49,228] INFO  {DAGScheduler} running: Set()
[13:13:49,229] INFO  {DAGScheduler} waiting: Set(ResultStage 2)
[13:13:49,230] INFO  {DAGScheduler} failed: Set()
[13:13:49,232] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[14] at foreach at Main.scala:46), which has no missing parents
[13:13:49,260] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 14.8 KB, free 1128.7 MB)
[13:13:49,264] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.4 KB, free 1128.7 MB)
[13:13:49,265] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:37163 (size: 7.4 KB, free: 1128.9 MB)
[13:13:49,266] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[13:13:49,267] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at foreach at Main.scala:46)
[13:13:49,268] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:13:49,276] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5317 bytes)
[13:13:49,277] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:13:49,320] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:13:49,323] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 9 ms
[13:13:49,365] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 2222 bytes result sent to driver
[13:13:49,368] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 95 ms on localhost (1/1)
[13:13:49,368] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:13:49,370] INFO  {DAGScheduler} ResultStage 2 (foreach at Main.scala:46) finished in 0.096 s
[13:13:49,371] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:46, took 1.248589 s
[13:13:49,888] INFO  {CodeGenerator} Code generated in 33.399324 ms
[13:13:49,976] INFO  {CodeGenerator} Code generated in 69.676012 ms
[13:13:50,087] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[13:13:50,089] INFO  {DAGScheduler} Registering RDD 17 (collect at PipelineBuilder.scala:59)
[13:13:50,090] INFO  {DAGScheduler} Got job 2 (collect at PipelineBuilder.scala:59) with 1 output partitions
[13:13:50,090] INFO  {DAGScheduler} Final stage: ResultStage 4 (collect at PipelineBuilder.scala:59)
[13:13:50,090] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 3)
[13:13:50,090] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 3)
[13:13:50,091] INFO  {DAGScheduler} Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:13:50,097] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 30.9 KB, free 1128.7 MB)
[13:13:50,100] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.7 KB, free 1128.7 MB)
[13:13:50,101] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:37163 (size: 12.7 KB, free: 1128.9 MB)
[13:13:50,102] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[13:13:50,103] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at PipelineBuilder.scala:59)
[13:13:50,103] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[13:13:50,106] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:13:50,106] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[13:13:50,123] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:13:50,811] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 192.168.0.103:37163 in memory (size: 7.4 KB, free: 1128.9 MB)
[13:13:50,816] INFO  {ContextCleaner} Cleaned accumulator 153
[13:13:51,413] ERROR {Executor} Exception in task 0.0 in stage 3.0 (TID 3)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "0.419193351817
2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more
[13:13:51,451] WARN  {TaskSetManager} Lost task 0.0 in stage 3.0 (TID 3, localhost): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: "0.419193351817
2001.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more

[13:13:51,453] ERROR {TaskSetManager} Task 0 in stage 3.0 failed 1 times; aborting job
[13:13:51,455] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[13:13:51,461] INFO  {TaskSchedulerImpl} Cancelling stage 3
[13:13:51,463] INFO  {DAGScheduler} ShuffleMapStage 3 (collect at PipelineBuilder.scala:59) failed in 1.359 s
[13:13:51,465] INFO  {DAGScheduler} Job 2 failed: collect at PipelineBuilder.scala:59, took 1.377686 s
[13:13:51,479] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:13:51,490] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:13:51,494] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[13:13:51,495] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[13:13:51,495] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[13:13:51,495] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[13:13:51,496] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[13:13:51,496] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[13:13:51,496] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[13:13:51,496] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[13:13:51,496] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[13:13:51,497] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[13:13:51,497] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[13:13:51,497] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[13:13:51,497] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[13:13:51,498] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[13:13:51,498] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[13:13:51,498] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[13:13:51,498] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[13:13:51,499] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[13:13:51,499] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[13:13:51,499] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[13:13:51,499] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[13:13:51,500] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[13:13:51,500] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[13:13:51,500] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[13:13:51,503] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:13:51,522] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:13:51,533] INFO  {MemoryStore} MemoryStore cleared
[13:13:51,535] INFO  {BlockManager} BlockManager stopped
[13:13:51,539] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:13:51,544] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:13:51,553] INFO  {SparkContext} Successfully stopped SparkContext
[13:13:51,554] INFO  {ShutdownHookManager} Shutdown hook called
[13:13:51,556] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-d2be6e16-edde-4bf4-a608-1437625f2fd8
[13:14:47,125] INFO  {SparkContext} Running Spark version 2.0.1
[13:14:47,370] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:14:47,615] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:14:47,616] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:14:47,796] INFO  {SecurityManager} Changing view acls to: victor
[13:14:47,798] INFO  {SecurityManager} Changing modify acls to: victor
[13:14:47,800] INFO  {SecurityManager} Changing view acls groups to: 
[13:14:47,802] INFO  {SecurityManager} Changing modify acls groups to: 
[13:14:47,803] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:14:48,542] INFO  {Utils} Successfully started service 'sparkDriver' on port 34331.
[13:14:48,583] INFO  {SparkEnv} Registering MapOutputTracker
[13:14:48,617] INFO  {SparkEnv} Registering BlockManagerMaster
[13:14:48,645] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-12035891-5d54-424c-a0e9-bcf985ec50ba
[13:14:48,682] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:14:48,798] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:14:48,976] INFO  {log} Logging initialized @2593ms
[13:14:49,204] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:14:49,242] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[13:14:49,243] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[13:14:49,243] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[13:14:49,244] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[13:14:49,244] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[13:14:49,245] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[13:14:49,245] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[13:14:49,245] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[13:14:49,246] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[13:14:49,246] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[13:14:49,247] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[13:14:49,247] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[13:14:49,248] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[13:14:49,249] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[13:14:49,249] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[13:14:49,250] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[13:14:49,250] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[13:14:49,251] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[13:14:49,251] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[13:14:49,251] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[13:14:49,263] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[13:14:49,264] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[13:14:49,265] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[13:14:49,266] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[13:14:49,277] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:14:49,277] INFO  {Server} Started @2896ms
[13:14:49,278] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:14:49,281] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:14:49,450] INFO  {Executor} Starting executor ID driver on host localhost
[13:14:49,494] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44253.
[13:14:49,495] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:44253
[13:14:49,498] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 44253)
[13:14:49,504] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:44253 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 44253)
[13:14:49,511] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 44253)
[13:14:49,857] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[13:14:50,983] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[13:14:51,100] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:14:51,106] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:44253 (size: 14.6 KB, free: 1128.9 MB)
[13:14:51,114] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:30
[13:14:54,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ad179b4{/SQL,null,AVAILABLE}
[13:14:54,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59c500f7{/SQL/json,null,AVAILABLE}
[13:14:54,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@310b2b6f{/SQL/execution,null,AVAILABLE}
[13:14:54,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6b5ab2f2{/SQL/execution/json,null,AVAILABLE}
[13:14:54,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5bcec67e{/static/sql,null,AVAILABLE}
[13:14:54,180] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:14:55,652] INFO  {CodeGenerator} Code generated in 201.363699 ms
[13:14:55,722] INFO  {FileInputFormat} Total input paths to process : 2
[13:14:55,725] INFO  {FileInputFormat} Total input paths to process : 2
[13:14:55,738] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[13:14:55,744] INFO  {SparkContext} Starting job: show at Main.scala:47
[13:14:55,756] INFO  {DAGScheduler} Got job 0 (show at Main.scala:47) with 1 output partitions
[13:14:55,757] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:47)
[13:14:55,757] INFO  {DAGScheduler} Parents of final stage: List()
[13:14:55,759] INFO  {DAGScheduler} Missing parents: List()
[13:14:55,765] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[9] at show at Main.scala:47), which has no missing parents
[13:14:55,787] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 14.6 KB, free 1128.7 MB)
[13:14:55,792] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.9 KB, free 1128.7 MB)
[13:14:55,793] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:44253 (size: 6.9 KB, free: 1128.9 MB)
[13:14:55,794] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:14:55,797] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at show at Main.scala:47)
[13:14:55,799] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:14:55,838] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5523 bytes)
[13:14:55,845] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:14:55,878] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:14:55,898] INFO  {CodeGenerator} Code generated in 10.260416 ms
[13:14:55,920] INFO  {CodeGenerator} Code generated in 15.862048 ms
[13:14:55,933] INFO  {CodeGenerator} Code generated in 7.302314 ms
[13:14:55,975] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[13:14:55,981] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[13:14:55,981] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[13:14:55,984] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[13:14:56,309] INFO  {CodeGenerator} Code generated in 9.747255 ms
[13:14:56,684] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2474 bytes result sent to driver
[13:14:56,690] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 873 ms on localhost (1/1)
[13:14:56,692] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:14:56,695] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:47) finished in 0.888 s
[13:14:56,700] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:47, took 0.955109 s
[13:14:56,728] INFO  {CodeGenerator} Code generated in 11.216251 ms
[13:14:56,823] INFO  {CodeGenerator} Code generated in 13.165146 ms
[13:14:56,848] INFO  {CodeGenerator} Code generated in 18.093423 ms
[13:14:56,884] INFO  {SparkContext} Starting job: foreach at Main.scala:50
[13:14:56,888] INFO  {DAGScheduler} Registering RDD 12 (foreach at Main.scala:50)
[13:14:56,889] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:50) with 1 output partitions
[13:14:56,889] INFO  {DAGScheduler} Final stage: ResultStage 2 (foreach at Main.scala:50)
[13:14:56,889] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 1)
[13:14:56,889] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 1)
[13:14:56,890] INFO  {DAGScheduler} Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at foreach at Main.scala:50), which has no missing parents
[13:14:56,902] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 16.8 KB, free 1128.7 MB)
[13:14:56,905] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.8 KB, free 1128.7 MB)
[13:14:56,905] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:44253 (size: 7.8 KB, free: 1128.9 MB)
[13:14:56,906] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[13:14:56,908] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at foreach at Main.scala:50)
[13:14:56,908] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:14:56,911] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:14:56,912] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:14:56,921] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:14:57,008] INFO  {ContextCleaner} Cleaned accumulator 56
[13:14:57,474] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2223 bytes result sent to driver
[13:14:57,477] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 569 ms on localhost (1/1)
[13:14:57,477] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:14:57,478] INFO  {DAGScheduler} ShuffleMapStage 1 (foreach at Main.scala:50) finished in 0.570 s
[13:14:57,479] INFO  {DAGScheduler} looking for newly runnable stages
[13:14:57,479] INFO  {DAGScheduler} running: Set()
[13:14:57,479] INFO  {DAGScheduler} waiting: Set(ResultStage 2)
[13:14:57,480] INFO  {DAGScheduler} failed: Set()
[13:14:57,481] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[16] at foreach at Main.scala:50), which has no missing parents
[13:14:57,494] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 15.1 KB, free 1128.7 MB)
[13:14:57,496] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.5 KB, free 1128.7 MB)
[13:14:57,496] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:44253 (size: 7.5 KB, free: 1128.9 MB)
[13:14:57,497] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[13:14:57,497] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at foreach at Main.scala:50)
[13:14:57,497] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:14:57,502] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5317 bytes)
[13:14:57,503] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:14:57,526] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:14:57,528] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[13:14:57,704] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 2295 bytes result sent to driver
[13:14:57,706] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 206 ms on localhost (1/1)
[13:14:57,707] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:14:57,708] INFO  {DAGScheduler} ResultStage 2 (foreach at Main.scala:50) finished in 0.207 s
[13:14:57,709] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:50, took 0.824532 s
[13:14:57,715] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 192.168.0.103:44253 in memory (size: 7.8 KB, free: 1128.9 MB)
[13:14:57,718] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:44253 in memory (size: 6.9 KB, free: 1128.9 MB)
[13:14:57,719] INFO  {ContextCleaner} Cleaned accumulator 5
[13:14:57,719] INFO  {ContextCleaner} Cleaned accumulator 4
[13:14:57,719] INFO  {ContextCleaner} Cleaned accumulator 3
[13:14:57,720] INFO  {ContextCleaner} Cleaned accumulator 2
[13:14:57,720] INFO  {ContextCleaner} Cleaned accumulator 1
[13:14:57,720] INFO  {ContextCleaner} Cleaned accumulator 0
[13:14:57,934] INFO  {CodeGenerator} Code generated in 15.080569 ms
[13:14:57,976] INFO  {CodeGenerator} Code generated in 32.424431 ms
[13:14:58,028] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[13:14:58,029] INFO  {DAGScheduler} Registering RDD 19 (collect at PipelineBuilder.scala:59)
[13:14:58,030] INFO  {DAGScheduler} Got job 2 (collect at PipelineBuilder.scala:59) with 1 output partitions
[13:14:58,030] INFO  {DAGScheduler} Final stage: ResultStage 4 (collect at PipelineBuilder.scala:59)
[13:14:58,030] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 3)
[13:14:58,030] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 3)
[13:14:58,031] INFO  {DAGScheduler} Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:14:58,035] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 31.2 KB, free 1128.7 MB)
[13:14:58,037] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.8 KB, free 1128.7 MB)
[13:14:58,038] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:44253 (size: 12.8 KB, free: 1128.9 MB)
[13:14:58,038] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[13:14:58,038] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at PipelineBuilder.scala:59)
[13:14:58,039] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[13:14:58,040] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5597 bytes)
[13:14:58,041] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[13:14:58,051] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:14:58,405] INFO  {ContextCleaner} Cleaned accumulator 153
[13:14:59,322] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 2479 bytes result sent to driver
[13:14:59,325] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 1286 ms on localhost (1/1)
[13:14:59,325] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[13:14:59,326] INFO  {DAGScheduler} ShuffleMapStage 3 (collect at PipelineBuilder.scala:59) finished in 1.287 s
[13:14:59,326] INFO  {DAGScheduler} looking for newly runnable stages
[13:14:59,326] INFO  {DAGScheduler} running: Set()
[13:14:59,327] INFO  {DAGScheduler} waiting: Set(ResultStage 4)
[13:14:59,327] INFO  {DAGScheduler} failed: Set()
[13:14:59,327] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[22] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:14:59,332] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 7.3 KB, free 1128.7 MB)
[13:14:59,335] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1128.7 MB)
[13:14:59,336] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:44253 (size: 3.9 KB, free: 1128.9 MB)
[13:14:59,337] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[13:14:59,337] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[22] at collect at PipelineBuilder.scala:59)
[13:14:59,337] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[13:14:59,340] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, ANY, 5317 bytes)
[13:14:59,340] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[13:14:59,345] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:14:59,345] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[13:14:59,351] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1955 bytes result sent to driver
[13:14:59,352] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 14 ms on localhost (1/1)
[13:14:59,353] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[13:14:59,353] INFO  {DAGScheduler} ResultStage 4 (collect at PipelineBuilder.scala:59) finished in 0.015 s
[13:14:59,354] INFO  {DAGScheduler} Job 2 finished: collect at PipelineBuilder.scala:59, took 1.325666 s
[13:14:59,380] INFO  {CodeGenerator} Code generated in 18.976218 ms
[13:14:59,896] INFO  {CodeGenerator} Code generated in 125.789473 ms
[13:14:59,956] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:63
[13:14:59,958] INFO  {DAGScheduler} Got job 3 (count at MyLinearRegressionImpl.scala:63) with 1 output partitions
[13:14:59,958] INFO  {DAGScheduler} Final stage: ResultStage 5 (count at MyLinearRegressionImpl.scala:63)
[13:14:59,958] INFO  {DAGScheduler} Parents of final stage: List()
[13:14:59,959] INFO  {DAGScheduler} Missing parents: List()
[13:14:59,961] INFO  {DAGScheduler} Submitting ResultStage 5 (MapPartitionsRDD[27] at map at MyLinearRegressionImpl.scala:92), which has no missing parents
[13:14:59,978] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 45.4 KB, free 1128.6 MB)
[13:14:59,982] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.7 KB, free 1128.6 MB)
[13:14:59,983] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:44253 (size: 15.7 KB, free: 1128.8 MB)
[13:14:59,985] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[13:14:59,985] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at map at MyLinearRegressionImpl.scala:92)
[13:14:59,985] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[13:14:59,989] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5494 bytes)
[13:14:59,990] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[13:15:00,004] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:15:00,051] INFO  {CodeGenerator} Code generated in 21.303728 ms
[13:15:00,747] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 192.168.0.103:44253 in memory (size: 3.9 KB, free: 1128.9 MB)
[13:15:01,862] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1843 bytes result sent to driver
[13:15:01,863] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 1875 ms on localhost (1/1)
[13:15:01,863] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[13:15:01,863] INFO  {DAGScheduler} ResultStage 5 (count at MyLinearRegressionImpl.scala:63) finished in 1.876 s
[13:15:01,863] INFO  {DAGScheduler} Job 3 finished: count at MyLinearRegressionImpl.scala:63, took 1.907141 s
[13:15:01,875] INFO  {SparkContext} Starting job: take at MyLinearRegressionImpl.scala:64
[13:15:01,876] INFO  {DAGScheduler} Got job 4 (take at MyLinearRegressionImpl.scala:64) with 1 output partitions
[13:15:01,876] INFO  {DAGScheduler} Final stage: ResultStage 6 (take at MyLinearRegressionImpl.scala:64)
[13:15:01,876] INFO  {DAGScheduler} Parents of final stage: List()
[13:15:01,877] INFO  {DAGScheduler} Missing parents: List()
[13:15:01,877] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[27] at map at MyLinearRegressionImpl.scala:92), which has no missing parents
[13:15:01,880] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 45.5 KB, free 1128.6 MB)
[13:15:01,885] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.8 KB, free 1128.6 MB)
[13:15:01,886] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:44253 (size: 15.8 KB, free: 1128.8 MB)
[13:15:01,886] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[13:15:01,887] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at map at MyLinearRegressionImpl.scala:92)
[13:15:01,887] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[13:15:01,888] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5576 bytes)
[13:15:01,889] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[13:15:01,893] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:15:02,327] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 2677 bytes result sent to driver
[13:15:02,328] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 441 ms on localhost (1/1)
[13:15:02,328] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[13:15:02,329] INFO  {DAGScheduler} ResultStage 6 (take at MyLinearRegressionImpl.scala:64) finished in 0.442 s
[13:15:02,329] INFO  {DAGScheduler} Job 4 finished: take at MyLinearRegressionImpl.scala:64, took 0.453737 s
[13:15:02,352] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:15:02,353] INFO  {DAGScheduler} Got job 5 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:15:02,353] INFO  {DAGScheduler} Final stage: ResultStage 7 (sum at MyLinearRegressionImpl.scala:24)
[13:15:02,353] INFO  {DAGScheduler} Parents of final stage: List()
[13:15:02,353] INFO  {DAGScheduler} Missing parents: List()
[13:15:02,354] INFO  {DAGScheduler} Submitting ResultStage 7 (MapPartitionsRDD[29] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:15:02,357] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 46.9 KB, free 1128.5 MB)
[13:15:02,359] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 16.1 KB, free 1128.5 MB)
[13:15:02,360] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 192.168.0.103:44253 (size: 16.1 KB, free: 1128.8 MB)
[13:15:02,360] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[13:15:02,361] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[29] at map at MyLinearRegressionImpl.scala:22)
[13:15:02,361] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[13:15:02,363] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5575 bytes)
[13:15:02,363] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[13:15:02,370] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:15:02,912] INFO  {BlockManagerInfo} Removed broadcast_7_piece0 on 192.168.0.103:44253 in memory (size: 15.8 KB, free: 1128.8 MB)
[13:15:03,298] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1758 bytes result sent to driver
[13:15:03,299] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 938 ms on localhost (1/1)
[13:15:03,299] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[13:15:03,299] INFO  {DAGScheduler} ResultStage 7 (sum at MyLinearRegressionImpl.scala:24) finished in 0.938 s
[13:15:03,300] INFO  {DAGScheduler} Job 5 finished: sum at MyLinearRegressionImpl.scala:24, took 0.947826 s
[13:15:03,303] INFO  {SparkContext} Starting job: count at MyLinearRegressionImpl.scala:26
[13:15:03,303] INFO  {DAGScheduler} Got job 6 (count at MyLinearRegressionImpl.scala:26) with 1 output partitions
[13:15:03,304] INFO  {DAGScheduler} Final stage: ResultStage 8 (count at MyLinearRegressionImpl.scala:26)
[13:15:03,304] INFO  {DAGScheduler} Parents of final stage: List()
[13:15:03,304] INFO  {DAGScheduler} Missing parents: List()
[13:15:03,304] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[28] at map at MyLinearRegressionImpl.scala:36), which has no missing parents
[13:15:03,307] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 46.3 KB, free 1128.5 MB)
[13:15:03,309] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.9 KB, free 1128.5 MB)
[13:15:03,309] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 192.168.0.103:44253 (size: 15.9 KB, free: 1128.8 MB)
[13:15:03,310] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[13:15:03,310] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[28] at map at MyLinearRegressionImpl.scala:36)
[13:15:03,310] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[13:15:03,312] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5494 bytes)
[13:15:03,312] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[13:15:03,316] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:15:04,107] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 1756 bytes result sent to driver
[13:15:04,108] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 797 ms on localhost (1/1)
[13:15:04,108] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[13:15:04,109] INFO  {DAGScheduler} ResultStage 8 (count at MyLinearRegressionImpl.scala:26) finished in 0.798 s
[13:15:04,109] INFO  {DAGScheduler} Job 6 finished: count at MyLinearRegressionImpl.scala:26, took 0.806194 s
[13:15:04,122] INFO  {SparkContext} Starting job: reduce at MyLinearRegressionImpl.scala:56
[13:15:04,123] INFO  {DAGScheduler} Got job 7 (reduce at MyLinearRegressionImpl.scala:56) with 1 output partitions
[13:15:04,123] INFO  {DAGScheduler} Final stage: ResultStage 9 (reduce at MyLinearRegressionImpl.scala:56)
[13:15:04,123] INFO  {DAGScheduler} Parents of final stage: List()
[13:15:04,123] INFO  {DAGScheduler} Missing parents: List()
[13:15:04,124] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[30] at map at MyLinearRegressionImpl.scala:54), which has no missing parents
[13:15:04,126] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 47.1 KB, free 1128.5 MB)
[13:15:04,128] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.2 KB, free 1128.5 MB)
[13:15:04,129] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 192.168.0.103:44253 (size: 16.2 KB, free: 1128.8 MB)
[13:15:04,129] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[13:15:04,130] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at map at MyLinearRegressionImpl.scala:54)
[13:15:04,130] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[13:15:04,132] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5578 bytes)
[13:15:04,132] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[13:15:04,137] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:15:04,893] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 2572 bytes result sent to driver
[13:15:04,894] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 763 ms on localhost (1/1)
[13:15:04,894] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[13:15:04,894] INFO  {DAGScheduler} ResultStage 9 (reduce at MyLinearRegressionImpl.scala:56) finished in 0.764 s
[13:15:04,895] INFO  {DAGScheduler} Job 7 finished: reduce at MyLinearRegressionImpl.scala:56, took 0.772404 s
[13:15:04,902] INFO  {SparkContext} Starting job: sum at MyLinearRegressionImpl.scala:24
[13:15:04,903] INFO  {DAGScheduler} Got job 8 (sum at MyLinearRegressionImpl.scala:24) with 1 output partitions
[13:15:04,903] INFO  {DAGScheduler} Final stage: ResultStage 10 (sum at MyLinearRegressionImpl.scala:24)
[13:15:04,903] INFO  {DAGScheduler} Parents of final stage: List()
[13:15:04,903] INFO  {DAGScheduler} Missing parents: List()
[13:15:04,904] INFO  {DAGScheduler} Submitting ResultStage 10 (MapPartitionsRDD[32] at map at MyLinearRegressionImpl.scala:22), which has no missing parents
[13:15:04,906] INFO  {MemoryStore} Block broadcast_11 stored as values in memory (estimated size 46.9 KB, free 1128.4 MB)
[13:15:04,907] INFO  {MemoryStore} Block broadcast_11_piece0 stored as bytes in memory (estimated size 16.8 KB, free 1128.4 MB)
[13:15:04,908] INFO  {BlockManagerInfo} Added broadcast_11_piece0 in memory on 192.168.0.103:44253 (size: 16.8 KB, free: 1128.8 MB)
[13:15:04,908] INFO  {SparkContext} Created broadcast 11 from broadcast at DAGScheduler.scala:1012
[13:15:04,909] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[32] at map at MyLinearRegressionImpl.scala:22)
[13:15:04,909] INFO  {TaskSchedulerImpl} Adding task set 10.0 with 1 tasks
[13:15:04,910] INFO  {TaskSetManager} Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5575 bytes)
[13:15:04,910] INFO  {Executor} Running task 0.0 in stage 10.0 (TID 10)
[13:15:04,914] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:15:05,561] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:15:05,564] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:15:05,566] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[13:15:05,566] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[13:15:05,566] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[13:15:05,566] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[13:15:05,567] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[13:15:05,567] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[13:15:05,567] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[13:15:05,567] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[13:15:05,567] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[13:15:05,567] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[13:15:05,567] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[13:15:05,567] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[13:15:05,567] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[13:15:05,567] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[13:15:05,568] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[13:15:05,568] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[13:15:05,568] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[13:15:05,568] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[13:15:05,568] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[13:15:05,568] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[13:15:05,568] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[13:15:05,568] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[13:15:05,568] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[13:15:05,568] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[13:15:05,570] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:15:05,574] INFO  {DAGScheduler} Job 8 failed: sum at MyLinearRegressionImpl.scala:24, took 0.672290 s
[13:15:05,575] INFO  {DAGScheduler} ResultStage 10 (sum at MyLinearRegressionImpl.scala:24) failed in 0.665 s
[13:15:05,575] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@d55d40)
[13:15:05,576] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(8,1511093705576,JobFailed(org.apache.spark.SparkException: Job 8 cancelled because SparkContext was shut down))
[13:15:05,581] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:15:05,589] INFO  {MemoryStore} MemoryStore cleared
[13:15:05,590] INFO  {BlockManager} BlockManager stopped
[13:15:05,591] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:15:05,593] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:15:05,600] INFO  {SparkContext} Successfully stopped SparkContext
[13:15:05,600] INFO  {ShutdownHookManager} Shutdown hook called
[13:15:05,601] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-16791cd1-42c3-449f-af82-e1c95f4bdabe
[13:16:40,142] INFO  {SparkContext} Running Spark version 2.0.1
[13:16:40,614] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:16:40,855] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:16:40,856] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:16:41,000] INFO  {SecurityManager} Changing view acls to: victor
[13:16:41,002] INFO  {SecurityManager} Changing modify acls to: victor
[13:16:41,004] INFO  {SecurityManager} Changing view acls groups to: 
[13:16:41,005] INFO  {SecurityManager} Changing modify acls groups to: 
[13:16:41,007] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:16:41,834] INFO  {Utils} Successfully started service 'sparkDriver' on port 45855.
[13:16:41,879] INFO  {SparkEnv} Registering MapOutputTracker
[13:16:41,913] INFO  {SparkEnv} Registering BlockManagerMaster
[13:16:41,941] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-f045d401-ca8c-46f1-a16b-961f6788c2c7
[13:16:41,977] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:16:42,095] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:16:42,298] INFO  {log} Logging initialized @3609ms
[13:16:42,551] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:16:42,589] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[13:16:42,590] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[13:16:42,590] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[13:16:42,591] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[13:16:42,592] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[13:16:42,592] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[13:16:42,593] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[13:16:42,594] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[13:16:42,594] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[13:16:42,595] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[13:16:42,595] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[13:16:42,596] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[13:16:42,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[13:16:42,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[13:16:42,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[13:16:42,599] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[13:16:42,599] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[13:16:42,600] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[13:16:42,600] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[13:16:42,601] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[13:16:42,613] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[13:16:42,613] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[13:16:42,615] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[13:16:42,616] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[13:16:42,628] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:16:42,628] INFO  {Server} Started @3942ms
[13:16:42,629] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:16:42,632] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:16:42,812] INFO  {Executor} Starting executor ID driver on host localhost
[13:16:42,861] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39907.
[13:16:42,863] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:39907
[13:16:42,866] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 39907)
[13:16:42,872] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:39907 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 39907)
[13:16:42,879] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 39907)
[13:16:43,249] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[13:16:43,342] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[13:16:43,344] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[13:16:43,346] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[13:16:43,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[13:16:43,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[13:16:43,379] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[13:16:46,991] INFO  {FileSourceStrategy} Pruning directories with: 
[13:16:46,993] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:16:46,997] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:16:46,998] INFO  {FileSourceStrategy} Pushed Filters: 
[13:16:47,106] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 131.0 KB, free 1128.8 MB)
[13:16:47,161] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:16:47,165] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:39907 (size: 14.6 KB, free: 1128.9 MB)
[13:16:47,174] INFO  {SparkContext} Created broadcast 0 from show at Main.scala:50
[13:16:47,178] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 9480334 bytes, open cost is considered as scanning 4194304 bytes.
[13:16:47,694] INFO  {CodeGenerator} Code generated in 208.073903 ms
[13:16:47,802] INFO  {SparkContext} Starting job: show at Main.scala:50
[13:16:47,819] INFO  {DAGScheduler} Got job 0 (show at Main.scala:50) with 1 output partitions
[13:16:47,820] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:50)
[13:16:47,820] INFO  {DAGScheduler} Parents of final stage: List()
[13:16:47,821] INFO  {DAGScheduler} Missing parents: List()
[13:16:47,825] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:50), which has no missing parents
[13:16:47,841] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[13:16:47,844] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1128.7 MB)
[13:16:47,845] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:39907 (size: 6.3 KB, free: 1128.9 MB)
[13:16:47,846] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:16:47,849] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:50)
[13:16:47,850] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:16:47,890] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5980 bytes)
[13:16:47,897] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:16:47,960] INFO  {CodeGenerator} Code generated in 16.558356 ms
[13:16:47,978] INFO  {CodeGenerator} Code generated in 9.271597 ms
[13:16:47,992] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/a.tar.gz, range: 0-545863, partition values: [empty row]
[13:16:48,001] INFO  {CodeGenerator} Code generated in 7.40516 ms
[13:16:48,080] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:16:48,178] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/b.tar.gz, range: 0-545863, partition values: [empty row]
[13:16:48,179] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:16:48,264] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2237 bytes result sent to driver
[13:16:48,271] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 400 ms on localhost (1/1)
[13:16:48,273] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:16:48,277] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:50) finished in 0.418 s
[13:16:48,282] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:50, took 0.479745 s
[13:16:48,315] INFO  {CodeGenerator} Code generated in 23.0134 ms
[13:16:48,321] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 192.168.0.103:39907 in memory (size: 6.3 KB, free: 1128.9 MB)
[13:16:48,352] INFO  {FileSourceStrategy} Pruning directories with: 
[13:16:48,352] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:16:48,353] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:16:48,353] INFO  {FileSourceStrategy} Pushed Filters: 
[13:16:48,360] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[13:16:48,371] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[13:16:48,371] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 192.168.0.103:39907 (size: 14.6 KB, free: 1128.9 MB)
[13:16:48,373] INFO  {SparkContext} Created broadcast 2 from foreach at Main.scala:53
[13:16:48,373] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 9480334 bytes, open cost is considered as scanning 4194304 bytes.
[13:16:48,388] INFO  {FileSourceStrategy} Pruning directories with: 
[13:16:48,388] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:16:48,389] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:16:48,389] INFO  {FileSourceStrategy} Pushed Filters: 
[13:16:48,393] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[13:16:48,401] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[13:16:48,402] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 192.168.0.103:39907 (size: 14.6 KB, free: 1128.9 MB)
[13:16:48,404] INFO  {SparkContext} Created broadcast 3 from foreach at Main.scala:53
[13:16:48,404] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 9480334 bytes, open cost is considered as scanning 4194304 bytes.
[13:16:48,428] INFO  {CodeGenerator} Code generated in 9.045738 ms
[13:16:48,455] INFO  {CodeGenerator} Code generated in 20.035032 ms
[13:16:48,487] INFO  {SparkContext} Starting job: foreach at Main.scala:53
[13:16:48,490] INFO  {DAGScheduler} Registering RDD 6 (foreach at Main.scala:53)
[13:16:48,491] INFO  {DAGScheduler} Got job 1 (foreach at Main.scala:53) with 1 output partitions
[13:16:48,491] INFO  {DAGScheduler} Final stage: ResultStage 2 (foreach at Main.scala:53)
[13:16:48,491] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 1)
[13:16:48,491] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 1)
[13:16:48,493] INFO  {DAGScheduler} Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at foreach at Main.scala:53), which has no missing parents
[13:16:48,503] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 15.0 KB, free 1128.5 MB)
[13:16:48,504] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.1 KB, free 1128.5 MB)
[13:16:48,505] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 192.168.0.103:39907 (size: 7.1 KB, free: 1128.9 MB)
[13:16:48,506] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[13:16:48,508] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at foreach at Main.scala:53)
[13:16:48,508] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[13:16:48,511] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 6054 bytes)
[13:16:48,512] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[13:16:48,540] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/a.tar.gz, range: 0-545863, partition values: [empty row]
[13:16:48,544] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:16:48,584] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/b.tar.gz, range: 0-545863, partition values: [empty row]
[13:16:48,585] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:16:48,642] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2150 bytes result sent to driver
[13:16:48,644] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 135 ms on localhost (1/1)
[13:16:48,645] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[13:16:48,646] INFO  {DAGScheduler} ShuffleMapStage 1 (foreach at Main.scala:53) finished in 0.138 s
[13:16:48,647] INFO  {DAGScheduler} looking for newly runnable stages
[13:16:48,647] INFO  {DAGScheduler} running: Set()
[13:16:48,648] INFO  {DAGScheduler} waiting: Set(ResultStage 2)
[13:16:48,648] INFO  {DAGScheduler} failed: Set()
[13:16:48,650] INFO  {DAGScheduler} Submitting ResultStage 2 (MapPartitionsRDD[10] at foreach at Main.scala:53), which has no missing parents
[13:16:48,669] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 13.8 KB, free 1128.4 MB)
[13:16:48,671] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.0 KB, free 1128.4 MB)
[13:16:48,672] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 192.168.0.103:39907 (size: 7.0 KB, free: 1128.8 MB)
[13:16:48,673] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[13:16:48,673] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at foreach at Main.scala:53)
[13:16:48,673] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[13:16:48,679] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5317 bytes)
[13:16:48,679] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[13:16:48,698] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[13:16:48,701] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 6 ms
[13:16:48,800] INFO  {BlockManagerInfo} Removed broadcast_0_piece0 on 192.168.0.103:39907 in memory (size: 14.6 KB, free: 1128.9 MB)
[13:16:48,801] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 2295 bytes result sent to driver
[13:16:48,801] INFO  {ContextCleaner} Cleaned accumulator 0
[13:16:48,802] INFO  {ContextCleaner} Cleaned accumulator 1
[13:16:48,802] INFO  {ContextCleaner} Cleaned accumulator 2
[13:16:48,802] INFO  {ContextCleaner} Cleaned accumulator 3
[13:16:48,802] INFO  {ContextCleaner} Cleaned accumulator 4
[13:16:48,802] INFO  {ContextCleaner} Cleaned accumulator 5
[13:16:48,802] INFO  {ContextCleaner} Cleaned accumulator 56
[13:16:48,803] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 125 ms on localhost (1/1)
[13:16:48,803] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[13:16:48,803] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 192.168.0.103:39907 in memory (size: 7.1 KB, free: 1128.9 MB)
[13:16:48,803] INFO  {DAGScheduler} ResultStage 2 (foreach at Main.scala:53) finished in 0.126 s
[13:16:48,804] INFO  {DAGScheduler} Job 1 finished: foreach at Main.scala:53, took 0.316099 s
[13:16:49,013] INFO  {FileSourceStrategy} Pruning directories with: 
[13:16:49,013] INFO  {FileSourceStrategy} Post-Scan Filters: 
[13:16:49,014] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[13:16:49,014] INFO  {FileSourceStrategy} Pushed Filters: 
[13:16:49,020] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[13:16:49,028] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[13:16:49,028] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 192.168.0.103:39907 (size: 14.6 KB, free: 1128.9 MB)
[13:16:49,030] INFO  {SparkContext} Created broadcast 6 from collect at PipelineBuilder.scala:59
[13:16:49,030] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 9480334 bytes, open cost is considered as scanning 4194304 bytes.
[13:16:49,070] INFO  {CodeGenerator} Code generated in 12.831241 ms
[13:16:49,117] INFO  {CodeGenerator} Code generated in 38.501605 ms
[13:16:49,179] INFO  {SparkContext} Starting job: collect at PipelineBuilder.scala:59
[13:16:49,181] INFO  {DAGScheduler} Registering RDD 13 (collect at PipelineBuilder.scala:59)
[13:16:49,181] INFO  {DAGScheduler} Got job 2 (collect at PipelineBuilder.scala:59) with 1 output partitions
[13:16:49,181] INFO  {DAGScheduler} Final stage: ResultStage 4 (collect at PipelineBuilder.scala:59)
[13:16:49,181] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 3)
[13:16:49,181] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 3)
[13:16:49,182] INFO  {DAGScheduler} Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at PipelineBuilder.scala:59), which has no missing parents
[13:16:49,185] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 29.5 KB, free 1128.4 MB)
[13:16:49,186] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.1 KB, free 1128.4 MB)
[13:16:49,187] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 192.168.0.103:39907 (size: 12.1 KB, free: 1128.8 MB)
[13:16:49,188] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[13:16:49,188] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at PipelineBuilder.scala:59)
[13:16:49,188] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[13:16:49,190] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 6054 bytes)
[13:16:49,190] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[13:16:49,208] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/a.tar.gz, range: 0-545863, partition values: [empty row]
[13:16:49,210] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:16:49,239] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/dataset/fakeData/b.tar.gz, range: 0-545863, partition values: [empty row]
[13:16:49,239] INFO  {CodecPool} Got brand-new decompressor [.gz]
[13:16:49,271] ERROR {Executor} Exception in task 0.0 in stage 3.0 (TID 3)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: empty String
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1842)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more
[13:16:49,297] WARN  {TaskSetManager} Lost task 0.0 in stage 3.0 (TID 3, localhost): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$createTransformFunc$1: (array<string>) => vector)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:362)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: empty String
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1842)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:253)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:30)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1$$anonfun$apply$1.apply(Array2Vector.scala:16)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	at se.kth.spark.lab1.Array2Vector$$anonfun$createTransformFunc$1.apply(Array2Vector.scala:16)
	... 13 more

[13:16:49,299] ERROR {TaskSetManager} Task 0 in stage 3.0 failed 1 times; aborting job
[13:16:49,300] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[13:16:49,303] INFO  {TaskSchedulerImpl} Cancelling stage 3
[13:16:49,304] INFO  {DAGScheduler} ShuffleMapStage 3 (collect at PipelineBuilder.scala:59) failed in 0.116 s
[13:16:49,305] INFO  {DAGScheduler} Job 2 failed: collect at PipelineBuilder.scala:59, took 0.125385 s
[13:16:49,310] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:16:49,313] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:16:49,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[13:16:49,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[13:16:49,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[13:16:49,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[13:16:49,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[13:16:49,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[13:16:49,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[13:16:49,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[13:16:49,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[13:16:49,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[13:16:49,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[13:16:49,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[13:16:49,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[13:16:49,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[13:16:49,317] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[13:16:49,317] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[13:16:49,317] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[13:16:49,317] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[13:16:49,317] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[13:16:49,317] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[13:16:49,317] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[13:16:49,318] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[13:16:49,318] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[13:16:49,318] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[13:16:49,319] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:16:49,328] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:16:49,333] INFO  {MemoryStore} MemoryStore cleared
[13:16:49,333] INFO  {BlockManager} BlockManager stopped
[13:16:49,335] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:16:49,342] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:16:49,345] INFO  {SparkContext} Successfully stopped SparkContext
[13:16:49,345] INFO  {ShutdownHookManager} Shutdown hook called
[13:16:49,346] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-8510dcc3-c2c4-485c-ba12-677b4d1ea05c
[13:32:04,963] INFO  {SparkContext} Running Spark version 2.0.1
[13:32:05,648] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:32:05,982] ERROR {SparkContext} Error initializing SparkContext.
org.apache.spark.SparkException: A master URL must be set in your configuration
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:368)
	at se.kth.spark.lab1.task6.Main$.main(Main.scala:19)
	at se.kth.spark.lab1.task6.Main.main(Main.scala)
[13:32:06,150] INFO  {SparkContext} Successfully stopped SparkContext
[13:50:45,580] INFO  {SparkContext} Running Spark version 2.0.1
[13:50:45,875] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:50:46,078] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:50:46,078] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:50:46,226] INFO  {SecurityManager} Changing view acls to: victor
[13:50:46,227] INFO  {SecurityManager} Changing modify acls to: victor
[13:50:46,228] INFO  {SecurityManager} Changing view acls groups to: 
[13:50:46,228] INFO  {SecurityManager} Changing modify acls groups to: 
[13:50:46,229] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:50:46,666] INFO  {Utils} Successfully started service 'sparkDriver' on port 36117.
[13:50:46,687] INFO  {SparkEnv} Registering MapOutputTracker
[13:50:46,708] INFO  {SparkEnv} Registering BlockManagerMaster
[13:50:46,722] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-1223b603-da80-4ad2-9a0c-ff89370b1b8a
[13:50:46,738] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:50:46,812] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:50:46,910] INFO  {log} Logging initialized @2229ms
[13:50:47,027] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:50:47,044] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[13:50:47,044] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[13:50:47,045] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[13:50:47,045] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[13:50:47,045] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[13:50:47,045] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[13:50:47,045] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[13:50:47,045] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[13:50:47,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[13:50:47,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[13:50:47,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[13:50:47,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[13:50:47,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[13:50:47,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[13:50:47,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[13:50:47,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[13:50:47,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[13:50:47,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[13:50:47,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[13:50:47,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[13:50:47,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[13:50:47,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[13:50:47,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[13:50:47,054] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[13:50:47,059] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:50:47,059] INFO  {Server} Started @2380ms
[13:50:47,059] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:50:47,061] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:50:47,167] INFO  {Executor} Starting executor ID driver on host localhost
[13:50:47,190] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44381.
[13:50:47,191] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:44381
[13:50:47,194] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 44381)
[13:50:47,197] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:44381 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 44381)
[13:50:47,203] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 44381)
[13:50:47,388] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[13:50:47,990] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[13:50:48,054] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[13:50:48,056] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:44381 (size: 14.6 KB, free: 1128.9 MB)
[13:50:48,060] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:42
[13:50:48,129] INFO  {FileInputFormat} Total input paths to process : 2
[13:50:48,132] INFO  {FileInputFormat} Total input paths to process : 2
[13:50:48,158] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[13:50:48,228] INFO  {SparkContext} Starting job: take at Main.scala:44
[13:50:48,246] INFO  {DAGScheduler} Got job 0 (take at Main.scala:44) with 1 output partitions
[13:50:48,247] INFO  {DAGScheduler} Final stage: ResultStage 0 (take at Main.scala:44)
[13:50:48,247] INFO  {DAGScheduler} Parents of final stage: List()
[13:50:48,249] INFO  {DAGScheduler} Missing parents: List()
[13:50:48,258] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at mapValues at Main.scala:44), which has no missing parents
[13:50:48,284] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 1128.8 MB)
[13:50:48,287] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 1718.0 B, free 1128.8 MB)
[13:50:48,288] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:44381 (size: 1718.0 B, free: 1128.9 MB)
[13:50:48,289] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[13:50:48,292] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at mapValues at Main.scala:44)
[13:50:48,294] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[13:50:48,363] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5575 bytes)
[13:50:48,374] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[13:50:48,396] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[13:50:48,443] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[13:50:48,451] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[13:50:48,452] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[13:50:48,455] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[13:50:49,188] INFO  {MemoryStore} Block taskresult_0 stored as bytes in memory (estimated size 2.4 MB, free 1126.4 MB)
[13:50:49,189] INFO  {BlockManagerInfo} Added taskresult_0 in memory on 192.168.0.103:44381 (size: 2.4 MB, free: 1126.5 MB)
[13:50:49,190] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2509739 bytes result sent via BlockManager)
[13:50:49,263] INFO  {TransportClientFactory} Successfully created connection to /192.168.0.103:44381 after 46 ms (0 ms spent in bootstraps)
[13:50:49,406] INFO  {BlockManagerInfo} Removed taskresult_0 on 192.168.0.103:44381 in memory (size: 2.4 MB, free: 1128.9 MB)
[13:50:49,441] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 1072 ms on localhost (1/1)
[13:50:49,442] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[13:50:49,445] INFO  {DAGScheduler} ResultStage 0 (take at Main.scala:44) finished in 1.137 s
[13:50:49,450] INFO  {DAGScheduler} Job 0 finished: take at Main.scala:44, took 1.221281 s
[13:50:49,457] INFO  {SparkContext} Invoking stop() from shutdown hook
[13:50:49,462] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:50:49,465] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[13:50:49,465] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[13:50:49,465] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[13:50:49,465] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[13:50:49,466] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[13:50:49,466] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[13:50:49,466] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[13:50:49,466] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[13:50:49,466] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[13:50:49,466] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[13:50:49,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[13:50:49,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[13:50:49,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[13:50:49,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[13:50:49,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[13:50:49,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[13:50:49,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[13:50:49,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[13:50:49,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[13:50:49,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[13:50:49,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[13:50:49,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[13:50:49,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[13:50:49,469] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[13:50:49,471] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[13:50:49,482] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[13:50:49,492] INFO  {MemoryStore} MemoryStore cleared
[13:50:49,493] INFO  {BlockManager} BlockManager stopped
[13:50:49,494] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[13:50:49,496] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[13:50:49,502] INFO  {SparkContext} Successfully stopped SparkContext
[13:50:49,503] INFO  {ShutdownHookManager} Shutdown hook called
[13:50:49,504] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-e1f6a95f-84c0-4b6b-ab40-4dbb86971b2c
[13:59:54,855] INFO  {SparkContext} Running Spark version 2.0.1
[13:59:55,679] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[13:59:55,925] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[13:59:55,927] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[13:59:56,096] INFO  {SecurityManager} Changing view acls to: victor
[13:59:56,098] INFO  {SecurityManager} Changing modify acls to: victor
[13:59:56,102] INFO  {SecurityManager} Changing view acls groups to: 
[13:59:56,104] INFO  {SecurityManager} Changing modify acls groups to: 
[13:59:56,107] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[13:59:57,083] INFO  {Utils} Successfully started service 'sparkDriver' on port 45447.
[13:59:57,168] INFO  {SparkEnv} Registering MapOutputTracker
[13:59:57,227] INFO  {SparkEnv} Registering BlockManagerMaster
[13:59:57,275] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-71541834-8168-4694-ac82-dc1295f7074d
[13:59:57,361] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[13:59:57,607] INFO  {SparkEnv} Registering OutputCommitCoordinator
[13:59:57,942] INFO  {log} Logging initialized @5830ms
[13:59:58,349] INFO  {Server} jetty-9.2.z-SNAPSHOT
[13:59:58,403] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[13:59:58,404] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[13:59:58,405] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[13:59:58,406] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[13:59:58,406] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[13:59:58,407] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[13:59:58,408] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[13:59:58,408] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[13:59:58,409] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[13:59:58,410] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[13:59:58,411] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[13:59:58,411] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[13:59:58,412] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[13:59:58,413] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[13:59:58,414] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[13:59:58,415] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[13:59:58,415] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[13:59:58,416] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[13:59:58,416] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[13:59:58,417] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[13:59:58,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[13:59:58,437] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[13:59:58,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[13:59:58,441] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[13:59:58,468] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[13:59:58,470] INFO  {Server} Started @6359ms
[13:59:58,470] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[13:59:58,481] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[13:59:58,720] INFO  {Executor} Starting executor ID driver on host localhost
[13:59:58,778] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39249.
[13:59:58,780] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:39249
[13:59:58,784] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 39249)
[13:59:58,792] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:39249 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 39249)
[13:59:58,804] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 39249)
[13:59:59,054] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:00:00,428] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[14:00:00,660] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:00:00,672] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:39249 (size: 14.6 KB, free: 1128.9 MB)
[14:00:00,690] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:42
[14:00:00,938] INFO  {FileInputFormat} Total input paths to process : 2
[14:00:00,947] INFO  {FileInputFormat} Total input paths to process : 2
[14:00:01,009] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[14:00:01,240] INFO  {SparkContext} Starting job: take at Main.scala:44
[14:00:01,311] INFO  {DAGScheduler} Got job 0 (take at Main.scala:44) with 1 output partitions
[14:00:01,312] INFO  {DAGScheduler} Final stage: ResultStage 0 (take at Main.scala:44)
[14:00:01,314] INFO  {DAGScheduler} Parents of final stage: List()
[14:00:01,332] INFO  {DAGScheduler} Missing parents: List()
[14:00:01,362] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at mapValues at Main.scala:44), which has no missing parents
[14:00:01,440] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 1128.8 MB)
[14:00:01,458] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 1718.0 B, free 1128.8 MB)
[14:00:01,462] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:39249 (size: 1718.0 B, free: 1128.9 MB)
[14:00:01,464] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:00:01,472] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at mapValues at Main.scala:44)
[14:00:01,477] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:00:01,682] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5575 bytes)
[14:00:01,712] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:00:01,775] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[14:00:01,879] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[14:00:01,898] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[14:00:01,900] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[14:00:01,905] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[14:00:03,147] INFO  {MemoryStore} Block taskresult_0 stored as bytes in memory (estimated size 2.4 MB, free 1126.4 MB)
[14:00:03,149] INFO  {BlockManagerInfo} Added taskresult_0 in memory on 192.168.0.103:39249 (size: 2.4 MB, free: 1126.5 MB)
[14:00:03,153] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2509739 bytes result sent via BlockManager)
[14:00:03,380] INFO  {TransportClientFactory} Successfully created connection to /192.168.0.103:39249 after 121 ms (0 ms spent in bootstraps)
[14:00:04,385] INFO  {BlockManagerInfo} Removed taskresult_0 on 192.168.0.103:39249 in memory (size: 2.4 MB, free: 1128.9 MB)
[14:00:04,461] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 2776 ms on localhost (1/1)
[14:00:04,475] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:00:04,479] INFO  {DAGScheduler} ResultStage 0 (take at Main.scala:44) finished in 2.962 s
[14:00:04,509] INFO  {DAGScheduler} Job 0 finished: take at Main.scala:44, took 3.267878 s
[14:00:04,579] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:00:04,625] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:00:04,631] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:00:04,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:00:04,634] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:00:04,635] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:00:04,635] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:00:04,636] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:00:04,638] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:00:04,639] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:00:04,640] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:00:04,641] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:00:04,643] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:00:04,644] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:00:04,644] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:00:04,645] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:00:04,646] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:00:04,649] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:00:04,650] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:00:04,651] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:00:04,652] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:00:04,653] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:00:04,653] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:00:04,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:00:04,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:00:04,655] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:00:04,661] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:00:04,729] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:00:04,754] INFO  {MemoryStore} MemoryStore cleared
[14:00:04,756] INFO  {BlockManager} BlockManager stopped
[14:00:04,778] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:00:04,797] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:00:04,863] INFO  {SparkContext} Successfully stopped SparkContext
[14:00:04,864] INFO  {ShutdownHookManager} Shutdown hook called
[14:00:04,868] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-444c6738-bff1-4bde-9471-8556babe0466
[14:00:24,687] INFO  {SparkContext} Running Spark version 2.0.1
[14:00:24,981] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:00:25,186] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:00:25,187] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:00:25,321] INFO  {SecurityManager} Changing view acls to: victor
[14:00:25,322] INFO  {SecurityManager} Changing modify acls to: victor
[14:00:25,323] INFO  {SecurityManager} Changing view acls groups to: 
[14:00:25,324] INFO  {SecurityManager} Changing modify acls groups to: 
[14:00:25,325] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:00:25,757] INFO  {Utils} Successfully started service 'sparkDriver' on port 35753.
[14:00:25,778] INFO  {SparkEnv} Registering MapOutputTracker
[14:00:25,797] INFO  {SparkEnv} Registering BlockManagerMaster
[14:00:25,810] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-f2744c41-b727-48ef-9048-77e1e982bcde
[14:00:25,826] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:00:25,880] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:00:25,974] INFO  {log} Logging initialized @2105ms
[14:00:26,093] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:00:26,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d3ac898{/jobs,null,AVAILABLE}
[14:00:26,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b73be9f{/jobs/json,null,AVAILABLE}
[14:00:26,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@628c4ac0{/jobs/job,null,AVAILABLE}
[14:00:26,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7b84fcf8{/jobs/job/json,null,AVAILABLE}
[14:00:26,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30b19518{/stages,null,AVAILABLE}
[14:00:26,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@363042d7{/stages/json,null,AVAILABLE}
[14:00:26,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@366ac49b{/stages/stage,null,AVAILABLE}
[14:00:26,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ad59d92{/stages/stage/json,null,AVAILABLE}
[14:00:26,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56f0cc85{/stages/pool,null,AVAILABLE}
[14:00:26,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62e20a76{/stages/pool/json,null,AVAILABLE}
[14:00:26,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2cc44ad{/storage,null,AVAILABLE}
[14:00:26,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@44b3606b{/storage/json,null,AVAILABLE}
[14:00:26,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1477089c{/storage/rdd,null,AVAILABLE}
[14:00:26,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@663411de{/storage/rdd/json,null,AVAILABLE}
[14:00:26,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@63dd899{/environment,null,AVAILABLE}
[14:00:26,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59d2400d{/environment/json,null,AVAILABLE}
[14:00:26,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@75cd8043{/executors,null,AVAILABLE}
[14:00:26,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@33b1c5c5{/executors/json,null,AVAILABLE}
[14:00:26,118] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5b202a3a{/executors/threadDump,null,AVAILABLE}
[14:00:26,118] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10b9db7b{/executors/threadDump/json,null,AVAILABLE}
[14:00:26,124] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@9ef8eb7{/static,null,AVAILABLE}
[14:00:26,124] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@34cdeda2{/,null,AVAILABLE}
[14:00:26,125] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ee660fb{/api,null,AVAILABLE}
[14:00:26,125] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@305a0c5f{/stages/stage/kill,null,AVAILABLE}
[14:00:26,130] INFO  {ServerConnector} Started ServerConnector@fc258b1{HTTP/1.1}{0.0.0.0:4040}
[14:00:26,131] INFO  {Server} Started @2263ms
[14:00:26,131] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:00:26,132] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:00:26,248] INFO  {Executor} Starting executor ID driver on host localhost
[14:00:26,271] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44287.
[14:00:26,272] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:44287
[14:00:26,273] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 44287)
[14:00:26,276] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:44287 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 44287)
[14:00:26,280] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 44287)
[14:00:26,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:00:27,028] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 1128.8 MB)
[14:00:27,118] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.8 MB)
[14:00:27,121] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:44287 (size: 14.6 KB, free: 1128.9 MB)
[14:00:27,126] INFO  {SparkContext} Created broadcast 0 from binaryFiles at Main.scala:42
[14:00:27,211] INFO  {FileInputFormat} Total input paths to process : 2
[14:00:27,213] INFO  {FileInputFormat} Total input paths to process : 2
[14:00:27,232] INFO  {CombineFileInputFormat} DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
[14:00:27,294] INFO  {SparkContext} Starting job: take at Main.scala:44
[14:00:27,317] INFO  {DAGScheduler} Got job 0 (take at Main.scala:44) with 1 output partitions
[14:00:27,318] INFO  {DAGScheduler} Final stage: ResultStage 0 (take at Main.scala:44)
[14:00:27,320] INFO  {DAGScheduler} Parents of final stage: List()
[14:00:27,324] INFO  {DAGScheduler} Missing parents: List()
[14:00:27,335] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at mapValues at Main.scala:44), which has no missing parents
[14:00:27,354] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 1128.8 MB)
[14:00:27,357] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 1718.0 B, free 1128.8 MB)
[14:00:27,359] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 192.168.0.103:44287 (size: 1718.0 B, free: 1128.9 MB)
[14:00:27,360] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[14:00:27,367] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at mapValues at Main.scala:44)
[14:00:27,370] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[14:00:27,437] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5575 bytes)
[14:00:27,448] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[14:00:27,473] INFO  {BinaryFileRDD} Input split: Paths:/home/victor/Desktop/dataset/fakeData/a.tar.gz:0+545863,/home/victor/Desktop/dataset/fakeData/b.tar.gz:0+545863
[14:00:27,527] INFO  {deprecation} map.input.start is deprecated. Instead, use mapreduce.map.input.start
[14:00:27,538] INFO  {deprecation} mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
[14:00:27,539] INFO  {deprecation} map.input.length is deprecated. Instead, use mapreduce.map.input.length
[14:00:27,543] INFO  {deprecation} map.input.file is deprecated. Instead, use mapreduce.map.input.file
[14:00:28,598] INFO  {MemoryStore} Block taskresult_0 stored as bytes in memory (estimated size 2.4 MB, free 1126.4 MB)
[14:00:28,599] INFO  {BlockManagerInfo} Added taskresult_0 in memory on 192.168.0.103:44287 (size: 2.4 MB, free: 1126.5 MB)
[14:00:28,601] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2509739 bytes result sent via BlockManager)
[14:00:28,686] INFO  {TransportClientFactory} Successfully created connection to /192.168.0.103:44287 after 40 ms (0 ms spent in bootstraps)
[14:00:28,855] INFO  {BlockManagerInfo} Removed taskresult_0 on 192.168.0.103:44287 in memory (size: 2.4 MB, free: 1128.9 MB)
[14:00:28,943] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 1450 ms on localhost (1/1)
[14:00:28,947] INFO  {DAGScheduler} ResultStage 0 (take at Main.scala:44) finished in 1.562 s
[14:00:28,956] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[14:00:28,971] INFO  {DAGScheduler} Job 0 finished: take at Main.scala:44, took 1.676069 s
[14:00:29,002] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:00:29,018] INFO  {ServerConnector} Stopped ServerConnector@fc258b1{HTTP/1.1}{0.0.0.0:4040}
[14:00:29,023] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@305a0c5f{/stages/stage/kill,null,UNAVAILABLE}
[14:00:29,024] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6ee660fb{/api,null,UNAVAILABLE}
[14:00:29,025] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@34cdeda2{/,null,UNAVAILABLE}
[14:00:29,025] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@9ef8eb7{/static,null,UNAVAILABLE}
[14:00:29,025] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10b9db7b{/executors/threadDump/json,null,UNAVAILABLE}
[14:00:29,026] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5b202a3a{/executors/threadDump,null,UNAVAILABLE}
[14:00:29,026] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@33b1c5c5{/executors/json,null,UNAVAILABLE}
[14:00:29,026] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@75cd8043{/executors,null,UNAVAILABLE}
[14:00:29,027] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59d2400d{/environment/json,null,UNAVAILABLE}
[14:00:29,027] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@63dd899{/environment,null,UNAVAILABLE}
[14:00:29,027] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@663411de{/storage/rdd/json,null,UNAVAILABLE}
[14:00:29,028] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1477089c{/storage/rdd,null,UNAVAILABLE}
[14:00:29,028] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@44b3606b{/storage/json,null,UNAVAILABLE}
[14:00:29,028] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2cc44ad{/storage,null,UNAVAILABLE}
[14:00:29,028] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@62e20a76{/stages/pool/json,null,UNAVAILABLE}
[14:00:29,029] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56f0cc85{/stages/pool,null,UNAVAILABLE}
[14:00:29,029] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6ad59d92{/stages/stage/json,null,UNAVAILABLE}
[14:00:29,029] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@366ac49b{/stages/stage,null,UNAVAILABLE}
[14:00:29,030] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@363042d7{/stages/json,null,UNAVAILABLE}
[14:00:29,030] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@30b19518{/stages,null,UNAVAILABLE}
[14:00:29,030] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7b84fcf8{/jobs/job/json,null,UNAVAILABLE}
[14:00:29,030] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@628c4ac0{/jobs/job,null,UNAVAILABLE}
[14:00:29,031] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1b73be9f{/jobs/json,null,UNAVAILABLE}
[14:00:29,031] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d3ac898{/jobs,null,UNAVAILABLE}
[14:00:29,034] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:00:29,059] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:00:29,081] INFO  {MemoryStore} MemoryStore cleared
[14:00:29,082] INFO  {BlockManager} BlockManager stopped
[14:00:29,085] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:00:29,091] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:00:29,108] INFO  {SparkContext} Successfully stopped SparkContext
[14:00:29,109] INFO  {ShutdownHookManager} Shutdown hook called
[14:00:29,112] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-cb863031-2326-4688-b8db-3b7e420b40aa
