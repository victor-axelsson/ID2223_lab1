[09:46:23,349] INFO  {SparkContext} Running Spark version 2.0.1
[09:46:23,813] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:46:23,980] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 130.229.178.24 instead (on interface wlp4s0)
[09:46:23,981] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:46:24,087] INFO  {SecurityManager} Changing view acls to: victor
[09:46:24,088] INFO  {SecurityManager} Changing modify acls to: victor
[09:46:24,089] INFO  {SecurityManager} Changing view acls groups to: 
[09:46:24,090] INFO  {SecurityManager} Changing modify acls groups to: 
[09:46:24,090] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:46:24,631] INFO  {Utils} Successfully started service 'sparkDriver' on port 44397.
[09:46:24,660] INFO  {SparkEnv} Registering MapOutputTracker
[09:46:24,683] INFO  {SparkEnv} Registering BlockManagerMaster
[09:46:24,701] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-11b7f6aa-b9f3-4069-9019-380f938ebaf1
[09:46:24,727] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:46:24,830] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:46:24,975] INFO  {log} Logging initialized @2687ms
[09:46:25,197] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:46:25,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1e8ce150{/jobs,null,AVAILABLE}
[09:46:25,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@604f2bd2{/jobs/json,null,AVAILABLE}
[09:46:25,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d3ac898{/jobs/job,null,AVAILABLE}
[09:46:25,233] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b73be9f{/jobs/job/json,null,AVAILABLE}
[09:46:25,233] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@628c4ac0{/stages,null,AVAILABLE}
[09:46:25,233] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7b84fcf8{/stages/json,null,AVAILABLE}
[09:46:25,233] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30b19518{/stages/stage,null,AVAILABLE}
[09:46:25,234] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@363042d7{/stages/stage/json,null,AVAILABLE}
[09:46:25,234] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@366ac49b{/stages/pool,null,AVAILABLE}
[09:46:25,234] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ad59d92{/stages/pool/json,null,AVAILABLE}
[09:46:25,235] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56f0cc85{/storage,null,AVAILABLE}
[09:46:25,235] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62e20a76{/storage/json,null,AVAILABLE}
[09:46:25,235] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2cc44ad{/storage/rdd,null,AVAILABLE}
[09:46:25,236] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@44b3606b{/storage/rdd/json,null,AVAILABLE}
[09:46:25,236] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1477089c{/environment,null,AVAILABLE}
[09:46:25,236] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@663411de{/environment/json,null,AVAILABLE}
[09:46:25,236] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@63dd899{/executors,null,AVAILABLE}
[09:46:25,237] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59d2400d{/executors/json,null,AVAILABLE}
[09:46:25,237] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@75cd8043{/executors/threadDump,null,AVAILABLE}
[09:46:25,237] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@33b1c5c5{/executors/threadDump/json,null,AVAILABLE}
[09:46:25,245] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5b202a3a{/static,null,AVAILABLE}
[09:46:25,245] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10b9db7b{/,null,AVAILABLE}
[09:46:25,246] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@9ef8eb7{/api,null,AVAILABLE}
[09:46:25,247] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@34cdeda2{/stages/stage/kill,null,AVAILABLE}
[09:46:25,256] INFO  {ServerConnector} Started ServerConnector@2d1dee39{HTTP/1.1}{0.0.0.0:4040}
[09:46:25,257] INFO  {Server} Started @2970ms
[09:46:25,257] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:46:25,259] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://130.229.178.24:4040
[09:46:25,435] INFO  {Executor} Starting executor ID driver on host localhost
[09:46:25,481] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37605.
[09:46:25,482] INFO  {NettyBlockTransferService} Server created on 130.229.178.24:37605
[09:46:25,485] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 130.229.178.24, 37605)
[09:46:25,489] INFO  {BlockManagerMasterEndpoint} Registering block manager 130.229.178.24:37605 with 1128.9 MB RAM, BlockManagerId(driver, 130.229.178.24, 37605)
[09:46:25,501] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 130.229.178.24, 37605)
[09:46:25,742] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[09:46:25,802] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:46:25,811] INFO  {ServerConnector} Stopped ServerConnector@2d1dee39{HTTP/1.1}{0.0.0.0:4040}
[09:46:25,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@34cdeda2{/stages/stage/kill,null,UNAVAILABLE}
[09:46:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@9ef8eb7{/api,null,UNAVAILABLE}
[09:46:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10b9db7b{/,null,UNAVAILABLE}
[09:46:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5b202a3a{/static,null,UNAVAILABLE}
[09:46:25,815] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@33b1c5c5{/executors/threadDump/json,null,UNAVAILABLE}
[09:46:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@75cd8043{/executors/threadDump,null,UNAVAILABLE}
[09:46:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59d2400d{/executors/json,null,UNAVAILABLE}
[09:46:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@63dd899{/executors,null,UNAVAILABLE}
[09:46:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@663411de{/environment/json,null,UNAVAILABLE}
[09:46:25,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1477089c{/environment,null,UNAVAILABLE}
[09:46:25,817] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@44b3606b{/storage/rdd/json,null,UNAVAILABLE}
[09:46:25,817] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2cc44ad{/storage/rdd,null,UNAVAILABLE}
[09:46:25,817] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@62e20a76{/storage/json,null,UNAVAILABLE}
[09:46:25,817] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56f0cc85{/storage,null,UNAVAILABLE}
[09:46:25,817] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6ad59d92{/stages/pool/json,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@366ac49b{/stages/pool,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@363042d7{/stages/stage/json,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@30b19518{/stages/stage,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7b84fcf8{/stages/json,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@628c4ac0{/stages,null,UNAVAILABLE}
[09:46:25,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1b73be9f{/jobs/job/json,null,UNAVAILABLE}
[09:46:25,819] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d3ac898{/jobs/job,null,UNAVAILABLE}
[09:46:25,819] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@604f2bd2{/jobs/json,null,UNAVAILABLE}
[09:46:25,819] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1e8ce150{/jobs,null,UNAVAILABLE}
[09:46:25,823] INFO  {SparkUI} Stopped Spark web UI at http://130.229.178.24:4040
[09:46:25,847] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:46:25,859] INFO  {MemoryStore} MemoryStore cleared
[09:46:25,860] INFO  {BlockManager} BlockManager stopped
[09:46:25,869] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:46:25,874] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:46:25,895] INFO  {SparkContext} Successfully stopped SparkContext
[09:46:25,896] INFO  {ShutdownHookManager} Shutdown hook called
[09:46:25,898] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-8702c5f0-7507-4165-affb-1bac1255d128
[08:43:45,742] INFO  {SparkContext} Running Spark version 2.0.1
[08:43:46,353] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:43:46,600] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:43:46,601] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:43:46,760] INFO  {SecurityManager} Changing view acls to: victor
[08:43:46,775] INFO  {SecurityManager} Changing modify acls to: victor
[08:43:46,776] INFO  {SecurityManager} Changing view acls groups to: 
[08:43:46,777] INFO  {SecurityManager} Changing modify acls groups to: 
[08:43:46,779] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:43:47,348] INFO  {Utils} Successfully started service 'sparkDriver' on port 42575.
[08:43:47,442] INFO  {SparkEnv} Registering MapOutputTracker
[08:43:47,520] INFO  {SparkEnv} Registering BlockManagerMaster
[08:43:47,546] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e954d319-02fd-444e-8703-dd8a78526d8a
[08:43:47,598] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:43:47,722] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:43:47,960] INFO  {log} Logging initialized @3935ms
[08:43:48,103] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:43:48,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:43:48,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:43:48,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:43:48,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:43:48,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:43:48,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:43:48,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:43:48,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:43:48,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:43:48,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:43:48,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:43:48,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:43:48,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:43:48,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:43:48,122] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:43:48,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:43:48,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:43:48,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:43:48,130] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:43:48,138] INFO  {ServerConnector} Started ServerConnector@716d7f02{HTTP/1.1}{0.0.0.0:4040}
[08:43:48,138] INFO  {Server} Started @4114ms
[08:43:48,138] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:43:48,141] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:43:48,375] INFO  {Executor} Starting executor ID driver on host localhost
[08:43:48,413] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36609.
[08:43:48,414] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:36609
[08:43:48,421] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 36609)
[08:43:48,432] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:36609 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 36609)
[08:43:48,439] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 36609)
[08:43:48,615] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[08:43:48,843] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:43:48,856] INFO  {ServerConnector} Stopped ServerConnector@716d7f02{HTTP/1.1}{0.0.0.0:4040}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:43:48,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:43:48,859] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:43:48,860] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:43:48,861] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:43:48,861] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:43:48,862] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:43:48,871] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:43:48,875] INFO  {MemoryStore} MemoryStore cleared
[08:43:48,876] INFO  {BlockManager} BlockManager stopped
[08:43:48,993] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:43:49,007] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:43:49,009] INFO  {SparkContext} Successfully stopped SparkContext
[08:43:49,019] INFO  {ShutdownHookManager} Shutdown hook called
[08:43:49,020] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f7d8bbd9-2dba-483c-a46c-788a2d3a2e8f
[08:45:29,117] INFO  {SparkContext} Running Spark version 2.0.1
[08:45:29,323] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:45:29,417] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:45:29,418] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:45:29,476] INFO  {SecurityManager} Changing view acls to: victor
[08:45:29,476] INFO  {SecurityManager} Changing modify acls to: victor
[08:45:29,477] INFO  {SecurityManager} Changing view acls groups to: 
[08:45:29,478] INFO  {SecurityManager} Changing modify acls groups to: 
[08:45:29,478] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:45:29,848] INFO  {Utils} Successfully started service 'sparkDriver' on port 33095.
[08:45:29,866] INFO  {SparkEnv} Registering MapOutputTracker
[08:45:29,882] INFO  {SparkEnv} Registering BlockManagerMaster
[08:45:29,894] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-d6480a92-1a0d-425a-a570-f8717b0847f6
[08:45:29,908] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:45:29,961] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:45:30,038] INFO  {log} Logging initialized @1585ms
[08:45:30,139] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:45:30,156] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:45:30,156] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:45:30,156] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:45:30,156] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:45:30,156] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:45:30,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:45:30,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:45:30,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:45:30,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:45:30,157] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:45:30,158] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:45:30,158] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:45:30,158] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:45:30,158] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:45:30,158] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:45:30,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:45:30,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:45:30,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:45:30,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:45:30,159] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:45:30,165] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:45:30,165] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:45:30,166] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:45:30,166] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:45:30,172] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:45:30,173] INFO  {Server} Started @1721ms
[08:45:30,173] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:45:30,175] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:45:30,253] INFO  {Executor} Starting executor ID driver on host localhost
[08:45:30,277] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41087.
[08:45:30,278] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:41087
[08:45:30,280] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 41087)
[08:45:30,284] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:41087 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 41087)
[08:45:30,287] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 41087)
[08:45:30,412] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[08:45:30,457] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:45:30,464] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:45:30,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:45:30,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:45:30,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:45:30,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:45:30,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:45:30,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:45:30,469] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:45:30,469] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:45:30,469] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:45:30,469] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:45:30,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:45:30,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:45:30,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:45:30,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:45:30,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:45:30,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:45:30,472] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:45:30,472] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:45:30,472] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:45:30,475] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:45:30,487] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:45:30,494] INFO  {MemoryStore} MemoryStore cleared
[08:45:30,494] INFO  {BlockManager} BlockManager stopped
[08:45:30,500] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:45:30,505] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:45:30,506] INFO  {SparkContext} Successfully stopped SparkContext
[08:45:30,507] INFO  {ShutdownHookManager} Shutdown hook called
[08:45:30,508] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-8a2e4fdc-1dce-4380-8432-cb705a2eae7c
[08:45:54,292] INFO  {SparkContext} Running Spark version 2.0.1
[08:45:54,502] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:45:54,591] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:45:54,591] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:45:54,655] INFO  {SecurityManager} Changing view acls to: victor
[08:45:54,655] INFO  {SecurityManager} Changing modify acls to: victor
[08:45:54,656] INFO  {SecurityManager} Changing view acls groups to: 
[08:45:54,656] INFO  {SecurityManager} Changing modify acls groups to: 
[08:45:54,657] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:45:55,005] INFO  {Utils} Successfully started service 'sparkDriver' on port 39237.
[08:45:55,022] INFO  {SparkEnv} Registering MapOutputTracker
[08:45:55,044] INFO  {SparkEnv} Registering BlockManagerMaster
[08:45:55,062] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-a97d9f46-c0f0-427a-a02b-4912bfbc69c9
[08:45:55,076] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:45:55,124] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:45:55,196] INFO  {log} Logging initialized @1539ms
[08:45:55,302] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:45:55,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:45:55,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:45:55,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:45:55,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:45:55,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:45:55,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:45:55,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:45:55,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:45:55,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:45:55,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:45:55,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:45:55,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:45:55,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:45:55,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:45:55,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:45:55,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:45:55,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:45:55,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:45:55,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:45:55,323] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:45:55,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:45:55,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:45:55,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:45:55,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:45:55,339] INFO  {ServerConnector} Started ServerConnector@7fdeec44{HTTP/1.1}{0.0.0.0:4040}
[08:45:55,339] INFO  {Server} Started @1683ms
[08:45:55,339] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:45:55,342] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:45:55,431] INFO  {Executor} Starting executor ID driver on host localhost
[08:45:55,455] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38849.
[08:45:55,456] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:38849
[08:45:55,458] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 38849)
[08:45:55,461] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:38849 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 38849)
[08:45:55,464] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 38849)
[08:45:55,585] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6a1d204a{/metrics/json,null,AVAILABLE}
[08:45:56,467] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[08:45:56,592] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[08:45:56,596] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:38849 (size: 14.3 KB, free: 1128.9 MB)
[08:45:56,626] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:24
[08:45:57,033] INFO  {FileInputFormat} Total input paths to process : 1
[08:45:57,072] INFO  {SparkContext} Starting job: top at Main.scala:27
[08:45:57,109] INFO  {DAGScheduler} Got job 0 (top at Main.scala:27) with 1 output partitions
[08:45:57,109] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:27)
[08:45:57,109] INFO  {DAGScheduler} Parents of final stage: List()
[08:45:57,119] INFO  {DAGScheduler} Missing parents: List()
[08:45:57,149] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27), which has no missing parents
[08:45:57,285] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[08:45:57,287] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[08:45:57,288] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:38849 (size: 2.1 KB, free: 1128.9 MB)
[08:45:57,289] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[08:45:57,292] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27)
[08:45:57,293] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[08:45:57,371] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:45:57,378] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[08:45:57,434] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:45:57,473] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[08:45:57,473] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[08:45:57,473] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[08:45:57,473] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[08:45:57,473] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[08:45:57,593] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[08:45:57,609] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 275 ms on localhost (1/1)
[08:45:57,610] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[08:45:57,615] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:27) finished in 0.313 s
[08:45:57,623] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:27, took 0.550697 s
[08:45:57,660] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:45:57,664] INFO  {ServerConnector} Stopped ServerConnector@7fdeec44{HTTP/1.1}{0.0.0.0:4040}
[08:45:57,666] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:45:57,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:45:57,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:45:57,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:45:57,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:45:57,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:45:57,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:45:57,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:45:57,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:45:57,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:45:57,671] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:45:57,680] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:45:57,684] INFO  {MemoryStore} MemoryStore cleared
[08:45:57,685] INFO  {BlockManager} BlockManager stopped
[08:45:57,689] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:45:57,691] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:45:57,692] INFO  {SparkContext} Successfully stopped SparkContext
[08:45:57,693] INFO  {ShutdownHookManager} Shutdown hook called
[08:45:57,693] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a65e21e4-917c-41b4-bd54-d1d708e042ba
[08:49:04,782] INFO  {SparkContext} Running Spark version 2.0.1
[08:49:05,016] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:49:05,166] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:49:05,167] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:49:05,264] INFO  {SecurityManager} Changing view acls to: victor
[08:49:05,265] INFO  {SecurityManager} Changing modify acls to: victor
[08:49:05,266] INFO  {SecurityManager} Changing view acls groups to: 
[08:49:05,267] INFO  {SecurityManager} Changing modify acls groups to: 
[08:49:05,267] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:49:05,666] INFO  {Utils} Successfully started service 'sparkDriver' on port 34185.
[08:49:05,683] INFO  {SparkEnv} Registering MapOutputTracker
[08:49:05,700] INFO  {SparkEnv} Registering BlockManagerMaster
[08:49:05,713] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e606bd99-df72-45bf-a583-8ccdc6957b0a
[08:49:05,729] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:49:05,786] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:49:05,863] INFO  {log} Logging initialized @1852ms
[08:49:05,980] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:49:05,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:49:05,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:49:05,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:49:05,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:49:05,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:49:05,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:49:05,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:49:05,999] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:49:06,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:49:06,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:49:06,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:49:06,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:49:06,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:49:06,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:49:06,002] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:49:06,009] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:49:06,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:49:06,012] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:49:06,013] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:49:06,021] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:49:06,022] INFO  {Server} Started @2012ms
[08:49:06,022] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:49:06,028] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:49:06,131] INFO  {Executor} Starting executor ID driver on host localhost
[08:49:06,162] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34249.
[08:49:06,163] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:34249
[08:49:06,166] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 34249)
[08:49:06,169] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:34249 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 34249)
[08:49:06,176] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 34249)
[08:49:06,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[08:49:06,476] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[08:49:06,477] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[08:49:06,478] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[08:49:06,479] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[08:49:06,481] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[08:49:06,513] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[08:49:09,393] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[08:49:09,441] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[08:49:09,443] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:34249 (size: 14.3 KB, free: 1128.9 MB)
[08:49:09,447] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:24
[08:49:09,824] INFO  {FileSourceStrategy} Pruning directories with: 
[08:49:09,827] INFO  {FileSourceStrategy} Post-Scan Filters: 
[08:49:09,831] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[08:49:09,832] INFO  {FileSourceStrategy} Pushed Filters: 
[08:49:09,840] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 131.0 KB, free 1128.6 MB)
[08:49:09,852] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.6 MB)
[08:49:09,854] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:34249 (size: 14.6 KB, free: 1128.9 MB)
[08:49:09,857] INFO  {SparkContext} Created broadcast 1 from foreach at Main.scala:33
[08:49:09,861] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[08:49:10,093] INFO  {FileSourceStrategy} Pruning directories with: 
[08:49:10,094] INFO  {FileSourceStrategy} Post-Scan Filters: 
[08:49:10,094] INFO  {FileSourceStrategy} Pruned Data Schema: struct<value: string>
[08:49:10,094] INFO  {FileSourceStrategy} Pushed Filters: 
[08:49:10,099] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 131.0 KB, free 1128.5 MB)
[08:49:10,111] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1128.5 MB)
[08:49:10,112] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:34249 (size: 14.6 KB, free: 1128.9 MB)
[08:49:10,114] INFO  {SparkContext} Created broadcast 2 from foreach at Main.scala:33
[08:49:10,114] INFO  {FileSourceStrategy} Planning scan with bin packing, max size: 5442419 bytes, open cost is considered as scanning 4194304 bytes.
[08:49:10,635] INFO  {CodeGenerator} Code generated in 382.629725 ms
[08:49:10,653] INFO  {CodeGenerator} Code generated in 12.703581 ms
[08:49:10,749] INFO  {SparkContext} Starting job: foreach at Main.scala:33
[08:49:10,768] INFO  {DAGScheduler} Registering RDD 5 (foreach at Main.scala:33)
[08:49:10,770] INFO  {DAGScheduler} Got job 0 (foreach at Main.scala:33) with 1 output partitions
[08:49:10,771] INFO  {DAGScheduler} Final stage: ResultStage 1 (foreach at Main.scala:33)
[08:49:10,771] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 0)
[08:49:10,772] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 0)
[08:49:10,777] INFO  {DAGScheduler} Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at foreach at Main.scala:33), which has no missing parents
[08:49:10,835] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 8.8 KB, free 1128.5 MB)
[08:49:10,838] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.5 MB)
[08:49:10,839] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:34249 (size: 4.6 KB, free: 1128.9 MB)
[08:49:10,839] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[08:49:10,843] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at foreach at Main.scala:33)
[08:49:10,844] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[08:49:10,890] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5978 bytes)
[08:49:10,899] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[08:49:10,954] INFO  {ContextCleaner} Cleaned accumulator 2
[08:49:10,973] INFO  {FileScanRDD} Reading File path: file:///home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt, range: 0-1248115, partition values: [empty row]
[08:49:10,991] INFO  {CodeGenerator} Code generated in 13.25467 ms
[08:49:11,157] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
[08:49:11,167] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 299 ms on localhost (1/1)
[08:49:11,168] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[08:49:11,174] INFO  {DAGScheduler} ShuffleMapStage 0 (foreach at Main.scala:33) finished in 0.317 s
[08:49:11,174] INFO  {DAGScheduler} looking for newly runnable stages
[08:49:11,175] INFO  {DAGScheduler} running: Set()
[08:49:11,175] INFO  {DAGScheduler} waiting: Set(ResultStage 1)
[08:49:11,176] INFO  {DAGScheduler} failed: Set()
[08:49:11,177] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[9] at foreach at Main.scala:33), which has no missing parents
[08:49:11,210] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 12.2 KB, free 1128.5 MB)
[08:49:11,212] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1128.4 MB)
[08:49:11,213] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:34249 (size: 6.3 KB, free: 1128.8 MB)
[08:49:11,214] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[08:49:11,215] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at foreach at Main.scala:33)
[08:49:11,216] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[08:49:11,221] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5317 bytes)
[08:49:11,222] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[08:49:11,243] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[08:49:11,245] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[08:49:11,272] INFO  {CodeGenerator} Code generated in 10.663486 ms
[08:49:11,284] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1797 bytes result sent to driver
[08:49:11,287] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 68 ms on localhost (1/1)
[08:49:11,287] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[08:49:11,287] INFO  {DAGScheduler} ResultStage 1 (foreach at Main.scala:33) finished in 0.069 s
[08:49:11,295] INFO  {DAGScheduler} Job 0 finished: foreach at Main.scala:33, took 0.545768 s
[08:49:11,302] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:49:11,308] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:49:11,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:49:11,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:49:11,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:49:11,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:49:11,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:49:11,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:49:11,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:49:11,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:49:11,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:49:11,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:49:11,316] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:49:11,317] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:49:11,327] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:49:11,331] INFO  {MemoryStore} MemoryStore cleared
[08:49:11,331] INFO  {BlockManager} BlockManager stopped
[08:49:11,337] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:49:11,339] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:49:11,345] INFO  {SparkContext} Successfully stopped SparkContext
[08:49:11,346] INFO  {ShutdownHookManager} Shutdown hook called
[08:49:11,347] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-4cb8d534-cf10-4cdc-9142-416c2a05200d
[08:53:23,287] INFO  {SparkContext} Running Spark version 2.0.1
[08:53:23,488] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:53:23,592] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:53:23,592] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:53:23,661] INFO  {SecurityManager} Changing view acls to: victor
[08:53:23,661] INFO  {SecurityManager} Changing modify acls to: victor
[08:53:23,662] INFO  {SecurityManager} Changing view acls groups to: 
[08:53:23,663] INFO  {SecurityManager} Changing modify acls groups to: 
[08:53:23,664] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:53:24,007] INFO  {Utils} Successfully started service 'sparkDriver' on port 41773.
[08:53:24,023] INFO  {SparkEnv} Registering MapOutputTracker
[08:53:24,040] INFO  {SparkEnv} Registering BlockManagerMaster
[08:53:24,052] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-98928cdf-182b-493d-b25f-219f6c4f5982
[08:53:24,066] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:53:24,119] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:53:24,193] INFO  {log} Logging initialized @1518ms
[08:53:24,296] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:53:24,311] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[08:53:24,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[08:53:24,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[08:53:24,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[08:53:24,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[08:53:24,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[08:53:24,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[08:53:24,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[08:53:24,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[08:53:24,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[08:53:24,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[08:53:24,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[08:53:24,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[08:53:24,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[08:53:24,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[08:53:24,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[08:53:24,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[08:53:24,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[08:53:24,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[08:53:24,328] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[08:53:24,329] INFO  {Server} Started @1654ms
[08:53:24,329] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:53:24,331] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:53:24,406] INFO  {Executor} Starting executor ID driver on host localhost
[08:53:24,425] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46025.
[08:53:24,425] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:46025
[08:53:24,427] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 46025)
[08:53:24,430] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:46025 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 46025)
[08:53:24,433] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 46025)
[08:53:24,547] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[08:53:24,590] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL,null,AVAILABLE}
[08:53:24,590] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46c670a6{/SQL/json,null,AVAILABLE}
[08:53:24,591] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution,null,AVAILABLE}
[08:53:24,592] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@355e34c7{/SQL/execution/json,null,AVAILABLE}
[08:53:24,593] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@770d0ea6{/static/sql,null,AVAILABLE}
[08:53:24,608] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[08:53:26,506] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[08:53:26,549] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[08:53:26,551] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:46025 (size: 14.3 KB, free: 1128.9 MB)
[08:53:26,554] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:24
[08:53:26,629] INFO  {FileInputFormat} Total input paths to process : 1
[08:53:26,641] INFO  {SparkContext} Starting job: top at Main.scala:27
[08:53:26,656] INFO  {DAGScheduler} Got job 0 (top at Main.scala:27) with 1 output partitions
[08:53:26,656] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:27)
[08:53:26,656] INFO  {DAGScheduler} Parents of final stage: List()
[08:53:26,658] INFO  {DAGScheduler} Missing parents: List()
[08:53:26,665] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27), which has no missing parents
[08:53:26,712] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[08:53:26,714] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[08:53:26,715] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:46025 (size: 2.1 KB, free: 1128.9 MB)
[08:53:26,716] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[08:53:26,719] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27)
[08:53:26,720] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[08:53:26,758] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:53:26,764] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[08:53:26,787] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:53:26,792] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[08:53:26,793] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[08:53:26,793] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[08:53:26,793] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[08:53:26,793] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[08:53:26,843] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[08:53:26,850] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 112 ms on localhost (1/1)
[08:53:26,852] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[08:53:26,854] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:27) finished in 0.125 s
[08:53:26,859] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:27, took 0.217079 s
[08:53:26,876] INFO  {SparkContext} Starting job: top at Main.scala:40
[08:53:26,877] INFO  {DAGScheduler} Got job 1 (top at Main.scala:40) with 1 output partitions
[08:53:26,877] INFO  {DAGScheduler} Final stage: ResultStage 1 (top at Main.scala:40)
[08:53:26,877] INFO  {DAGScheduler} Parents of final stage: List()
[08:53:26,877] INFO  {DAGScheduler} Missing parents: List()
[08:53:26,877] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[4] at top at Main.scala:40), which has no missing parents
[08:53:26,882] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 1128.8 MB)
[08:53:26,884] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1128.8 MB)
[08:53:26,885] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:46025 (size: 2.3 KB, free: 1128.9 MB)
[08:53:26,886] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[08:53:26,886] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at top at Main.scala:40)
[08:53:26,886] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[08:53:26,889] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:53:26,889] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[08:53:26,895] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:53:26,986] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1392 bytes result sent to driver
[08:53:26,990] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 102 ms on localhost (1/1)
[08:53:26,990] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[08:53:26,990] INFO  {DAGScheduler} ResultStage 1 (top at Main.scala:40) finished in 0.104 s
[08:53:26,991] INFO  {DAGScheduler} Job 1 finished: top at Main.scala:40, took 0.115049 s
[08:53:27,004] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:53:27,010] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[08:53:27,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[08:53:27,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[08:53:27,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[08:53:27,013] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[08:53:27,014] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[08:53:27,015] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[08:53:27,016] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[08:53:27,017] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[08:53:27,019] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:53:27,030] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:53:27,035] INFO  {MemoryStore} MemoryStore cleared
[08:53:27,035] INFO  {BlockManager} BlockManager stopped
[08:53:27,040] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:53:27,042] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:53:27,043] INFO  {SparkContext} Successfully stopped SparkContext
[08:53:27,044] INFO  {ShutdownHookManager} Shutdown hook called
[08:53:27,045] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-619101db-9c84-4d99-b556-dc6a9c7ad89f
[08:53:48,595] INFO  {SparkContext} Running Spark version 2.0.1
[08:53:48,833] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:53:48,928] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:53:48,928] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:53:48,981] INFO  {SecurityManager} Changing view acls to: victor
[08:53:48,982] INFO  {SecurityManager} Changing modify acls to: victor
[08:53:48,982] INFO  {SecurityManager} Changing view acls groups to: 
[08:53:48,983] INFO  {SecurityManager} Changing modify acls groups to: 
[08:53:48,983] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:53:49,327] INFO  {Utils} Successfully started service 'sparkDriver' on port 46685.
[08:53:49,343] INFO  {SparkEnv} Registering MapOutputTracker
[08:53:49,358] INFO  {SparkEnv} Registering BlockManagerMaster
[08:53:49,370] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-82a230cd-5786-495d-9c0c-4ae6271df88f
[08:53:49,385] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:53:49,443] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:53:49,517] INFO  {log} Logging initialized @1578ms
[08:53:49,624] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:53:49,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:53:49,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:53:49,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:53:49,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:53:49,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:53:49,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:53:49,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:53:49,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:53:49,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:53:49,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:53:49,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:53:49,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:53:49,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:53:49,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:53:49,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:53:49,650] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:53:49,650] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:53:49,651] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:53:49,651] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:53:49,657] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:53:49,658] INFO  {Server} Started @1720ms
[08:53:49,658] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:53:49,660] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:53:49,741] INFO  {Executor} Starting executor ID driver on host localhost
[08:53:49,765] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44509.
[08:53:49,765] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:44509
[08:53:49,767] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 44509)
[08:53:49,771] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:44509 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 44509)
[08:53:49,774] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 44509)
[08:53:49,894] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[08:53:49,936] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[08:53:49,937] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[08:53:49,938] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[08:53:49,938] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[08:53:49,940] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[08:53:49,953] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[08:53:51,872] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[08:53:51,915] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[08:53:51,917] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:44509 (size: 14.3 KB, free: 1128.9 MB)
[08:53:51,922] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:24
[08:53:51,997] INFO  {FileInputFormat} Total input paths to process : 1
[08:53:52,009] INFO  {SparkContext} Starting job: top at Main.scala:27
[08:53:52,024] INFO  {DAGScheduler} Got job 0 (top at Main.scala:27) with 1 output partitions
[08:53:52,024] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:27)
[08:53:52,025] INFO  {DAGScheduler} Parents of final stage: List()
[08:53:52,026] INFO  {DAGScheduler} Missing parents: List()
[08:53:52,033] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27), which has no missing parents
[08:53:52,075] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[08:53:52,076] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[08:53:52,077] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:44509 (size: 2.1 KB, free: 1128.9 MB)
[08:53:52,078] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[08:53:52,081] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27)
[08:53:52,082] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[08:53:52,123] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:53:52,129] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[08:53:52,158] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:53:52,164] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[08:53:52,164] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[08:53:52,164] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[08:53:52,165] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[08:53:52,165] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[08:53:52,230] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[08:53:52,236] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 133 ms on localhost (1/1)
[08:53:52,237] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[08:53:52,239] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:27) finished in 0.148 s
[08:53:52,243] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:27, took 0.234226 s
[08:53:52,263] INFO  {SparkContext} Starting job: top at Main.scala:40
[08:53:52,264] INFO  {DAGScheduler} Got job 1 (top at Main.scala:40) with 1 output partitions
[08:53:52,265] INFO  {DAGScheduler} Final stage: ResultStage 1 (top at Main.scala:40)
[08:53:52,265] INFO  {DAGScheduler} Parents of final stage: List()
[08:53:52,265] INFO  {DAGScheduler} Missing parents: List()
[08:53:52,265] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[4] at top at Main.scala:40), which has no missing parents
[08:53:52,270] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 1128.8 MB)
[08:53:52,271] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1128.8 MB)
[08:53:52,272] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:44509 (size: 2.3 KB, free: 1128.9 MB)
[08:53:52,273] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[08:53:52,273] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at top at Main.scala:40)
[08:53:52,273] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[08:53:52,276] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:53:52,277] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[08:53:52,283] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:53:52,365] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1392 bytes result sent to driver
[08:53:52,368] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 93 ms on localhost (1/1)
[08:53:52,368] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[08:53:52,368] INFO  {DAGScheduler} ResultStage 1 (top at Main.scala:40) finished in 0.094 s
[08:53:52,369] INFO  {DAGScheduler} Job 1 finished: top at Main.scala:40, took 0.105300 s
[08:53:52,377] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:53:52,381] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:53:52,383] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:53:52,383] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:53:52,383] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:53:52,383] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:53:52,383] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:53:52,384] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:53:52,385] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:53:52,386] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:53:52,387] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:53:52,398] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:53:52,405] INFO  {MemoryStore} MemoryStore cleared
[08:53:52,405] INFO  {BlockManager} BlockManager stopped
[08:53:52,410] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:53:52,412] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:53:52,414] INFO  {SparkContext} Successfully stopped SparkContext
[08:53:52,414] INFO  {ShutdownHookManager} Shutdown hook called
[08:53:52,415] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-8287ab6d-7325-407f-9374-7b305330899b
[08:56:02,508] INFO  {SparkContext} Running Spark version 2.0.1
[08:56:02,733] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[08:56:02,824] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[08:56:02,824] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[08:56:02,881] INFO  {SecurityManager} Changing view acls to: victor
[08:56:02,881] INFO  {SecurityManager} Changing modify acls to: victor
[08:56:02,882] INFO  {SecurityManager} Changing view acls groups to: 
[08:56:02,883] INFO  {SecurityManager} Changing modify acls groups to: 
[08:56:02,883] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[08:56:03,237] INFO  {Utils} Successfully started service 'sparkDriver' on port 36723.
[08:56:03,254] INFO  {SparkEnv} Registering MapOutputTracker
[08:56:03,269] INFO  {SparkEnv} Registering BlockManagerMaster
[08:56:03,281] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e7bf0abf-69b4-41d4-a93d-8a3cdfba8a58
[08:56:03,295] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[08:56:03,352] INFO  {SparkEnv} Registering OutputCommitCoordinator
[08:56:03,430] INFO  {log} Logging initialized @1506ms
[08:56:03,538] INFO  {Server} jetty-9.2.z-SNAPSHOT
[08:56:03,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,AVAILABLE}
[08:56:03,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,AVAILABLE}
[08:56:03,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,AVAILABLE}
[08:56:03,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,AVAILABLE}
[08:56:03,556] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/stages,null,AVAILABLE}
[08:56:03,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,AVAILABLE}
[08:56:03,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,AVAILABLE}
[08:56:03,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,AVAILABLE}
[08:56:03,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,AVAILABLE}
[08:56:03,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,AVAILABLE}
[08:56:03,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/storage,null,AVAILABLE}
[08:56:03,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/storage/json,null,AVAILABLE}
[08:56:03,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,AVAILABLE}
[08:56:03,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,AVAILABLE}
[08:56:03,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,AVAILABLE}
[08:56:03,559] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,AVAILABLE}
[08:56:03,559] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/executors,null,AVAILABLE}
[08:56:03,559] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,AVAILABLE}
[08:56:03,559] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,AVAILABLE}
[08:56:03,559] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,AVAILABLE}
[08:56:03,565] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,AVAILABLE}
[08:56:03,566] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/,null,AVAILABLE}
[08:56:03,566] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/api,null,AVAILABLE}
[08:56:03,567] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,AVAILABLE}
[08:56:03,573] INFO  {ServerConnector} Started ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:56:03,573] INFO  {Server} Started @1651ms
[08:56:03,573] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[08:56:03,575] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[08:56:03,649] INFO  {Executor} Starting executor ID driver on host localhost
[08:56:03,669] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40239.
[08:56:03,670] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:40239
[08:56:03,672] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 40239)
[08:56:03,675] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:40239 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 40239)
[08:56:03,677] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 40239)
[08:56:03,801] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@62dae245{/metrics/json,null,AVAILABLE}
[08:56:03,854] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@64712be{/SQL,null,AVAILABLE}
[08:56:03,854] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@30ed9c6c{/SQL/json,null,AVAILABLE}
[08:56:03,855] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2fd1731c{/SQL/execution,null,AVAILABLE}
[08:56:03,856] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6063d80a{/SQL/execution/json,null,AVAILABLE}
[08:56:03,858] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@60cf80e7{/static/sql,null,AVAILABLE}
[08:56:03,871] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[08:56:05,748] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[08:56:05,794] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[08:56:05,796] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:40239 (size: 14.3 KB, free: 1128.9 MB)
[08:56:05,800] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:24
[08:56:05,892] INFO  {FileInputFormat} Total input paths to process : 1
[08:56:05,904] INFO  {SparkContext} Starting job: top at Main.scala:27
[08:56:05,922] INFO  {DAGScheduler} Got job 0 (top at Main.scala:27) with 1 output partitions
[08:56:05,923] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:27)
[08:56:05,923] INFO  {DAGScheduler} Parents of final stage: List()
[08:56:05,925] INFO  {DAGScheduler} Missing parents: List()
[08:56:05,935] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27), which has no missing parents
[08:56:05,975] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[08:56:05,977] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[08:56:05,978] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:40239 (size: 2.1 KB, free: 1128.9 MB)
[08:56:05,979] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[08:56:05,982] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:27)
[08:56:05,983] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[08:56:06,020] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[08:56:06,027] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[08:56:06,048] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:56:06,053] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[08:56:06,053] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[08:56:06,053] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[08:56:06,053] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[08:56:06,053] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[08:56:06,108] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[08:56:06,114] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 114 ms on localhost (1/1)
[08:56:06,115] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[08:56:06,118] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:27) finished in 0.126 s
[08:56:06,122] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:27, took 0.218351 s
[08:56:06,170] INFO  {SparkContext} Starting job: take at Main.scala:38
[08:56:06,171] INFO  {DAGScheduler} Got job 1 (take at Main.scala:38) with 1 output partitions
[08:56:06,171] INFO  {DAGScheduler} Final stage: ResultStage 1 (take at Main.scala:38)
[08:56:06,171] INFO  {DAGScheduler} Parents of final stage: List()
[08:56:06,171] INFO  {DAGScheduler} Missing parents: List()
[08:56:06,171] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[3] at map at Main.scala:37), which has no missing parents
[08:56:06,173] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 1128.8 MB)
[08:56:06,175] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 1979.0 B, free 1128.8 MB)
[08:56:06,176] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:40239 (size: 1979.0 B, free: 1128.9 MB)
[08:56:06,176] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[08:56:06,177] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at map at Main.scala:37)
[08:56:06,177] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[08:56:06,179] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5450 bytes)
[08:56:06,180] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[08:56:06,187] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[08:56:06,192] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 2149 bytes result sent to driver
[08:56:06,194] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 17 ms on localhost (1/1)
[08:56:06,194] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[08:56:06,194] INFO  {DAGScheduler} ResultStage 1 (take at Main.scala:38) finished in 0.017 s
[08:56:06,195] INFO  {DAGScheduler} Job 1 finished: take at Main.scala:38, took 0.024843 s
[08:56:06,198] INFO  {SparkContext} Invoking stop() from shutdown hook
[08:56:06,202] INFO  {ServerConnector} Stopped ServerConnector@70ab2d48{HTTP/1.1}{0.0.0.0:4040}
[08:56:06,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage/kill,null,UNAVAILABLE}
[08:56:06,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/api,null,UNAVAILABLE}
[08:56:06,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/,null,UNAVAILABLE}
[08:56:06,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/static,null,UNAVAILABLE}
[08:56:06,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/threadDump/json,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors/threadDump,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/executors/json,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/executors,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/environment/json,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/environment,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/rdd/json,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage/rdd,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/storage/json,null,UNAVAILABLE}
[08:56:06,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/storage,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/pool/json,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/pool,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/stage/json,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages/stage,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/stages/json,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/stages,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/job/json,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs/job,null,UNAVAILABLE}
[08:56:06,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1817f1eb{/jobs/json,null,UNAVAILABLE}
[08:56:06,207] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@54dcfa5a{/jobs,null,UNAVAILABLE}
[08:56:06,208] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[08:56:06,216] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[08:56:06,220] INFO  {MemoryStore} MemoryStore cleared
[08:56:06,221] INFO  {BlockManager} BlockManager stopped
[08:56:06,225] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[08:56:06,227] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[08:56:06,229] INFO  {SparkContext} Successfully stopped SparkContext
[08:56:06,230] INFO  {ShutdownHookManager} Shutdown hook called
[08:56:06,230] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-db9799d0-c79a-4ad0-a1cf-c4687a86b36f
[09:04:38,124] INFO  {SparkContext} Running Spark version 2.0.1
[09:04:38,344] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:04:38,432] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:04:38,433] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:04:38,499] INFO  {SecurityManager} Changing view acls to: victor
[09:04:38,499] INFO  {SecurityManager} Changing modify acls to: victor
[09:04:38,500] INFO  {SecurityManager} Changing view acls groups to: 
[09:04:38,500] INFO  {SecurityManager} Changing modify acls groups to: 
[09:04:38,501] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:04:38,892] INFO  {Utils} Successfully started service 'sparkDriver' on port 39321.
[09:04:38,912] INFO  {SparkEnv} Registering MapOutputTracker
[09:04:38,930] INFO  {SparkEnv} Registering BlockManagerMaster
[09:04:38,943] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-89e5c744-3d50-458d-baec-b69d6902de18
[09:04:38,957] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:04:39,015] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:04:39,094] INFO  {log} Logging initialized @1580ms
[09:04:39,200] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:04:39,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[09:04:39,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[09:04:39,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[09:04:39,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[09:04:39,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[09:04:39,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[09:04:39,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[09:04:39,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[09:04:39,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[09:04:39,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[09:04:39,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[09:04:39,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[09:04:39,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[09:04:39,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[09:04:39,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[09:04:39,225] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[09:04:39,225] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[09:04:39,226] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[09:04:39,226] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[09:04:39,232] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[09:04:39,233] INFO  {Server} Started @1720ms
[09:04:39,233] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:04:39,236] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:04:39,323] INFO  {Executor} Starting executor ID driver on host localhost
[09:04:39,349] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33443.
[09:04:39,350] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:33443
[09:04:39,352] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 33443)
[09:04:39,355] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:33443 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 33443)
[09:04:39,358] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 33443)
[09:04:39,482] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[09:04:39,924] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:04:39,992] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:04:39,995] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:33443 (size: 14.3 KB, free: 1128.9 MB)
[09:04:40,000] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:04:40,141] INFO  {FileInputFormat} Total input paths to process : 1
[09:04:40,162] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:04:40,175] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:04:40,176] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:04:40,177] INFO  {DAGScheduler} Parents of final stage: List()
[09:04:40,179] INFO  {DAGScheduler} Missing parents: List()
[09:04:40,188] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:04:40,238] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:04:40,241] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:04:40,242] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:33443 (size: 2.1 KB, free: 1128.9 MB)
[09:04:40,243] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:04:40,248] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:04:40,250] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:04:40,297] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:04:40,303] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:04:40,327] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:04:40,335] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:04:40,335] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:04:40,335] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:04:40,336] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:04:40,336] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:04:40,397] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[09:04:40,404] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 130 ms on localhost (1/1)
[09:04:40,405] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:04:40,410] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.148 s
[09:04:40,415] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.252677 s
[09:04:40,571] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:33443 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:04:41,965] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@13250132{/SQL,null,AVAILABLE}
[09:04:41,966] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a864d4d{/SQL/json,null,AVAILABLE}
[09:04:41,966] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7558c24b{/SQL/execution,null,AVAILABLE}
[09:04:41,967] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1f129467{/SQL/execution/json,null,AVAILABLE}
[09:04:41,968] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@501957bf{/static/sql,null,AVAILABLE}
[09:04:41,977] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:04:42,701] INFO  {CodeGenerator} Code generated in 182.626704 ms
[09:04:42,752] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:04:42,753] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:04:42,753] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:04:42,753] INFO  {DAGScheduler} Parents of final stage: List()
[09:04:42,753] INFO  {DAGScheduler} Missing parents: List()
[09:04:42,754] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:04:42,769] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 11.7 KB, free 1128.8 MB)
[09:04:42,771] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1128.7 MB)
[09:04:42,772] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:33443 (size: 5.8 KB, free: 1128.9 MB)
[09:04:42,773] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:04:42,773] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:04:42,773] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:04:42,792] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:04:42,792] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:04:42,807] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:04:42,826] INFO  {CodeGenerator} Code generated in 12.522918 ms
[09:04:42,863] INFO  {CodeGenerator} Code generated in 22.516055 ms
[09:04:42,867] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1485 bytes result sent to driver
[09:04:42,868] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 79 ms on localhost (1/1)
[09:04:42,869] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:04:42,869] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) finished in 0.096 s
[09:04:42,869] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:40, took 0.117552 s
[09:04:42,905] INFO  {CodeGenerator} Code generated in 13.870498 ms
[09:04:42,920] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:04:42,924] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[09:04:42,926] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[09:04:42,926] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[09:04:42,926] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[09:04:42,926] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[09:04:42,927] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[09:04:42,928] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[09:04:42,929] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[09:04:42,930] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[09:04:42,931] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:04:42,939] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:04:42,942] INFO  {MemoryStore} MemoryStore cleared
[09:04:42,943] INFO  {BlockManager} BlockManager stopped
[09:04:42,944] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:04:42,946] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:04:42,947] INFO  {SparkContext} Successfully stopped SparkContext
[09:04:42,948] INFO  {ShutdownHookManager} Shutdown hook called
[09:04:42,948] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-1ea605d7-1931-4c5e-92ac-f5c1c3666d09
[09:05:49,058] INFO  {SparkContext} Running Spark version 2.0.1
[09:05:49,270] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:05:49,348] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:05:49,349] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:05:49,427] INFO  {SecurityManager} Changing view acls to: victor
[09:05:49,428] INFO  {SecurityManager} Changing modify acls to: victor
[09:05:49,428] INFO  {SecurityManager} Changing view acls groups to: 
[09:05:49,429] INFO  {SecurityManager} Changing modify acls groups to: 
[09:05:49,429] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:05:49,790] INFO  {Utils} Successfully started service 'sparkDriver' on port 41629.
[09:05:49,813] INFO  {SparkEnv} Registering MapOutputTracker
[09:05:49,827] INFO  {SparkEnv} Registering BlockManagerMaster
[09:05:49,840] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-da686539-5bbc-4bc1-b211-37364746f4b4
[09:05:49,854] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:05:49,912] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:05:49,985] INFO  {log} Logging initialized @1490ms
[09:05:50,092] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:05:50,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:05:50,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:05:50,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:05:50,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:05:50,110] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:05:50,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:05:50,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:05:50,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:05:50,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:05:50,111] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:05:50,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:05:50,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:05:50,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:05:50,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:05:50,112] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:05:50,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:05:50,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:05:50,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:05:50,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:05:50,113] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:05:50,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:05:50,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:05:50,120] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:05:50,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:05:50,127] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:05:50,127] INFO  {Server} Started @1633ms
[09:05:50,128] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:05:50,130] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:05:50,206] INFO  {Executor} Starting executor ID driver on host localhost
[09:05:50,227] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35615.
[09:05:50,228] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:35615
[09:05:50,229] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 35615)
[09:05:50,232] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:35615 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 35615)
[09:05:50,236] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 35615)
[09:05:50,375] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:05:50,785] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:05:50,841] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:05:50,843] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:35615 (size: 14.3 KB, free: 1128.9 MB)
[09:05:50,849] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:05:50,971] INFO  {FileInputFormat} Total input paths to process : 1
[09:05:50,989] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:05:51,002] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:05:51,003] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:05:51,003] INFO  {DAGScheduler} Parents of final stage: List()
[09:05:51,004] INFO  {DAGScheduler} Missing parents: List()
[09:05:51,012] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:05:51,062] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:05:51,064] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:05:51,065] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:35615 (size: 2.1 KB, free: 1128.9 MB)
[09:05:51,066] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:05:51,069] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:05:51,070] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:05:51,114] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:05:51,123] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:05:51,148] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:05:51,158] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:05:51,158] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:05:51,158] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:05:51,159] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:05:51,159] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:05:51,231] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[09:05:51,239] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 147 ms on localhost (1/1)
[09:05:51,241] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:05:51,244] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.164 s
[09:05:51,249] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.259089 s
[09:05:51,366] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:35615 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:05:52,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3b10f4{/SQL,null,AVAILABLE}
[09:05:52,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@525647f3{/SQL/json,null,AVAILABLE}
[09:05:52,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@691541bc{/SQL/execution,null,AVAILABLE}
[09:05:52,727] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@43a4a9e5{/SQL/execution/json,null,AVAILABLE}
[09:05:52,728] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@f245bdd{/static/sql,null,AVAILABLE}
[09:05:52,738] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:05:53,440] INFO  {CodeGenerator} Code generated in 178.37186 ms
[09:05:53,468] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:05:53,469] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:05:53,470] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:05:53,470] INFO  {DAGScheduler} Parents of final stage: List()
[09:05:53,470] INFO  {DAGScheduler} Missing parents: List()
[09:05:53,471] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:05:53,492] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 11.5 KB, free 1128.8 MB)
[09:05:53,494] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1128.7 MB)
[09:05:53,495] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:35615 (size: 5.8 KB, free: 1128.9 MB)
[09:05:53,496] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:05:53,496] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:05:53,496] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:05:53,499] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:05:53,499] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:05:53,513] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:05:53,534] INFO  {CodeGenerator} Code generated in 14.026865 ms
[09:05:53,541] ERROR {Executor} Exception in task 0.0 in stage 1.0 (TID 1)
java.lang.NumberFormatException: For input string: "2001.0"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:241)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:30)
	at se.kth.spark.lab1.task1.Main$$anonfun$2.apply(Main.scala:35)
	at se.kth.spark.lab1.task1.Main$$anonfun$2.apply(Main.scala:34)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[09:05:53,562] WARN  {TaskSetManager} Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.NumberFormatException: For input string: "2001.0"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:241)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:30)
	at se.kth.spark.lab1.task1.Main$$anonfun$2.apply(Main.scala:35)
	at se.kth.spark.lab1.task1.Main$$anonfun$2.apply(Main.scala:34)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

[09:05:53,563] ERROR {TaskSetManager} Task 0 in stage 1.0 failed 1 times; aborting job
[09:05:53,564] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:05:53,567] INFO  {TaskSchedulerImpl} Cancelling stage 1
[09:05:53,568] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) failed in 0.070 s
[09:05:53,569] INFO  {DAGScheduler} Job 1 failed: show at Main.scala:40, took 0.100536 s
[09:05:53,576] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:05:53,583] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:05:53,585] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:05:53,585] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:05:53,586] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:05:53,587] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:05:53,587] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:05:53,587] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:05:53,587] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:05:53,587] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:05:53,588] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:05:53,589] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:05:53,589] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:05:53,589] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:05:53,589] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:05:53,591] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:05:53,615] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:05:53,620] INFO  {MemoryStore} MemoryStore cleared
[09:05:53,620] INFO  {BlockManager} BlockManager stopped
[09:05:53,622] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:05:53,624] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:05:53,626] INFO  {SparkContext} Successfully stopped SparkContext
[09:05:53,626] INFO  {ShutdownHookManager} Shutdown hook called
[09:05:53,627] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-e46e3af4-0b09-41c9-9ac7-16bb061fee2c
[09:06:28,096] INFO  {SparkContext} Running Spark version 2.0.1
[09:06:28,331] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:06:28,430] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:06:28,431] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:06:28,516] INFO  {SecurityManager} Changing view acls to: victor
[09:06:28,517] INFO  {SecurityManager} Changing modify acls to: victor
[09:06:28,518] INFO  {SecurityManager} Changing view acls groups to: 
[09:06:28,519] INFO  {SecurityManager} Changing modify acls groups to: 
[09:06:28,520] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:06:28,875] INFO  {Utils} Successfully started service 'sparkDriver' on port 45525.
[09:06:28,894] INFO  {SparkEnv} Registering MapOutputTracker
[09:06:28,910] INFO  {SparkEnv} Registering BlockManagerMaster
[09:06:28,922] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-2e6773bf-03b3-46e5-8d68-9ab83d02b520
[09:06:28,936] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:06:28,989] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:06:29,059] INFO  {log} Logging initialized @1602ms
[09:06:29,161] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:06:29,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:06:29,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:06:29,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:06:29,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:06:29,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:06:29,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:06:29,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:06:29,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:06:29,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:06:29,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:06:29,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:06:29,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:06:29,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:06:29,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:06:29,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:06:29,185] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:06:29,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:06:29,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:06:29,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:06:29,193] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:06:29,193] INFO  {Server} Started @1737ms
[09:06:29,193] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:06:29,195] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:06:29,275] INFO  {Executor} Starting executor ID driver on host localhost
[09:06:29,296] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33181.
[09:06:29,297] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:33181
[09:06:29,299] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 33181)
[09:06:29,302] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:33181 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 33181)
[09:06:29,305] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 33181)
[09:06:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:06:29,889] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:06:29,948] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:06:29,950] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:33181 (size: 14.3 KB, free: 1128.9 MB)
[09:06:29,956] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:06:30,079] INFO  {FileInputFormat} Total input paths to process : 1
[09:06:30,095] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:06:30,113] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:06:30,113] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:06:30,114] INFO  {DAGScheduler} Parents of final stage: List()
[09:06:30,116] INFO  {DAGScheduler} Missing parents: List()
[09:06:30,126] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:06:30,193] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:06:30,196] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:06:30,196] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:33181 (size: 2.1 KB, free: 1128.9 MB)
[09:06:30,197] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:06:30,201] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:06:30,202] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:06:30,260] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:06:30,266] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:06:30,292] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:06:30,307] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:06:30,308] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:06:30,308] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:06:30,308] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:06:30,308] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:06:30,367] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:06:30,376] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 148 ms on localhost (1/1)
[09:06:30,377] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:06:30,380] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.167 s
[09:06:30,384] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.289028 s
[09:06:30,489] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:33181 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:06:31,798] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,AVAILABLE}
[09:06:31,799] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@13250132{/SQL/json,null,AVAILABLE}
[09:06:31,799] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@44bc2449{/SQL/execution,null,AVAILABLE}
[09:06:31,800] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7558c24b{/SQL/execution/json,null,AVAILABLE}
[09:06:31,801] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2dff7085{/static/sql,null,AVAILABLE}
[09:06:31,810] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:06:32,534] INFO  {CodeGenerator} Code generated in 196.20034 ms
[09:06:32,561] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:06:32,562] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:06:32,562] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:06:32,562] INFO  {DAGScheduler} Parents of final stage: List()
[09:06:32,562] INFO  {DAGScheduler} Missing parents: List()
[09:06:32,563] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:06:32,578] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 11.7 KB, free 1128.8 MB)
[09:06:32,580] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1128.7 MB)
[09:06:32,581] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:33181 (size: 5.8 KB, free: 1128.9 MB)
[09:06:32,581] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:06:32,582] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:06:32,582] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:06:32,584] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:06:32,584] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:06:32,598] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:06:32,617] INFO  {CodeGenerator} Code generated in 12.23662 ms
[09:06:32,647] INFO  {CodeGenerator} Code generated in 19.677965 ms
[09:06:32,650] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1485 bytes result sent to driver
[09:06:32,652] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 70 ms on localhost (1/1)
[09:06:32,653] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:06:32,654] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) finished in 0.071 s
[09:06:32,654] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:40, took 0.093268 s
[09:06:32,683] INFO  {CodeGenerator} Code generated in 15.310861 ms
[09:06:32,698] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:06:32,703] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:06:32,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:06:32,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:06:32,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:06:32,705] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:06:32,706] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:06:32,707] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:06:32,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:06:32,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:06:32,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:06:32,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:06:32,708] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:06:32,709] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:06:32,717] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:06:32,721] INFO  {MemoryStore} MemoryStore cleared
[09:06:32,721] INFO  {BlockManager} BlockManager stopped
[09:06:32,722] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:06:32,724] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:06:32,726] INFO  {SparkContext} Successfully stopped SparkContext
[09:06:32,726] INFO  {ShutdownHookManager} Shutdown hook called
[09:06:32,727] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-74997ecb-eb48-4d37-b820-9ef9070a066d
[09:07:42,020] INFO  {SparkContext} Running Spark version 2.0.1
[09:07:42,261] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:07:42,356] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:07:42,356] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:07:42,427] INFO  {SecurityManager} Changing view acls to: victor
[09:07:42,428] INFO  {SecurityManager} Changing modify acls to: victor
[09:07:42,429] INFO  {SecurityManager} Changing view acls groups to: 
[09:07:42,430] INFO  {SecurityManager} Changing modify acls groups to: 
[09:07:42,430] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:07:42,786] INFO  {Utils} Successfully started service 'sparkDriver' on port 43115.
[09:07:42,803] INFO  {SparkEnv} Registering MapOutputTracker
[09:07:42,817] INFO  {SparkEnv} Registering BlockManagerMaster
[09:07:42,829] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-3647c375-5a2b-46d6-a459-ca9f5d9f1be4
[09:07:42,843] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:07:42,905] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:07:42,976] INFO  {log} Logging initialized @1566ms
[09:07:43,085] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:07:43,102] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:07:43,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:07:43,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:07:43,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:07:43,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:07:43,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:07:43,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:07:43,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:07:43,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:07:43,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:07:43,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:07:43,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:07:43,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:07:43,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:07:43,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:07:43,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:07:43,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:07:43,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:07:43,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:07:43,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:07:43,117] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:07:43,118] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:07:43,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:07:43,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:07:43,128] INFO  {ServerConnector} Started ServerConnector@1b7a28e6{HTTP/1.1}{0.0.0.0:4040}
[09:07:43,129] INFO  {Server} Started @1720ms
[09:07:43,129] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:07:43,131] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:07:43,227] INFO  {Executor} Starting executor ID driver on host localhost
[09:07:43,250] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38571.
[09:07:43,251] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:38571
[09:07:43,253] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 38571)
[09:07:43,257] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:38571 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 38571)
[09:07:43,260] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 38571)
[09:07:43,380] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:07:43,809] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:07:43,863] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:07:43,865] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:38571 (size: 14.3 KB, free: 1128.9 MB)
[09:07:43,870] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:07:43,990] INFO  {FileInputFormat} Total input paths to process : 1
[09:07:44,005] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:07:44,016] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:07:44,016] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:07:44,017] INFO  {DAGScheduler} Parents of final stage: List()
[09:07:44,018] INFO  {DAGScheduler} Missing parents: List()
[09:07:44,026] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:07:44,081] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:07:44,083] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:07:44,084] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:38571 (size: 2.1 KB, free: 1128.9 MB)
[09:07:44,085] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:07:44,089] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:07:44,093] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:07:44,156] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:07:44,165] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:07:44,196] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:07:44,207] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:07:44,207] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:07:44,207] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:07:44,207] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:07:44,207] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:07:44,280] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:07:44,286] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 169 ms on localhost (1/1)
[09:07:44,287] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:07:44,291] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.187 s
[09:07:44,297] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.291437 s
[09:07:44,400] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:38571 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:07:45,744] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a864d4d{/SQL,null,AVAILABLE}
[09:07:45,745] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46a123e4{/SQL/json,null,AVAILABLE}
[09:07:45,747] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1f129467{/SQL/execution,null,AVAILABLE}
[09:07:45,748] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@57151b3a{/SQL/execution/json,null,AVAILABLE}
[09:07:45,750] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@b30a50d{/static/sql,null,AVAILABLE}
[09:07:45,761] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:07:46,501] INFO  {CodeGenerator} Code generated in 202.15206 ms
[09:07:46,527] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:07:46,528] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:07:46,528] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:07:46,528] INFO  {DAGScheduler} Parents of final stage: List()
[09:07:46,529] INFO  {DAGScheduler} Missing parents: List()
[09:07:46,529] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:07:46,545] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 11.7 KB, free 1128.8 MB)
[09:07:46,547] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1128.7 MB)
[09:07:46,548] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:38571 (size: 5.8 KB, free: 1128.9 MB)
[09:07:46,548] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:07:46,548] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:07:46,549] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:07:46,552] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:07:46,553] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:07:46,568] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:07:46,588] INFO  {CodeGenerator} Code generated in 13.292013 ms
[09:07:46,618] INFO  {CodeGenerator} Code generated in 19.472299 ms
[09:07:46,621] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1485 bytes result sent to driver
[09:07:46,623] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 74 ms on localhost (1/1)
[09:07:46,623] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:07:46,624] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) finished in 0.075 s
[09:07:46,624] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:40, took 0.097065 s
[09:07:46,656] INFO  {CodeGenerator} Code generated in 19.364208 ms
[09:07:46,813] INFO  {CodeGenerator} Code generated in 13.342075 ms
[09:07:46,827] INFO  {CodeGenerator} Code generated in 9.381998 ms
[09:07:46,872] INFO  {SparkContext} Starting job: count at Main.scala:41
[09:07:46,876] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:41)
[09:07:46,877] INFO  {DAGScheduler} Got job 2 (count at Main.scala:41) with 1 output partitions
[09:07:46,877] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:41)
[09:07:46,877] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:07:46,878] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:07:46,879] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:41), which has no missing parents
[09:07:46,889] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 13.3 KB, free 1128.7 MB)
[09:07:46,891] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.7 KB, free 1128.7 MB)
[09:07:46,891] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:38571 (size: 6.7 KB, free: 1128.9 MB)
[09:07:46,892] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:07:46,893] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:41)
[09:07:46,894] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:07:46,896] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:07:46,897] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:07:46,905] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:07:46,986] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:07:46,989] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 94 ms on localhost (1/1)
[09:07:46,989] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:07:46,990] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:41) finished in 0.095 s
[09:07:46,990] INFO  {DAGScheduler} looking for newly runnable stages
[09:07:46,990] INFO  {DAGScheduler} running: Set()
[09:07:46,991] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:07:46,991] INFO  {DAGScheduler} failed: Set()
[09:07:46,992] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:41), which has no missing parents
[09:07:46,997] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:07:46,999] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:07:47,000] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:38571 (size: 3.7 KB, free: 1128.9 MB)
[09:07:47,000] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:07:47,000] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:41)
[09:07:47,000] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:07:47,005] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:07:47,005] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:07:47,018] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:07:47,020] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[09:07:47,031] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:07:47,033] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 30 ms on localhost (1/1)
[09:07:47,034] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:07:47,034] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:41) finished in 0.031 s
[09:07:47,035] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:41, took 0.163060 s
[09:07:47,161] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:38571 in memory (size: 6.7 KB, free: 1128.9 MB)
[09:07:47,162] INFO  {CodeGenerator} Code generated in 122.189716 ms
[09:07:47,163] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:38571 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:07:47,164] INFO  {ContextCleaner} Cleaned accumulator 44
[09:07:47,164] INFO  {ContextCleaner} Cleaned accumulator 45
[09:07:47,165] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:38571 in memory (size: 5.8 KB, free: 1128.9 MB)
[09:07:47,165] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:07:47,166] INFO  {ContextCleaner} Cleaned accumulator 90
[09:07:47,169] INFO  {ServerConnector} Stopped ServerConnector@1b7a28e6{HTTP/1.1}{0.0.0.0:4040}
[09:07:47,171] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:07:47,171] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:07:47,171] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:07:47,171] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:07:47,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:07:47,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:07:47,174] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:07:47,174] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:07:47,175] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:07:47,184] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:07:47,189] INFO  {MemoryStore} MemoryStore cleared
[09:07:47,190] INFO  {BlockManager} BlockManager stopped
[09:07:47,192] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:07:47,194] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:07:47,196] INFO  {SparkContext} Successfully stopped SparkContext
[09:07:47,196] INFO  {ShutdownHookManager} Shutdown hook called
[09:07:47,197] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-641aa216-243d-45fd-8cd6-474cd3396a7e
[09:08:51,293] INFO  {SparkContext} Running Spark version 2.0.1
[09:08:51,507] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:08:51,618] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:08:51,619] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:08:51,692] INFO  {SecurityManager} Changing view acls to: victor
[09:08:51,692] INFO  {SecurityManager} Changing modify acls to: victor
[09:08:51,693] INFO  {SecurityManager} Changing view acls groups to: 
[09:08:51,694] INFO  {SecurityManager} Changing modify acls groups to: 
[09:08:51,694] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:08:52,049] INFO  {Utils} Successfully started service 'sparkDriver' on port 35547.
[09:08:52,065] INFO  {SparkEnv} Registering MapOutputTracker
[09:08:52,080] INFO  {SparkEnv} Registering BlockManagerMaster
[09:08:52,092] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-22fd4c6e-c7ed-428a-9203-cd8ada0039f6
[09:08:52,106] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:08:52,162] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:08:52,231] INFO  {log} Logging initialized @1525ms
[09:08:52,332] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:08:52,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:08:52,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:08:52,348] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:08:52,349] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:08:52,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:08:52,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:08:52,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:08:52,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:08:52,350] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:08:52,351] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:08:52,357] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:08:52,358] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:08:52,358] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:08:52,359] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:08:52,365] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:08:52,365] INFO  {Server} Started @1660ms
[09:08:52,365] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:08:52,367] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:08:52,446] INFO  {Executor} Starting executor ID driver on host localhost
[09:08:52,471] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45197.
[09:08:52,472] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:45197
[09:08:52,474] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 45197)
[09:08:52,477] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:45197 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 45197)
[09:08:52,480] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 45197)
[09:08:52,605] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:08:53,034] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:08:53,090] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:08:53,092] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:45197 (size: 14.3 KB, free: 1128.9 MB)
[09:08:53,098] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:08:53,228] INFO  {FileInputFormat} Total input paths to process : 1
[09:08:53,245] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:08:53,262] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:08:53,262] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:08:53,263] INFO  {DAGScheduler} Parents of final stage: List()
[09:08:53,265] INFO  {DAGScheduler} Missing parents: List()
[09:08:53,277] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:08:53,335] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:08:53,337] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:08:53,338] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:45197 (size: 2.1 KB, free: 1128.9 MB)
[09:08:53,339] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:08:53,342] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:08:53,344] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:08:53,391] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:08:53,397] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:08:53,420] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:08:53,429] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:08:53,430] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:08:53,430] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:08:53,430] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:08:53,430] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:08:53,510] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:08:53,516] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 151 ms on localhost (1/1)
[09:08:53,517] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:08:53,520] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.168 s
[09:08:53,526] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.280128 s
[09:08:53,620] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:45197 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:08:54,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:08:54,929] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:08:54,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:08:54,930] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:08:54,931] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:08:54,941] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:08:55,645] INFO  {CodeGenerator} Code generated in 180.813275 ms
[09:08:55,680] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:08:55,682] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:08:55,682] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:08:55,682] INFO  {DAGScheduler} Parents of final stage: List()
[09:08:55,682] INFO  {DAGScheduler} Missing parents: List()
[09:08:55,683] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:08:55,699] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:08:55,714] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:08:55,715] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:45197 (size: 5.5 KB, free: 1128.9 MB)
[09:08:55,716] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:08:55,716] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:08:55,716] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:08:55,719] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:08:55,719] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:08:55,735] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:08:55,756] INFO  {CodeGenerator} Code generated in 14.46433 ms
[09:08:55,779] INFO  {CodeGenerator} Code generated in 14.41985 ms
[09:08:55,782] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:08:55,784] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 67 ms on localhost (1/1)
[09:08:55,784] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:08:55,785] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) finished in 0.068 s
[09:08:55,785] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:40, took 0.104298 s
[09:08:55,813] INFO  {CodeGenerator} Code generated in 16.748081 ms
[09:08:55,922] INFO  {CodeGenerator} Code generated in 14.922959 ms
[09:08:55,940] INFO  {CodeGenerator} Code generated in 13.111847 ms
[09:08:55,969] INFO  {SparkContext} Starting job: count at Main.scala:41
[09:08:55,972] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:41)
[09:08:55,972] INFO  {DAGScheduler} Got job 2 (count at Main.scala:41) with 1 output partitions
[09:08:55,972] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:41)
[09:08:55,973] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:08:55,973] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:08:55,974] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:41), which has no missing parents
[09:08:55,980] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:08:55,981] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:08:55,982] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:45197 (size: 6.6 KB, free: 1128.9 MB)
[09:08:55,982] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:08:55,984] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:41)
[09:08:55,984] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:08:55,987] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:08:55,987] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:08:55,995] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:08:56,107] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:08:56,109] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 124 ms on localhost (1/1)
[09:08:56,109] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:08:56,110] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:41) finished in 0.126 s
[09:08:56,111] INFO  {DAGScheduler} looking for newly runnable stages
[09:08:56,111] INFO  {DAGScheduler} running: Set()
[09:08:56,112] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:08:56,112] INFO  {DAGScheduler} failed: Set()
[09:08:56,113] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:41), which has no missing parents
[09:08:56,120] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:08:56,122] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:08:56,123] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:45197 (size: 3.7 KB, free: 1128.9 MB)
[09:08:56,123] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:08:56,124] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:41)
[09:08:56,124] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:08:56,129] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:08:56,129] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:08:56,146] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:08:56,148] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[09:08:56,161] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:08:56,165] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:41) finished in 0.038 s
[09:08:56,165] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 38 ms on localhost (1/1)
[09:08:56,165] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:41, took 0.195637 s
[09:08:56,165] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:08:56,176] INFO  {CodeGenerator} Code generated in 6.734554 ms
[09:08:56,179] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:08:56,183] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:08:56,185] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:08:56,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:08:56,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:08:56,189] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:08:56,298] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:08:56,302] INFO  {MemoryStore} MemoryStore cleared
[09:08:56,303] INFO  {BlockManager} BlockManager stopped
[09:08:56,304] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:08:56,306] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:08:56,308] INFO  {SparkContext} Successfully stopped SparkContext
[09:08:56,308] INFO  {ShutdownHookManager} Shutdown hook called
[09:08:56,309] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-454b0896-3001-4416-b9bc-e70992882f1c
[09:12:41,246] INFO  {SparkContext} Running Spark version 2.0.1
[09:12:41,460] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:12:41,561] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:12:41,561] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:12:41,625] INFO  {SecurityManager} Changing view acls to: victor
[09:12:41,626] INFO  {SecurityManager} Changing modify acls to: victor
[09:12:41,626] INFO  {SecurityManager} Changing view acls groups to: 
[09:12:41,627] INFO  {SecurityManager} Changing modify acls groups to: 
[09:12:41,628] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:12:41,989] INFO  {Utils} Successfully started service 'sparkDriver' on port 40039.
[09:12:42,009] INFO  {SparkEnv} Registering MapOutputTracker
[09:12:42,028] INFO  {SparkEnv} Registering BlockManagerMaster
[09:12:42,042] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-81e69e69-6f0f-454b-9495-74d964c90f79
[09:12:42,056] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:12:42,114] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:12:42,185] INFO  {log} Logging initialized @1541ms
[09:12:42,284] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:12:42,299] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:12:42,299] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:12:42,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:12:42,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:12:42,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:12:42,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:12:42,300] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:12:42,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:12:42,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:12:42,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:12:42,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:12:42,301] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:12:42,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:12:42,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:12:42,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:12:42,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:12:42,302] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:12:42,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:12:42,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:12:42,303] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:12:42,309] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:12:42,310] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:12:42,310] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:12:42,311] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:12:42,317] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:12:42,317] INFO  {Server} Started @1674ms
[09:12:42,318] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:12:42,320] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:12:42,407] INFO  {Executor} Starting executor ID driver on host localhost
[09:12:42,429] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37783.
[09:12:42,429] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:37783
[09:12:42,431] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 37783)
[09:12:42,435] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:37783 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 37783)
[09:12:42,438] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 37783)
[09:12:42,561] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:12:42,983] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:12:43,044] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:12:43,046] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:37783 (size: 14.3 KB, free: 1128.9 MB)
[09:12:43,052] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:23
[09:12:43,174] INFO  {FileInputFormat} Total input paths to process : 1
[09:12:43,189] INFO  {SparkContext} Starting job: top at Main.scala:26
[09:12:43,200] INFO  {DAGScheduler} Got job 0 (top at Main.scala:26) with 1 output partitions
[09:12:43,201] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:26)
[09:12:43,201] INFO  {DAGScheduler} Parents of final stage: List()
[09:12:43,202] INFO  {DAGScheduler} Missing parents: List()
[09:12:43,209] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26), which has no missing parents
[09:12:43,266] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:12:43,269] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:12:43,269] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:37783 (size: 2.1 KB, free: 1128.9 MB)
[09:12:43,270] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:12:43,273] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:26)
[09:12:43,275] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:12:43,330] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:12:43,337] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:12:43,363] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:12:43,373] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:12:43,373] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:12:43,373] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:12:43,373] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:12:43,373] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:12:43,442] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:12:43,449] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 152 ms on localhost (1/1)
[09:12:43,450] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:12:43,454] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:26) finished in 0.169 s
[09:12:43,460] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:26, took 0.270692 s
[09:12:43,569] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:37783 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:12:44,933] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:12:44,934] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:12:44,934] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:12:44,935] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:12:44,936] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:12:44,945] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:12:45,662] INFO  {CodeGenerator} Code generated in 200.16935 ms
[09:12:45,690] INFO  {SparkContext} Starting job: show at Main.scala:40
[09:12:45,692] INFO  {DAGScheduler} Got job 1 (show at Main.scala:40) with 1 output partitions
[09:12:45,692] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:40)
[09:12:45,692] INFO  {DAGScheduler} Parents of final stage: List()
[09:12:45,692] INFO  {DAGScheduler} Missing parents: List()
[09:12:45,692] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40), which has no missing parents
[09:12:45,709] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:12:45,711] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:12:45,712] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:37783 (size: 5.5 KB, free: 1128.9 MB)
[09:12:45,712] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:12:45,713] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:40)
[09:12:45,713] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:12:45,715] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:12:45,715] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:12:45,727] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:12:45,747] INFO  {CodeGenerator} Code generated in 13.740169 ms
[09:12:45,768] INFO  {CodeGenerator} Code generated in 13.850656 ms
[09:12:45,772] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:12:45,773] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 60 ms on localhost (1/1)
[09:12:45,773] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:12:45,774] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:40) finished in 0.061 s
[09:12:45,774] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:40, took 0.083519 s
[09:12:45,797] INFO  {CodeGenerator} Code generated in 13.268963 ms
[09:12:45,898] INFO  {CodeGenerator} Code generated in 13.529717 ms
[09:12:45,913] INFO  {CodeGenerator} Code generated in 9.5853 ms
[09:12:45,943] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:12:45,946] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:43)
[09:12:45,946] INFO  {DAGScheduler} Got job 2 (count at Main.scala:43) with 1 output partitions
[09:12:45,946] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:43)
[09:12:45,946] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:12:45,947] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:12:45,947] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:43), which has no missing parents
[09:12:45,954] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:12:45,955] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:12:45,956] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:37783 (size: 6.6 KB, free: 1128.9 MB)
[09:12:45,956] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:12:45,958] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:43)
[09:12:45,958] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:12:45,961] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:12:45,962] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:12:45,970] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:12:46,095] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:12:46,098] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 139 ms on localhost (1/1)
[09:12:46,098] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:12:46,099] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:43) finished in 0.140 s
[09:12:46,099] INFO  {DAGScheduler} looking for newly runnable stages
[09:12:46,100] INFO  {DAGScheduler} running: Set()
[09:12:46,100] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:12:46,100] INFO  {DAGScheduler} failed: Set()
[09:12:46,102] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:43), which has no missing parents
[09:12:46,107] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:12:46,109] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:12:46,110] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:37783 (size: 3.7 KB, free: 1128.9 MB)
[09:12:46,110] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:12:46,111] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:43)
[09:12:46,111] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:12:46,115] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:12:46,116] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:12:46,128] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:12:46,130] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[09:12:46,143] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:12:46,144] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 30 ms on localhost (1/1)
[09:12:46,144] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:12:46,145] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:43) finished in 0.032 s
[09:12:46,145] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:43, took 0.201997 s
[09:12:46,156] INFO  {CodeGenerator} Code generated in 7.804237 ms
[09:12:46,170] INFO  {SparkContext} Starting job: count at Main.scala:46
[09:12:46,171] INFO  {DAGScheduler} Got job 3 (count at Main.scala:46) with 1 output partitions
[09:12:46,171] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:46)
[09:12:46,171] INFO  {DAGScheduler} Parents of final stage: List()
[09:12:46,172] INFO  {DAGScheduler} Missing parents: List()
[09:12:46,172] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:46), which has no missing parents
[09:12:46,174] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:12:46,175] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:12:46,176] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:37783 (size: 2.0 KB, free: 1128.9 MB)
[09:12:46,177] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:12:46,177] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:46)
[09:12:46,177] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:12:46,179] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:12:46,179] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:12:46,183] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:12:46,220] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:12:46,221] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 43 ms on localhost (1/1)
[09:12:46,221] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:12:46,221] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:46) finished in 0.043 s
[09:12:46,222] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:46, took 0.051001 s
[09:12:46,225] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:12:46,231] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:12:46,233] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:12:46,234] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:12:46,235] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:12:46,235] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:12:46,235] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:12:46,235] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:12:46,235] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:12:46,236] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:12:46,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:12:46,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:12:46,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:12:46,237] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:12:46,239] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:12:46,369] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:12:46,373] INFO  {MemoryStore} MemoryStore cleared
[09:12:46,374] INFO  {BlockManager} BlockManager stopped
[09:12:46,375] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:12:46,377] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:12:46,379] INFO  {SparkContext} Successfully stopped SparkContext
[09:12:46,380] INFO  {ShutdownHookManager} Shutdown hook called
[09:12:46,380] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a4ba6cac-81fa-4858-87ad-7a1ee2207346
[09:21:28,326] INFO  {SparkContext} Running Spark version 2.0.1
[09:21:28,589] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:21:28,722] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:21:28,726] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:21:28,797] INFO  {SecurityManager} Changing view acls to: victor
[09:21:28,798] INFO  {SecurityManager} Changing modify acls to: victor
[09:21:28,799] INFO  {SecurityManager} Changing view acls groups to: 
[09:21:28,799] INFO  {SecurityManager} Changing modify acls groups to: 
[09:21:28,800] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:21:29,138] INFO  {Utils} Successfully started service 'sparkDriver' on port 37599.
[09:21:29,156] INFO  {SparkEnv} Registering MapOutputTracker
[09:21:29,171] INFO  {SparkEnv} Registering BlockManagerMaster
[09:21:29,183] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-abfba9a8-f487-4a86-a6ad-e6f7bfac4944
[09:21:29,197] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:21:29,247] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:21:29,316] INFO  {log} Logging initialized @1668ms
[09:21:29,417] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:21:29,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:21:29,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:21:29,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:21:29,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:21:29,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:21:29,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:21:29,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:21:29,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:21:29,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:21:29,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:21:29,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:21:29,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:21:29,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:21:29,437] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:21:29,437] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:21:29,443] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:21:29,443] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:21:29,444] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:21:29,444] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:21:29,451] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:21:29,451] INFO  {Server} Started @1804ms
[09:21:29,451] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:21:29,455] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:21:29,551] INFO  {Executor} Starting executor ID driver on host localhost
[09:21:29,576] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37145.
[09:21:29,577] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:37145
[09:21:29,579] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 37145)
[09:21:29,582] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:37145 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 37145)
[09:21:29,586] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 37145)
[09:21:29,716] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:21:30,157] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:21:30,214] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:21:30,216] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:37145 (size: 14.3 KB, free: 1128.9 MB)
[09:21:30,221] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:21:30,370] INFO  {FileInputFormat} Total input paths to process : 1
[09:21:30,388] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:21:30,403] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:21:30,404] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:21:30,405] INFO  {DAGScheduler} Parents of final stage: List()
[09:21:30,406] INFO  {DAGScheduler} Missing parents: List()
[09:21:30,416] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:21:30,481] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:21:30,485] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:21:30,486] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:37145 (size: 2.1 KB, free: 1128.9 MB)
[09:21:30,487] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:21:30,491] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:21:30,492] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:21:30,552] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:21:30,558] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:21:30,584] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:21:30,592] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:21:30,593] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:21:30,593] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:21:30,593] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:21:30,593] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:21:30,682] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:21:30,688] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 170 ms on localhost (1/1)
[09:21:30,689] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:21:30,692] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.189 s
[09:21:30,696] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.308075 s
[09:21:30,795] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:37145 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:21:32,098] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:21:32,098] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:21:32,099] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:21:32,099] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:21:32,101] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:21:32,110] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:21:32,810] INFO  {CodeGenerator} Code generated in 181.591536 ms
[09:21:32,839] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:21:32,840] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:21:32,840] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:21:32,840] INFO  {DAGScheduler} Parents of final stage: List()
[09:21:32,841] INFO  {DAGScheduler} Missing parents: List()
[09:21:32,841] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:21:32,858] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:21:32,860] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:21:32,874] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:37145 (size: 5.5 KB, free: 1128.9 MB)
[09:21:32,874] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:21:32,875] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:21:32,875] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:21:32,877] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:21:32,877] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:21:32,894] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:21:32,915] INFO  {CodeGenerator} Code generated in 14.918374 ms
[09:21:32,937] INFO  {CodeGenerator} Code generated in 13.812527 ms
[09:21:32,940] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:21:32,942] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 67 ms on localhost (1/1)
[09:21:32,942] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:21:32,943] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.068 s
[09:21:32,943] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.103861 s
[09:21:32,967] INFO  {CodeGenerator} Code generated in 14.428225 ms
[09:21:33,069] INFO  {CodeGenerator} Code generated in 11.278976 ms
[09:21:33,082] INFO  {CodeGenerator} Code generated in 9.099814 ms
[09:21:33,111] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:21:33,114] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:21:33,115] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:21:33,115] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:21:33,115] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:21:33,115] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:21:33,116] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:21:33,122] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:21:33,124] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:21:33,125] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:37145 (size: 6.6 KB, free: 1128.9 MB)
[09:21:33,126] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:21:33,128] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:21:33,128] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:21:33,131] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:21:33,131] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:21:33,141] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:21:33,261] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1801 bytes result sent to driver
[09:21:33,264] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 134 ms on localhost (1/1)
[09:21:33,264] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:21:33,265] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.136 s
[09:21:33,265] INFO  {DAGScheduler} looking for newly runnable stages
[09:21:33,265] INFO  {DAGScheduler} running: Set()
[09:21:33,266] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:21:33,266] INFO  {DAGScheduler} failed: Set()
[09:21:33,267] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:21:33,273] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:21:33,274] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:21:33,275] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:37145 (size: 3.7 KB, free: 1128.9 MB)
[09:21:33,276] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:21:33,276] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:21:33,276] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:21:33,280] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:21:33,280] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:21:33,293] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:21:33,295] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[09:21:33,306] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:21:33,308] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 29 ms on localhost (1/1)
[09:21:33,308] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:21:33,308] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.030 s
[09:21:33,309] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.197199 s
[09:21:33,319] INFO  {CodeGenerator} Code generated in 6.613664 ms
[09:21:33,326] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:21:33,327] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:21:33,327] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:21:33,327] INFO  {DAGScheduler} Parents of final stage: List()
[09:21:33,327] INFO  {DAGScheduler} Missing parents: List()
[09:21:33,327] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:21:33,329] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:21:33,331] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:21:33,332] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:37145 (size: 2.0 KB, free: 1128.9 MB)
[09:21:33,332] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:21:33,333] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:21:33,333] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:21:33,334] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:21:33,335] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:21:33,338] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:21:33,374] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:21:33,376] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 42 ms on localhost (1/1)
[09:21:33,376] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:21:33,376] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.043 s
[09:21:33,376] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.050442 s
[09:21:33,509] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:37145 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:21:33,511] INFO  {ContextCleaner} Cleaned accumulator 44
[09:21:33,511] INFO  {ContextCleaner} Cleaned accumulator 45
[09:21:33,512] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:37145 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 90
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 91
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 92
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 93
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 94
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 95
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 96
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 97
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 98
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 99
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 100
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 101
[09:21:33,513] INFO  {ContextCleaner} Cleaned accumulator 102
[09:21:33,516] INFO  {ContextCleaner} Cleaned shuffle 0
[09:21:33,517] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:37145 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:21:33,518] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:37145 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:21:33,586] INFO  {CodeGenerator} Code generated in 12.28617 ms
[09:21:33,603] INFO  {CodeGenerator} Code generated in 12.526978 ms
[09:21:33,617] INFO  {SparkContext} Starting job: show at Main.scala:48
[09:21:33,618] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:48)
[09:21:33,619] INFO  {DAGScheduler} Got job 4 (show at Main.scala:48) with 1 output partitions
[09:21:33,619] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:48)
[09:21:33,619] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:21:33,619] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:21:33,620] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:48), which has no missing parents
[09:21:33,623] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 14.0 KB, free 1128.7 MB)
[09:21:33,626] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.9 KB, free 1128.7 MB)
[09:21:33,627] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:37145 (size: 6.9 KB, free: 1128.9 MB)
[09:21:33,627] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:21:33,628] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:48)
[09:21:33,628] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:21:33,630] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:21:33,630] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:21:33,637] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:21:33,682] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:21:33,684] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 54 ms on localhost (1/1)
[09:21:33,684] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:21:33,684] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:48) finished in 0.056 s
[09:21:33,685] INFO  {DAGScheduler} looking for newly runnable stages
[09:21:33,685] INFO  {DAGScheduler} running: Set()
[09:21:33,685] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:21:33,685] INFO  {DAGScheduler} failed: Set()
[09:21:33,685] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:48), which has no missing parents
[09:21:33,688] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 7.7 KB, free 1128.7 MB)
[09:21:33,691] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1128.7 MB)
[09:21:33,692] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:37145 (size: 4.0 KB, free: 1128.9 MB)
[09:21:33,693] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:21:33,693] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:48)
[09:21:33,693] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:21:33,697] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:21:33,697] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:21:33,701] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:21:33,701] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:21:33,705] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1854 bytes result sent to driver
[09:21:33,706] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 11 ms on localhost (1/1)
[09:21:33,707] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:21:33,707] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:48) finished in 0.012 s
[09:21:33,707] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:48, took 0.089882 s
[09:21:33,722] INFO  {CodeGenerator} Code generated in 12.015744 ms
[09:21:33,727] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:21:33,732] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:21:33,734] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:21:33,734] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:21:33,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:21:33,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:21:33,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:21:33,738] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:21:33,738] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:21:33,738] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:21:33,740] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:21:33,748] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:21:33,754] INFO  {MemoryStore} MemoryStore cleared
[09:21:33,755] INFO  {BlockManager} BlockManager stopped
[09:21:33,756] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:21:33,759] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:21:33,761] INFO  {SparkContext} Successfully stopped SparkContext
[09:21:33,761] INFO  {ShutdownHookManager} Shutdown hook called
[09:21:33,762] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-e9d6bfe4-b523-4c1a-b92c-a8d6c245081a
[09:22:18,002] INFO  {SparkContext} Running Spark version 2.0.1
[09:22:18,226] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:22:18,329] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:22:18,330] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:22:18,417] INFO  {SecurityManager} Changing view acls to: victor
[09:22:18,418] INFO  {SecurityManager} Changing modify acls to: victor
[09:22:18,419] INFO  {SecurityManager} Changing view acls groups to: 
[09:22:18,422] INFO  {SecurityManager} Changing modify acls groups to: 
[09:22:18,423] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:22:18,754] INFO  {Utils} Successfully started service 'sparkDriver' on port 38635.
[09:22:18,771] INFO  {SparkEnv} Registering MapOutputTracker
[09:22:18,786] INFO  {SparkEnv} Registering BlockManagerMaster
[09:22:18,798] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-2faef6ba-2f2c-4318-a446-d723fba37948
[09:22:18,812] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:22:18,863] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:22:18,933] INFO  {log} Logging initialized @1543ms
[09:22:19,031] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:22:19,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:22:19,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:22:19,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:22:19,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:22:19,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:22:19,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:22:19,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:22:19,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:22:19,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:22:19,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:22:19,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:22:19,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:22:19,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:22:19,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:22:19,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:22:19,055] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:22:19,056] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:22:19,056] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:22:19,057] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:22:19,062] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:22:19,063] INFO  {Server} Started @1674ms
[09:22:19,063] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:22:19,065] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:22:19,140] INFO  {Executor} Starting executor ID driver on host localhost
[09:22:19,161] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34055.
[09:22:19,162] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:34055
[09:22:19,164] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 34055)
[09:22:19,167] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:34055 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 34055)
[09:22:19,170] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 34055)
[09:22:19,287] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:22:19,691] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:22:19,752] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:22:19,754] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:34055 (size: 14.3 KB, free: 1128.9 MB)
[09:22:19,761] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:22:19,894] INFO  {FileInputFormat} Total input paths to process : 1
[09:22:19,912] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:22:19,928] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:22:19,930] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:22:19,931] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:19,933] INFO  {DAGScheduler} Missing parents: List()
[09:22:19,944] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:22:20,015] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:22:20,018] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:22:20,019] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:34055 (size: 2.1 KB, free: 1128.9 MB)
[09:22:20,020] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:22:20,026] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:22:20,028] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:22:20,099] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:22:20,108] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:22:20,137] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:20,148] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:22:20,148] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:22:20,148] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:22:20,148] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:22:20,148] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:22:20,228] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:22:20,234] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 176 ms on localhost (1/1)
[09:22:20,235] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:22:20,239] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.197 s
[09:22:20,245] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.332971 s
[09:22:20,335] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:34055 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:22:21,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:22:21,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:22:21,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:22:21,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:22:21,644] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:22:21,654] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:22:22,376] INFO  {CodeGenerator} Code generated in 186.259555 ms
[09:22:22,410] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:22:22,412] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:22:22,412] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:22:22,412] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:22,412] INFO  {DAGScheduler} Missing parents: List()
[09:22:22,413] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:22:22,433] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:22:22,452] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:22:22,453] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:34055 (size: 5.5 KB, free: 1128.9 MB)
[09:22:22,454] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:22:22,454] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:22:22,454] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:22:22,457] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:22:22,458] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:22:22,473] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:22,494] INFO  {CodeGenerator} Code generated in 13.874675 ms
[09:22:22,516] INFO  {CodeGenerator} Code generated in 14.374296 ms
[09:22:22,519] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1466 bytes result sent to driver
[09:22:22,521] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 66 ms on localhost (1/1)
[09:22:22,521] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:22:22,522] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.067 s
[09:22:22,522] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.112307 s
[09:22:22,548] INFO  {CodeGenerator} Code generated in 15.174938 ms
[09:22:22,652] INFO  {CodeGenerator} Code generated in 12.276473 ms
[09:22:22,666] INFO  {CodeGenerator} Code generated in 9.675742 ms
[09:22:22,697] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:22:22,700] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:22:22,701] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:22:22,701] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:22:22,701] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:22:22,702] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:22:22,703] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:22:22,712] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:22:22,714] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:22:22,715] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:34055 (size: 6.6 KB, free: 1128.9 MB)
[09:22:22,716] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:22:22,717] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:22:22,718] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:22:22,721] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:22:22,721] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:22:22,728] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:22,867] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:22:22,870] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 152 ms on localhost (1/1)
[09:22:22,871] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:22:22,871] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.153 s
[09:22:22,872] INFO  {DAGScheduler} looking for newly runnable stages
[09:22:22,872] INFO  {DAGScheduler} running: Set()
[09:22:22,873] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:22:22,873] INFO  {DAGScheduler} failed: Set()
[09:22:22,874] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:22:22,879] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:22:22,881] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:22:22,882] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:34055 (size: 3.7 KB, free: 1128.9 MB)
[09:22:22,882] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:22:22,882] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:22:22,883] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:22:22,887] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:22:22,887] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:22:22,903] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:22:22,904] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 6 ms
[09:22:22,915] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:22:22,917] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 32 ms on localhost (1/1)
[09:22:22,917] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:22:22,918] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.032 s
[09:22:22,919] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.221699 s
[09:22:22,930] INFO  {CodeGenerator} Code generated in 7.122578 ms
[09:22:22,937] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:22:22,938] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:22:22,938] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:22:22,938] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:22,939] INFO  {DAGScheduler} Missing parents: List()
[09:22:22,939] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:22:22,942] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:22:22,944] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:22:22,944] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:34055 (size: 2.0 KB, free: 1128.9 MB)
[09:22:22,945] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:22:22,945] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:22:22,945] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:22:22,947] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:22:22,947] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:22:22,950] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:22,982] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:22:22,983] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 37 ms on localhost (1/1)
[09:22:22,983] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:22:22,983] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.037 s
[09:22:22,984] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.046384 s
[09:22:23,097] INFO  {ContextCleaner} Cleaned accumulator 44
[09:22:23,097] INFO  {ContextCleaner} Cleaned accumulator 45
[09:22:23,099] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:34055 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:22:23,099] INFO  {ContextCleaner} Cleaned accumulator 90
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 91
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 92
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 93
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 94
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 95
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 96
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 97
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 98
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 99
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 100
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 101
[09:22:23,100] INFO  {ContextCleaner} Cleaned accumulator 102
[09:22:23,104] INFO  {ContextCleaner} Cleaned shuffle 0
[09:22:23,105] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:34055 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:22:23,106] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:34055 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:22:23,108] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:34055 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:22:23,186] INFO  {CodeGenerator} Code generated in 16.992414 ms
[09:22:23,209] INFO  {CodeGenerator} Code generated in 14.782918 ms
[09:22:23,228] INFO  {SparkContext} Starting job: show at Main.scala:47
[09:22:23,230] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[09:22:23,230] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[09:22:23,230] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[09:22:23,230] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:22:23,230] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:22:23,231] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[09:22:23,234] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[09:22:23,236] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[09:22:23,237] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:34055 (size: 7.6 KB, free: 1128.9 MB)
[09:22:23,237] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:22:23,238] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[09:22:23,238] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:22:23,240] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:22:23,240] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:22:23,246] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:23,276] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:22:23,277] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 39 ms on localhost (1/1)
[09:22:23,277] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:22:23,278] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.040 s
[09:22:23,278] INFO  {DAGScheduler} looking for newly runnable stages
[09:22:23,278] INFO  {DAGScheduler} running: Set()
[09:22:23,278] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:22:23,278] INFO  {DAGScheduler} failed: Set()
[09:22:23,278] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[09:22:23,280] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[09:22:23,282] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[09:22:23,283] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:34055 (size: 4.6 KB, free: 1128.9 MB)
[09:22:23,283] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:22:23,283] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[09:22:23,283] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:22:23,285] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:22:23,285] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:22:23,289] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:22:23,289] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:22:23,293] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1858 bytes result sent to driver
[09:22:23,294] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 10 ms on localhost (1/1)
[09:22:23,294] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:22:23,294] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.010 s
[09:22:23,295] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.066115 s
[09:22:23,305] INFO  {CodeGenerator} Code generated in 8.396117 ms
[09:22:23,308] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:22:23,311] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:22:23,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:22:23,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:22:23,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:22:23,316] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:22:23,326] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:22:23,331] INFO  {MemoryStore} MemoryStore cleared
[09:22:23,331] INFO  {BlockManager} BlockManager stopped
[09:22:23,332] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:22:23,335] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:22:23,336] INFO  {SparkContext} Successfully stopped SparkContext
[09:22:23,337] INFO  {ShutdownHookManager} Shutdown hook called
[09:22:23,337] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-da71d3e8-a328-4259-bb06-4dab1c3fdda8
[09:22:35,139] INFO  {SparkContext} Running Spark version 2.0.1
[09:22:35,360] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:22:35,453] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:22:35,454] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:22:35,520] INFO  {SecurityManager} Changing view acls to: victor
[09:22:35,521] INFO  {SecurityManager} Changing modify acls to: victor
[09:22:35,522] INFO  {SecurityManager} Changing view acls groups to: 
[09:22:35,523] INFO  {SecurityManager} Changing modify acls groups to: 
[09:22:35,524] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:22:35,926] INFO  {Utils} Successfully started service 'sparkDriver' on port 36919.
[09:22:35,944] INFO  {SparkEnv} Registering MapOutputTracker
[09:22:35,959] INFO  {SparkEnv} Registering BlockManagerMaster
[09:22:35,971] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-9cd32d82-5941-46d7-ba18-9bbda1381796
[09:22:35,985] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:22:36,028] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:22:36,102] INFO  {log} Logging initialized @1540ms
[09:22:36,211] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:22:36,228] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[09:22:36,228] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[09:22:36,228] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[09:22:36,228] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[09:22:36,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[09:22:36,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[09:22:36,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[09:22:36,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[09:22:36,230] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[09:22:36,230] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[09:22:36,230] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[09:22:36,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[09:22:36,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[09:22:36,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[09:22:36,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[09:22:36,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[09:22:36,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[09:22:36,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[09:22:36,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[09:22:36,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[09:22:36,239] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[09:22:36,239] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[09:22:36,240] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[09:22:36,241] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[09:22:36,247] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[09:22:36,248] INFO  {Server} Started @1687ms
[09:22:36,248] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:22:36,251] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:22:36,344] INFO  {Executor} Starting executor ID driver on host localhost
[09:22:36,368] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44571.
[09:22:36,369] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:44571
[09:22:36,370] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 44571)
[09:22:36,373] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:44571 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 44571)
[09:22:36,376] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 44571)
[09:22:36,499] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[09:22:36,895] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:22:36,957] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:22:36,960] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:44571 (size: 14.3 KB, free: 1128.9 MB)
[09:22:36,966] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:22:37,096] INFO  {FileInputFormat} Total input paths to process : 1
[09:22:37,113] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:22:37,130] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:22:37,131] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:22:37,132] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:37,135] INFO  {DAGScheduler} Missing parents: List()
[09:22:37,146] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:22:37,215] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:22:37,218] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:22:37,219] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:44571 (size: 2.1 KB, free: 1128.9 MB)
[09:22:37,220] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:22:37,224] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:22:37,226] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:22:37,282] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:22:37,288] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:22:37,312] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:37,320] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:22:37,320] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:22:37,320] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:22:37,321] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:22:37,321] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:22:37,389] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2277 bytes result sent to driver
[09:22:37,396] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 145 ms on localhost (1/1)
[09:22:37,397] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:22:37,402] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.165 s
[09:22:37,408] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.294925 s
[09:22:37,506] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:44571 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:22:38,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL,null,AVAILABLE}
[09:22:38,813] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@26d5a317{/SQL/json,null,AVAILABLE}
[09:22:38,813] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution,null,AVAILABLE}
[09:22:38,814] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@89caf47{/SQL/execution/json,null,AVAILABLE}
[09:22:38,815] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b24ea2a{/static/sql,null,AVAILABLE}
[09:22:38,824] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:22:39,504] INFO  {CodeGenerator} Code generated in 172.295374 ms
[09:22:39,531] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:22:39,532] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:22:39,533] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:22:39,533] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:39,533] INFO  {DAGScheduler} Missing parents: List()
[09:22:39,533] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:22:39,549] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:22:39,551] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:22:39,552] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:44571 (size: 5.5 KB, free: 1128.9 MB)
[09:22:39,552] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:22:39,553] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:22:39,553] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:22:39,555] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:22:39,555] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:22:39,568] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:39,593] INFO  {CodeGenerator} Code generated in 17.987036 ms
[09:22:39,624] INFO  {CodeGenerator} Code generated in 19.439276 ms
[09:22:39,627] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:22:39,629] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 76 ms on localhost (1/1)
[09:22:39,629] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:22:39,630] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.076 s
[09:22:39,630] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.098308 s
[09:22:39,656] INFO  {CodeGenerator} Code generated in 15.540176 ms
[09:22:39,705] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:44571 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:22:39,706] INFO  {ContextCleaner} Cleaned accumulator 44
[09:22:39,707] INFO  {ContextCleaner} Cleaned accumulator 45
[09:22:39,774] INFO  {CodeGenerator} Code generated in 11.341945 ms
[09:22:39,788] INFO  {CodeGenerator} Code generated in 8.814804 ms
[09:22:39,816] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:22:39,819] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:22:39,819] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:22:39,819] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:22:39,819] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:22:39,820] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:22:39,820] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:22:39,827] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:22:39,829] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:22:39,830] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:44571 (size: 6.6 KB, free: 1128.9 MB)
[09:22:39,831] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:22:39,832] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:22:39,832] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:22:39,836] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:22:39,836] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:22:39,847] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:39,983] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:22:39,986] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 153 ms on localhost (1/1)
[09:22:39,986] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:22:39,987] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.154 s
[09:22:39,988] INFO  {DAGScheduler} looking for newly runnable stages
[09:22:39,989] INFO  {DAGScheduler} running: Set()
[09:22:39,989] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:22:39,990] INFO  {DAGScheduler} failed: Set()
[09:22:39,991] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:22:39,996] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:22:39,998] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:22:39,998] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:44571 (size: 3.7 KB, free: 1128.9 MB)
[09:22:39,999] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:22:39,999] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:22:39,999] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:22:40,003] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:22:40,003] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:22:40,017] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:22:40,019] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[09:22:40,030] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:22:40,032] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 31 ms on localhost (1/1)
[09:22:40,032] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:22:40,033] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.032 s
[09:22:40,033] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.217160 s
[09:22:40,044] INFO  {CodeGenerator} Code generated in 6.95479 ms
[09:22:40,052] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:22:40,053] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:22:40,053] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:22:40,053] INFO  {DAGScheduler} Parents of final stage: List()
[09:22:40,054] INFO  {DAGScheduler} Missing parents: List()
[09:22:40,054] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:22:40,057] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:22:40,059] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:22:40,059] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:44571 (size: 2.0 KB, free: 1128.9 MB)
[09:22:40,060] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:22:40,060] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:22:40,060] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:22:40,062] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:22:40,062] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:22:40,066] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:22:40,120] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:22:40,121] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 60 ms on localhost (1/1)
[09:22:40,121] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:22:40,122] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.061 s
[09:22:40,122] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.069742 s
[09:22:40,235] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:44571 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:22:40,236] INFO  {ContextCleaner} Cleaned accumulator 90
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 91
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 92
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 93
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 94
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 95
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 96
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 97
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 98
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 99
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 100
[09:22:40,237] INFO  {ContextCleaner} Cleaned accumulator 101
[09:22:40,238] INFO  {ContextCleaner} Cleaned accumulator 102
[09:22:40,241] INFO  {ContextCleaner} Cleaned shuffle 0
[09:22:40,243] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:44571 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:22:40,245] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:44571 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:22:40,273] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:22:40,277] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[09:22:40,278] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[09:22:40,278] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[09:22:40,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[09:22:40,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[09:22:40,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[09:22:40,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[09:22:40,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[09:22:40,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[09:22:40,282] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:22:40,292] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:22:40,296] INFO  {MemoryStore} MemoryStore cleared
[09:22:40,296] INFO  {BlockManager} BlockManager stopped
[09:22:40,298] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:22:40,299] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:22:40,301] INFO  {SparkContext} Successfully stopped SparkContext
[09:22:40,301] INFO  {ShutdownHookManager} Shutdown hook called
[09:22:40,302] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a332c959-9124-40d0-9cea-0e62d7d7b2a6
[09:23:10,792] INFO  {SparkContext} Running Spark version 2.0.1
[09:23:11,013] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:23:11,110] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:23:11,111] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:23:11,178] INFO  {SecurityManager} Changing view acls to: victor
[09:23:11,179] INFO  {SecurityManager} Changing modify acls to: victor
[09:23:11,180] INFO  {SecurityManager} Changing view acls groups to: 
[09:23:11,181] INFO  {SecurityManager} Changing modify acls groups to: 
[09:23:11,181] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:23:11,569] INFO  {Utils} Successfully started service 'sparkDriver' on port 42129.
[09:23:11,588] INFO  {SparkEnv} Registering MapOutputTracker
[09:23:11,603] INFO  {SparkEnv} Registering BlockManagerMaster
[09:23:11,616] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-274a810b-2b69-4418-8910-f02d9c2f34c5
[09:23:11,631] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:23:11,683] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:23:11,756] INFO  {log} Logging initialized @1580ms
[09:23:11,861] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:23:11,878] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:23:11,878] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:23:11,879] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:23:11,879] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:23:11,879] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:23:11,880] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:23:11,880] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:23:11,880] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:23:11,880] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:23:11,881] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:23:11,881] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:23:11,881] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:23:11,882] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:23:11,882] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:23:11,882] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:23:11,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:23:11,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:23:11,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:23:11,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:23:11,884] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:23:11,893] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:23:11,893] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:23:11,894] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:23:11,895] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:23:11,903] INFO  {ServerConnector} Started ServerConnector@43dbeaf4{HTTP/1.1}{0.0.0.0:4040}
[09:23:11,904] INFO  {Server} Started @1729ms
[09:23:11,904] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:23:11,907] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:23:12,005] INFO  {Executor} Starting executor ID driver on host localhost
[09:23:12,033] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33845.
[09:23:12,034] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:33845
[09:23:12,036] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 33845)
[09:23:12,039] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:33845 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 33845)
[09:23:12,042] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 33845)
[09:23:12,168] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:23:12,601] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:23:12,657] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:23:12,660] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:33845 (size: 14.3 KB, free: 1128.9 MB)
[09:23:12,665] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:23:12,812] INFO  {FileInputFormat} Total input paths to process : 1
[09:23:12,834] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:23:12,852] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:23:12,853] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:23:12,854] INFO  {DAGScheduler} Parents of final stage: List()
[09:23:12,856] INFO  {DAGScheduler} Missing parents: List()
[09:23:12,866] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:23:12,924] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:23:12,927] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:23:12,928] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:33845 (size: 2.1 KB, free: 1128.9 MB)
[09:23:12,928] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:23:12,931] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:23:12,933] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:23:12,980] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:23:12,989] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:23:13,013] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:23:13,022] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:23:13,022] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:23:13,022] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:23:13,022] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:23:13,022] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:23:13,088] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:23:13,095] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 138 ms on localhost (1/1)
[09:23:13,096] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:23:13,099] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.158 s
[09:23:13,104] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.269491 s
[09:23:13,204] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:33845 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:23:14,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:23:14,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:23:14,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:23:14,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:23:14,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:23:14,521] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:23:15,230] INFO  {CodeGenerator} Code generated in 183.650875 ms
[09:23:15,260] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:23:15,262] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:23:15,262] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:23:15,262] INFO  {DAGScheduler} Parents of final stage: List()
[09:23:15,262] INFO  {DAGScheduler} Missing parents: List()
[09:23:15,263] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:23:15,278] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:23:15,281] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:23:15,282] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:33845 (size: 5.5 KB, free: 1128.9 MB)
[09:23:15,283] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:23:15,283] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:23:15,283] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:23:15,286] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:23:15,287] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:23:15,318] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:23:15,339] INFO  {CodeGenerator} Code generated in 13.981869 ms
[09:23:15,360] INFO  {CodeGenerator} Code generated in 13.900065 ms
[09:23:15,363] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1452 bytes result sent to driver
[09:23:15,365] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 81 ms on localhost (1/1)
[09:23:15,365] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:23:15,366] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.082 s
[09:23:15,366] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.105503 s
[09:23:15,392] INFO  {CodeGenerator} Code generated in 15.021926 ms
[09:23:15,494] INFO  {CodeGenerator} Code generated in 11.226647 ms
[09:23:15,507] INFO  {CodeGenerator} Code generated in 9.41617 ms
[09:23:15,537] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:23:15,540] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:23:15,541] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:23:15,541] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:23:15,542] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:23:15,542] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:23:15,544] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:23:15,554] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:23:15,556] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:23:15,557] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:33845 (size: 6.6 KB, free: 1128.9 MB)
[09:23:15,557] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:23:15,560] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:23:15,560] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:23:15,563] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:23:15,563] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:23:15,572] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:23:15,726] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:23:15,729] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 168 ms on localhost (1/1)
[09:23:15,729] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:23:15,731] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.169 s
[09:23:15,732] INFO  {DAGScheduler} looking for newly runnable stages
[09:23:15,732] INFO  {DAGScheduler} running: Set()
[09:23:15,733] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:23:15,733] INFO  {DAGScheduler} failed: Set()
[09:23:15,734] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:23:15,740] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:23:15,742] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:23:15,743] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:33845 (size: 3.7 KB, free: 1128.9 MB)
[09:23:15,743] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:23:15,744] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:23:15,744] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:23:15,749] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:23:15,749] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:23:15,761] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:23:15,763] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[09:23:15,775] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:23:15,776] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 29 ms on localhost (1/1)
[09:23:15,776] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:23:15,777] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.030 s
[09:23:15,777] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.239750 s
[09:23:15,788] INFO  {CodeGenerator} Code generated in 6.936911 ms
[09:23:15,795] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:23:15,796] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:23:15,796] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:23:15,796] INFO  {DAGScheduler} Parents of final stage: List()
[09:23:15,796] INFO  {DAGScheduler} Missing parents: List()
[09:23:15,796] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:23:15,798] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:23:15,800] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:23:15,801] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:33845 (size: 2.0 KB, free: 1128.9 MB)
[09:23:15,801] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:23:15,801] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:23:15,801] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:23:15,803] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:23:15,803] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:23:15,809] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:23:15,851] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:23:15,853] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 51 ms on localhost (1/1)
[09:23:15,853] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:23:15,853] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.052 s
[09:23:15,854] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.058494 s
[09:23:15,959] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:33845 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:23:15,961] INFO  {ContextCleaner} Cleaned accumulator 44
[09:23:15,961] INFO  {ContextCleaner} Cleaned accumulator 45
[09:23:15,963] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:33845 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:23:15,963] INFO  {ContextCleaner} Cleaned accumulator 90
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 91
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 92
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 93
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 94
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 95
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 96
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 97
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 98
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 99
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 100
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 101
[09:23:15,964] INFO  {ContextCleaner} Cleaned accumulator 102
[09:23:15,968] INFO  {ContextCleaner} Cleaned shuffle 0
[09:23:15,969] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:33845 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:23:15,970] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:33845 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:23:16,058] INFO  {CodeGenerator} Code generated in 20.887189 ms
[09:23:16,081] INFO  {CodeGenerator} Code generated in 14.285161 ms
[09:23:16,094] INFO  {SparkContext} Starting job: show at Main.scala:47
[09:23:16,096] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[09:23:16,096] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[09:23:16,096] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[09:23:16,096] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:23:16,096] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:23:16,097] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[09:23:16,101] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[09:23:16,104] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[09:23:16,104] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:33845 (size: 7.6 KB, free: 1128.9 MB)
[09:23:16,105] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:23:16,105] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[09:23:16,105] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:23:16,107] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:23:16,107] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:23:16,112] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:23:16,145] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:23:16,146] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 40 ms on localhost (1/1)
[09:23:16,147] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:23:16,147] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.041 s
[09:23:16,147] INFO  {DAGScheduler} looking for newly runnable stages
[09:23:16,147] INFO  {DAGScheduler} running: Set()
[09:23:16,148] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:23:16,148] INFO  {DAGScheduler} failed: Set()
[09:23:16,148] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[09:23:16,150] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[09:23:16,153] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[09:23:16,154] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:33845 (size: 4.6 KB, free: 1128.9 MB)
[09:23:16,155] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:23:16,155] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[09:23:16,155] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:23:16,158] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:23:16,158] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:23:16,161] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:23:16,161] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:23:16,164] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1858 bytes result sent to driver
[09:23:16,166] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 9 ms on localhost (1/1)
[09:23:16,166] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:23:16,166] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.010 s
[09:23:16,167] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.072094 s
[09:23:16,177] INFO  {CodeGenerator} Code generated in 8.634441 ms
[09:23:16,181] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:23:16,184] INFO  {ServerConnector} Stopped ServerConnector@43dbeaf4{HTTP/1.1}{0.0.0.0:4040}
[09:23:16,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:23:16,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:23:16,186] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:23:16,187] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:23:16,188] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:23:16,189] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:23:16,189] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:23:16,190] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:23:16,198] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:23:16,203] INFO  {MemoryStore} MemoryStore cleared
[09:23:16,203] INFO  {BlockManager} BlockManager stopped
[09:23:16,204] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:23:16,206] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:23:16,208] INFO  {SparkContext} Successfully stopped SparkContext
[09:23:16,208] INFO  {ShutdownHookManager} Shutdown hook called
[09:23:16,209] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-bb67112f-e4c4-4034-b4eb-7bdd0ce02b40
[09:24:04,731] INFO  {SparkContext} Running Spark version 2.0.1
[09:24:04,944] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:24:05,050] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:24:05,051] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:24:05,111] INFO  {SecurityManager} Changing view acls to: victor
[09:24:05,111] INFO  {SecurityManager} Changing modify acls to: victor
[09:24:05,112] INFO  {SecurityManager} Changing view acls groups to: 
[09:24:05,113] INFO  {SecurityManager} Changing modify acls groups to: 
[09:24:05,113] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:24:05,476] INFO  {Utils} Successfully started service 'sparkDriver' on port 39915.
[09:24:05,494] INFO  {SparkEnv} Registering MapOutputTracker
[09:24:05,509] INFO  {SparkEnv} Registering BlockManagerMaster
[09:24:05,522] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-32d55a7e-2cf0-48bf-b322-20ad0e481b89
[09:24:05,538] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:24:05,588] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:24:05,659] INFO  {log} Logging initialized @1540ms
[09:24:05,768] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:24:05,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:24:05,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:24:05,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:24:05,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:24:05,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:24:05,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:24:05,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:24:05,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:24:05,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:24:05,788] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:24:05,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:24:05,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:24:05,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:24:05,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:24:05,801] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:24:05,802] INFO  {Server} Started @1683ms
[09:24:05,802] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:24:05,804] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:24:05,877] INFO  {Executor} Starting executor ID driver on host localhost
[09:24:05,897] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34171.
[09:24:05,898] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:34171
[09:24:05,900] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 34171)
[09:24:05,902] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:34171 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 34171)
[09:24:05,905] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 34171)
[09:24:06,030] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:24:06,448] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:24:06,509] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:24:06,512] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:34171 (size: 14.3 KB, free: 1128.9 MB)
[09:24:06,517] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:24:06,654] INFO  {FileInputFormat} Total input paths to process : 1
[09:24:06,673] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:24:06,693] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:24:06,693] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:24:06,694] INFO  {DAGScheduler} Parents of final stage: List()
[09:24:06,696] INFO  {DAGScheduler} Missing parents: List()
[09:24:06,707] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:24:06,770] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:24:06,773] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:24:06,774] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:34171 (size: 2.1 KB, free: 1128.9 MB)
[09:24:06,775] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:24:06,778] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:24:06,780] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:24:06,841] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:24:06,847] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:24:06,872] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:24:06,880] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:24:06,881] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:24:06,881] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:24:06,881] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:24:06,881] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:24:06,954] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:24:06,961] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 153 ms on localhost (1/1)
[09:24:06,962] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:24:06,966] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.174 s
[09:24:06,970] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.297371 s
[09:24:07,082] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:34171 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:24:08,455] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL,null,AVAILABLE}
[09:24:08,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@26d5a317{/SQL/json,null,AVAILABLE}
[09:24:08,456] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution,null,AVAILABLE}
[09:24:08,457] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@89caf47{/SQL/execution/json,null,AVAILABLE}
[09:24:08,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b24ea2a{/static/sql,null,AVAILABLE}
[09:24:08,468] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:24:09,221] INFO  {CodeGenerator} Code generated in 201.724266 ms
[09:24:09,250] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:24:09,252] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:24:09,252] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:24:09,252] INFO  {DAGScheduler} Parents of final stage: List()
[09:24:09,252] INFO  {DAGScheduler} Missing parents: List()
[09:24:09,253] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:24:09,273] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:24:09,275] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:24:09,275] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:34171 (size: 5.5 KB, free: 1128.9 MB)
[09:24:09,276] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:24:09,276] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:24:09,276] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:24:09,279] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:24:09,279] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:24:09,293] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:24:09,315] INFO  {CodeGenerator} Code generated in 15.39429 ms
[09:24:09,340] INFO  {CodeGenerator} Code generated in 15.858651 ms
[09:24:09,344] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:24:09,346] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 69 ms on localhost (1/1)
[09:24:09,346] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:24:09,346] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.069 s
[09:24:09,347] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.096340 s
[09:24:09,377] INFO  {CodeGenerator} Code generated in 17.332579 ms
[09:24:09,505] INFO  {CodeGenerator} Code generated in 12.274558 ms
[09:24:09,519] INFO  {CodeGenerator} Code generated in 9.649911 ms
[09:24:09,550] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:24:09,553] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:24:09,554] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:24:09,554] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:24:09,554] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:24:09,554] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:24:09,555] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:24:09,562] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:24:09,564] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:24:09,564] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:34171 (size: 6.6 KB, free: 1128.9 MB)
[09:24:09,565] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:24:09,566] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:24:09,567] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:24:09,569] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:24:09,569] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:24:09,578] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:24:09,687] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:24:09,690] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 122 ms on localhost (1/1)
[09:24:09,690] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:24:09,691] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.124 s
[09:24:09,692] INFO  {DAGScheduler} looking for newly runnable stages
[09:24:09,692] INFO  {DAGScheduler} running: Set()
[09:24:09,692] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:24:09,693] INFO  {DAGScheduler} failed: Set()
[09:24:09,695] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:24:09,702] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:24:09,704] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:24:09,704] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:34171 (size: 3.7 KB, free: 1128.9 MB)
[09:24:09,705] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:24:09,705] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:24:09,705] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:24:09,710] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:24:09,711] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:24:09,725] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:24:09,727] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[09:24:09,739] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1960 bytes result sent to driver
[09:24:09,741] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 33 ms on localhost (1/1)
[09:24:09,741] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:24:09,742] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.034 s
[09:24:09,743] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.191942 s
[09:24:09,753] INFO  {CodeGenerator} Code generated in 6.914037 ms
[09:24:09,759] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:24:09,760] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:24:09,760] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:24:09,760] INFO  {DAGScheduler} Parents of final stage: List()
[09:24:09,761] INFO  {DAGScheduler} Missing parents: List()
[09:24:09,761] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:24:09,763] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:24:09,764] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:24:09,765] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:34171 (size: 2.0 KB, free: 1128.9 MB)
[09:24:09,766] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:24:09,766] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:24:09,766] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:24:09,768] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:24:09,768] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:24:09,772] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:24:09,809] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:24:09,810] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 43 ms on localhost (1/1)
[09:24:09,810] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:24:09,811] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.045 s
[09:24:09,811] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.051351 s
[09:24:09,935] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:34171 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:24:09,939] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:34171 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:24:09,941] INFO  {ContextCleaner} Cleaned accumulator 44
[09:24:09,941] INFO  {ContextCleaner} Cleaned accumulator 45
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 90
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 91
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 92
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 93
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 94
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 95
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 96
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 97
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 98
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 99
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 100
[09:24:09,942] INFO  {ContextCleaner} Cleaned accumulator 101
[09:24:09,943] INFO  {ContextCleaner} Cleaned accumulator 102
[09:24:09,946] INFO  {ContextCleaner} Cleaned shuffle 0
[09:24:09,948] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:34171 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:24:09,950] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:34171 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:24:10,004] INFO  {CodeGenerator} Code generated in 15.560166 ms
[09:24:10,028] INFO  {CodeGenerator} Code generated in 14.450904 ms
[09:24:10,041] INFO  {SparkContext} Starting job: show at Main.scala:47
[09:24:10,042] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[09:24:10,043] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[09:24:10,043] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[09:24:10,043] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:24:10,043] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:24:10,044] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[09:24:10,047] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[09:24:10,049] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[09:24:10,049] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:34171 (size: 7.6 KB, free: 1128.9 MB)
[09:24:10,050] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:24:10,050] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[09:24:10,050] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:24:10,052] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:24:10,052] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:24:10,057] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:24:10,087] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:24:10,089] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 38 ms on localhost (1/1)
[09:24:10,089] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:24:10,089] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.038 s
[09:24:10,089] INFO  {DAGScheduler} looking for newly runnable stages
[09:24:10,090] INFO  {DAGScheduler} running: Set()
[09:24:10,090] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:24:10,090] INFO  {DAGScheduler} failed: Set()
[09:24:10,090] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[09:24:10,092] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[09:24:10,094] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[09:24:10,095] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:34171 (size: 4.6 KB, free: 1128.9 MB)
[09:24:10,095] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:24:10,095] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[09:24:10,095] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:24:10,097] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:24:10,098] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:24:10,100] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:24:10,100] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:24:10,104] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1858 bytes result sent to driver
[09:24:10,105] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 8 ms on localhost (1/1)
[09:24:10,105] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:24:10,105] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.009 s
[09:24:10,106] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.064344 s
[09:24:10,116] INFO  {CodeGenerator} Code generated in 8.364947 ms
[09:24:10,119] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:24:10,123] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:24:10,125] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:24:10,125] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:24:10,125] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:24:10,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:24:10,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:24:10,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:24:10,129] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:24:10,140] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:24:10,145] INFO  {MemoryStore} MemoryStore cleared
[09:24:10,146] INFO  {BlockManager} BlockManager stopped
[09:24:10,147] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:24:10,149] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:24:10,152] INFO  {SparkContext} Successfully stopped SparkContext
[09:24:10,152] INFO  {ShutdownHookManager} Shutdown hook called
[09:24:10,154] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-faae2d92-be7a-4dc4-aedb-bd50793e84e0
[09:49:59,385] INFO  {SparkContext} Running Spark version 2.0.1
[09:49:59,607] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:49:59,694] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:49:59,694] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:49:59,754] INFO  {SecurityManager} Changing view acls to: victor
[09:49:59,754] INFO  {SecurityManager} Changing modify acls to: victor
[09:49:59,755] INFO  {SecurityManager} Changing view acls groups to: 
[09:49:59,756] INFO  {SecurityManager} Changing modify acls groups to: 
[09:49:59,757] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:50:00,123] INFO  {Utils} Successfully started service 'sparkDriver' on port 43719.
[09:50:00,141] INFO  {SparkEnv} Registering MapOutputTracker
[09:50:00,155] INFO  {SparkEnv} Registering BlockManagerMaster
[09:50:00,168] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-981af496-622b-4a54-8446-5492750418e1
[09:50:00,182] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:50:00,242] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:50:00,310] INFO  {log} Logging initialized @1530ms
[09:50:00,409] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:50:00,425] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:50:00,425] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:50:00,425] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:50:00,425] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:50:00,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:50:00,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:50:00,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:50:00,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:50:00,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:50:00,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:50:00,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:50:00,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:50:00,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:50:00,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:50:00,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:50:00,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:50:00,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:50:00,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:50:00,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:50:00,443] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:50:00,443] INFO  {Server} Started @1663ms
[09:50:00,443] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:50:00,446] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:50:00,531] INFO  {Executor} Starting executor ID driver on host localhost
[09:50:00,555] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45379.
[09:50:00,556] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:45379
[09:50:00,558] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 45379)
[09:50:00,561] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:45379 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 45379)
[09:50:00,564] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 45379)
[09:50:00,690] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:50:01,128] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:50:01,186] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:50:01,188] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:45379 (size: 14.3 KB, free: 1128.9 MB)
[09:50:01,194] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:50:01,329] INFO  {FileInputFormat} Total input paths to process : 1
[09:50:01,349] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:50:01,366] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:50:01,367] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:50:01,368] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:01,370] INFO  {DAGScheduler} Missing parents: List()
[09:50:01,381] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:50:01,437] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:50:01,440] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:50:01,440] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:45379 (size: 2.1 KB, free: 1128.9 MB)
[09:50:01,441] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:50:01,445] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:50:01,446] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:50:01,494] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:50:01,501] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:50:01,525] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:01,533] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:50:01,534] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:50:01,534] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:50:01,534] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:50:01,534] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:50:01,606] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:50:01,614] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 146 ms on localhost (1/1)
[09:50:01,616] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:50:01,620] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.164 s
[09:50:01,626] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.276235 s
[09:50:01,711] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:45379 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:50:03,058] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:50:03,058] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:50:03,059] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:50:03,059] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:50:03,061] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:50:03,070] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:50:03,811] INFO  {CodeGenerator} Code generated in 185.424048 ms
[09:50:03,840] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:50:03,842] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:50:03,842] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:50:03,842] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:03,843] INFO  {DAGScheduler} Missing parents: List()
[09:50:03,843] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:50:03,860] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:50:03,875] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:50:03,876] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:45379 (size: 5.5 KB, free: 1128.9 MB)
[09:50:03,877] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:50:03,877] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:50:03,877] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:50:03,879] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:50:03,880] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:50:03,897] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:03,925] INFO  {CodeGenerator} Code generated in 19.548092 ms
[09:50:03,953] INFO  {CodeGenerator} Code generated in 18.73467 ms
[09:50:03,957] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:50:03,958] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 80 ms on localhost (1/1)
[09:50:03,958] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:50:03,959] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.082 s
[09:50:03,959] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.118458 s
[09:50:03,986] INFO  {CodeGenerator} Code generated in 14.493203 ms
[09:50:04,086] INFO  {CodeGenerator} Code generated in 11.595864 ms
[09:50:04,099] INFO  {CodeGenerator} Code generated in 9.035518 ms
[09:50:04,128] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:50:04,131] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:50:04,132] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:50:04,132] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:50:04,132] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:50:04,132] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:50:04,133] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:50:04,141] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:50:04,142] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:50:04,143] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:45379 (size: 6.6 KB, free: 1128.9 MB)
[09:50:04,144] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:50:04,146] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:50:04,146] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:50:04,148] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:50:04,148] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:50:04,160] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:04,295] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:50:04,297] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 151 ms on localhost (1/1)
[09:50:04,297] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:50:04,298] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.152 s
[09:50:04,299] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:04,299] INFO  {DAGScheduler} running: Set()
[09:50:04,299] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:50:04,300] INFO  {DAGScheduler} failed: Set()
[09:50:04,301] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:50:04,306] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:50:04,308] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:50:04,308] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:45379 (size: 3.7 KB, free: 1128.9 MB)
[09:50:04,309] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:50:04,309] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:50:04,309] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:50:04,313] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:50:04,314] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:50:04,328] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:04,329] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 5 ms
[09:50:04,341] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1960 bytes result sent to driver
[09:50:04,343] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 31 ms on localhost (1/1)
[09:50:04,343] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:50:04,343] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.031 s
[09:50:04,345] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.216611 s
[09:50:04,359] INFO  {CodeGenerator} Code generated in 8.920652 ms
[09:50:04,369] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:50:04,370] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:50:04,370] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:50:04,370] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:04,370] INFO  {DAGScheduler} Missing parents: List()
[09:50:04,371] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:50:04,374] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:50:04,376] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:50:04,376] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:45379 (size: 2.0 KB, free: 1128.9 MB)
[09:50:04,377] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:50:04,377] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:50:04,377] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:50:04,379] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:50:04,379] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:50:04,382] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:04,417] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:50:04,418] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 40 ms on localhost (1/1)
[09:50:04,418] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:50:04,419] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.042 s
[09:50:04,419] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.050343 s
[09:50:04,529] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:45379 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:50:04,531] INFO  {ContextCleaner} Cleaned accumulator 44
[09:50:04,531] INFO  {ContextCleaner} Cleaned accumulator 45
[09:50:04,532] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:45379 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 90
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 91
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 92
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 93
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 94
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 95
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 96
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 97
[09:50:04,533] INFO  {ContextCleaner} Cleaned accumulator 98
[09:50:04,534] INFO  {ContextCleaner} Cleaned accumulator 99
[09:50:04,534] INFO  {ContextCleaner} Cleaned accumulator 100
[09:50:04,534] INFO  {ContextCleaner} Cleaned accumulator 101
[09:50:04,534] INFO  {ContextCleaner} Cleaned accumulator 102
[09:50:04,537] INFO  {ContextCleaner} Cleaned shuffle 0
[09:50:04,538] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:45379 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:50:04,539] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:45379 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:50:04,604] INFO  {CodeGenerator} Code generated in 16.135308 ms
[09:50:04,627] INFO  {CodeGenerator} Code generated in 15.182145 ms
[09:50:04,641] INFO  {SparkContext} Starting job: show at Main.scala:47
[09:50:04,642] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[09:50:04,644] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[09:50:04,644] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[09:50:04,644] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:50:04,644] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:50:04,645] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[09:50:04,648] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[09:50:04,651] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[09:50:04,652] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:45379 (size: 7.6 KB, free: 1128.9 MB)
[09:50:04,652] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:50:04,652] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[09:50:04,653] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:50:04,655] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:50:04,655] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:50:04,661] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:04,706] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:50:04,707] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 54 ms on localhost (1/1)
[09:50:04,707] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:50:04,708] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.055 s
[09:50:04,708] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:04,708] INFO  {DAGScheduler} running: Set()
[09:50:04,708] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:50:04,708] INFO  {DAGScheduler} failed: Set()
[09:50:04,709] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[09:50:04,710] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[09:50:04,712] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[09:50:04,713] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:45379 (size: 4.6 KB, free: 1128.9 MB)
[09:50:04,713] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:50:04,714] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[09:50:04,714] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:50:04,716] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:50:04,716] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:50:04,720] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:04,720] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:50:04,724] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1858 bytes result sent to driver
[09:50:04,726] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 11 ms on localhost (1/1)
[09:50:04,726] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:50:04,726] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.012 s
[09:50:04,727] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.084960 s
[09:50:04,738] INFO  {CodeGenerator} Code generated in 9.0091 ms
[09:50:04,799] INFO  {SparkContext} Starting job: foreach at Main.scala:61
[09:50:04,801] INFO  {DAGScheduler} Registering RDD 23 (groupBy at Main.scala:51)
[09:50:04,801] INFO  {DAGScheduler} Got job 5 (foreach at Main.scala:61) with 1 output partitions
[09:50:04,801] INFO  {DAGScheduler} Final stage: ResultStage 8 (foreach at Main.scala:61)
[09:50:04,802] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 7)
[09:50:04,802] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 7)
[09:50:04,802] INFO  {DAGScheduler} Submitting ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51), which has no missing parents
[09:50:04,812] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 5.4 KB, free 1128.7 MB)
[09:50:04,814] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1128.7 MB)
[09:50:04,815] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.111:45379 (size: 2.9 KB, free: 1128.9 MB)
[09:50:04,816] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[09:50:04,816] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51)
[09:50:04,816] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[09:50:04,818] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5443 bytes)
[09:50:04,819] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[09:50:04,829] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:04,862] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1244 bytes result sent to driver
[09:50:04,863] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 47 ms on localhost (1/1)
[09:50:04,863] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[09:50:04,863] INFO  {DAGScheduler} ShuffleMapStage 7 (groupBy at Main.scala:51) finished in 0.047 s
[09:50:04,863] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:04,863] INFO  {DAGScheduler} running: Set()
[09:50:04,863] INFO  {DAGScheduler} waiting: Set(ResultStage 8)
[09:50:04,864] INFO  {DAGScheduler} failed: Set()
[09:50:04,864] INFO  {DAGScheduler} Submitting ResultStage 8 (MapPartitionsRDD[25] at map at Main.scala:52), which has no missing parents
[09:50:04,870] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 6.4 KB, free 1128.7 MB)
[09:50:04,872] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1128.7 MB)
[09:50:04,873] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.111:45379 (size: 3.2 KB, free: 1128.9 MB)
[09:50:04,873] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[09:50:04,873] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[25] at map at Main.scala:52)
[09:50:04,874] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[09:50:04,876] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, ANY, 5183 bytes)
[09:50:04,876] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[09:50:04,880] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:04,880] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:50:04,988] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 1640 bytes result sent to driver
[09:50:04,989] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 115 ms on localhost (1/1)
[09:50:04,990] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[09:50:04,990] INFO  {DAGScheduler} ResultStage 8 (foreach at Main.scala:61) finished in 0.116 s
[09:50:04,991] INFO  {DAGScheduler} Job 5 finished: foreach at Main.scala:61, took 0.191154 s
[09:50:04,994] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:50:05,000] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:50:05,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:50:05,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:50:05,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:50:05,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:50:05,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:50:05,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:50:05,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:50:05,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:50:05,008] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:50:05,023] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:50:05,032] INFO  {MemoryStore} MemoryStore cleared
[09:50:05,032] INFO  {BlockManager} BlockManager stopped
[09:50:05,033] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:50:05,035] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:50:05,037] INFO  {SparkContext} Successfully stopped SparkContext
[09:50:05,038] INFO  {ShutdownHookManager} Shutdown hook called
[09:50:05,038] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-bc1a8eb4-45ad-4191-aae7-7c88aa3fa316
[09:50:38,547] INFO  {SparkContext} Running Spark version 2.0.1
[09:50:38,743] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[09:50:38,820] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 80.216.145.111 instead (on interface enp5s0)
[09:50:38,820] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[09:50:38,884] INFO  {SecurityManager} Changing view acls to: victor
[09:50:38,884] INFO  {SecurityManager} Changing modify acls to: victor
[09:50:38,885] INFO  {SecurityManager} Changing view acls groups to: 
[09:50:38,885] INFO  {SecurityManager} Changing modify acls groups to: 
[09:50:38,886] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[09:50:39,307] INFO  {Utils} Successfully started service 'sparkDriver' on port 36867.
[09:50:39,325] INFO  {SparkEnv} Registering MapOutputTracker
[09:50:39,342] INFO  {SparkEnv} Registering BlockManagerMaster
[09:50:39,359] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-6c17d498-94bc-45a7-871b-82d7a9bae8a1
[09:50:39,374] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[09:50:39,440] INFO  {SparkEnv} Registering OutputCommitCoordinator
[09:50:39,511] INFO  {log} Logging initialized @1522ms
[09:50:39,608] INFO  {Server} jetty-9.2.z-SNAPSHOT
[09:50:39,624] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,AVAILABLE}
[09:50:39,624] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,AVAILABLE}
[09:50:39,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,AVAILABLE}
[09:50:39,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,AVAILABLE}
[09:50:39,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages,null,AVAILABLE}
[09:50:39,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,AVAILABLE}
[09:50:39,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,AVAILABLE}
[09:50:39,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,AVAILABLE}
[09:50:39,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,AVAILABLE}
[09:50:39,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,AVAILABLE}
[09:50:39,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,AVAILABLE}
[09:50:39,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,AVAILABLE}
[09:50:39,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,AVAILABLE}
[09:50:39,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,AVAILABLE}
[09:50:39,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,AVAILABLE}
[09:50:39,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,AVAILABLE}
[09:50:39,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors,null,AVAILABLE}
[09:50:39,628] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,AVAILABLE}
[09:50:39,628] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,AVAILABLE}
[09:50:39,628] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,AVAILABLE}
[09:50:39,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/static,null,AVAILABLE}
[09:50:39,634] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/,null,AVAILABLE}
[09:50:39,635] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/api,null,AVAILABLE}
[09:50:39,636] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,AVAILABLE}
[09:50:39,642] INFO  {ServerConnector} Started ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:50:39,642] INFO  {Server} Started @1654ms
[09:50:39,642] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[09:50:39,644] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://80.216.145.111:4040
[09:50:39,723] INFO  {Executor} Starting executor ID driver on host localhost
[09:50:39,745] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45389.
[09:50:39,746] INFO  {NettyBlockTransferService} Server created on 80.216.145.111:45389
[09:50:39,747] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 80.216.145.111, 45389)
[09:50:39,751] INFO  {BlockManagerMasterEndpoint} Registering block manager 80.216.145.111:45389 with 1128.9 MB RAM, BlockManagerId(driver, 80.216.145.111, 45389)
[09:50:39,754] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 80.216.145.111, 45389)
[09:50:39,876] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@593e824f{/metrics/json,null,AVAILABLE}
[09:50:40,315] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1128.8 MB)
[09:50:40,386] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1128.8 MB)
[09:50:40,388] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 80.216.145.111:45389 (size: 14.3 KB, free: 1128.9 MB)
[09:50:40,393] INFO  {SparkContext} Created broadcast 0 from textFile at Main.scala:20
[09:50:40,520] INFO  {FileInputFormat} Total input paths to process : 1
[09:50:40,540] INFO  {SparkContext} Starting job: top at Main.scala:23
[09:50:40,550] INFO  {DAGScheduler} Got job 0 (top at Main.scala:23) with 1 output partitions
[09:50:40,551] INFO  {DAGScheduler} Final stage: ResultStage 0 (top at Main.scala:23)
[09:50:40,551] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:40,552] INFO  {DAGScheduler} Missing parents: List()
[09:50:40,559] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23), which has no missing parents
[09:50:40,610] INFO  {MemoryStore} Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 1128.8 MB)
[09:50:40,613] INFO  {MemoryStore} Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1128.8 MB)
[09:50:40,614] INFO  {BlockManagerInfo} Added broadcast_1_piece0 in memory on 80.216.145.111:45389 (size: 2.1 KB, free: 1128.9 MB)
[09:50:40,615] INFO  {SparkContext} Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[09:50:40,619] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at top at Main.scala:23)
[09:50:40,621] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[09:50:40,664] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5449 bytes)
[09:50:40,671] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[09:50:40,697] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:40,705] INFO  {deprecation} mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[09:50:40,705] INFO  {deprecation} mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[09:50:40,705] INFO  {deprecation} mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[09:50:40,705] INFO  {deprecation} mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[09:50:40,705] INFO  {deprecation} mapred.job.id is deprecated. Instead, use mapreduce.job.id
[09:50:40,774] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 2350 bytes result sent to driver
[09:50:40,783] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 138 ms on localhost (1/1)
[09:50:40,784] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[09:50:40,787] INFO  {DAGScheduler} ResultStage 0 (top at Main.scala:23) finished in 0.155 s
[09:50:40,792] INFO  {DAGScheduler} Job 0 finished: top at Main.scala:23, took 0.251882 s
[09:50:40,896] INFO  {BlockManagerInfo} Removed broadcast_1_piece0 on 80.216.145.111:45389 in memory (size: 2.1 KB, free: 1128.9 MB)
[09:50:42,224] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6403a4a5{/SQL,null,AVAILABLE}
[09:50:42,224] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a6c0f38{/SQL/json,null,AVAILABLE}
[09:50:42,225] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@559af296{/SQL/execution,null,AVAILABLE}
[09:50:42,225] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18709cb2{/SQL/execution/json,null,AVAILABLE}
[09:50:42,226] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b87760e{/static/sql,null,AVAILABLE}
[09:50:42,236] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[09:50:42,939] INFO  {CodeGenerator} Code generated in 180.211045 ms
[09:50:42,981] INFO  {SparkContext} Starting job: show at Main.scala:37
[09:50:42,982] INFO  {DAGScheduler} Got job 1 (show at Main.scala:37) with 1 output partitions
[09:50:42,983] INFO  {DAGScheduler} Final stage: ResultStage 1 (show at Main.scala:37)
[09:50:42,983] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:42,983] INFO  {DAGScheduler} Missing parents: List()
[09:50:42,983] INFO  {DAGScheduler} Submitting ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37), which has no missing parents
[09:50:42,998] INFO  {MemoryStore} Block broadcast_2 stored as values in memory (estimated size 10.6 KB, free 1128.8 MB)
[09:50:43,000] INFO  {MemoryStore} Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 1128.7 MB)
[09:50:43,000] INFO  {BlockManagerInfo} Added broadcast_2_piece0 in memory on 80.216.145.111:45389 (size: 5.5 KB, free: 1128.9 MB)
[09:50:43,001] INFO  {SparkContext} Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[09:50:43,001] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at Main.scala:37)
[09:50:43,001] INFO  {TaskSchedulerImpl} Adding task set 1.0 with 1 tasks
[09:50:43,003] INFO  {TaskSetManager} Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5398 bytes)
[09:50:43,004] INFO  {Executor} Running task 0.0 in stage 1.0 (TID 1)
[09:50:43,016] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:43,037] INFO  {CodeGenerator} Code generated in 14.505346 ms
[09:50:43,058] INFO  {CodeGenerator} Code generated in 13.729221 ms
[09:50:43,062] INFO  {Executor} Finished task 0.0 in stage 1.0 (TID 1). 1379 bytes result sent to driver
[09:50:43,063] INFO  {TaskSetManager} Finished task 0.0 in stage 1.0 (TID 1) in 61 ms on localhost (1/1)
[09:50:43,063] INFO  {TaskSchedulerImpl} Removed TaskSet 1.0, whose tasks have all completed, from pool 
[09:50:43,064] INFO  {DAGScheduler} ResultStage 1 (show at Main.scala:37) finished in 0.063 s
[09:50:43,064] INFO  {DAGScheduler} Job 1 finished: show at Main.scala:37, took 0.082779 s
[09:50:43,087] INFO  {CodeGenerator} Code generated in 13.472337 ms
[09:50:43,191] INFO  {CodeGenerator} Code generated in 11.661845 ms
[09:50:43,204] INFO  {CodeGenerator} Code generated in 8.987698 ms
[09:50:43,234] INFO  {SparkContext} Starting job: count at Main.scala:40
[09:50:43,236] INFO  {DAGScheduler} Registering RDD 11 (count at Main.scala:40)
[09:50:43,237] INFO  {DAGScheduler} Got job 2 (count at Main.scala:40) with 1 output partitions
[09:50:43,237] INFO  {DAGScheduler} Final stage: ResultStage 3 (count at Main.scala:40)
[09:50:43,237] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 2)
[09:50:43,237] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 2)
[09:50:43,239] INFO  {DAGScheduler} Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40), which has no missing parents
[09:50:43,246] INFO  {MemoryStore} Block broadcast_3 stored as values in memory (estimated size 12.9 KB, free 1128.7 MB)
[09:50:43,248] INFO  {MemoryStore} Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1128.7 MB)
[09:50:43,249] INFO  {BlockManagerInfo} Added broadcast_3_piece0 in memory on 80.216.145.111:45389 (size: 6.6 KB, free: 1128.9 MB)
[09:50:43,249] INFO  {SparkContext} Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[09:50:43,251] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at count at Main.scala:40)
[09:50:43,251] INFO  {TaskSchedulerImpl} Adding task set 2.0 with 1 tasks
[09:50:43,254] INFO  {TaskSetManager} Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5472 bytes)
[09:50:43,254] INFO  {Executor} Running task 0.0 in stage 2.0 (TID 2)
[09:50:43,263] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:43,373] INFO  {Executor} Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
[09:50:43,376] INFO  {TaskSetManager} Finished task 0.0 in stage 2.0 (TID 2) in 124 ms on localhost (1/1)
[09:50:43,376] INFO  {TaskSchedulerImpl} Removed TaskSet 2.0, whose tasks have all completed, from pool 
[09:50:43,377] INFO  {DAGScheduler} ShuffleMapStage 2 (count at Main.scala:40) finished in 0.125 s
[09:50:43,377] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:43,378] INFO  {DAGScheduler} running: Set()
[09:50:43,378] INFO  {DAGScheduler} waiting: Set(ResultStage 3)
[09:50:43,379] INFO  {DAGScheduler} failed: Set()
[09:50:43,380] INFO  {DAGScheduler} Submitting ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40), which has no missing parents
[09:50:43,386] INFO  {MemoryStore} Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 1128.7 MB)
[09:50:43,388] INFO  {MemoryStore} Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1128.7 MB)
[09:50:43,388] INFO  {BlockManagerInfo} Added broadcast_4_piece0 in memory on 80.216.145.111:45389 (size: 3.7 KB, free: 1128.9 MB)
[09:50:43,389] INFO  {SparkContext} Created broadcast 4 from broadcast at DAGScheduler.scala:1012
[09:50:43,389] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at count at Main.scala:40)
[09:50:43,389] INFO  {TaskSchedulerImpl} Adding task set 3.0 with 1 tasks
[09:50:43,394] INFO  {TaskSetManager} Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5317 bytes)
[09:50:43,394] INFO  {Executor} Running task 0.0 in stage 3.0 (TID 3)
[09:50:43,407] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:43,408] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 4 ms
[09:50:43,421] INFO  {Executor} Finished task 0.0 in stage 3.0 (TID 3). 1873 bytes result sent to driver
[09:50:43,423] INFO  {TaskSetManager} Finished task 0.0 in stage 3.0 (TID 3) in 31 ms on localhost (1/1)
[09:50:43,423] INFO  {TaskSchedulerImpl} Removed TaskSet 3.0, whose tasks have all completed, from pool 
[09:50:43,424] INFO  {DAGScheduler} ResultStage 3 (count at Main.scala:40) finished in 0.031 s
[09:50:43,424] INFO  {DAGScheduler} Job 2 finished: count at Main.scala:40, took 0.190042 s
[09:50:43,434] INFO  {CodeGenerator} Code generated in 7.113293 ms
[09:50:43,441] INFO  {SparkContext} Starting job: count at Main.scala:43
[09:50:43,441] INFO  {DAGScheduler} Got job 3 (count at Main.scala:43) with 1 output partitions
[09:50:43,442] INFO  {DAGScheduler} Final stage: ResultStage 4 (count at Main.scala:43)
[09:50:43,442] INFO  {DAGScheduler} Parents of final stage: List()
[09:50:43,442] INFO  {DAGScheduler} Missing parents: List()
[09:50:43,442] INFO  {DAGScheduler} Submitting ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43), which has no missing parents
[09:50:43,444] INFO  {MemoryStore} Block broadcast_5 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:50:43,446] INFO  {MemoryStore} Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1128.7 MB)
[09:50:43,446] INFO  {BlockManagerInfo} Added broadcast_5_piece0 in memory on 80.216.145.111:45389 (size: 2.0 KB, free: 1128.9 MB)
[09:50:43,447] INFO  {SparkContext} Created broadcast 5 from broadcast at DAGScheduler.scala:1012
[09:50:43,447] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at filter at Main.scala:43)
[09:50:43,447] INFO  {TaskSchedulerImpl} Adding task set 4.0 with 1 tasks
[09:50:43,449] INFO  {TaskSetManager} Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5369 bytes)
[09:50:43,449] INFO  {Executor} Running task 0.0 in stage 4.0 (TID 4)
[09:50:43,452] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:43,505] INFO  {Executor} Finished task 0.0 in stage 4.0 (TID 4). 1041 bytes result sent to driver
[09:50:43,507] INFO  {TaskSetManager} Finished task 0.0 in stage 4.0 (TID 4) in 58 ms on localhost (1/1)
[09:50:43,507] INFO  {TaskSchedulerImpl} Removed TaskSet 4.0, whose tasks have all completed, from pool 
[09:50:43,507] INFO  {DAGScheduler} ResultStage 4 (count at Main.scala:43) finished in 0.060 s
[09:50:43,508] INFO  {DAGScheduler} Job 3 finished: count at Main.scala:43, took 0.066827 s
[09:50:43,643] INFO  {BlockManagerInfo} Removed broadcast_5_piece0 on 80.216.145.111:45389 in memory (size: 2.0 KB, free: 1128.9 MB)
[09:50:43,645] INFO  {ContextCleaner} Cleaned accumulator 44
[09:50:43,645] INFO  {ContextCleaner} Cleaned accumulator 45
[09:50:43,646] INFO  {BlockManagerInfo} Removed broadcast_2_piece0 on 80.216.145.111:45389 in memory (size: 5.5 KB, free: 1128.9 MB)
[09:50:43,647] INFO  {ContextCleaner} Cleaned accumulator 90
[09:50:43,647] INFO  {ContextCleaner} Cleaned accumulator 91
[09:50:43,647] INFO  {ContextCleaner} Cleaned accumulator 92
[09:50:43,647] INFO  {ContextCleaner} Cleaned accumulator 93
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 94
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 95
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 96
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 97
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 98
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 99
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 100
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 101
[09:50:43,648] INFO  {ContextCleaner} Cleaned accumulator 102
[09:50:43,653] INFO  {ContextCleaner} Cleaned shuffle 0
[09:50:43,654] INFO  {BlockManagerInfo} Removed broadcast_3_piece0 on 80.216.145.111:45389 in memory (size: 6.6 KB, free: 1128.9 MB)
[09:50:43,656] INFO  {BlockManagerInfo} Removed broadcast_4_piece0 on 80.216.145.111:45389 in memory (size: 3.7 KB, free: 1128.9 MB)
[09:50:43,710] INFO  {CodeGenerator} Code generated in 16.072226 ms
[09:50:43,734] INFO  {CodeGenerator} Code generated in 14.706132 ms
[09:50:43,747] INFO  {SparkContext} Starting job: show at Main.scala:47
[09:50:43,748] INFO  {DAGScheduler} Registering RDD 18 (show at Main.scala:47)
[09:50:43,748] INFO  {DAGScheduler} Got job 4 (show at Main.scala:47) with 1 output partitions
[09:50:43,748] INFO  {DAGScheduler} Final stage: ResultStage 6 (show at Main.scala:47)
[09:50:43,748] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 5)
[09:50:43,749] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 5)
[09:50:43,749] INFO  {DAGScheduler} Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47), which has no missing parents
[09:50:43,752] INFO  {MemoryStore} Block broadcast_6 stored as values in memory (estimated size 15.8 KB, free 1128.7 MB)
[09:50:43,754] INFO  {MemoryStore} Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1128.7 MB)
[09:50:43,755] INFO  {BlockManagerInfo} Added broadcast_6_piece0 in memory on 80.216.145.111:45389 (size: 7.6 KB, free: 1128.9 MB)
[09:50:43,755] INFO  {SparkContext} Created broadcast 6 from broadcast at DAGScheduler.scala:1012
[09:50:43,755] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at show at Main.scala:47)
[09:50:43,756] INFO  {TaskSchedulerImpl} Adding task set 5.0 with 1 tasks
[09:50:43,758] INFO  {TaskSetManager} Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5387 bytes)
[09:50:43,758] INFO  {Executor} Running task 0.0 in stage 5.0 (TID 5)
[09:50:43,763] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:43,792] INFO  {Executor} Finished task 0.0 in stage 5.0 (TID 5). 1801 bytes result sent to driver
[09:50:43,794] INFO  {TaskSetManager} Finished task 0.0 in stage 5.0 (TID 5) in 37 ms on localhost (1/1)
[09:50:43,794] INFO  {TaskSchedulerImpl} Removed TaskSet 5.0, whose tasks have all completed, from pool 
[09:50:43,794] INFO  {DAGScheduler} ShuffleMapStage 5 (show at Main.scala:47) finished in 0.038 s
[09:50:43,794] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:43,794] INFO  {DAGScheduler} running: Set()
[09:50:43,794] INFO  {DAGScheduler} waiting: Set(ResultStage 6)
[09:50:43,795] INFO  {DAGScheduler} failed: Set()
[09:50:43,795] INFO  {DAGScheduler} Submitting ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47), which has no missing parents
[09:50:43,797] INFO  {MemoryStore} Block broadcast_7 stored as values in memory (estimated size 9.4 KB, free 1128.7 MB)
[09:50:43,798] INFO  {MemoryStore} Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1128.7 MB)
[09:50:43,799] INFO  {BlockManagerInfo} Added broadcast_7_piece0 in memory on 80.216.145.111:45389 (size: 4.6 KB, free: 1128.9 MB)
[09:50:43,799] INFO  {SparkContext} Created broadcast 7 from broadcast at DAGScheduler.scala:1012
[09:50:43,800] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at show at Main.scala:47)
[09:50:43,800] INFO  {TaskSchedulerImpl} Adding task set 6.0 with 1 tasks
[09:50:43,801] INFO  {TaskSetManager} Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5232 bytes)
[09:50:43,802] INFO  {Executor} Running task 0.0 in stage 6.0 (TID 6)
[09:50:43,805] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:43,805] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:50:43,809] INFO  {Executor} Finished task 0.0 in stage 6.0 (TID 6). 1858 bytes result sent to driver
[09:50:43,810] INFO  {TaskSetManager} Finished task 0.0 in stage 6.0 (TID 6) in 10 ms on localhost (1/1)
[09:50:43,811] INFO  {TaskSchedulerImpl} Removed TaskSet 6.0, whose tasks have all completed, from pool 
[09:50:43,811] INFO  {DAGScheduler} ResultStage 6 (show at Main.scala:47) finished in 0.011 s
[09:50:43,811] INFO  {DAGScheduler} Job 4 finished: show at Main.scala:47, took 0.064343 s
[09:50:43,821] INFO  {CodeGenerator} Code generated in 8.001598 ms
[09:50:43,872] INFO  {SparkContext} Starting job: foreach at Main.scala:61
[09:50:43,875] INFO  {DAGScheduler} Registering RDD 23 (groupBy at Main.scala:51)
[09:50:43,875] INFO  {DAGScheduler} Registering RDD 26 (sortBy at Main.scala:61)
[09:50:43,875] INFO  {DAGScheduler} Got job 5 (foreach at Main.scala:61) with 1 output partitions
[09:50:43,875] INFO  {DAGScheduler} Final stage: ResultStage 9 (foreach at Main.scala:61)
[09:50:43,875] INFO  {DAGScheduler} Parents of final stage: List(ShuffleMapStage 8)
[09:50:43,876] INFO  {DAGScheduler} Missing parents: List(ShuffleMapStage 8)
[09:50:43,876] INFO  {DAGScheduler} Submitting ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51), which has no missing parents
[09:50:43,883] INFO  {MemoryStore} Block broadcast_8 stored as values in memory (estimated size 5.4 KB, free 1128.7 MB)
[09:50:43,885] INFO  {MemoryStore} Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1128.7 MB)
[09:50:43,886] INFO  {BlockManagerInfo} Added broadcast_8_piece0 in memory on 80.216.145.111:45389 (size: 2.9 KB, free: 1128.9 MB)
[09:50:43,887] INFO  {SparkContext} Created broadcast 8 from broadcast at DAGScheduler.scala:1012
[09:50:43,887] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[23] at groupBy at Main.scala:51)
[09:50:43,887] INFO  {TaskSchedulerImpl} Adding task set 7.0 with 1 tasks
[09:50:43,889] INFO  {TaskSetManager} Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5443 bytes)
[09:50:43,890] INFO  {Executor} Running task 0.0 in stage 7.0 (TID 7)
[09:50:43,895] INFO  {HadoopRDD} Input split: file:/home/victor/Desktop/ML/vt17-lab1/src/main/resources/millionsong.txt:0+1248115
[09:50:43,943] INFO  {Executor} Finished task 0.0 in stage 7.0 (TID 7). 1244 bytes result sent to driver
[09:50:43,944] INFO  {TaskSetManager} Finished task 0.0 in stage 7.0 (TID 7) in 56 ms on localhost (1/1)
[09:50:43,945] INFO  {TaskSchedulerImpl} Removed TaskSet 7.0, whose tasks have all completed, from pool 
[09:50:43,945] INFO  {DAGScheduler} ShuffleMapStage 7 (groupBy at Main.scala:51) finished in 0.058 s
[09:50:43,945] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:43,945] INFO  {DAGScheduler} running: Set()
[09:50:43,945] INFO  {DAGScheduler} waiting: Set(ResultStage 9, ShuffleMapStage 8)
[09:50:43,945] INFO  {DAGScheduler} failed: Set()
[09:50:43,946] INFO  {DAGScheduler} Submitting ShuffleMapStage 8 (MapPartitionsRDD[26] at sortBy at Main.scala:61), which has no missing parents
[09:50:43,958] INFO  {MemoryStore} Block broadcast_9 stored as values in memory (estimated size 6.9 KB, free 1128.7 MB)
[09:50:43,960] INFO  {MemoryStore} Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.5 KB, free 1128.7 MB)
[09:50:43,961] INFO  {BlockManagerInfo} Added broadcast_9_piece0 in memory on 80.216.145.111:45389 (size: 3.5 KB, free: 1128.9 MB)
[09:50:43,962] INFO  {SparkContext} Created broadcast 9 from broadcast at DAGScheduler.scala:1012
[09:50:43,962] INFO  {DAGScheduler} Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[26] at sortBy at Main.scala:61)
[09:50:43,962] INFO  {TaskSchedulerImpl} Adding task set 8.0 with 1 tasks
[09:50:43,965] INFO  {TaskSetManager} Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, ANY, 5172 bytes)
[09:50:43,966] INFO  {Executor} Running task 0.0 in stage 8.0 (TID 8)
[09:50:43,973] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:43,973] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 0 ms
[09:50:44,081] INFO  {Executor} Finished task 0.0 in stage 8.0 (TID 8). 1881 bytes result sent to driver
[09:50:44,083] INFO  {TaskSetManager} Finished task 0.0 in stage 8.0 (TID 8) in 120 ms on localhost (1/1)
[09:50:44,084] INFO  {TaskSchedulerImpl} Removed TaskSet 8.0, whose tasks have all completed, from pool 
[09:50:44,084] INFO  {DAGScheduler} ShuffleMapStage 8 (sortBy at Main.scala:61) finished in 0.121 s
[09:50:44,084] INFO  {DAGScheduler} looking for newly runnable stages
[09:50:44,084] INFO  {DAGScheduler} running: Set()
[09:50:44,084] INFO  {DAGScheduler} waiting: Set(ResultStage 9)
[09:50:44,084] INFO  {DAGScheduler} failed: Set()
[09:50:44,085] INFO  {DAGScheduler} Submitting ResultStage 9 (MapPartitionsRDD[28] at sortBy at Main.scala:61), which has no missing parents
[09:50:44,087] INFO  {MemoryStore} Block broadcast_10 stored as values in memory (estimated size 3.4 KB, free 1128.7 MB)
[09:50:44,089] INFO  {MemoryStore} Block broadcast_10_piece0 stored as bytes in memory (estimated size 2003.0 B, free 1128.7 MB)
[09:50:44,090] INFO  {BlockManagerInfo} Added broadcast_10_piece0 in memory on 80.216.145.111:45389 (size: 2003.0 B, free: 1128.9 MB)
[09:50:44,091] INFO  {SparkContext} Created broadcast 10 from broadcast at DAGScheduler.scala:1012
[09:50:44,091] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[28] at sortBy at Main.scala:61)
[09:50:44,091] INFO  {TaskSchedulerImpl} Adding task set 9.0 with 1 tasks
[09:50:44,093] INFO  {TaskSetManager} Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, ANY, 5183 bytes)
[09:50:44,093] INFO  {Executor} Running task 0.0 in stage 9.0 (TID 9)
[09:50:44,097] INFO  {ShuffleBlockFetcherIterator} Getting 1 non-empty blocks out of 1 blocks
[09:50:44,097] INFO  {ShuffleBlockFetcherIterator} Started 0 remote fetches in 1 ms
[09:50:44,136] INFO  {Executor} Finished task 0.0 in stage 9.0 (TID 9). 1553 bytes result sent to driver
[09:50:44,137] INFO  {TaskSetManager} Finished task 0.0 in stage 9.0 (TID 9) in 45 ms on localhost (1/1)
[09:50:44,137] INFO  {TaskSchedulerImpl} Removed TaskSet 9.0, whose tasks have all completed, from pool 
[09:50:44,138] INFO  {DAGScheduler} ResultStage 9 (foreach at Main.scala:61) finished in 0.046 s
[09:50:44,138] INFO  {DAGScheduler} Job 5 finished: foreach at Main.scala:61, took 0.266292 s
[09:50:44,142] INFO  {SparkContext} Invoking stop() from shutdown hook
[09:50:44,148] INFO  {ServerConnector} Stopped ServerConnector@49872d67{HTTP/1.1}{0.0.0.0:4040}
[09:50:44,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/stages/stage/kill,null,UNAVAILABLE}
[09:50:44,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/api,null,UNAVAILABLE}
[09:50:44,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/,null,UNAVAILABLE}
[09:50:44,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/static,null,UNAVAILABLE}
[09:50:44,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/threadDump/json,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors/threadDump,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/executors/json,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/environment/json,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/environment,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/rdd/json,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage/rdd,null,UNAVAILABLE}
[09:50:44,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/storage/json,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/pool/json,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/pool,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/stage/json,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/stage,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/json,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages,null,UNAVAILABLE}
[09:50:44,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/job/json,null,UNAVAILABLE}
[09:50:44,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs/job,null,UNAVAILABLE}
[09:50:44,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/jobs/json,null,UNAVAILABLE}
[09:50:44,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs,null,UNAVAILABLE}
[09:50:44,157] INFO  {SparkUI} Stopped Spark web UI at http://80.216.145.111:4040
[09:50:44,171] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[09:50:44,180] INFO  {MemoryStore} MemoryStore cleared
[09:50:44,180] INFO  {BlockManager} BlockManager stopped
[09:50:44,182] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[09:50:44,186] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[09:50:44,191] INFO  {SparkContext} Successfully stopped SparkContext
[09:50:44,192] INFO  {ShutdownHookManager} Shutdown hook called
[09:50:44,193] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a883287c-ce27-4caa-85a8-4b305dc23f28
