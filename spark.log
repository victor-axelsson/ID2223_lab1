[14:44:45,196] INFO  {SparkContext} Running Spark version 2.0.1
[14:44:45,843] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:44:46,188] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:44:46,190] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:44:46,468] INFO  {SecurityManager} Changing view acls to: victor
[14:44:46,470] INFO  {SecurityManager} Changing modify acls to: victor
[14:44:46,472] INFO  {SecurityManager} Changing view acls groups to: 
[14:44:46,475] INFO  {SecurityManager} Changing modify acls groups to: 
[14:44:46,478] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:44:47,434] INFO  {Utils} Successfully started service 'sparkDriver' on port 42645.
[14:44:47,484] INFO  {SparkEnv} Registering MapOutputTracker
[14:44:47,536] INFO  {SparkEnv} Registering BlockManagerMaster
[14:44:47,570] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-9588a287-9c5e-49e3-b47a-d4f296a44abd
[14:44:47,618] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:44:47,739] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:44:47,983] INFO  {log} Logging initialized @5076ms
[14:44:48,377] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:44:48,424] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[14:44:48,425] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[14:44:48,425] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[14:44:48,426] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[14:44:48,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[14:44:48,427] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[14:44:48,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[14:44:48,428] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[14:44:48,429] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[14:44:48,430] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[14:44:48,430] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[14:44:48,431] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[14:44:48,432] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[14:44:48,432] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[14:44:48,433] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[14:44:48,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[14:44:48,434] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[14:44:48,435] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[14:44:48,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[14:44:48,436] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[14:44:48,458] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[14:44:48,460] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[14:44:48,463] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[14:44:48,464] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[14:44:48,490] INFO  {ServerConnector} Started ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[14:44:48,492] INFO  {Server} Started @5588ms
[14:44:48,492] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:44:48,499] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:44:48,822] INFO  {Executor} Starting executor ID driver on host localhost
[14:44:48,938] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39989.
[14:44:48,942] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:39989
[14:44:48,949] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 39989)
[14:44:48,959] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:39989 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 39989)
[14:44:48,972] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 39989)
[14:44:49,356] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[14:44:49,821] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:44:49,834] INFO  {ServerConnector} Stopped ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[14:44:49,839] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[14:44:49,840] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[14:44:49,841] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[14:44:49,842] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[14:44:49,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[14:44:49,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[14:44:49,844] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[14:44:49,844] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[14:44:49,845] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[14:44:49,846] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[14:44:49,847] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[14:44:49,848] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[14:44:49,848] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[14:44:49,849] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[14:44:49,850] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[14:44:49,851] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[14:44:49,851] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[14:44:49,852] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[14:44:49,853] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[14:44:49,853] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[14:44:49,854] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[14:44:49,854] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[14:44:49,855] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[14:44:49,855] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[14:44:49,860] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:44:49,896] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:44:49,909] INFO  {MemoryStore} MemoryStore cleared
[14:44:49,910] INFO  {BlockManager} BlockManager stopped
[14:44:49,921] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:44:49,932] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:44:49,935] INFO  {SparkContext} Successfully stopped SparkContext
[14:44:49,936] INFO  {ShutdownHookManager} Shutdown hook called
[14:44:49,938] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-50b46feb-b146-4b83-abe6-93bf4b2592b3
[14:45:08,592] INFO  {SparkContext} Running Spark version 2.0.1
[14:45:09,247] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:45:09,605] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:45:09,607] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:45:09,815] INFO  {SecurityManager} Changing view acls to: victor
[14:45:09,817] INFO  {SecurityManager} Changing modify acls to: victor
[14:45:09,821] INFO  {SecurityManager} Changing view acls groups to: 
[14:45:09,826] INFO  {SecurityManager} Changing modify acls groups to: 
[14:45:09,828] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:45:10,820] INFO  {Utils} Successfully started service 'sparkDriver' on port 33611.
[14:45:10,867] INFO  {SparkEnv} Registering MapOutputTracker
[14:45:10,911] INFO  {SparkEnv} Registering BlockManagerMaster
[14:45:10,942] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-29e7a139-4f19-4b21-853d-e884551f8cc9
[14:45:10,979] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:45:11,097] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:45:11,288] INFO  {log} Logging initialized @4635ms
[14:45:11,551] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:45:11,592] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:45:11,593] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:45:11,594] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:45:11,595] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:45:11,595] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:45:11,596] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:45:11,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:45:11,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:45:11,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:45:11,599] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:45:11,600] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:45:11,601] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:45:11,601] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:45:11,602] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:45:11,602] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:45:11,603] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:45:11,603] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:45:11,604] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:45:11,604] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:45:11,604] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:45:11,616] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:45:11,616] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:45:11,618] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:45:11,618] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:45:11,634] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:45:11,634] INFO  {Server} Started @4984ms
[14:45:11,635] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:45:11,638] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:45:11,853] INFO  {Executor} Starting executor ID driver on host localhost
[14:45:11,912] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46053.
[14:45:11,915] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:46053
[14:45:11,921] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 46053)
[14:45:11,928] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:46053 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 46053)
[14:45:11,941] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 46053)
[14:45:12,289] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:45:12,693] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:45:12,709] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:45:12,717] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:45:12,718] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:45:12,718] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:45:12,719] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:45:12,719] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:45:12,720] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:45:12,722] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:45:12,723] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:45:12,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:45:12,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:45:12,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:45:12,726] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:45:12,726] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:45:12,727] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:45:12,727] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:45:12,728] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:45:12,728] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:45:12,729] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:45:12,729] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:45:12,730] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:45:12,731] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:45:12,731] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:45:12,731] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:45:12,731] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:45:12,736] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:45:12,762] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:45:12,775] INFO  {MemoryStore} MemoryStore cleared
[14:45:12,776] INFO  {BlockManager} BlockManager stopped
[14:45:12,793] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:45:12,820] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:45:12,824] INFO  {SparkContext} Successfully stopped SparkContext
[14:45:12,825] INFO  {ShutdownHookManager} Shutdown hook called
[14:45:12,827] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-d593889e-6e24-49c4-94d1-c0efbea55b35
[14:45:24,940] INFO  {SparkContext} Running Spark version 2.0.1
[14:45:25,536] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:45:25,902] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:45:25,904] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:45:26,136] INFO  {SecurityManager} Changing view acls to: victor
[14:45:26,139] INFO  {SecurityManager} Changing modify acls to: victor
[14:45:26,141] INFO  {SecurityManager} Changing view acls groups to: 
[14:45:26,145] INFO  {SecurityManager} Changing modify acls groups to: 
[14:45:26,147] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:45:27,024] INFO  {Utils} Successfully started service 'sparkDriver' on port 41897.
[14:45:27,064] INFO  {SparkEnv} Registering MapOutputTracker
[14:45:27,113] INFO  {SparkEnv} Registering BlockManagerMaster
[14:45:27,146] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-53fee845-2f5b-4194-8b0b-088ce70bc4b6
[14:45:27,186] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:45:27,319] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:45:27,508] INFO  {log} Logging initialized @3996ms
[14:45:27,819] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:45:27,861] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:45:27,862] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:45:27,862] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:45:27,863] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:45:27,863] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:45:27,864] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:45:27,864] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:45:27,864] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:45:27,865] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:45:27,865] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:45:27,866] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:45:27,866] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:45:27,867] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:45:27,867] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:45:27,867] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:45:27,868] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:45:27,868] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:45:27,869] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:45:27,869] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:45:27,870] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:45:27,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:45:27,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:45:27,885] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:45:27,885] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:45:27,898] INFO  {ServerConnector} Started ServerConnector@4e4afc2b{HTTP/1.1}{0.0.0.0:4040}
[14:45:27,899] INFO  {Server} Started @4389ms
[14:45:27,899] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:45:27,903] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:45:28,123] INFO  {Executor} Starting executor ID driver on host localhost
[14:45:28,188] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42073.
[14:45:28,190] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:42073
[14:45:28,194] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 42073)
[14:45:28,202] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:42073 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 42073)
[14:45:28,211] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 42073)
[14:45:28,523] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b6579e8{/metrics/json,null,AVAILABLE}
[14:45:28,936] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:45:28,951] INFO  {ServerConnector} Stopped ServerConnector@4e4afc2b{HTTP/1.1}{0.0.0.0:4040}
[14:45:28,955] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:45:28,955] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:45:28,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:45:28,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:45:28,956] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:45:28,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:45:28,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:45:28,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:45:28,957] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:45:28,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:45:28,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:45:28,958] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:45:28,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:45:28,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:45:28,959] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:45:28,960] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:45:28,960] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:45:28,960] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:45:28,961] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:45:28,961] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:45:28,961] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:45:28,961] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:45:28,962] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:45:28,962] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:45:28,966] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:45:28,990] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:45:29,003] INFO  {MemoryStore} MemoryStore cleared
[14:45:29,004] INFO  {BlockManager} BlockManager stopped
[14:45:29,035] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:45:29,044] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:45:29,049] INFO  {SparkContext} Successfully stopped SparkContext
[14:45:29,051] INFO  {ShutdownHookManager} Shutdown hook called
[14:45:29,052] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-57ddd4c6-4767-4b11-a59c-fe3bea1fd17a
[14:46:10,436] INFO  {SparkContext} Running Spark version 2.0.1
[14:46:11,109] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:46:11,557] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:46:11,559] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:46:11,856] INFO  {SecurityManager} Changing view acls to: victor
[14:46:11,858] INFO  {SecurityManager} Changing modify acls to: victor
[14:46:11,860] INFO  {SecurityManager} Changing view acls groups to: 
[14:46:11,864] INFO  {SecurityManager} Changing modify acls groups to: 
[14:46:11,866] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:46:12,971] INFO  {Utils} Successfully started service 'sparkDriver' on port 35647.
[14:46:13,014] INFO  {SparkEnv} Registering MapOutputTracker
[14:46:13,058] INFO  {SparkEnv} Registering BlockManagerMaster
[14:46:13,092] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-487948b1-334d-4aee-a468-c97077d87607
[14:46:13,133] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:46:13,239] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:46:13,434] INFO  {log} Logging initialized @4843ms
[14:46:13,738] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:46:13,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:46:13,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:46:13,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:46:13,789] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:46:13,790] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:46:13,791] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:46:13,791] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:46:13,792] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:46:13,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:46:13,793] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:46:13,794] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:46:13,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:46:13,795] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:46:13,796] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:46:13,796] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:46:13,797] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:46:13,797] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:46:13,797] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:46:13,798] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:46:13,798] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:46:13,814] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:46:13,815] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:46:13,817] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:46:13,818] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:46:13,851] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:46:13,851] INFO  {Server} Started @5263ms
[14:46:13,852] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:46:13,859] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:46:14,169] INFO  {Executor} Starting executor ID driver on host localhost
[14:46:14,264] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42329.
[14:46:14,267] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:42329
[14:46:14,272] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 42329)
[14:46:14,292] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:42329 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 42329)
[14:46:14,308] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 42329)
[14:46:14,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:46:15,030] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:46:15,042] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:46:15,050] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:46:15,051] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:46:15,051] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:46:15,052] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:46:15,052] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:46:15,053] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:46:15,053] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:46:15,054] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:46:15,054] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:46:15,055] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:46:15,055] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:46:15,056] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:46:15,056] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:46:15,057] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:46:15,057] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:46:15,058] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:46:15,058] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:46:15,059] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:46:15,059] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:46:15,060] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:46:15,060] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:46:15,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:46:15,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:46:15,061] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:46:15,066] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:46:15,090] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:46:15,103] INFO  {MemoryStore} MemoryStore cleared
[14:46:15,104] INFO  {BlockManager} BlockManager stopped
[14:46:15,117] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:46:15,145] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:46:15,155] INFO  {SparkContext} Successfully stopped SparkContext
[14:46:15,157] INFO  {ShutdownHookManager} Shutdown hook called
[14:46:15,159] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-6c00f794-b53c-4db8-8c34-5f97e813c638
[14:46:28,239] INFO  {SparkContext} Running Spark version 2.0.1
[14:46:28,921] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:46:29,254] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:46:29,256] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:46:29,471] INFO  {SecurityManager} Changing view acls to: victor
[14:46:29,472] INFO  {SecurityManager} Changing modify acls to: victor
[14:46:29,474] INFO  {SecurityManager} Changing view acls groups to: 
[14:46:29,475] INFO  {SecurityManager} Changing modify acls groups to: 
[14:46:29,476] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:46:30,363] INFO  {Utils} Successfully started service 'sparkDriver' on port 44081.
[14:46:30,409] INFO  {SparkEnv} Registering MapOutputTracker
[14:46:30,446] INFO  {SparkEnv} Registering BlockManagerMaster
[14:46:30,477] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-4541146a-b6ab-4fcd-8323-6333b5cbc2b4
[14:46:30,516] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:46:30,639] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:46:30,859] INFO  {log} Logging initialized @3903ms
[14:46:31,118] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:46:31,163] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:46:31,163] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:46:31,164] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:46:31,164] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:46:31,165] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:46:31,166] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:46:31,166] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:46:31,167] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:46:31,168] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:46:31,168] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:46:31,169] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:46:31,169] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:46:31,170] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:46:31,170] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:46:31,171] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:46:31,171] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:46:31,172] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:46:31,172] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:46:31,173] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:46:31,173] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:46:31,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:46:31,188] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:46:31,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:46:31,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:46:31,208] INFO  {ServerConnector} Started ServerConnector@2e35551b{HTTP/1.1}{0.0.0.0:4040}
[14:46:31,209] INFO  {Server} Started @4257ms
[14:46:31,209] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:46:31,215] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:46:31,455] INFO  {Executor} Starting executor ID driver on host localhost
[14:46:31,513] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43951.
[14:46:31,515] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:43951
[14:46:31,519] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 43951)
[14:46:31,526] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:43951 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 43951)
[14:46:31,534] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 43951)
[14:46:31,845] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b6579e8{/metrics/json,null,AVAILABLE}
[14:46:32,178] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:46:32,194] INFO  {ServerConnector} Stopped ServerConnector@2e35551b{HTTP/1.1}{0.0.0.0:4040}
[14:46:32,199] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:46:32,200] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:46:32,200] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:46:32,201] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:46:32,201] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:46:32,201] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:46:32,202] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:46:32,202] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:46:32,202] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:46:32,202] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:46:32,203] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:46:32,203] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:46:32,203] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:46:32,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:46:32,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:46:32,204] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:46:32,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:46:32,205] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:46:32,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:46:32,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:46:32,206] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:46:32,207] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:46:32,207] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:46:32,207] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:46:32,215] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:46:32,241] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:46:32,256] INFO  {MemoryStore} MemoryStore cleared
[14:46:32,258] INFO  {BlockManager} BlockManager stopped
[14:46:32,280] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:46:32,293] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:46:32,299] INFO  {SparkContext} Successfully stopped SparkContext
[14:46:32,300] INFO  {ShutdownHookManager} Shutdown hook called
[14:46:32,303] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-357f0c6c-d1a9-4b0b-b944-c0edaac02313
[14:46:47,925] INFO  {SparkContext} Running Spark version 2.0.1
[14:46:48,494] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:46:48,823] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:46:48,825] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:46:49,013] INFO  {SecurityManager} Changing view acls to: victor
[14:46:49,016] INFO  {SecurityManager} Changing modify acls to: victor
[14:46:49,018] INFO  {SecurityManager} Changing view acls groups to: 
[14:46:49,023] INFO  {SecurityManager} Changing modify acls groups to: 
[14:46:49,026] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:46:50,145] INFO  {Utils} Successfully started service 'sparkDriver' on port 45819.
[14:46:50,230] INFO  {SparkEnv} Registering MapOutputTracker
[14:46:50,302] INFO  {SparkEnv} Registering BlockManagerMaster
[14:46:50,353] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-8b427845-c8ff-4cde-b9ef-27b61198e18c
[14:46:50,430] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:46:50,752] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:46:51,100] INFO  {log} Logging initialized @4765ms
[14:46:51,629] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:46:51,729] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:46:51,730] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:46:51,731] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:46:51,734] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:46:51,737] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:46:51,738] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:46:51,739] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:46:51,739] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:46:51,741] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:46:51,742] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:46:51,743] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:46:51,744] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:46:51,745] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:46:51,746] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:46:51,747] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:46:51,748] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:46:51,749] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:46:51,749] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:46:51,751] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:46:51,752] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:46:51,779] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:46:51,780] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:46:51,783] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:46:51,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:46:51,829] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:46:51,830] INFO  {Server} Started @5503ms
[14:46:51,830] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:46:51,841] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:46:52,197] INFO  {Executor} Starting executor ID driver on host localhost
[14:46:52,369] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44183.
[14:46:52,372] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:44183
[14:46:52,377] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 44183)
[14:46:52,397] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:44183 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 44183)
[14:46:52,413] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 44183)
[14:46:53,061] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:46:53,652] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:46:53,730] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:46:53,739] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:46:53,741] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:46:53,742] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:46:53,743] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:46:53,746] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:46:53,748] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:46:53,753] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:46:53,766] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:46:53,767] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:46:53,768] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:46:53,769] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:46:53,770] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:46:53,770] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:46:53,771] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:46:53,772] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:46:53,773] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:46:53,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:46:53,784] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:46:53,790] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:46:53,793] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:46:53,794] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:46:53,795] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:46:53,795] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:46:53,796] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:46:53,819] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:46:53,881] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:46:53,901] INFO  {MemoryStore} MemoryStore cleared
[14:46:53,903] INFO  {BlockManager} BlockManager stopped
[14:46:53,928] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:46:53,940] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:46:54,039] INFO  {SparkContext} Successfully stopped SparkContext
[14:46:54,040] INFO  {ShutdownHookManager} Shutdown hook called
[14:46:54,043] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-d3bc5414-80de-4dea-b7c7-0d4472f4fa3c
[14:46:54,425] INFO  {SparkContext} Running Spark version 2.0.1
[14:46:55,030] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:46:55,563] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:46:55,565] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:46:55,772] INFO  {SecurityManager} Changing view acls to: victor
[14:46:55,774] INFO  {SecurityManager} Changing modify acls to: victor
[14:46:55,776] INFO  {SecurityManager} Changing view acls groups to: 
[14:46:55,778] INFO  {SecurityManager} Changing modify acls groups to: 
[14:46:55,780] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:46:56,737] INFO  {Utils} Successfully started service 'sparkDriver' on port 45927.
[14:46:56,779] INFO  {SparkEnv} Registering MapOutputTracker
[14:46:56,817] INFO  {SparkEnv} Registering BlockManagerMaster
[14:46:56,848] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-1a5bc139-efad-4fc0-8528-79cc61ceac3b
[14:46:56,887] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:46:57,006] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:46:57,193] INFO  {log} Logging initialized @5617ms
[14:46:57,466] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:46:57,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:46:57,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:46:57,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:46:57,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:46:57,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:46:57,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:46:57,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:46:57,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:46:57,512] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:46:57,513] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:46:57,513] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:46:57,514] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:46:57,514] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:46:57,515] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:46:57,515] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:46:57,516] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:46:57,516] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:46:57,517] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:46:57,517] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:46:57,517] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:46:57,530] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:46:57,531] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:46:57,532] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:46:57,532] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:46:57,547] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:46:57,548] INFO  {Server} Started @5975ms
[14:46:57,548] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:46:57,552] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:46:57,762] INFO  {Executor} Starting executor ID driver on host localhost
[14:46:57,821] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42227.
[14:46:57,823] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:42227
[14:46:57,827] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 42227)
[14:46:57,835] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:42227 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 42227)
[14:46:57,846] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 42227)
[14:46:58,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:46:58,445] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:46:58,459] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:46:58,465] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:46:58,466] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:46:58,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:46:58,467] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:46:58,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:46:58,468] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:46:58,469] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:46:58,469] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:46:58,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:46:58,470] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:46:58,471] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:46:58,472] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:46:58,473] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:46:58,473] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:46:58,474] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:46:58,475] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:46:58,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:46:58,476] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:46:58,477] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:46:58,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:46:58,479] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:46:58,480] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:46:58,480] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:46:58,481] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:46:58,486] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:46:58,516] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:46:58,526] INFO  {MemoryStore} MemoryStore cleared
[14:46:58,528] INFO  {BlockManager} BlockManager stopped
[14:46:58,542] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:46:58,560] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:46:58,575] INFO  {SparkContext} Successfully stopped SparkContext
[14:46:58,577] INFO  {ShutdownHookManager} Shutdown hook called
[14:46:58,581] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f40b5ef9-0df1-439f-bda5-cb9a039e903b
[14:47:11,780] INFO  {SparkContext} Running Spark version 2.0.1
[14:47:12,397] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:47:12,714] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:47:12,716] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:47:12,928] INFO  {SecurityManager} Changing view acls to: victor
[14:47:12,930] INFO  {SecurityManager} Changing modify acls to: victor
[14:47:12,932] INFO  {SecurityManager} Changing view acls groups to: 
[14:47:12,934] INFO  {SecurityManager} Changing modify acls groups to: 
[14:47:12,936] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:47:13,881] INFO  {Utils} Successfully started service 'sparkDriver' on port 37437.
[14:47:13,923] INFO  {SparkEnv} Registering MapOutputTracker
[14:47:13,971] INFO  {SparkEnv} Registering BlockManagerMaster
[14:47:14,015] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-b0666184-004c-4335-900b-e164ba7fb95e
[14:47:14,054] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:47:14,190] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:47:14,434] INFO  {log} Logging initialized @4471ms
[14:47:14,730] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:47:14,772] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:47:14,773] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:47:14,774] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:47:14,774] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:47:14,775] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:47:14,776] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:47:14,776] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:47:14,777] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:47:14,778] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:47:14,778] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:47:14,779] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:47:14,779] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:47:14,780] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:47:14,780] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:47:14,780] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:47:14,781] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:47:14,781] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:47:14,782] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:47:14,782] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:47:14,783] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:47:14,797] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:47:14,798] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:47:14,800] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:47:14,801] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:47:14,815] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:47:14,815] INFO  {Server} Started @4856ms
[14:47:14,816] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:47:14,819] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:47:15,039] INFO  {Executor} Starting executor ID driver on host localhost
[14:47:15,101] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37171.
[14:47:15,103] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:37171
[14:47:15,108] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 37171)
[14:47:15,117] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:37171 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 37171)
[14:47:15,138] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 37171)
[14:47:15,440] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:47:15,736] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:47:15,748] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:47:15,753] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:47:15,754] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:47:15,756] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:47:15,757] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:47:15,758] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:47:15,759] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:47:15,759] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:47:15,760] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:47:15,761] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:47:15,762] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:47:15,762] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:47:15,763] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:47:15,763] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:47:15,764] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:47:15,764] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:47:15,765] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:47:15,765] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:47:15,766] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:47:15,766] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:47:15,767] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:47:15,767] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:47:15,768] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:47:15,768] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:47:15,768] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:47:15,772] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:47:15,805] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:47:15,820] INFO  {MemoryStore} MemoryStore cleared
[14:47:15,821] INFO  {BlockManager} BlockManager stopped
[14:47:15,837] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:47:15,849] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:47:15,867] INFO  {SparkContext} Successfully stopped SparkContext
[14:47:15,868] INFO  {ShutdownHookManager} Shutdown hook called
[14:47:15,870] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-2503b97a-3d6e-4629-a77f-b9110e11ae23
[14:47:25,066] INFO  {SparkContext} Running Spark version 2.0.1
[14:47:25,734] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:47:26,094] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:47:26,096] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:47:26,305] INFO  {SecurityManager} Changing view acls to: victor
[14:47:26,307] INFO  {SecurityManager} Changing modify acls to: victor
[14:47:26,308] INFO  {SecurityManager} Changing view acls groups to: 
[14:47:26,309] INFO  {SecurityManager} Changing modify acls groups to: 
[14:47:26,310] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:47:27,154] INFO  {Utils} Successfully started service 'sparkDriver' on port 41621.
[14:47:27,197] INFO  {SparkEnv} Registering MapOutputTracker
[14:47:27,236] INFO  {SparkEnv} Registering BlockManagerMaster
[14:47:27,268] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-9231a9b7-e787-43d6-a923-fe4bf35a9d99
[14:47:27,306] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:47:27,452] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:47:27,699] INFO  {log} Logging initialized @3627ms
[14:47:27,995] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:47:28,045] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:47:28,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:47:28,046] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:47:28,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:47:28,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:47:28,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:47:28,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:47:28,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:47:28,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:47:28,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:47:28,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:47:28,052] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:47:28,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:47:28,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:47:28,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:47:28,054] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:47:28,054] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:47:28,055] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:47:28,055] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:47:28,056] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:47:28,070] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:47:28,071] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:47:28,072] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:47:28,073] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:47:28,090] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:47:28,090] INFO  {Server} Started @4023ms
[14:47:28,091] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:47:28,096] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:47:28,340] INFO  {Executor} Starting executor ID driver on host localhost
[14:47:28,396] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38477.
[14:47:28,398] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:38477
[14:47:28,404] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 38477)
[14:47:28,412] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:38477 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 38477)
[14:47:28,428] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 38477)
[14:47:28,743] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:47:29,079] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:47:29,093] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:47:29,098] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:47:29,099] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:47:29,099] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:47:29,099] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:47:29,100] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:47:29,100] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:47:29,101] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:47:29,101] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:47:29,102] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:47:29,102] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:47:29,103] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:47:29,103] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:47:29,104] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:47:29,104] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:47:29,104] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:47:29,105] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:47:29,105] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:47:29,106] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:47:29,106] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:47:29,106] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:47:29,107] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:47:29,107] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:47:29,108] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:47:29,108] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:47:29,112] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:47:29,150] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:47:29,163] INFO  {MemoryStore} MemoryStore cleared
[14:47:29,164] INFO  {BlockManager} BlockManager stopped
[14:47:29,177] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:47:29,185] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:47:29,202] INFO  {SparkContext} Successfully stopped SparkContext
[14:47:29,203] INFO  {ShutdownHookManager} Shutdown hook called
[14:47:29,205] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-5355c3be-36ac-4384-bbb1-2233611bcc7d
[14:47:37,057] INFO  {SparkContext} Running Spark version 2.0.1
[14:47:37,656] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:47:38,049] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:47:38,050] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:47:38,272] INFO  {SecurityManager} Changing view acls to: victor
[14:47:38,274] INFO  {SecurityManager} Changing modify acls to: victor
[14:47:38,277] INFO  {SecurityManager} Changing view acls groups to: 
[14:47:38,280] INFO  {SecurityManager} Changing modify acls groups to: 
[14:47:38,282] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:47:39,399] INFO  {Utils} Successfully started service 'sparkDriver' on port 39783.
[14:47:39,446] INFO  {SparkEnv} Registering MapOutputTracker
[14:47:39,492] INFO  {SparkEnv} Registering BlockManagerMaster
[14:47:39,525] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-2acf5935-c606-4d5f-bb21-3c80b68180e4
[14:47:39,570] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:47:39,702] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:47:39,908] INFO  {log} Logging initialized @4747ms
[14:47:40,184] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:47:40,222] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[14:47:40,223] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[14:47:40,224] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[14:47:40,224] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[14:47:40,225] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[14:47:40,225] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[14:47:40,225] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[14:47:40,226] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[14:47:40,226] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[14:47:40,227] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[14:47:40,227] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[14:47:40,228] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[14:47:40,228] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[14:47:40,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[14:47:40,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[14:47:40,230] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[14:47:40,230] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[14:47:40,230] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[14:47:40,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[14:47:40,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[14:47:40,244] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[14:47:40,244] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[14:47:40,246] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[14:47:40,247] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[14:47:40,263] INFO  {ServerConnector} Started ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[14:47:40,264] INFO  {Server} Started @5106ms
[14:47:40,265] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:47:40,270] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:47:40,500] INFO  {Executor} Starting executor ID driver on host localhost
[14:47:40,563] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44609.
[14:47:40,565] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:44609
[14:47:40,569] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 44609)
[14:47:40,577] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:44609 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 44609)
[14:47:40,591] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 44609)
[14:47:40,907] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@591e58fa{/metrics/json,null,AVAILABLE}
[14:47:41,324] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:47:41,337] INFO  {ServerConnector} Stopped ServerConnector@13518f37{HTTP/1.1}{0.0.0.0:4040}
[14:47:41,341] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[14:47:41,343] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[14:47:41,343] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[14:47:41,344] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[14:47:41,345] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[14:47:41,345] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[14:47:41,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[14:47:41,346] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[14:47:41,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[14:47:41,347] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[14:47:41,348] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[14:47:41,350] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[14:47:41,355] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[14:47:41,356] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[14:47:41,356] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[14:47:41,357] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[14:47:41,357] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[14:47:41,358] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[14:47:41,358] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[14:47:41,359] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[14:47:41,359] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[14:47:41,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[14:47:41,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[14:47:41,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[14:47:41,364] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:47:41,391] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:47:41,415] INFO  {MemoryStore} MemoryStore cleared
[14:47:41,417] INFO  {BlockManager} BlockManager stopped
[14:47:41,433] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:47:41,443] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:47:41,452] INFO  {SparkContext} Successfully stopped SparkContext
[14:47:41,453] INFO  {ShutdownHookManager} Shutdown hook called
[14:47:41,455] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-4f4e75e6-c402-4ed0-aa52-bdd3cc5ed257
[14:48:45,549] INFO  {SparkContext} Running Spark version 2.0.1
[14:48:46,166] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:48:46,447] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:48:46,448] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:48:46,682] INFO  {SecurityManager} Changing view acls to: victor
[14:48:46,683] INFO  {SecurityManager} Changing modify acls to: victor
[14:48:46,685] INFO  {SecurityManager} Changing view acls groups to: 
[14:48:46,687] INFO  {SecurityManager} Changing modify acls groups to: 
[14:48:46,689] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:48:47,697] INFO  {Utils} Successfully started service 'sparkDriver' on port 34739.
[14:48:47,740] INFO  {SparkEnv} Registering MapOutputTracker
[14:48:47,780] INFO  {SparkEnv} Registering BlockManagerMaster
[14:48:47,812] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-a9d5efde-4b73-4ffe-9a82-d4bf507e1648
[14:48:47,850] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:48:47,973] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:48:48,191] INFO  {log} Logging initialized @4273ms
[14:48:48,454] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:48:48,500] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:48:48,501] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:48:48,502] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:48:48,502] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:48:48,503] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:48:48,503] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:48:48,504] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:48:48,504] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:48:48,505] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:48:48,505] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:48:48,506] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:48:48,506] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:48:48,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:48:48,507] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:48:48,508] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:48:48,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:48:48,509] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:48:48,510] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:48:48,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:48:48,511] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:48:48,526] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:48:48,527] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:48:48,530] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:48:48,531] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:48:48,549] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:48:48,550] INFO  {Server} Started @4637ms
[14:48:48,550] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:48:48,556] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:48:48,839] INFO  {Executor} Starting executor ID driver on host localhost
[14:48:48,902] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44485.
[14:48:48,904] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:44485
[14:48:48,909] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 44485)
[14:48:48,917] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:44485 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 44485)
[14:48:48,929] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 44485)
[14:48:49,243] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:48:49,699] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:48:49,717] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:48:49,722] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:48:49,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:48:49,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:48:49,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:48:49,726] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:48:49,726] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:48:49,727] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:48:49,728] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:48:49,728] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:48:49,729] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:48:49,729] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:48:49,730] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:48:49,733] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:48:49,734] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:48:49,735] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:48:49,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:48:49,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:48:49,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:48:49,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:48:49,739] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:48:49,739] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:48:49,739] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:48:49,740] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:48:49,740] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:48:49,744] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:48:49,775] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:48:49,788] INFO  {MemoryStore} MemoryStore cleared
[14:48:49,789] INFO  {BlockManager} BlockManager stopped
[14:48:49,809] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:48:49,821] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:48:49,834] INFO  {SparkContext} Successfully stopped SparkContext
[14:48:49,836] INFO  {ShutdownHookManager} Shutdown hook called
[14:48:49,839] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-be72c53c-b28c-49cb-94e1-431bf045fcbb
[14:50:50,271] INFO  {SparkContext} Running Spark version 2.0.1
[14:50:50,895] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:50:51,207] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:50:51,210] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:50:51,436] INFO  {SecurityManager} Changing view acls to: victor
[14:50:51,438] INFO  {SecurityManager} Changing modify acls to: victor
[14:50:51,440] INFO  {SecurityManager} Changing view acls groups to: 
[14:50:51,444] INFO  {SecurityManager} Changing modify acls groups to: 
[14:50:51,445] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:50:52,372] INFO  {Utils} Successfully started service 'sparkDriver' on port 33395.
[14:50:52,415] INFO  {SparkEnv} Registering MapOutputTracker
[14:50:52,456] INFO  {SparkEnv} Registering BlockManagerMaster
[14:50:52,488] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-30770c45-0429-4b48-932b-9e448eba053e
[14:50:52,530] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:50:52,642] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:50:52,891] INFO  {log} Logging initialized @3757ms
[14:50:53,165] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:50:53,214] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:50:53,215] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:50:53,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:50:53,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:50:53,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:50:53,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:50:53,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:50:53,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:50:53,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:50:53,219] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:50:53,220] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:50:53,220] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:50:53,221] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:50:53,221] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:50:53,222] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:50:53,222] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:50:53,222] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:50:53,223] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:50:53,223] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:50:53,224] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:50:53,236] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:50:53,237] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:50:53,239] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:50:53,239] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:50:53,253] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:50:53,254] INFO  {Server} Started @4123ms
[14:50:53,254] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:50:53,258] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:50:53,473] INFO  {Executor} Starting executor ID driver on host localhost
[14:50:53,533] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41743.
[14:50:53,535] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:41743
[14:50:53,539] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 41743)
[14:50:53,547] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:41743 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 41743)
[14:50:53,558] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 41743)
[14:50:53,880] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:50:54,288] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:50:54,299] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:50:54,304] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:50:54,305] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:50:54,305] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:50:54,306] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:50:54,306] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:50:54,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:50:54,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:50:54,307] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:50:54,308] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:50:54,308] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:50:54,309] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:50:54,309] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:50:54,310] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:50:54,310] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:50:54,311] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:50:54,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:50:54,312] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:50:54,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:50:54,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:50:54,313] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:50:54,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:50:54,314] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:50:54,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:50:54,315] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:50:54,319] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:50:54,344] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:50:54,357] INFO  {MemoryStore} MemoryStore cleared
[14:50:54,358] INFO  {BlockManager} BlockManager stopped
[14:50:54,371] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:50:54,381] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:50:54,391] INFO  {SparkContext} Successfully stopped SparkContext
[14:50:54,392] INFO  {ShutdownHookManager} Shutdown hook called
[14:50:54,394] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-1df0101c-06fe-4542-89ea-a94335cb86bd
[14:51:05,289] INFO  {SparkContext} Running Spark version 2.0.1
[14:51:05,927] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:51:06,295] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:51:06,297] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:51:06,538] INFO  {SecurityManager} Changing view acls to: victor
[14:51:06,540] INFO  {SecurityManager} Changing modify acls to: victor
[14:51:06,543] INFO  {SecurityManager} Changing view acls groups to: 
[14:51:06,546] INFO  {SecurityManager} Changing modify acls groups to: 
[14:51:06,548] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:51:07,531] INFO  {Utils} Successfully started service 'sparkDriver' on port 33311.
[14:51:07,572] INFO  {SparkEnv} Registering MapOutputTracker
[14:51:07,609] INFO  {SparkEnv} Registering BlockManagerMaster
[14:51:07,640] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-baf8f7ae-4921-4203-9d8a-8b76ff7c5439
[14:51:07,680] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:51:07,810] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:51:07,995] INFO  {log} Logging initialized @4309ms
[14:51:08,276] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:51:08,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:51:08,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:51:08,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:51:08,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:51:08,316] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:51:08,316] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:51:08,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:51:08,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:51:08,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:51:08,318] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:51:08,318] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:51:08,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:51:08,319] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:51:08,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:51:08,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:51:08,320] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:51:08,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:51:08,321] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:51:08,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:51:08,322] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:51:08,336] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:51:08,337] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:51:08,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:51:08,338] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:51:08,352] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:51:08,354] INFO  {Server} Started @4670ms
[14:51:08,354] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:51:08,358] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:51:08,587] INFO  {Executor} Starting executor ID driver on host localhost
[14:51:08,653] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34051.
[14:51:08,663] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:34051
[14:51:08,669] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 34051)
[14:51:08,675] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:34051 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 34051)
[14:51:08,685] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 34051)
[14:51:09,017] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:51:09,421] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:51:09,435] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:51:09,440] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:51:09,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:51:09,441] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:51:09,442] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:51:09,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:51:09,443] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:51:09,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:51:09,444] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:51:09,445] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:51:09,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:51:09,446] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:51:09,447] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:51:09,448] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:51:09,448] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:51:09,448] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:51:09,449] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:51:09,450] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:51:09,451] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:51:09,451] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:51:09,452] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:51:09,452] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:51:09,453] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:51:09,453] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:51:09,453] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:51:09,457] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:51:09,478] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:51:09,489] INFO  {MemoryStore} MemoryStore cleared
[14:51:09,490] INFO  {BlockManager} BlockManager stopped
[14:51:09,501] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:51:09,509] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:51:09,520] INFO  {SparkContext} Successfully stopped SparkContext
[14:51:09,522] INFO  {ShutdownHookManager} Shutdown hook called
[14:51:09,524] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-43f6aad2-afc2-4a1a-9d39-f181f7246e89
[14:55:36,619] INFO  {SparkContext} Running Spark version 2.0.1
[14:55:37,320] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:55:37,615] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:55:37,617] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:55:37,857] INFO  {SecurityManager} Changing view acls to: victor
[14:55:37,859] INFO  {SecurityManager} Changing modify acls to: victor
[14:55:37,861] INFO  {SecurityManager} Changing view acls groups to: 
[14:55:37,864] INFO  {SecurityManager} Changing modify acls groups to: 
[14:55:37,865] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:55:38,934] INFO  {Utils} Successfully started service 'sparkDriver' on port 36685.
[14:55:38,986] INFO  {SparkEnv} Registering MapOutputTracker
[14:55:39,031] INFO  {SparkEnv} Registering BlockManagerMaster
[14:55:39,065] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-d1011ff4-ecae-489b-a26a-04371bc93c80
[14:55:39,108] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:55:39,262] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:55:39,512] INFO  {log} Logging initialized @4427ms
[14:55:39,773] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:55:39,811] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:55:39,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:55:39,812] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:55:39,813] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:55:39,813] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:55:39,814] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:55:39,814] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:55:39,814] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:55:39,815] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:55:39,815] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:55:39,816] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:55:39,816] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:55:39,816] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:55:39,817] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:55:39,817] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:55:39,818] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:55:39,818] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:55:39,819] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:55:39,819] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:55:39,820] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:55:39,832] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:55:39,832] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:55:39,833] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:55:39,834] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:55:39,847] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:55:39,847] INFO  {Server} Started @4767ms
[14:55:39,848] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:55:39,853] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:55:40,084] INFO  {Executor} Starting executor ID driver on host localhost
[14:55:40,160] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33667.
[14:55:40,163] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:33667
[14:55:40,168] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 33667)
[14:55:40,178] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:33667 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 33667)
[14:55:40,185] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 33667)
[14:55:40,504] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:55:40,797] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:55:40,812] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:55:40,817] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:55:40,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:55:40,819] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:55:40,819] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:55:40,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:55:40,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:55:40,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:55:40,822] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:55:40,823] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:55:40,823] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:55:40,824] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:55:40,825] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:55:40,825] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:55:40,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:55:40,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:55:40,827] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:55:40,828] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:55:40,828] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:55:40,829] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:55:40,830] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:55:40,830] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:55:40,831] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:55:40,831] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:55:40,832] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:55:40,836] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:55:40,871] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:55:40,885] INFO  {MemoryStore} MemoryStore cleared
[14:55:40,887] INFO  {BlockManager} BlockManager stopped
[14:55:40,899] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:55:40,909] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:55:40,916] INFO  {SparkContext} Successfully stopped SparkContext
[14:55:40,917] INFO  {ShutdownHookManager} Shutdown hook called
[14:55:40,918] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-0253d45e-6e5e-400c-ad44-31f7af1a04de
[14:55:59,646] INFO  {SparkContext} Running Spark version 2.0.1
[14:56:00,294] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:56:00,626] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:56:00,628] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:56:00,848] INFO  {SecurityManager} Changing view acls to: victor
[14:56:00,855] INFO  {SecurityManager} Changing modify acls to: victor
[14:56:00,857] INFO  {SecurityManager} Changing view acls groups to: 
[14:56:00,859] INFO  {SecurityManager} Changing modify acls groups to: 
[14:56:00,861] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:56:01,844] INFO  {Utils} Successfully started service 'sparkDriver' on port 37561.
[14:56:01,889] INFO  {SparkEnv} Registering MapOutputTracker
[14:56:01,934] INFO  {SparkEnv} Registering BlockManagerMaster
[14:56:01,968] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-2ecb2da8-9a08-46c5-89c3-ca8ec8228ade
[14:56:02,007] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:56:02,118] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:56:02,321] INFO  {log} Logging initialized @4577ms
[14:56:02,613] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:56:02,652] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:56:02,652] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:56:02,653] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:56:02,653] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:56:02,653] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:56:02,653] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:56:02,654] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:56:02,654] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:56:02,654] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:56:02,654] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:56:02,654] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:56:02,655] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:56:02,655] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:56:02,655] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:56:02,655] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:56:02,655] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:56:02,656] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:56:02,656] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:56:02,656] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:56:02,656] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:56:02,663] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:56:02,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:56:02,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:56:02,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:56:02,672] INFO  {ServerConnector} Started ServerConnector@53a18b82{HTTP/1.1}{0.0.0.0:4040}
[14:56:02,672] INFO  {Server} Started @4931ms
[14:56:02,672] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:56:02,675] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:56:02,803] INFO  {Executor} Starting executor ID driver on host localhost
[14:56:02,827] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46355.
[14:56:02,828] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:46355
[14:56:02,829] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 46355)
[14:56:02,834] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:46355 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 46355)
[14:56:02,840] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 46355)
[14:56:02,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b6579e8{/metrics/json,null,AVAILABLE}
[14:56:03,184] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:56:03,191] INFO  {ServerConnector} Stopped ServerConnector@53a18b82{HTTP/1.1}{0.0.0.0:4040}
[14:56:03,196] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:56:03,197] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:56:03,197] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:56:03,197] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:56:03,197] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:56:03,198] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:56:03,198] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:56:03,198] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:56:03,198] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:56:03,199] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:56:03,199] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:56:03,199] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:56:03,199] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:56:03,200] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:56:03,200] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:56:03,200] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:56:03,200] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:56:03,201] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:56:03,201] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:56:03,201] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:56:03,201] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:56:03,202] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:56:03,202] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:56:03,202] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:56:03,204] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:56:03,215] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:56:03,220] INFO  {MemoryStore} MemoryStore cleared
[14:56:03,221] INFO  {BlockManager} BlockManager stopped
[14:56:03,228] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:56:03,233] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:56:03,248] INFO  {SparkContext} Successfully stopped SparkContext
[14:56:03,249] INFO  {ShutdownHookManager} Shutdown hook called
[14:56:03,249] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-1d296d69-bd3a-4d3c-a845-bcc3e4a67dd9
[14:56:22,222] INFO  {SparkContext} Running Spark version 2.0.1
[14:56:22,813] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:56:23,103] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:56:23,105] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:56:23,348] INFO  {SecurityManager} Changing view acls to: victor
[14:56:23,350] INFO  {SecurityManager} Changing modify acls to: victor
[14:56:23,352] INFO  {SecurityManager} Changing view acls groups to: 
[14:56:23,354] INFO  {SecurityManager} Changing modify acls groups to: 
[14:56:23,356] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:56:24,321] INFO  {Utils} Successfully started service 'sparkDriver' on port 33961.
[14:56:24,374] INFO  {SparkEnv} Registering MapOutputTracker
[14:56:24,418] INFO  {SparkEnv} Registering BlockManagerMaster
[14:56:24,456] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-f3913512-c238-4666-9c97-a6272ed69b41
[14:56:24,502] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:56:24,618] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:56:24,865] INFO  {log} Logging initialized @3845ms
[14:56:25,136] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:56:25,173] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:56:25,174] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:56:25,175] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:56:25,175] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:56:25,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:56:25,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:56:25,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:56:25,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:56:25,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:56:25,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:56:25,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:56:25,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:56:25,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:56:25,180] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:56:25,181] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:56:25,181] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:56:25,182] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:56:25,183] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:56:25,183] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:56:25,184] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:56:25,199] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:56:25,200] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:56:25,201] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:56:25,202] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:56:25,214] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:56:25,215] INFO  {Server} Started @4198ms
[14:56:25,215] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:56:25,220] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:56:25,457] INFO  {Executor} Starting executor ID driver on host localhost
[14:56:25,515] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35071.
[14:56:25,517] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:35071
[14:56:25,522] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 35071)
[14:56:25,530] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:35071 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 35071)
[14:56:25,537] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 35071)
[14:56:25,841] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[14:56:26,139] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:56:26,159] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[14:56:26,165] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:56:26,165] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:56:26,166] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:56:26,166] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:56:26,167] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:56:26,168] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:56:26,168] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:56:26,169] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:56:26,170] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:56:26,170] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:56:26,171] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:56:26,171] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:56:26,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:56:26,172] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:56:26,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:56:26,173] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:56:26,174] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:56:26,174] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:56:26,174] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:56:26,175] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:56:26,175] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:56:26,176] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:56:26,176] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:56:26,176] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:56:26,181] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:56:26,212] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:56:26,222] INFO  {MemoryStore} MemoryStore cleared
[14:56:26,223] INFO  {BlockManager} BlockManager stopped
[14:56:26,238] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:56:26,251] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:56:26,256] INFO  {SparkContext} Successfully stopped SparkContext
[14:56:26,257] INFO  {ShutdownHookManager} Shutdown hook called
[14:56:26,259] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-0d6888f0-a0ac-4c38-ae8d-ec0b9e8339c7
[14:56:38,637] INFO  {SparkContext} Running Spark version 2.0.1
[14:56:39,373] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[14:56:39,864] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[14:56:39,875] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[14:56:40,171] INFO  {SecurityManager} Changing view acls to: victor
[14:56:40,174] INFO  {SecurityManager} Changing modify acls to: victor
[14:56:40,185] INFO  {SecurityManager} Changing view acls groups to: 
[14:56:40,188] INFO  {SecurityManager} Changing modify acls groups to: 
[14:56:40,190] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[14:56:41,088] INFO  {Utils} Successfully started service 'sparkDriver' on port 38095.
[14:56:41,129] INFO  {SparkEnv} Registering MapOutputTracker
[14:56:41,173] INFO  {SparkEnv} Registering BlockManagerMaster
[14:56:41,205] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-0d48d049-77dc-4870-834f-ada13bca46c5
[14:56:41,250] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[14:56:41,386] INFO  {SparkEnv} Registering OutputCommitCoordinator
[14:56:41,661] INFO  {log} Logging initialized @5199ms
[14:56:42,011] INFO  {Server} jetty-9.2.z-SNAPSHOT
[14:56:42,087] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[14:56:42,088] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[14:56:42,089] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[14:56:42,089] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[14:56:42,090] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[14:56:42,091] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[14:56:42,092] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[14:56:42,092] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[14:56:42,092] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[14:56:42,093] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[14:56:42,093] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[14:56:42,094] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[14:56:42,095] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[14:56:42,095] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[14:56:42,096] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[14:56:42,096] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[14:56:42,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[14:56:42,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[14:56:42,098] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[14:56:42,098] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[14:56:42,114] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[14:56:42,115] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[14:56:42,118] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[14:56:42,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[14:56:42,146] INFO  {ServerConnector} Started ServerConnector@34172b75{HTTP/1.1}{0.0.0.0:4040}
[14:56:42,147] INFO  {Server} Started @5689ms
[14:56:42,147] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[14:56:42,156] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[14:56:42,412] INFO  {Executor} Starting executor ID driver on host localhost
[14:56:42,475] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45685.
[14:56:42,477] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:45685
[14:56:42,481] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 45685)
[14:56:42,490] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:45685 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 45685)
[14:56:42,505] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 45685)
[14:56:42,847] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b6579e8{/metrics/json,null,AVAILABLE}
[14:56:43,402] INFO  {SparkContext} Invoking stop() from shutdown hook
[14:56:43,415] INFO  {ServerConnector} Stopped ServerConnector@34172b75{HTTP/1.1}{0.0.0.0:4040}
[14:56:43,420] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[14:56:43,421] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[14:56:43,421] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[14:56:43,422] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[14:56:43,426] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[14:56:43,427] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[14:56:43,428] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[14:56:43,429] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[14:56:43,429] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[14:56:43,430] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[14:56:43,430] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[14:56:43,431] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[14:56:43,431] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[14:56:43,432] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[14:56:43,433] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[14:56:43,433] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[14:56:43,434] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[14:56:43,434] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[14:56:43,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[14:56:43,435] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[14:56:43,436] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[14:56:43,436] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[14:56:43,437] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[14:56:43,437] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[14:56:43,444] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[14:56:43,475] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[14:56:43,491] INFO  {MemoryStore} MemoryStore cleared
[14:56:43,493] INFO  {BlockManager} BlockManager stopped
[14:56:43,507] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[14:56:43,518] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[14:56:43,524] INFO  {SparkContext} Successfully stopped SparkContext
[14:56:43,525] INFO  {ShutdownHookManager} Shutdown hook called
[14:56:43,527] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-3d3834fa-69c4-4670-9619-46b5c7dcdd08
[15:13:39,810] INFO  {SparkContext} Running Spark version 2.0.1
[15:13:40,494] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:13:40,888] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[15:13:40,889] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:13:41,026] INFO  {SecurityManager} Changing view acls to: victor
[15:13:41,027] INFO  {SecurityManager} Changing modify acls to: victor
[15:13:41,028] INFO  {SecurityManager} Changing view acls groups to: 
[15:13:41,029] INFO  {SecurityManager} Changing modify acls groups to: 
[15:13:41,030] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:13:42,106] INFO  {Utils} Successfully started service 'sparkDriver' on port 37051.
[15:13:42,179] INFO  {SparkEnv} Registering MapOutputTracker
[15:13:42,229] INFO  {SparkEnv} Registering BlockManagerMaster
[15:13:42,270] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-2a020326-86cf-41a2-84ab-d381c782616a
[15:13:42,311] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:13:42,464] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:13:42,661] INFO  {log} Logging initialized @5126ms
[15:13:42,944] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:13:42,984] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:13:42,985] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:13:42,985] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:13:42,986] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:13:42,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:13:42,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:13:42,987] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:13:42,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:13:42,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:13:42,989] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:13:42,989] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:13:42,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:13:42,990] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:13:42,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:13:42,991] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:13:42,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:13:42,992] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:13:42,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:13:42,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:13:42,993] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:13:43,008] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:13:43,009] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:13:43,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:13:43,011] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:13:43,027] INFO  {ServerConnector} Started ServerConnector@12da0d85{HTTP/1.1}{0.0.0.0:4040}
[15:13:43,029] INFO  {Server} Started @5496ms
[15:13:43,030] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:13:43,036] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[15:13:43,291] INFO  {Executor} Starting executor ID driver on host localhost
[15:13:43,352] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39085.
[15:13:43,354] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:39085
[15:13:43,358] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 39085)
[15:13:43,366] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:39085 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 39085)
[15:13:43,377] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 39085)
[15:13:43,684] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4b6579e8{/metrics/json,null,AVAILABLE}
[15:13:45,284] INFO  {SparkContext} Starting job: collect at Main.scala:30
[15:13:45,374] INFO  {DAGScheduler} Got job 0 (collect at Main.scala:30) with 5 output partitions
[15:13:45,376] INFO  {DAGScheduler} Final stage: ResultStage 0 (collect at Main.scala:30)
[15:13:45,377] INFO  {DAGScheduler} Parents of final stage: List()
[15:13:45,382] INFO  {DAGScheduler} Missing parents: List()
[15:13:45,409] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:28), which has no missing parents
[15:13:45,716] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1128.9 MB)
[15:13:45,796] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1471.0 B, free 1128.9 MB)
[15:13:45,800] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:39085 (size: 1471.0 B, free: 1128.9 MB)
[15:13:45,805] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[15:13:45,814] INFO  {DAGScheduler} Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:28)
[15:13:45,818] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 5 tasks
[15:13:45,971] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[15:13:45,974] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169362 bytes)
[15:13:45,995] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:13:54,789] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:13:54,800] INFO  {ServerConnector} Stopped ServerConnector@12da0d85{HTTP/1.1}{0.0.0.0:4040}
[15:13:54,805] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:13:54,806] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:13:54,807] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:13:54,808] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:13:54,810] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:13:54,814] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:13:54,816] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:13:54,818] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:13:54,819] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:13:54,820] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:13:54,821] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:13:54,825] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:13:54,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:13:54,826] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:13:54,827] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:13:54,828] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:13:54,828] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:13:54,829] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:13:54,829] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:13:54,831] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:13:54,831] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:13:54,832] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:13:54,832] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:13:54,832] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:13:54,839] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[15:13:54,859] INFO  {DAGScheduler} Job 0 failed: collect at Main.scala:30, took 9.573653 s
[15:13:55,019] INFO  {DAGScheduler} ResultStage 0 (collect at Main.scala:30) failed in 9.016 s
[15:13:55,023] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@4ff5b8e0)
[15:13:55,030] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1511100835023,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down))
[15:13:55,061] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:13:55,075] INFO  {MemoryStore} MemoryStore cleared
[15:13:55,076] INFO  {BlockManager} BlockManager stopped
[15:13:55,087] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:13:55,095] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:13:55,100] INFO  {SparkContext} Successfully stopped SparkContext
[15:13:55,101] INFO  {ShutdownHookManager} Shutdown hook called
[15:13:55,103] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-9f113682-eea7-4494-965c-298fd7227071
[15:36:20,993] INFO  {SparkContext} Running Spark version 2.0.1
[15:36:22,053] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:36:22,385] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[15:36:22,386] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:36:22,587] INFO  {SecurityManager} Changing view acls to: victor
[15:36:22,588] INFO  {SecurityManager} Changing modify acls to: victor
[15:36:22,588] INFO  {SecurityManager} Changing view acls groups to: 
[15:36:22,589] INFO  {SecurityManager} Changing modify acls groups to: 
[15:36:22,589] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:36:23,172] INFO  {Utils} Successfully started service 'sparkDriver' on port 39709.
[15:36:23,281] INFO  {SparkEnv} Registering MapOutputTracker
[15:36:23,345] INFO  {SparkEnv} Registering BlockManagerMaster
[15:36:23,529] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-6be65b9b-d178-45d0-8b5b-3b2f7d6cfaa1
[15:36:23,632] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:36:23,713] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:36:23,968] INFO  {log} Logging initialized @4605ms
[15:36:24,162] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:36:24,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:36:24,180] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:36:24,180] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:36:24,180] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:36:24,180] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:36:24,181] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:36:24,181] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:36:24,181] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:36:24,181] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:36:24,182] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:36:24,182] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:36:24,182] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:36:24,182] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:36:24,182] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:36:24,183] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:36:24,183] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:36:24,183] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:36:24,183] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:36:24,183] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:36:24,183] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:36:24,189] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:36:24,189] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:36:24,189] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:36:24,190] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:36:24,195] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:36:24,196] INFO  {Server} Started @4834ms
[15:36:24,196] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:36:24,198] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[15:36:24,446] INFO  {Executor} Starting executor ID driver on host localhost
[15:36:24,500] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38847.
[15:36:24,501] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:38847
[15:36:24,512] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 38847)
[15:36:24,515] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:38847 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 38847)
[15:36:24,521] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 38847)
[15:36:24,692] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:36:25,786] INFO  {SparkContext} Starting job: collect at Main.scala:30
[15:36:25,865] INFO  {DAGScheduler} Got job 0 (collect at Main.scala:30) with 5 output partitions
[15:36:25,865] INFO  {DAGScheduler} Final stage: ResultStage 0 (collect at Main.scala:30)
[15:36:25,866] INFO  {DAGScheduler} Parents of final stage: List()
[15:36:25,878] INFO  {DAGScheduler} Missing parents: List()
[15:36:25,940] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:28), which has no missing parents
[15:36:26,415] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1128.9 MB)
[15:36:26,466] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1471.0 B, free 1128.9 MB)
[15:36:26,469] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:38847 (size: 1471.0 B, free: 1128.9 MB)
[15:36:26,471] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[15:36:26,477] INFO  {DAGScheduler} Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:28)
[15:36:26,479] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 5 tasks
[15:36:26,589] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[15:36:26,590] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169362 bytes)
[15:36:26,652] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:36:39,887] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:36:39,894] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:36:39,898] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:36:39,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:36:39,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:36:39,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:36:39,899] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:36:39,900] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:36:39,900] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:36:39,900] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:36:39,901] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:36:39,901] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:36:39,901] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:36:39,902] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:36:39,902] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:36:39,902] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:36:39,903] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:36:39,903] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:36:39,903] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:36:39,903] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:36:39,904] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:36:39,904] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:36:39,904] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:36:39,905] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:36:39,905] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:36:39,905] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:36:39,907] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[15:36:39,921] INFO  {DAGScheduler} Job 0 failed: collect at Main.scala:30, took 14.134446 s
[15:36:39,921] INFO  {DAGScheduler} ResultStage 0 (collect at Main.scala:30) failed in 13.418 s
[15:36:39,923] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@399fb61a)
[15:36:39,924] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1511102199923,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down))
[15:36:39,932] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:36:39,937] INFO  {MemoryStore} MemoryStore cleared
[15:36:39,938] INFO  {BlockManager} BlockManager stopped
[15:36:39,938] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:36:39,941] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:36:39,943] INFO  {SparkContext} Successfully stopped SparkContext
[15:36:39,943] INFO  {ShutdownHookManager} Shutdown hook called
[15:36:39,944] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-085c805d-142f-46bf-a1ee-884b149351e8
[15:46:14,908] INFO  {SparkContext} Running Spark version 2.0.1
[15:46:15,742] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:46:16,270] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[15:46:16,271] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:46:16,484] INFO  {SecurityManager} Changing view acls to: victor
[15:46:16,486] INFO  {SecurityManager} Changing modify acls to: victor
[15:46:16,488] INFO  {SecurityManager} Changing view acls groups to: 
[15:46:16,493] INFO  {SecurityManager} Changing modify acls groups to: 
[15:46:16,495] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:46:17,752] INFO  {Utils} Successfully started service 'sparkDriver' on port 46037.
[15:46:17,802] INFO  {SparkEnv} Registering MapOutputTracker
[15:46:17,852] INFO  {SparkEnv} Registering BlockManagerMaster
[15:46:17,885] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-7bd02299-0ba2-4f5e-81d1-26ef8dc2a286
[15:46:17,931] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:46:18,086] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:46:18,288] INFO  {log} Logging initialized @5385ms
[15:46:18,574] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:46:18,615] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:46:18,616] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:46:18,617] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:46:18,618] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:46:18,619] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:46:18,619] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:46:18,620] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:46:18,621] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:46:18,621] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:46:18,622] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:46:18,623] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:46:18,624] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:46:18,624] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:46:18,624] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:46:18,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:46:18,625] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:46:18,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:46:18,626] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:46:18,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:46:18,627] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:46:18,640] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:46:18,641] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:46:18,642] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:46:18,643] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:46:18,656] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:46:18,657] INFO  {Server} Started @5757ms
[15:46:18,658] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:46:18,662] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[15:46:18,916] INFO  {Executor} Starting executor ID driver on host localhost
[15:46:18,984] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46285.
[15:46:18,986] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:46285
[15:46:18,992] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 46285)
[15:46:19,002] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:46285 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 46285)
[15:46:19,013] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 46285)
[15:46:19,400] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:46:20,759] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:46:20,823] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:46:20,830] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:46:20,838] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:46:20,839] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:46:20,840] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:46:20,841] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:46:20,843] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:46:20,853] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:46:20,854] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:46:20,856] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:46:20,858] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:46:20,865] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:46:20,866] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:46:20,867] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:46:20,868] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:46:20,870] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:46:20,871] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:46:20,872] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:46:20,874] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:46:20,876] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:46:20,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:46:20,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:46:20,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:46:20,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:46:20,883] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:46:20,900] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[15:46:20,935] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:46:20,957] INFO  {MemoryStore} MemoryStore cleared
[15:46:20,958] INFO  {BlockManager} BlockManager stopped
[15:46:20,974] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:46:20,985] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:46:21,010] INFO  {SparkContext} Successfully stopped SparkContext
[15:46:21,012] INFO  {ShutdownHookManager} Shutdown hook called
[15:46:21,015] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-d8e716fb-8e53-4517-949a-3716fa4967fb
[15:46:52,096] INFO  {SparkContext} Running Spark version 2.0.1
[15:46:52,888] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:46:53,209] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[15:46:53,210] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:46:53,442] INFO  {SecurityManager} Changing view acls to: victor
[15:46:53,444] INFO  {SecurityManager} Changing modify acls to: victor
[15:46:53,446] INFO  {SecurityManager} Changing view acls groups to: 
[15:46:53,448] INFO  {SecurityManager} Changing modify acls groups to: 
[15:46:53,450] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:46:54,399] INFO  {Utils} Successfully started service 'sparkDriver' on port 40811.
[15:46:54,439] INFO  {SparkEnv} Registering MapOutputTracker
[15:46:54,480] INFO  {SparkEnv} Registering BlockManagerMaster
[15:46:54,512] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-1a6dd6d7-1f85-4676-b87d-db981347d179
[15:46:54,550] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:46:54,677] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:46:54,881] INFO  {log} Logging initialized @4934ms
[15:46:55,168] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:46:55,209] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:46:55,210] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:46:55,210] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:46:55,211] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:46:55,211] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:46:55,212] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:46:55,212] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:46:55,213] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:46:55,213] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:46:55,214] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:46:55,214] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:46:55,215] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:46:55,215] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:46:55,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:46:55,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:46:55,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:46:55,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:46:55,217] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:46:55,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:46:55,218] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:46:55,231] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:46:55,232] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:46:55,234] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:46:55,235] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:46:55,249] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:46:55,250] INFO  {Server} Started @5305ms
[15:46:55,250] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:46:55,256] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[15:46:55,497] INFO  {Executor} Starting executor ID driver on host localhost
[15:46:55,567] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40379.
[15:46:55,569] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:40379
[15:46:55,574] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 40379)
[15:46:55,582] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:40379 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 40379)
[15:46:55,593] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 40379)
[15:46:55,932] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:46:57,337] INFO  {SparkContext} Starting job: collect at Main.scala:40
[15:46:57,425] INFO  {DAGScheduler} Got job 0 (collect at Main.scala:40) with 5 output partitions
[15:46:57,426] INFO  {DAGScheduler} Final stage: ResultStage 0 (collect at Main.scala:40)
[15:46:57,427] INFO  {DAGScheduler} Parents of final stage: List()
[15:46:57,431] INFO  {DAGScheduler} Missing parents: List()
[15:46:57,460] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27), which has no missing parents
[15:46:57,828] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1128.9 MB)
[15:46:57,906] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1471.0 B, free 1128.9 MB)
[15:46:57,912] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:40379 (size: 1471.0 B, free: 1128.9 MB)
[15:46:57,918] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[15:46:57,927] INFO  {DAGScheduler} Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27)
[15:46:57,930] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 5 tasks
[15:46:58,095] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[15:46:58,098] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169362 bytes)
[15:46:58,116] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:46:58,522] ERROR {Executor} Exception in task 0.0 in stage 0.0 (TID 0)
ncsa.hdf.hdf5lib.exceptions.HDF5SymbolTableException: Symbol table:Object not found ["H5Gtraverse.c line 755 in H5G_traverse_real(): component not found"]
	at ch.systemsx.cisd.hdf5.hdf5lib.H5.H5Dopen(Native Method)
	at ch.systemsx.cisd.hdf5.hdf5lib.H5D.H5Dopen(H5D.java:78)
	at ch.systemsx.cisd.hdf5.HDF5.openDataSet(HDF5.java:717)
	at ch.systemsx.cisd.hdf5.HDF5CompoundInformationRetriever.getFullCompoundDataSetInformation(HDF5CompoundInformationRetriever.java:146)
	at ch.systemsx.cisd.hdf5.HDF5CompoundInformationRetriever.getDataSetType(HDF5CompoundInformationRetriever.java:483)
	at ch.systemsx.cisd.hdf5.HDF5CompoundInformationRetriever.getDataSetType(HDF5CompoundInformationRetriever.java:493)
	at ch.systemsx.cisd.hdf5.HDF5CompoundReader.read(HDF5CompoundReader.java:255)
	at se.kth.spark.lab1.task6.Main$$anonfun$3.apply(Main.scala:29)
	at se.kth.spark.lab1.task6.Main$$anonfun$3.apply(Main.scala:27)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$class.foreach(Iterator.scala:743)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1174)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:296)
	at scala.collection.AbstractIterator.to(Iterator.scala:1174)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:288)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1174)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:275)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1174)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1916)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1916)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[15:46:58,662] INFO  {TaskSetManager} Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 169388 bytes)
[15:46:58,667] INFO  {Executor} Running task 1.0 in stage 0.0 (TID 1)
[15:46:58,669] WARN  {TaskSetManager} Lost task 0.0 in stage 0.0 (TID 0, localhost): ncsa.hdf.hdf5lib.exceptions.HDF5SymbolTableException: Symbol table:Object not found ["H5Gtraverse.c line 755 in H5G_traverse_real(): component not found"]
	at ch.systemsx.cisd.hdf5.hdf5lib.H5.H5Dopen(Native Method)
	at ch.systemsx.cisd.hdf5.hdf5lib.H5D.H5Dopen(H5D.java:78)
	at ch.systemsx.cisd.hdf5.HDF5.openDataSet(HDF5.java:717)
	at ch.systemsx.cisd.hdf5.HDF5CompoundInformationRetriever.getFullCompoundDataSetInformation(HDF5CompoundInformationRetriever.java:146)
	at ch.systemsx.cisd.hdf5.HDF5CompoundInformationRetriever.getDataSetType(HDF5CompoundInformationRetriever.java:483)
	at ch.systemsx.cisd.hdf5.HDF5CompoundInformationRetriever.getDataSetType(HDF5CompoundInformationRetriever.java:493)
	at ch.systemsx.cisd.hdf5.HDF5CompoundReader.read(HDF5CompoundReader.java:255)
	at se.kth.spark.lab1.task6.Main$$anonfun$3.apply(Main.scala:29)
	at se.kth.spark.lab1.task6.Main$$anonfun$3.apply(Main.scala:27)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$class.foreach(Iterator.scala:743)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1174)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:296)
	at scala.collection.AbstractIterator.to(Iterator.scala:1174)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:288)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1174)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:275)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1174)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1916)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1916)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

[15:46:58,680] ERROR {TaskSetManager} Task 0 in stage 0.0 failed 1 times; aborting job
[15:46:58,718] INFO  {TaskSchedulerImpl} Cancelling stage 0
[15:46:58,724] INFO  {Executor} Executor is trying to kill task 1.0 in stage 0.0 (TID 1)
[15:46:58,725] INFO  {TaskSchedulerImpl} Stage 0 was cancelled
[15:46:58,726] INFO  {DAGScheduler} ResultStage 0 (collect at Main.scala:40) failed in 0.767 s
[15:46:58,729] INFO  {DAGScheduler} Job 0 failed: collect at Main.scala:40, took 1.390575 s
[15:46:58,745] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:46:58,764] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:46:58,772] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:46:58,774] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:46:58,774] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:46:58,775] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:46:58,776] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:46:58,777] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:46:58,777] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:46:58,778] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:46:58,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:46:58,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:46:58,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:46:58,781] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:46:58,782] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:46:58,783] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:46:58,783] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:46:58,784] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:46:58,784] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:46:58,785] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:46:58,786] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:46:58,787] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:46:58,787] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:46:58,788] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:46:58,788] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:46:58,789] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:46:58,795] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[15:46:58,821] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:46:58,831] INFO  {MemoryStore} MemoryStore cleared
[15:46:58,832] INFO  {BlockManager} BlockManager stopped
[15:46:59,008] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:46:59,043] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:46:59,091] INFO  {SparkContext} Successfully stopped SparkContext
[15:46:59,106] INFO  {ShutdownHookManager} Shutdown hook called
[15:46:59,113] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-0e7d5c64-05b8-4dfa-99ad-33e1778b59a4
[15:52:08,487] INFO  {SparkContext} Running Spark version 2.0.1
[15:52:10,120] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:52:10,621] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[15:52:10,622] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:52:10,772] INFO  {SecurityManager} Changing view acls to: victor
[15:52:10,782] INFO  {SecurityManager} Changing modify acls to: victor
[15:52:10,783] INFO  {SecurityManager} Changing view acls groups to: 
[15:52:10,784] INFO  {SecurityManager} Changing modify acls groups to: 
[15:52:10,784] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:52:11,743] INFO  {Utils} Successfully started service 'sparkDriver' on port 32799.
[15:52:11,827] INFO  {SparkEnv} Registering MapOutputTracker
[15:52:11,900] INFO  {SparkEnv} Registering BlockManagerMaster
[15:52:12,001] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-7ca95908-b0bd-48e7-8598-2f60b90a1c31
[15:52:12,040] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:52:12,109] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:52:12,428] INFO  {log} Logging initialized @9540ms
[15:52:12,927] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:52:13,000] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,AVAILABLE}
[15:52:13,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,AVAILABLE}
[15:52:13,001] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,AVAILABLE}
[15:52:13,002] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,AVAILABLE}
[15:52:13,002] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages,null,AVAILABLE}
[15:52:13,002] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/json,null,AVAILABLE}
[15:52:13,003] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,AVAILABLE}
[15:52:13,003] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,AVAILABLE}
[15:52:13,003] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,AVAILABLE}
[15:52:13,003] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,AVAILABLE}
[15:52:13,004] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,AVAILABLE}
[15:52:13,004] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,AVAILABLE}
[15:52:13,004] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,AVAILABLE}
[15:52:13,005] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,AVAILABLE}
[15:52:13,006] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/environment,null,AVAILABLE}
[15:52:13,006] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,AVAILABLE}
[15:52:13,006] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,AVAILABLE}
[15:52:13,007] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,AVAILABLE}
[15:52:13,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,AVAILABLE}
[15:52:13,011] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,AVAILABLE}
[15:52:13,068] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/static,null,AVAILABLE}
[15:52:13,069] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/,null,AVAILABLE}
[15:52:13,070] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/api,null,AVAILABLE}
[15:52:13,070] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,AVAILABLE}
[15:52:13,079] INFO  {ServerConnector} Started ServerConnector@42d7c37f{HTTP/1.1}{0.0.0.0:4040}
[15:52:13,079] INFO  {Server} Started @10194ms
[15:52:13,080] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:52:13,082] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[15:52:14,028] INFO  {Executor} Starting executor ID driver on host localhost
[15:52:14,077] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46301.
[15:52:14,078] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:46301
[15:52:14,079] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 46301)
[15:52:14,083] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:46301 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 46301)
[15:52:14,085] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 46301)
[15:52:15,262] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6c6357f9{/metrics/json,null,AVAILABLE}
[15:52:16,738] INFO  {SparkContext} Starting job: collect at Main.scala:42
[15:52:16,848] INFO  {DAGScheduler} Got job 0 (collect at Main.scala:42) with 5 output partitions
[15:52:16,848] INFO  {DAGScheduler} Final stage: ResultStage 0 (collect at Main.scala:42)
[15:52:16,848] INFO  {DAGScheduler} Parents of final stage: List()
[15:52:16,850] INFO  {DAGScheduler} Missing parents: List()
[15:52:16,859] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27), which has no missing parents
[15:52:17,174] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1128.9 MB)
[15:52:17,230] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1471.0 B, free 1128.9 MB)
[15:52:17,234] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:46301 (size: 1471.0 B, free: 1128.9 MB)
[15:52:17,274] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[15:52:17,285] INFO  {DAGScheduler} Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27)
[15:52:17,287] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 5 tasks
[15:52:17,407] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[15:52:17,408] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169388 bytes)
[15:52:17,417] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:52:25,756] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:52:25,912] INFO  {ServerConnector} Stopped ServerConnector@42d7c37f{HTTP/1.1}{0.0.0.0:4040}
[15:52:25,914] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/stages/stage/kill,null,UNAVAILABLE}
[15:52:25,915] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/api,null,UNAVAILABLE}
[15:52:25,915] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/,null,UNAVAILABLE}
[15:52:25,916] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/static,null,UNAVAILABLE}
[15:52:25,916] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/executors/threadDump/json,null,UNAVAILABLE}
[15:52:25,916] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/executors/threadDump,null,UNAVAILABLE}
[15:52:25,917] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/json,null,UNAVAILABLE}
[15:52:25,917] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors,null,UNAVAILABLE}
[15:52:25,917] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/environment/json,null,UNAVAILABLE}
[15:52:25,918] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/environment,null,UNAVAILABLE}
[15:52:25,918] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/storage/rdd/json,null,UNAVAILABLE}
[15:52:25,918] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/storage/rdd,null,UNAVAILABLE}
[15:52:25,919] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/json,null,UNAVAILABLE}
[15:52:25,919] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage,null,UNAVAILABLE}
[15:52:25,919] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages/pool/json,null,UNAVAILABLE}
[15:52:25,920] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/stages/pool,null,UNAVAILABLE}
[15:52:25,920] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/stage/json,null,UNAVAILABLE}
[15:52:25,920] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/stage,null,UNAVAILABLE}
[15:52:25,920] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/json,null,UNAVAILABLE}
[15:52:25,921] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages,null,UNAVAILABLE}
[15:52:25,921] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/jobs/job/json,null,UNAVAILABLE}
[15:52:25,921] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/jobs/job,null,UNAVAILABLE}
[15:52:25,921] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/json,null,UNAVAILABLE}
[15:52:25,922] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs,null,UNAVAILABLE}
[15:52:25,923] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[15:52:25,931] INFO  {DAGScheduler} Job 0 failed: collect at Main.scala:42, took 9.193202 s
[15:52:25,932] INFO  {DAGScheduler} ResultStage 0 (collect at Main.scala:42) failed in 8.633 s
[15:52:25,953] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@2a262fbb)
[15:52:25,954] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1511103145954,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down))
[15:52:25,964] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:52:26,009] INFO  {MemoryStore} MemoryStore cleared
[15:52:26,010] INFO  {BlockManager} BlockManager stopped
[15:52:26,481] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:52:26,503] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:52:26,516] INFO  {SparkContext} Successfully stopped SparkContext
[15:52:26,518] INFO  {ShutdownHookManager} Shutdown hook called
[15:52:26,521] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-35c84fd9-df84-4960-8914-2d37c150300a
[15:52:57,014] INFO  {SparkContext} Running Spark version 2.0.1
[15:52:57,596] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:52:57,941] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[15:52:57,943] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:52:58,175] INFO  {SecurityManager} Changing view acls to: victor
[15:52:58,176] INFO  {SecurityManager} Changing modify acls to: victor
[15:52:58,178] INFO  {SecurityManager} Changing view acls groups to: 
[15:52:58,182] INFO  {SecurityManager} Changing modify acls groups to: 
[15:52:58,184] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:52:59,110] INFO  {Utils} Successfully started service 'sparkDriver' on port 38087.
[15:52:59,159] INFO  {SparkEnv} Registering MapOutputTracker
[15:52:59,204] INFO  {SparkEnv} Registering BlockManagerMaster
[15:52:59,262] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-5341fd17-4351-431c-bc59-6b7ac66ffcdf
[15:52:59,304] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:52:59,424] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:52:59,615] INFO  {log} Logging initialized @4419ms
[15:52:59,929] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:52:59,966] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:52:59,966] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:52:59,967] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:52:59,967] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:52:59,968] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:52:59,968] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:52:59,969] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:52:59,969] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:52:59,970] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:52:59,970] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:52:59,971] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:52:59,971] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:52:59,972] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:52:59,973] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:52:59,974] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:52:59,975] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:52:59,975] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:52:59,976] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:52:59,977] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:52:59,977] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:52:59,996] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:52:59,996] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:52:59,997] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:52:59,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:53:00,012] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:53:00,012] INFO  {Server} Started @4819ms
[15:53:00,012] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:53:00,017] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[15:53:00,259] INFO  {Executor} Starting executor ID driver on host localhost
[15:53:00,333] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43803.
[15:53:00,335] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:43803
[15:53:00,339] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 43803)
[15:53:00,345] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:43803 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 43803)
[15:53:00,358] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 43803)
[15:53:00,541] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:53:01,129] INFO  {SparkContext} Starting job: collect at Main.scala:44
[15:53:01,176] INFO  {DAGScheduler} Got job 0 (collect at Main.scala:44) with 5 output partitions
[15:53:01,177] INFO  {DAGScheduler} Final stage: ResultStage 0 (collect at Main.scala:44)
[15:53:01,178] INFO  {DAGScheduler} Parents of final stage: List()
[15:53:01,179] INFO  {DAGScheduler} Missing parents: List()
[15:53:01,191] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27), which has no missing parents
[15:53:01,321] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1128.9 MB)
[15:53:01,354] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1471.0 B, free 1128.9 MB)
[15:53:01,357] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:43803 (size: 1471.0 B, free: 1128.9 MB)
[15:53:01,360] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[15:53:01,367] INFO  {DAGScheduler} Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27)
[15:53:01,370] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 5 tasks
[15:53:01,471] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[15:53:01,472] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169388 bytes)
[15:53:01,479] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:53:05,279] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:53:05,287] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:53:05,294] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:53:05,295] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:53:05,295] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:53:05,295] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:53:05,296] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:53:05,296] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:53:05,296] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:53:05,296] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:53:05,297] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:53:05,297] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:53:05,297] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:53:05,297] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:53:05,298] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:53:05,298] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:53:05,298] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:53:05,299] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:53:05,299] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:53:05,299] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:53:05,302] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:53:05,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:53:05,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:53:05,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:53:05,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:53:05,303] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:53:05,306] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[15:53:05,313] INFO  {DAGScheduler} Job 0 failed: collect at Main.scala:44, took 4.182722 s
[15:53:05,313] INFO  {DAGScheduler} ResultStage 0 (collect at Main.scala:44) failed in 3.929 s
[15:53:05,314] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@7b208a2b)
[15:53:05,315] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1511103185315,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down))
[15:53:05,320] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:53:05,326] INFO  {MemoryStore} MemoryStore cleared
[15:53:05,327] INFO  {BlockManager} BlockManager stopped
[15:53:05,339] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:53:05,344] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:53:05,346] INFO  {SparkContext} Successfully stopped SparkContext
[15:53:05,347] INFO  {ShutdownHookManager} Shutdown hook called
[15:53:05,348] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-6524004b-4f0b-45a2-935b-0240ce63ffce
[15:53:56,765] INFO  {SparkContext} Running Spark version 2.0.1
[15:53:57,439] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:53:57,839] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[15:53:57,840] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:53:58,085] INFO  {SecurityManager} Changing view acls to: victor
[15:53:58,093] INFO  {SecurityManager} Changing modify acls to: victor
[15:53:58,102] INFO  {SecurityManager} Changing view acls groups to: 
[15:53:58,107] INFO  {SecurityManager} Changing modify acls groups to: 
[15:53:58,109] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:53:59,255] INFO  {Utils} Successfully started service 'sparkDriver' on port 46169.
[15:53:59,300] INFO  {SparkEnv} Registering MapOutputTracker
[15:53:59,345] INFO  {SparkEnv} Registering BlockManagerMaster
[15:53:59,379] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-5f481dc4-c20f-4588-ba96-cf43cd8eac29
[15:53:59,423] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:53:59,558] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:53:59,767] INFO  {log} Logging initialized @4855ms
[15:54:00,084] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:54:00,133] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:54:00,134] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:54:00,135] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:54:00,135] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:54:00,136] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:54:00,136] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:54:00,137] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:54:00,137] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:54:00,138] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:54:00,139] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:54:00,139] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:54:00,140] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:54:00,140] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:54:00,141] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:54:00,142] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:54:00,142] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:54:00,143] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:54:00,143] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:54:00,144] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:54:00,144] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:54:00,160] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:54:00,160] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:54:00,162] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:54:00,163] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:54:00,186] INFO  {ServerConnector} Started ServerConnector@4183705{HTTP/1.1}{0.0.0.0:4040}
[15:54:00,187] INFO  {Server} Started @5278ms
[15:54:00,188] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:54:00,195] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[15:54:00,432] INFO  {Executor} Starting executor ID driver on host localhost
[15:54:00,496] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38995.
[15:54:00,498] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:38995
[15:54:00,503] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 38995)
[15:54:00,512] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:38995 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 38995)
[15:54:00,522] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 38995)
[15:54:00,852] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:54:01,460] INFO  {SparkContext} Starting job: collect at Main.scala:45
[15:54:01,516] INFO  {DAGScheduler} Got job 0 (collect at Main.scala:45) with 5 output partitions
[15:54:01,517] INFO  {DAGScheduler} Final stage: ResultStage 0 (collect at Main.scala:45)
[15:54:01,517] INFO  {DAGScheduler} Parents of final stage: List()
[15:54:01,519] INFO  {DAGScheduler} Missing parents: List()
[15:54:01,530] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27), which has no missing parents
[15:54:01,665] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1128.9 MB)
[15:54:01,698] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1471.0 B, free 1128.9 MB)
[15:54:01,702] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:38995 (size: 1471.0 B, free: 1128.9 MB)
[15:54:01,707] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[15:54:01,711] INFO  {DAGScheduler} Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27)
[15:54:01,713] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 5 tasks
[15:54:01,782] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[15:54:01,783] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169388 bytes)
[15:54:01,791] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:54:06,143] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:54:06,149] INFO  {ServerConnector} Stopped ServerConnector@4183705{HTTP/1.1}{0.0.0.0:4040}
[15:54:06,151] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:54:06,151] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:54:06,151] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:54:06,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:54:06,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:54:06,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:54:06,152] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:54:06,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:54:06,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:54:06,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:54:06,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:54:06,153] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:54:06,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:54:06,154] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:54:06,155] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:54:06,156] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:54:06,156] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:54:06,156] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:54:06,157] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:54:06,158] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:54:06,158] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:54:06,158] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:54:06,158] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:54:06,158] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:54:06,160] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[15:54:06,167] INFO  {DAGScheduler} Job 0 failed: collect at Main.scala:45, took 4.706017 s
[15:54:06,168] INFO  {DAGScheduler} ResultStage 0 (collect at Main.scala:45) failed in 4.443 s
[15:54:06,169] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@647bd3bb)
[15:54:06,170] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1511103246169,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down))
[15:54:06,235] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:54:06,245] INFO  {MemoryStore} MemoryStore cleared
[15:54:06,246] INFO  {BlockManager} BlockManager stopped
[15:54:06,251] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:54:06,253] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:54:06,257] INFO  {SparkContext} Successfully stopped SparkContext
[15:54:06,258] INFO  {ShutdownHookManager} Shutdown hook called
[15:54:06,259] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-fb376469-cdb5-4f98-b953-4b5d31a86a5d
[15:55:00,144] INFO  {SparkContext} Running Spark version 2.0.1
[15:55:00,402] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:55:00,573] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[15:55:00,574] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:55:00,701] INFO  {SecurityManager} Changing view acls to: victor
[15:55:00,704] INFO  {SecurityManager} Changing modify acls to: victor
[15:55:00,705] INFO  {SecurityManager} Changing view acls groups to: 
[15:55:00,707] INFO  {SecurityManager} Changing modify acls groups to: 
[15:55:00,709] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:55:01,172] INFO  {Utils} Successfully started service 'sparkDriver' on port 37589.
[15:55:01,190] INFO  {SparkEnv} Registering MapOutputTracker
[15:55:01,213] INFO  {SparkEnv} Registering BlockManagerMaster
[15:55:01,227] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e42de4cd-e5b6-4e00-b901-278be7ae420e
[15:55:01,245] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:55:01,299] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:55:01,396] INFO  {log} Logging initialized @2079ms
[15:55:01,520] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:55:01,542] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:55:01,542] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:55:01,542] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:55:01,542] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:55:01,543] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:55:01,543] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:55:01,543] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:55:01,543] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:55:01,544] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:55:01,544] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:55:01,544] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:55:01,545] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:55:01,545] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:55:01,545] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:55:01,545] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:55:01,545] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:55:01,545] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:55:01,546] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:55:01,546] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:55:01,546] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:55:01,551] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:55:01,552] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:55:01,552] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:55:01,553] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:55:01,558] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:55:01,559] INFO  {Server} Started @2243ms
[15:55:01,559] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:55:01,561] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[15:55:01,677] INFO  {Executor} Starting executor ID driver on host localhost
[15:55:01,708] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41079.
[15:55:01,709] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:41079
[15:55:01,711] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 41079)
[15:55:01,715] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:41079 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 41079)
[15:55:01,720] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 41079)
[15:55:01,865] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:55:02,364] INFO  {SparkContext} Starting job: collect at Main.scala:46
[15:55:02,405] INFO  {DAGScheduler} Got job 0 (collect at Main.scala:46) with 5 output partitions
[15:55:02,406] INFO  {DAGScheduler} Final stage: ResultStage 0 (collect at Main.scala:46)
[15:55:02,407] INFO  {DAGScheduler} Parents of final stage: List()
[15:55:02,414] INFO  {DAGScheduler} Missing parents: List()
[15:55:02,427] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27), which has no missing parents
[15:55:02,563] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1128.9 MB)
[15:55:02,602] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1471.0 B, free 1128.9 MB)
[15:55:02,605] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:41079 (size: 1471.0 B, free: 1128.9 MB)
[15:55:02,609] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[15:55:02,613] INFO  {DAGScheduler} Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27)
[15:55:02,615] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 5 tasks
[15:55:02,728] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[15:55:02,731] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169388 bytes)
[15:55:02,753] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:55:05,935] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:55:05,963] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:55:05,974] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:55:05,974] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:55:05,975] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:55:05,975] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:55:05,976] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:55:05,976] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:55:05,976] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:55:05,976] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:55:05,977] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:55:05,977] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:55:05,977] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:55:05,978] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:55:05,978] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:55:05,978] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:55:05,978] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:55:05,979] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:55:05,979] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:55:05,979] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:55:05,979] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:55:05,980] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:55:05,980] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:55:05,980] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:55:05,980] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:55:05,981] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:55:05,984] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[15:55:05,999] INFO  {DAGScheduler} Job 0 failed: collect at Main.scala:46, took 3.633516 s
[15:55:06,004] INFO  {DAGScheduler} ResultStage 0 (collect at Main.scala:46) failed in 3.369 s
[15:55:06,016] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@4cf77c8e)
[15:55:06,019] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1511103306017,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down))
[15:55:06,045] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:55:06,059] INFO  {MemoryStore} MemoryStore cleared
[15:55:06,060] INFO  {BlockManager} BlockManager stopped
[15:55:06,081] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:55:06,092] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:55:06,115] INFO  {SparkContext} Successfully stopped SparkContext
[15:55:06,116] INFO  {ShutdownHookManager} Shutdown hook called
[15:55:06,120] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-050d5de5-2b20-4fc7-8e89-f27f40cf7e89
[15:57:03,063] INFO  {SparkContext} Running Spark version 2.0.1
[15:57:03,685] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[15:57:04,095] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[15:57:04,097] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[15:57:04,372] INFO  {SecurityManager} Changing view acls to: victor
[15:57:04,374] INFO  {SecurityManager} Changing modify acls to: victor
[15:57:04,377] INFO  {SecurityManager} Changing view acls groups to: 
[15:57:04,379] INFO  {SecurityManager} Changing modify acls groups to: 
[15:57:04,381] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[15:57:05,324] INFO  {Utils} Successfully started service 'sparkDriver' on port 34121.
[15:57:05,345] INFO  {SparkEnv} Registering MapOutputTracker
[15:57:05,363] INFO  {SparkEnv} Registering BlockManagerMaster
[15:57:05,379] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-98a32ce9-02f1-4a38-9eca-f5f6e0cb3ca3
[15:57:05,395] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[15:57:05,441] INFO  {SparkEnv} Registering OutputCommitCoordinator
[15:57:05,525] INFO  {log} Logging initialized @3859ms
[15:57:05,647] INFO  {Server} jetty-9.2.z-SNAPSHOT
[15:57:05,663] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[15:57:05,663] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[15:57:05,663] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[15:57:05,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[15:57:05,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[15:57:05,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[15:57:05,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[15:57:05,664] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[15:57:05,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[15:57:05,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[15:57:05,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[15:57:05,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[15:57:05,665] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[15:57:05,666] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[15:57:05,666] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[15:57:05,666] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[15:57:05,666] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[15:57:05,666] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[15:57:05,666] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[15:57:05,667] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[15:57:05,671] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[15:57:05,672] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[15:57:05,672] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[15:57:05,672] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[15:57:05,677] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:57:05,677] INFO  {Server} Started @4013ms
[15:57:05,678] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[15:57:05,679] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[15:57:05,781] INFO  {Executor} Starting executor ID driver on host localhost
[15:57:05,803] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39835.
[15:57:05,804] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:39835
[15:57:05,806] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 39835)
[15:57:05,809] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:39835 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 39835)
[15:57:05,813] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 39835)
[15:57:05,966] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[15:57:06,537] INFO  {SparkContext} Starting job: collect at Main.scala:49
[15:57:06,581] INFO  {DAGScheduler} Got job 0 (collect at Main.scala:49) with 5 output partitions
[15:57:06,581] INFO  {DAGScheduler} Final stage: ResultStage 0 (collect at Main.scala:49)
[15:57:06,582] INFO  {DAGScheduler} Parents of final stage: List()
[15:57:06,583] INFO  {DAGScheduler} Missing parents: List()
[15:57:06,592] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27), which has no missing parents
[15:57:06,729] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1128.9 MB)
[15:57:06,772] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1471.0 B, free 1128.9 MB)
[15:57:06,774] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:39835 (size: 1471.0 B, free: 1128.9 MB)
[15:57:06,777] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[15:57:06,783] INFO  {DAGScheduler} Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27)
[15:57:06,785] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 5 tasks
[15:57:06,866] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[15:57:06,867] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169388 bytes)
[15:57:06,876] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[15:57:10,922] INFO  {SparkContext} Invoking stop() from shutdown hook
[15:57:10,929] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[15:57:10,933] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[15:57:10,933] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[15:57:10,934] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[15:57:10,934] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[15:57:10,934] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[15:57:10,935] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[15:57:10,935] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[15:57:10,935] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[15:57:10,935] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[15:57:10,935] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[15:57:10,935] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[15:57:10,936] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[15:57:10,936] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[15:57:10,936] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[15:57:10,936] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[15:57:10,936] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[15:57:10,937] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[15:57:10,937] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[15:57:10,937] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[15:57:10,937] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[15:57:10,937] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[15:57:10,937] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[15:57:10,938] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[15:57:10,938] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[15:57:10,940] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[15:57:10,949] INFO  {DAGScheduler} Job 0 failed: collect at Main.scala:49, took 4.411327 s
[15:57:10,950] INFO  {DAGScheduler} ResultStage 0 (collect at Main.scala:49) failed in 4.153 s
[15:57:10,952] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@1caa11fa)
[15:57:10,953] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1511103430952,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down))
[15:57:11,011] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[15:57:11,015] INFO  {MemoryStore} MemoryStore cleared
[15:57:11,015] INFO  {BlockManager} BlockManager stopped
[15:57:11,020] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[15:57:11,021] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[15:57:11,023] INFO  {SparkContext} Successfully stopped SparkContext
[15:57:11,023] INFO  {ShutdownHookManager} Shutdown hook called
[15:57:11,024] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-9180535f-252a-4880-ba7a-a9a83f8c0e8f
[16:03:52,312] INFO  {SparkContext} Running Spark version 2.0.1
[16:03:52,610] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:03:52,830] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:03:52,831] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:03:52,892] INFO  {SecurityManager} Changing view acls to: victor
[16:03:52,892] INFO  {SecurityManager} Changing modify acls to: victor
[16:03:52,893] INFO  {SecurityManager} Changing view acls groups to: 
[16:03:52,893] INFO  {SecurityManager} Changing modify acls groups to: 
[16:03:52,894] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:03:53,279] INFO  {Utils} Successfully started service 'sparkDriver' on port 36445.
[16:03:53,310] INFO  {SparkEnv} Registering MapOutputTracker
[16:03:53,337] INFO  {SparkEnv} Registering BlockManagerMaster
[16:03:53,355] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-03e8d86a-cc1d-43dc-a0b6-f9fe871079d5
[16:03:53,376] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:03:53,451] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:03:53,564] INFO  {log} Logging initialized @2107ms
[16:03:53,699] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:03:53,722] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[16:03:53,722] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[16:03:53,722] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[16:03:53,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[16:03:53,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[16:03:53,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[16:03:53,723] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[16:03:53,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[16:03:53,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[16:03:53,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[16:03:53,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[16:03:53,724] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[16:03:53,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[16:03:53,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[16:03:53,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[16:03:53,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[16:03:53,725] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[16:03:53,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[16:03:53,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[16:03:53,726] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[16:03:53,733] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[16:03:53,733] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[16:03:53,734] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[16:03:53,734] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[16:03:53,739] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:03:53,740] INFO  {Server} Started @2283ms
[16:03:53,740] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:03:53,741] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:03:53,840] INFO  {Executor} Starting executor ID driver on host localhost
[16:03:53,869] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41921.
[16:03:53,870] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:41921
[16:03:53,873] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 41921)
[16:03:53,878] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:41921 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 41921)
[16:03:53,885] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 41921)
[16:03:54,036] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[16:03:54,806] INFO  {SparkContext} Starting job: collect at Main.scala:87
[16:03:54,846] INFO  {DAGScheduler} Got job 0 (collect at Main.scala:87) with 5 output partitions
[16:03:54,846] INFO  {DAGScheduler} Final stage: ResultStage 0 (collect at Main.scala:87)
[16:03:54,847] INFO  {DAGScheduler} Parents of final stage: List()
[16:03:54,849] INFO  {DAGScheduler} Missing parents: List()
[16:03:54,860] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27), which has no missing parents
[16:03:54,983] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1128.9 MB)
[16:03:55,025] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1471.0 B, free 1128.9 MB)
[16:03:55,027] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:41921 (size: 1471.0 B, free: 1128.9 MB)
[16:03:55,030] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:03:55,037] INFO  {DAGScheduler} Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27)
[16:03:55,041] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 5 tasks
[16:03:55,168] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:03:55,171] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169388 bytes)
[16:03:55,184] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:03:58,330] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:03:58,336] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:03:58,339] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[16:03:58,339] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[16:03:58,339] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[16:03:58,339] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[16:03:58,340] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[16:03:58,340] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[16:03:58,340] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[16:03:58,340] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[16:03:58,340] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[16:03:58,341] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[16:03:58,341] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[16:03:58,341] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[16:03:58,341] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[16:03:58,341] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[16:03:58,341] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[16:03:58,342] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[16:03:58,342] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[16:03:58,342] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[16:03:58,342] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[16:03:58,343] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[16:03:58,343] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[16:03:58,343] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[16:03:58,343] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[16:03:58,343] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[16:03:58,348] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:03:58,361] INFO  {DAGScheduler} Job 0 failed: collect at Main.scala:87, took 3.555068 s
[16:03:58,362] INFO  {DAGScheduler} ResultStage 0 (collect at Main.scala:87) failed in 3.305 s
[16:03:58,365] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@70270982)
[16:03:58,367] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1511103838365,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down))
[16:03:58,372] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:03:58,380] INFO  {MemoryStore} MemoryStore cleared
[16:03:58,381] INFO  {BlockManager} BlockManager stopped
[16:03:58,390] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:03:58,394] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:03:58,396] INFO  {SparkContext} Successfully stopped SparkContext
[16:03:58,396] INFO  {ShutdownHookManager} Shutdown hook called
[16:03:58,397] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-4e1aaea7-55fb-48b7-858e-71f5f944f142
[16:05:27,629] INFO  {SparkContext} Running Spark version 2.0.1
[16:05:27,929] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:05:28,148] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:05:28,149] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:05:28,214] INFO  {SecurityManager} Changing view acls to: victor
[16:05:28,216] INFO  {SecurityManager} Changing modify acls to: victor
[16:05:28,217] INFO  {SecurityManager} Changing view acls groups to: 
[16:05:28,218] INFO  {SecurityManager} Changing modify acls groups to: 
[16:05:28,219] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:05:28,556] INFO  {Utils} Successfully started service 'sparkDriver' on port 46341.
[16:05:28,586] INFO  {SparkEnv} Registering MapOutputTracker
[16:05:28,609] INFO  {SparkEnv} Registering BlockManagerMaster
[16:05:28,632] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-26e155c7-e218-4ac7-896d-fd375ad33b79
[16:05:28,655] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:05:28,807] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:05:28,934] INFO  {log} Logging initialized @2161ms
[16:05:29,082] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:05:29,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[16:05:29,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[16:05:29,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[16:05:29,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[16:05:29,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[16:05:29,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[16:05:29,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[16:05:29,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[16:05:29,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[16:05:29,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[16:05:29,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[16:05:29,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[16:05:29,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[16:05:29,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[16:05:29,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[16:05:29,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[16:05:29,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[16:05:29,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[16:05:29,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[16:05:29,109] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[16:05:29,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[16:05:29,116] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[16:05:29,118] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[16:05:29,119] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[16:05:29,128] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:05:29,128] INFO  {Server} Started @2358ms
[16:05:29,129] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:05:29,134] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:05:29,278] INFO  {Executor} Starting executor ID driver on host localhost
[16:05:29,309] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45885.
[16:05:29,310] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:45885
[16:05:29,314] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 45885)
[16:05:29,320] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:45885 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 45885)
[16:05:29,327] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 45885)
[16:05:29,483] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[16:05:30,081] INFO  {SparkContext} Starting job: collect at Main.scala:84
[16:05:30,127] INFO  {DAGScheduler} Got job 0 (collect at Main.scala:84) with 5 output partitions
[16:05:30,128] INFO  {DAGScheduler} Final stage: ResultStage 0 (collect at Main.scala:84)
[16:05:30,128] INFO  {DAGScheduler} Parents of final stage: List()
[16:05:30,133] INFO  {DAGScheduler} Missing parents: List()
[16:05:30,144] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27), which has no missing parents
[16:05:30,298] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1128.9 MB)
[16:05:30,349] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1471.0 B, free 1128.9 MB)
[16:05:30,352] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:45885 (size: 1471.0 B, free: 1128.9 MB)
[16:05:30,355] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:05:30,358] INFO  {DAGScheduler} Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27)
[16:05:30,360] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 5 tasks
[16:05:30,428] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:05:30,430] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169388 bytes)
[16:05:30,436] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:05:33,138] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:05:33,143] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:05:33,144] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[16:05:33,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[16:05:33,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[16:05:33,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[16:05:33,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[16:05:33,145] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[16:05:33,146] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[16:05:33,146] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[16:05:33,146] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[16:05:33,146] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[16:05:33,146] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[16:05:33,146] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[16:05:33,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[16:05:33,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[16:05:33,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[16:05:33,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[16:05:33,147] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[16:05:33,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[16:05:33,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[16:05:33,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[16:05:33,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[16:05:33,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[16:05:33,148] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[16:05:33,149] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[16:05:33,151] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:05:33,161] INFO  {DAGScheduler} Job 0 failed: collect at Main.scala:84, took 3.078632 s
[16:05:33,162] INFO  {DAGScheduler} ResultStage 0 (collect at Main.scala:84) failed in 2.789 s
[16:05:33,165] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@28ede80f)
[16:05:33,167] ERROR {LiveListenerBus} SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1511103933166,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down))
[16:05:33,182] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:05:33,202] INFO  {MemoryStore} MemoryStore cleared
[16:05:33,205] INFO  {BlockManager} BlockManager stopped
[16:05:33,217] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:05:33,225] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:05:33,242] INFO  {SparkContext} Successfully stopped SparkContext
[16:05:33,242] INFO  {ShutdownHookManager} Shutdown hook called
[16:05:33,243] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-304dbb0e-e645-4166-abf4-e417cbaa72f5
[16:20:34,591] INFO  {SparkContext} Running Spark version 2.0.1
[16:20:35,283] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:20:35,692] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:20:35,694] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:20:35,886] INFO  {SecurityManager} Changing view acls to: victor
[16:20:35,888] INFO  {SecurityManager} Changing modify acls to: victor
[16:20:35,890] INFO  {SecurityManager} Changing view acls groups to: 
[16:20:35,892] INFO  {SecurityManager} Changing modify acls groups to: 
[16:20:35,894] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:20:36,767] INFO  {Utils} Successfully started service 'sparkDriver' on port 44225.
[16:20:36,810] INFO  {SparkEnv} Registering MapOutputTracker
[16:20:36,854] INFO  {SparkEnv} Registering BlockManagerMaster
[16:20:36,884] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-c7458c4b-625d-413f-b757-a09406be8946
[16:20:36,933] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:20:37,060] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:20:37,252] INFO  {log} Logging initialized @4625ms
[16:20:37,534] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:20:37,574] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[16:20:37,575] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[16:20:37,575] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[16:20:37,576] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[16:20:37,576] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[16:20:37,577] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[16:20:37,577] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[16:20:37,578] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[16:20:37,578] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[16:20:37,579] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[16:20:37,579] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[16:20:37,580] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[16:20:37,580] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[16:20:37,580] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[16:20:37,581] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[16:20:37,581] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[16:20:37,582] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[16:20:37,582] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[16:20:37,583] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[16:20:37,583] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[16:20:37,595] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[16:20:37,596] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[16:20:37,597] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[16:20:37,598] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[16:20:37,613] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:20:37,613] INFO  {Server} Started @4992ms
[16:20:37,613] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:20:37,617] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:20:37,787] INFO  {Executor} Starting executor ID driver on host localhost
[16:20:37,820] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41865.
[16:20:37,822] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:41865
[16:20:37,826] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 41865)
[16:20:37,833] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:41865 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 41865)
[16:20:37,840] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 41865)
[16:20:37,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[16:20:38,615] INFO  {SparkContext} Starting job: take at Main.scala:48
[16:20:38,677] INFO  {DAGScheduler} Got job 0 (take at Main.scala:48) with 1 output partitions
[16:20:38,678] INFO  {DAGScheduler} Final stage: ResultStage 0 (take at Main.scala:48)
[16:20:38,679] INFO  {DAGScheduler} Parents of final stage: List()
[16:20:38,682] INFO  {DAGScheduler} Missing parents: List()
[16:20:38,697] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27), which has no missing parents
[16:20:38,837] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 1128.9 MB)
[16:20:38,873] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1463.0 B, free 1128.9 MB)
[16:20:38,876] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:41865 (size: 1463.0 B, free: 1128.9 MB)
[16:20:38,879] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:20:38,885] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27)
[16:20:38,888] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:20:38,955] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:20:38,956] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169385 bytes)
[16:20:38,965] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:20:39,277] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 1582 bytes result sent to driver
[16:20:39,285] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 374 ms on localhost (1/1)
[16:20:39,287] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:20:39,289] INFO  {DAGScheduler} ResultStage 0 (take at Main.scala:48) finished in 0.392 s
[16:20:39,339] INFO  {DAGScheduler} Job 0 finished: take at Main.scala:48, took 0.723424 s
[16:20:39,346] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:20:39,353] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:20:39,355] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[16:20:39,356] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[16:20:39,357] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[16:20:39,357] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[16:20:39,358] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[16:20:39,358] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[16:20:39,358] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[16:20:39,359] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[16:20:39,359] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[16:20:39,359] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[16:20:39,360] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[16:20:39,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[16:20:39,361] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[16:20:39,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[16:20:39,362] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[16:20:39,363] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[16:20:39,363] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[16:20:39,363] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[16:20:39,363] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[16:20:39,364] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[16:20:39,364] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[16:20:39,364] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[16:20:39,364] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[16:20:39,364] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[16:20:39,366] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:20:39,400] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:20:39,407] INFO  {MemoryStore} MemoryStore cleared
[16:20:39,408] INFO  {BlockManager} BlockManager stopped
[16:20:39,415] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:20:39,419] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:20:39,423] INFO  {SparkContext} Successfully stopped SparkContext
[16:20:39,423] INFO  {ShutdownHookManager} Shutdown hook called
[16:20:39,425] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-44e2b317-51ab-4167-b5f8-712c9f429a68
[16:24:43,781] INFO  {SparkContext} Running Spark version 2.0.1
[16:24:44,035] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:24:44,253] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:24:44,254] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:24:44,383] INFO  {SecurityManager} Changing view acls to: victor
[16:24:44,384] INFO  {SecurityManager} Changing modify acls to: victor
[16:24:44,385] INFO  {SecurityManager} Changing view acls groups to: 
[16:24:44,385] INFO  {SecurityManager} Changing modify acls groups to: 
[16:24:44,386] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:24:44,800] INFO  {Utils} Successfully started service 'sparkDriver' on port 37193.
[16:24:44,824] INFO  {SparkEnv} Registering MapOutputTracker
[16:24:44,843] INFO  {SparkEnv} Registering BlockManagerMaster
[16:24:44,859] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-14c31061-02ee-4808-8898-ce9cd33c5524
[16:24:44,883] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:24:44,929] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:24:45,033] INFO  {log} Logging initialized @2029ms
[16:24:45,153] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:24:45,175] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[16:24:45,175] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[16:24:45,175] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[16:24:45,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[16:24:45,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[16:24:45,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[16:24:45,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[16:24:45,176] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[16:24:45,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[16:24:45,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[16:24:45,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[16:24:45,177] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[16:24:45,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[16:24:45,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[16:24:45,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[16:24:45,178] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[16:24:45,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[16:24:45,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[16:24:45,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[16:24:45,179] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[16:24:45,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[16:24:45,186] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[16:24:45,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[16:24:45,187] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[16:24:45,192] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:24:45,193] INFO  {Server} Started @2191ms
[16:24:45,193] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:24:45,194] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:24:45,296] INFO  {Executor} Starting executor ID driver on host localhost
[16:24:45,322] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37185.
[16:24:45,323] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:37185
[16:24:45,325] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 37185)
[16:24:45,328] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:37185 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 37185)
[16:24:45,348] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 37185)
[16:24:45,515] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[16:24:46,033] INFO  {SparkContext} Starting job: take at Main.scala:87
[16:24:46,083] INFO  {DAGScheduler} Got job 0 (take at Main.scala:87) with 1 output partitions
[16:24:46,083] INFO  {DAGScheduler} Final stage: ResultStage 0 (take at Main.scala:87)
[16:24:46,084] INFO  {DAGScheduler} Parents of final stage: List()
[16:24:46,086] INFO  {DAGScheduler} Missing parents: List()
[16:24:46,099] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27), which has no missing parents
[16:24:46,282] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.4 KB, free 1128.9 MB)
[16:24:46,330] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1486.0 B, free 1128.9 MB)
[16:24:46,334] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:37185 (size: 1486.0 B, free: 1128.9 MB)
[16:24:46,341] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:24:46,348] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at Main.scala:27)
[16:24:46,351] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:24:46,471] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:24:46,473] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169385 bytes)
[16:24:46,484] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:24:46,685] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 1920 bytes result sent to driver
[16:24:46,693] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 282 ms on localhost (1/1)
[16:24:46,694] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:24:46,699] INFO  {DAGScheduler} ResultStage 0 (take at Main.scala:87) finished in 0.317 s
[16:24:46,705] INFO  {DAGScheduler} Job 0 finished: take at Main.scala:87, took 0.672124 s
[16:24:46,710] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:24:46,714] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:24:46,715] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[16:24:46,716] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[16:24:46,716] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[16:24:46,716] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[16:24:46,716] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[16:24:46,716] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[16:24:46,716] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[16:24:46,717] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[16:24:46,717] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[16:24:46,717] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[16:24:46,717] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[16:24:46,717] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[16:24:46,717] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[16:24:46,718] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[16:24:46,718] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[16:24:46,718] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[16:24:46,718] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[16:24:46,718] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[16:24:46,719] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[16:24:46,719] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[16:24:46,719] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[16:24:46,719] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[16:24:46,719] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[16:24:46,720] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[16:24:46,722] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:24:46,734] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:24:46,738] INFO  {MemoryStore} MemoryStore cleared
[16:24:46,739] INFO  {BlockManager} BlockManager stopped
[16:24:46,744] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:24:46,746] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:24:46,747] INFO  {SparkContext} Successfully stopped SparkContext
[16:24:46,748] INFO  {ShutdownHookManager} Shutdown hook called
[16:24:46,748] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-bc8b625c-a4dd-424c-a356-4e3acf7e1e5c
[16:28:14,296] INFO  {SparkContext} Running Spark version 2.0.1
[16:28:14,572] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:28:14,769] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:28:14,770] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:28:14,853] INFO  {SecurityManager} Changing view acls to: victor
[16:28:14,854] INFO  {SecurityManager} Changing modify acls to: victor
[16:28:14,854] INFO  {SecurityManager} Changing view acls groups to: 
[16:28:14,855] INFO  {SecurityManager} Changing modify acls groups to: 
[16:28:14,856] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:28:15,446] INFO  {Utils} Successfully started service 'sparkDriver' on port 36985.
[16:28:15,491] INFO  {SparkEnv} Registering MapOutputTracker
[16:28:15,535] INFO  {SparkEnv} Registering BlockManagerMaster
[16:28:15,566] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-e5036b77-23ca-4b49-b0d9-76d8fd091254
[16:28:15,612] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:28:15,715] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:28:15,923] INFO  {log} Logging initialized @2389ms
[16:28:16,223] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:28:16,270] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[16:28:16,271] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[16:28:16,271] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[16:28:16,272] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[16:28:16,272] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[16:28:16,273] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[16:28:16,273] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[16:28:16,274] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[16:28:16,274] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[16:28:16,275] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[16:28:16,275] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[16:28:16,276] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[16:28:16,276] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[16:28:16,277] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[16:28:16,277] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[16:28:16,277] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[16:28:16,278] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[16:28:16,278] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[16:28:16,279] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[16:28:16,279] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[16:28:16,291] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[16:28:16,292] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[16:28:16,294] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[16:28:16,295] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[16:28:16,307] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:28:16,307] INFO  {Server} Started @2779ms
[16:28:16,307] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:28:16,311] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:28:16,543] INFO  {Executor} Starting executor ID driver on host localhost
[16:28:16,613] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42499.
[16:28:16,616] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:42499
[16:28:16,623] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 42499)
[16:28:16,630] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:42499 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 42499)
[16:28:16,641] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 42499)
[16:28:16,998] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[16:28:18,285] INFO  {SparkContext} Starting job: take at Main.scala:87
[16:28:18,388] INFO  {DAGScheduler} Got job 0 (take at Main.scala:87) with 1 output partitions
[16:28:18,389] INFO  {DAGScheduler} Final stage: ResultStage 0 (take at Main.scala:87)
[16:28:18,390] INFO  {DAGScheduler} Parents of final stage: List()
[16:28:18,393] INFO  {DAGScheduler} Missing parents: List()
[16:28:18,415] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[4] at filter at Main.scala:85), which has no missing parents
[16:28:18,733] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 1128.9 MB)
[16:28:18,816] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1547.0 B, free 1128.9 MB)
[16:28:18,822] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:42499 (size: 1547.0 B, free: 1128.9 MB)
[16:28:18,832] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:28:18,844] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at filter at Main.scala:85)
[16:28:18,851] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:28:19,051] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:28:19,054] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169385 bytes)
[16:28:19,070] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:28:19,571] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 1925 bytes result sent to driver
[16:28:19,599] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 671 ms on localhost (1/1)
[16:28:19,603] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:28:19,613] INFO  {DAGScheduler} ResultStage 0 (take at Main.scala:87) finished in 0.724 s
[16:28:19,629] INFO  {DAGScheduler} Job 0 finished: take at Main.scala:87, took 1.342910 s
[16:28:19,642] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:28:19,654] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:28:19,658] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[16:28:19,659] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[16:28:19,659] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[16:28:19,660] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[16:28:19,660] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[16:28:19,661] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[16:28:19,661] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[16:28:19,662] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[16:28:19,662] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[16:28:19,663] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[16:28:19,663] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[16:28:19,664] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[16:28:19,664] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[16:28:19,664] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[16:28:19,665] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[16:28:19,665] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[16:28:19,666] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[16:28:19,666] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[16:28:19,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[16:28:19,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[16:28:19,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[16:28:19,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[16:28:19,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[16:28:19,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[16:28:19,673] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:28:19,701] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:28:19,714] INFO  {MemoryStore} MemoryStore cleared
[16:28:19,716] INFO  {BlockManager} BlockManager stopped
[16:28:19,731] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:28:19,753] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:28:19,776] INFO  {SparkContext} Successfully stopped SparkContext
[16:28:19,778] INFO  {ShutdownHookManager} Shutdown hook called
[16:28:19,898] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-37000048-acb9-4cdf-b4ce-5086686ac25a
[16:30:33,962] INFO  {SparkContext} Running Spark version 2.0.1
[16:30:34,284] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:30:34,434] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:30:34,435] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:30:34,592] INFO  {SecurityManager} Changing view acls to: victor
[16:30:34,593] INFO  {SecurityManager} Changing modify acls to: victor
[16:30:34,593] INFO  {SecurityManager} Changing view acls groups to: 
[16:30:34,594] INFO  {SecurityManager} Changing modify acls groups to: 
[16:30:34,595] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:30:35,172] INFO  {Utils} Successfully started service 'sparkDriver' on port 35445.
[16:30:35,220] INFO  {SparkEnv} Registering MapOutputTracker
[16:30:35,266] INFO  {SparkEnv} Registering BlockManagerMaster
[16:30:35,299] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-a21b85dd-db6b-4ffb-a271-0dd4ff590e00
[16:30:35,344] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:30:35,477] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:30:35,704] INFO  {log} Logging initialized @2550ms
[16:30:35,960] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:30:36,007] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[16:30:36,008] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[16:30:36,009] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[16:30:36,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[16:30:36,010] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[16:30:36,011] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[16:30:36,012] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[16:30:36,013] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[16:30:36,013] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[16:30:36,014] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[16:30:36,015] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[16:30:36,016] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[16:30:36,016] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[16:30:36,017] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[16:30:36,017] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[16:30:36,018] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[16:30:36,018] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[16:30:36,019] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[16:30:36,019] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[16:30:36,019] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[16:30:36,032] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[16:30:36,032] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[16:30:36,034] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[16:30:36,035] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[16:30:36,048] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:30:36,048] INFO  {Server} Started @2898ms
[16:30:36,049] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:30:36,053] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:30:36,272] INFO  {Executor} Starting executor ID driver on host localhost
[16:30:36,341] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46177.
[16:30:36,343] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:46177
[16:30:36,348] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 46177)
[16:30:36,357] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:46177 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 46177)
[16:30:36,373] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 46177)
[16:30:36,557] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[16:30:37,055] INFO  {SparkContext} Starting job: take at Main.scala:87
[16:30:37,102] INFO  {DAGScheduler} Got job 0 (take at Main.scala:87) with 1 output partitions
[16:30:37,103] INFO  {DAGScheduler} Final stage: ResultStage 0 (take at Main.scala:87)
[16:30:37,103] INFO  {DAGScheduler} Parents of final stage: List()
[16:30:37,105] INFO  {DAGScheduler} Missing parents: List()
[16:30:37,124] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[4] at filter at Main.scala:85), which has no missing parents
[16:30:37,297] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 1128.9 MB)
[16:30:37,335] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1547.0 B, free 1128.9 MB)
[16:30:37,337] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:46177 (size: 1547.0 B, free: 1128.9 MB)
[16:30:37,343] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:30:37,347] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at filter at Main.scala:85)
[16:30:37,352] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:30:37,466] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:30:37,468] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169385 bytes)
[16:30:37,476] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:30:37,723] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 1925 bytes result sent to driver
[16:30:37,731] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 341 ms on localhost (1/1)
[16:30:37,732] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:30:37,736] INFO  {DAGScheduler} ResultStage 0 (take at Main.scala:87) finished in 0.361 s
[16:30:37,740] INFO  {DAGScheduler} Job 0 finished: take at Main.scala:87, took 0.684905 s
[16:30:37,745] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:30:37,752] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:30:37,755] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[16:30:37,756] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[16:30:37,756] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[16:30:37,756] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[16:30:37,757] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[16:30:37,757] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[16:30:37,758] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[16:30:37,758] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[16:30:37,758] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[16:30:37,758] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[16:30:37,759] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[16:30:37,759] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[16:30:37,759] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[16:30:37,759] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[16:30:37,759] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[16:30:37,759] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[16:30:37,760] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[16:30:37,760] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[16:30:37,760] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[16:30:37,760] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[16:30:37,760] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[16:30:37,761] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[16:30:37,761] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[16:30:37,761] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[16:30:37,762] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:30:37,774] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:30:37,779] INFO  {MemoryStore} MemoryStore cleared
[16:30:37,780] INFO  {BlockManager} BlockManager stopped
[16:30:37,786] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:30:37,827] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:30:37,832] INFO  {SparkContext} Successfully stopped SparkContext
[16:30:37,834] INFO  {ShutdownHookManager} Shutdown hook called
[16:30:37,837] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-947c1ef6-214e-4343-b2c1-f64ff6e2f0db
[16:31:40,625] INFO  {SparkContext} Running Spark version 2.0.1
[16:31:40,884] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:31:41,046] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:31:41,047] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:31:41,157] INFO  {SecurityManager} Changing view acls to: victor
[16:31:41,159] INFO  {SecurityManager} Changing modify acls to: victor
[16:31:41,160] INFO  {SecurityManager} Changing view acls groups to: 
[16:31:41,163] INFO  {SecurityManager} Changing modify acls groups to: 
[16:31:41,164] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:31:41,698] INFO  {Utils} Successfully started service 'sparkDriver' on port 40455.
[16:31:41,741] INFO  {SparkEnv} Registering MapOutputTracker
[16:31:41,778] INFO  {SparkEnv} Registering BlockManagerMaster
[16:31:41,817] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-3ffefe5a-f56a-473b-a584-36c67dd1ee7a
[16:31:41,864] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:31:41,976] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:31:42,187] INFO  {log} Logging initialized @2395ms
[16:31:42,512] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:31:42,558] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:31:42,559] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:31:42,560] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:31:42,561] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:31:42,562] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:31:42,562] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:31:42,563] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:31:42,564] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:31:42,564] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:31:42,565] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:31:42,566] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:31:42,567] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:31:42,567] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:31:42,568] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:31:42,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:31:42,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:31:42,570] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:31:42,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:31:42,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:31:42,572] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:31:42,589] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:31:42,590] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:31:42,593] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:31:42,594] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:31:42,610] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:31:42,611] INFO  {Server} Started @2822ms
[16:31:42,611] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:31:42,618] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:31:42,926] INFO  {Executor} Starting executor ID driver on host localhost
[16:31:42,996] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40705.
[16:31:42,999] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:40705
[16:31:43,003] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 40705)
[16:31:43,012] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:40705 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 40705)
[16:31:43,023] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 40705)
[16:31:43,393] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:31:46,639] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:31:46,646] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:31:46,650] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:31:46,650] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:31:46,650] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:31:46,651] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:31:46,651] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:31:46,651] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:31:46,651] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:31:46,651] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:31:46,652] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:31:46,652] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:31:46,652] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:31:46,652] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:31:46,652] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:31:46,653] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:31:46,653] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:31:46,653] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:31:46,653] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:31:46,653] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:31:46,653] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:31:46,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:31:46,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:31:46,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:31:46,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:31:46,654] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:31:46,656] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:31:46,667] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:31:46,673] INFO  {MemoryStore} MemoryStore cleared
[16:31:46,675] INFO  {BlockManager} BlockManager stopped
[16:31:46,680] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:31:46,683] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:31:46,685] INFO  {SparkContext} Successfully stopped SparkContext
[16:31:46,685] INFO  {ShutdownHookManager} Shutdown hook called
[16:31:46,686] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-f0d12268-bd30-41f7-be76-5b465a1e42c1
[16:32:02,878] INFO  {SparkContext} Running Spark version 2.0.1
[16:32:03,130] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:32:03,277] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:32:03,278] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:32:03,380] INFO  {SecurityManager} Changing view acls to: victor
[16:32:03,381] INFO  {SecurityManager} Changing modify acls to: victor
[16:32:03,382] INFO  {SecurityManager} Changing view acls groups to: 
[16:32:03,383] INFO  {SecurityManager} Changing modify acls groups to: 
[16:32:03,384] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:32:03,925] INFO  {Utils} Successfully started service 'sparkDriver' on port 38145.
[16:32:03,967] INFO  {SparkEnv} Registering MapOutputTracker
[16:32:04,008] INFO  {SparkEnv} Registering BlockManagerMaster
[16:32:04,046] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-589cdd6e-3931-4cb8-be09-8e0a0df0960b
[16:32:04,087] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:32:04,231] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:32:04,435] INFO  {log} Logging initialized @2373ms
[16:32:04,720] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:32:04,764] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:32:04,765] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:32:04,766] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:32:04,766] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:32:04,767] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:32:04,768] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:32:04,769] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:32:04,770] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:32:04,770] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:32:04,771] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:32:04,772] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:32:04,772] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:32:04,773] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:32:04,774] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:32:04,774] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:32:04,775] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:32:04,775] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:32:04,775] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:32:04,776] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:32:04,776] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:32:04,788] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:32:04,788] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:32:04,790] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:32:04,790] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:32:04,805] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:32:04,805] INFO  {Server} Started @2748ms
[16:32:04,805] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:32:04,809] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:32:05,039] INFO  {Executor} Starting executor ID driver on host localhost
[16:32:05,113] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35777.
[16:32:05,115] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:35777
[16:32:05,120] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 35777)
[16:32:05,128] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:35777 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 35777)
[16:32:05,142] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 35777)
[16:32:05,424] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:32:07,624] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:32:07,629] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:32:07,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:32:07,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:32:07,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:32:07,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:32:07,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:32:07,632] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:32:07,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:32:07,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:32:07,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:32:07,633] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:32:07,634] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:32:07,634] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:32:07,634] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:32:07,634] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:32:07,634] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:32:07,634] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:32:07,635] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:32:07,635] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:32:07,635] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:32:07,635] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:32:07,635] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:32:07,636] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:32:07,636] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:32:07,636] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:32:07,638] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:32:07,648] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:32:07,653] INFO  {MemoryStore} MemoryStore cleared
[16:32:07,653] INFO  {BlockManager} BlockManager stopped
[16:32:07,658] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:32:07,661] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:32:07,666] INFO  {SparkContext} Successfully stopped SparkContext
[16:32:07,667] INFO  {ShutdownHookManager} Shutdown hook called
[16:32:07,668] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-b1fa00fd-7b37-4f32-bfc8-59ba23810f28
[16:32:27,645] INFO  {SparkContext} Running Spark version 2.0.1
[16:32:27,892] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:32:28,013] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:32:28,014] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:32:28,129] INFO  {SecurityManager} Changing view acls to: victor
[16:32:28,130] INFO  {SecurityManager} Changing modify acls to: victor
[16:32:28,130] INFO  {SecurityManager} Changing view acls groups to: 
[16:32:28,131] INFO  {SecurityManager} Changing modify acls groups to: 
[16:32:28,132] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:32:28,490] INFO  {Utils} Successfully started service 'sparkDriver' on port 34297.
[16:32:28,509] INFO  {SparkEnv} Registering MapOutputTracker
[16:32:28,525] INFO  {SparkEnv} Registering BlockManagerMaster
[16:32:28,538] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-45951e5b-e0f5-469e-857e-7aba55506aa9
[16:32:28,556] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:32:28,603] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:32:28,698] INFO  {log} Logging initialized @1767ms
[16:32:28,807] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:32:28,828] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:32:28,829] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:32:28,829] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:32:28,829] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:32:28,829] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:32:28,830] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:32:28,830] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:32:28,830] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:32:28,830] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:32:28,830] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:32:28,831] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:32:28,831] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:32:28,831] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:32:28,831] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:32:28,831] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:32:28,832] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:32:28,832] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:32:28,832] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:32:28,832] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:32:28,832] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:32:28,840] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:32:28,840] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:32:28,841] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:32:28,841] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:32:28,847] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:32:28,847] INFO  {Server} Started @1918ms
[16:32:28,847] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:32:28,849] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:32:28,932] INFO  {Executor} Starting executor ID driver on host localhost
[16:32:28,960] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46147.
[16:32:28,962] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:46147
[16:32:28,965] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 46147)
[16:32:28,971] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:46147 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 46147)
[16:32:28,974] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 46147)
[16:32:29,102] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:32:31,061] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:32:31,065] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:32:31,067] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:32:31,067] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:32:31,067] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:32:31,067] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:32:31,068] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:32:31,068] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:32:31,068] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:32:31,068] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:32:31,068] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:32:31,068] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:32:31,068] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:32:31,069] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:32:31,069] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:32:31,069] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:32:31,069] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:32:31,069] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:32:31,069] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:32:31,069] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:32:31,069] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:32:31,070] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:32:31,070] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:32:31,070] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:32:31,070] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:32:31,070] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:32:31,072] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:32:31,085] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:32:31,092] INFO  {MemoryStore} MemoryStore cleared
[16:32:31,093] INFO  {BlockManager} BlockManager stopped
[16:32:31,098] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:32:31,102] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:32:31,107] INFO  {SparkContext} Successfully stopped SparkContext
[16:32:31,107] INFO  {ShutdownHookManager} Shutdown hook called
[16:32:31,108] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-cc1b3a4e-697c-4a67-b327-08ffb412d3b5
[16:42:08,028] INFO  {SparkContext} Running Spark version 2.0.1
[16:42:08,330] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:42:08,525] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:42:08,526] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:42:08,649] INFO  {SecurityManager} Changing view acls to: victor
[16:42:08,650] INFO  {SecurityManager} Changing modify acls to: victor
[16:42:08,651] INFO  {SecurityManager} Changing view acls groups to: 
[16:42:08,652] INFO  {SecurityManager} Changing modify acls groups to: 
[16:42:08,653] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:42:09,028] INFO  {Utils} Successfully started service 'sparkDriver' on port 37189.
[16:42:09,050] INFO  {SparkEnv} Registering MapOutputTracker
[16:42:09,073] INFO  {SparkEnv} Registering BlockManagerMaster
[16:42:09,085] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-dbe341c9-50b9-4e4f-81a2-843302d3af8c
[16:42:09,101] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:42:09,152] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:42:09,237] INFO  {log} Logging initialized @2063ms
[16:42:09,359] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:42:09,375] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/jobs,null,AVAILABLE}
[16:42:09,375] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,AVAILABLE}
[16:42:09,376] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,AVAILABLE}
[16:42:09,376] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,AVAILABLE}
[16:42:09,376] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/stages,null,AVAILABLE}
[16:42:09,376] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,AVAILABLE}
[16:42:09,376] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,AVAILABLE}
[16:42:09,377] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,AVAILABLE}
[16:42:09,377] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,AVAILABLE}
[16:42:09,377] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,AVAILABLE}
[16:42:09,377] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/storage,null,AVAILABLE}
[16:42:09,377] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,AVAILABLE}
[16:42:09,377] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,AVAILABLE}
[16:42:09,378] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,AVAILABLE}
[16:42:09,378] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/environment,null,AVAILABLE}
[16:42:09,378] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,AVAILABLE}
[16:42:09,378] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,AVAILABLE}
[16:42:09,378] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,AVAILABLE}
[16:42:09,378] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,AVAILABLE}
[16:42:09,379] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,AVAILABLE}
[16:42:09,386] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/static,null,AVAILABLE}
[16:42:09,386] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/,null,AVAILABLE}
[16:42:09,388] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/api,null,AVAILABLE}
[16:42:09,388] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,AVAILABLE}
[16:42:09,394] INFO  {ServerConnector} Started ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:42:09,394] INFO  {Server} Started @2222ms
[16:42:09,394] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:42:09,396] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:42:09,494] INFO  {Executor} Starting executor ID driver on host localhost
[16:42:09,523] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39245.
[16:42:09,524] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:39245
[16:42:09,529] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 39245)
[16:42:09,532] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:39245 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 39245)
[16:42:09,536] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 39245)
[16:42:09,671] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d8792db{/metrics/json,null,AVAILABLE}
[16:42:11,768] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:42:11,774] INFO  {ServerConnector} Stopped ServerConnector@4b2a01d4{HTTP/1.1}{0.0.0.0:4040}
[16:42:11,776] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/stage/kill,null,UNAVAILABLE}
[16:42:11,777] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/api,null,UNAVAILABLE}
[16:42:11,777] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/,null,UNAVAILABLE}
[16:42:11,777] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/static,null,UNAVAILABLE}
[16:42:11,777] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/executors/threadDump/json,null,UNAVAILABLE}
[16:42:11,777] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/executors/threadDump,null,UNAVAILABLE}
[16:42:11,777] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/executors/json,null,UNAVAILABLE}
[16:42:11,778] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/executors,null,UNAVAILABLE}
[16:42:11,778] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/environment/json,null,UNAVAILABLE}
[16:42:11,778] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/environment,null,UNAVAILABLE}
[16:42:11,778] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/storage/rdd/json,null,UNAVAILABLE}
[16:42:11,778] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/storage/rdd,null,UNAVAILABLE}
[16:42:11,778] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/storage/json,null,UNAVAILABLE}
[16:42:11,778] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/storage,null,UNAVAILABLE}
[16:42:11,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/stages/pool/json,null,UNAVAILABLE}
[16:42:11,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/stages/pool,null,UNAVAILABLE}
[16:42:11,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/stages/stage/json,null,UNAVAILABLE}
[16:42:11,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/stages/stage,null,UNAVAILABLE}
[16:42:11,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/stages/json,null,UNAVAILABLE}
[16:42:11,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/stages,null,UNAVAILABLE}
[16:42:11,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/jobs/job/json,null,UNAVAILABLE}
[16:42:11,779] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/jobs/job,null,UNAVAILABLE}
[16:42:11,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/jobs/json,null,UNAVAILABLE}
[16:42:11,780] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/jobs,null,UNAVAILABLE}
[16:42:11,781] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:42:11,790] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:42:11,794] INFO  {MemoryStore} MemoryStore cleared
[16:42:11,794] INFO  {BlockManager} BlockManager stopped
[16:42:11,800] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:42:11,804] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:42:11,807] INFO  {SparkContext} Successfully stopped SparkContext
[16:42:11,807] INFO  {ShutdownHookManager} Shutdown hook called
[16:42:11,808] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-939e800d-0127-4c84-8eaa-2f20d4d4d851
[16:44:17,449] INFO  {SparkContext} Running Spark version 2.0.1
[16:44:17,858] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:44:18,213] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:44:18,215] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:44:18,476] INFO  {SecurityManager} Changing view acls to: victor
[16:44:18,479] INFO  {SecurityManager} Changing modify acls to: victor
[16:44:18,481] INFO  {SecurityManager} Changing view acls groups to: 
[16:44:18,485] INFO  {SecurityManager} Changing modify acls groups to: 
[16:44:18,488] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:44:19,398] INFO  {Utils} Successfully started service 'sparkDriver' on port 36017.
[16:44:19,447] INFO  {SparkEnv} Registering MapOutputTracker
[16:44:19,497] INFO  {SparkEnv} Registering BlockManagerMaster
[16:44:19,531] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-9f423740-4073-491f-aed8-db7862d53d4b
[16:44:19,581] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:44:19,704] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:44:19,903] INFO  {log} Logging initialized @3219ms
[16:44:20,205] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:44:20,253] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,AVAILABLE}
[16:44:20,254] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,AVAILABLE}
[16:44:20,255] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,AVAILABLE}
[16:44:20,256] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,AVAILABLE}
[16:44:20,257] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,AVAILABLE}
[16:44:20,257] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,AVAILABLE}
[16:44:20,258] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,AVAILABLE}
[16:44:20,258] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,AVAILABLE}
[16:44:20,259] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,AVAILABLE}
[16:44:20,259] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,AVAILABLE}
[16:44:20,260] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,AVAILABLE}
[16:44:20,260] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,AVAILABLE}
[16:44:20,261] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,AVAILABLE}
[16:44:20,261] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,AVAILABLE}
[16:44:20,262] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@189aa67a{/environment,null,AVAILABLE}
[16:44:20,262] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,AVAILABLE}
[16:44:20,263] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/executors,null,AVAILABLE}
[16:44:20,263] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,AVAILABLE}
[16:44:20,263] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,AVAILABLE}
[16:44:20,264] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,AVAILABLE}
[16:44:20,276] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/static,null,AVAILABLE}
[16:44:20,277] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/,null,AVAILABLE}
[16:44:20,280] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/api,null,AVAILABLE}
[16:44:20,281] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,AVAILABLE}
[16:44:20,295] INFO  {ServerConnector} Started ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:44:20,296] INFO  {Server} Started @3615ms
[16:44:20,296] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:44:20,300] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:44:20,520] INFO  {Executor} Starting executor ID driver on host localhost
[16:44:20,592] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41209.
[16:44:20,594] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:41209
[16:44:20,599] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 41209)
[16:44:20,606] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:41209 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 41209)
[16:44:20,621] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 41209)
[16:44:20,988] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6fff253c{/metrics/json,null,AVAILABLE}
[16:44:22,466] INFO  {SparkContext} Starting job: take at Main.scala:86
[16:44:22,566] INFO  {DAGScheduler} Got job 0 (take at Main.scala:86) with 1 output partitions
[16:44:22,567] INFO  {DAGScheduler} Final stage: ResultStage 0 (take at Main.scala:86)
[16:44:22,568] INFO  {DAGScheduler} Parents of final stage: List()
[16:44:22,573] INFO  {DAGScheduler} Missing parents: List()
[16:44:22,595] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[4] at filter at Main.scala:84), which has no missing parents
[16:44:22,862] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 1128.9 MB)
[16:44:22,932] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 1548.0 B, free 1128.9 MB)
[16:44:22,938] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:41209 (size: 1548.0 B, free: 1128.9 MB)
[16:44:22,945] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:44:22,956] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at filter at Main.scala:84)
[16:44:22,959] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:44:23,120] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:44:23,123] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169385 bytes)
[16:44:23,137] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:44:23,556] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 1291 bytes result sent to driver
[16:44:23,573] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 553 ms on localhost (1/1)
[16:44:23,576] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:44:23,588] INFO  {DAGScheduler} ResultStage 0 (take at Main.scala:86) finished in 0.602 s
[16:44:23,602] INFO  {DAGScheduler} Job 0 finished: take at Main.scala:86, took 1.133666 s
[16:44:23,621] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:44:23,631] INFO  {ServerConnector} Stopped ServerConnector@6f152006{HTTP/1.1}{0.0.0.0:4040}
[16:44:23,635] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/stage/kill,null,UNAVAILABLE}
[16:44:23,635] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/api,null,UNAVAILABLE}
[16:44:23,636] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/,null,UNAVAILABLE}
[16:44:23,636] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/static,null,UNAVAILABLE}
[16:44:23,637] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/executors/threadDump/json,null,UNAVAILABLE}
[16:44:23,637] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/executors/threadDump,null,UNAVAILABLE}
[16:44:23,637] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/executors/json,null,UNAVAILABLE}
[16:44:23,638] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/executors,null,UNAVAILABLE}
[16:44:23,638] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/environment/json,null,UNAVAILABLE}
[16:44:23,639] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@189aa67a{/environment,null,UNAVAILABLE}
[16:44:23,639] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c4ed84{/storage/rdd/json,null,UNAVAILABLE}
[16:44:23,640] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5f9678e1{/storage/rdd,null,UNAVAILABLE}
[16:44:23,640] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@373ebf74{/storage/json,null,UNAVAILABLE}
[16:44:23,641] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5669c5fb{/storage,null,UNAVAILABLE}
[16:44:23,641] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@56113384{/stages/pool/json,null,UNAVAILABLE}
[16:44:23,642] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@340b9973{/stages/pool,null,UNAVAILABLE}
[16:44:23,642] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@52066604{/stages/stage/json,null,UNAVAILABLE}
[16:44:23,643] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4a194c39{/stages/stage,null,UNAVAILABLE}
[16:44:23,643] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@c5dc4a2{/stages/json,null,UNAVAILABLE}
[16:44:23,643] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@10ded6a9{/stages,null,UNAVAILABLE}
[16:44:23,644] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@17a1e4ca{/jobs/job/json,null,UNAVAILABLE}
[16:44:23,644] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@301ec38b{/jobs/job,null,UNAVAILABLE}
[16:44:23,645] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3a3e78f{/jobs/json,null,UNAVAILABLE}
[16:44:23,646] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@767e20cf{/jobs,null,UNAVAILABLE}
[16:44:23,651] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:44:23,675] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:44:23,684] INFO  {MemoryStore} MemoryStore cleared
[16:44:23,685] INFO  {BlockManager} BlockManager stopped
[16:44:23,697] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:44:23,703] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:44:23,723] INFO  {SparkContext} Successfully stopped SparkContext
[16:44:23,724] INFO  {ShutdownHookManager} Shutdown hook called
[16:44:23,728] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-8ca5117f-3733-4038-a576-67bdae42665a
[16:51:19,341] INFO  {SparkContext} Running Spark version 2.0.1
[16:51:19,971] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:51:20,386] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:51:20,387] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:51:20,527] INFO  {SecurityManager} Changing view acls to: victor
[16:51:20,530] INFO  {SecurityManager} Changing modify acls to: victor
[16:51:20,532] INFO  {SecurityManager} Changing view acls groups to: 
[16:51:20,533] INFO  {SecurityManager} Changing modify acls groups to: 
[16:51:20,535] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:51:21,291] INFO  {Utils} Successfully started service 'sparkDriver' on port 44777.
[16:51:21,330] INFO  {SparkEnv} Registering MapOutputTracker
[16:51:21,367] INFO  {SparkEnv} Registering BlockManagerMaster
[16:51:21,396] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-19ac1e22-bcc4-48eb-93b3-af30ce8f1730
[16:51:21,439] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:51:21,571] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:51:21,752] INFO  {log} Logging initialized @4553ms
[16:51:22,012] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:51:22,047] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/jobs,null,AVAILABLE}
[16:51:22,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/jobs/json,null,AVAILABLE}
[16:51:22,048] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/jobs/job,null,AVAILABLE}
[16:51:22,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/jobs/job/json,null,AVAILABLE}
[16:51:22,049] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/stages,null,AVAILABLE}
[16:51:22,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/json,null,AVAILABLE}
[16:51:22,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/stages/stage,null,AVAILABLE}
[16:51:22,050] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/json,null,AVAILABLE}
[16:51:22,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6c45ee6e{/stages/pool,null,AVAILABLE}
[16:51:22,051] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6b3e12b5{/stages/pool/json,null,AVAILABLE}
[16:51:22,052] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5aac4250{/storage,null,AVAILABLE}
[16:51:22,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1338fb5{/storage/json,null,AVAILABLE}
[16:51:22,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@42463763{/storage/rdd,null,AVAILABLE}
[16:51:22,053] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59f63e24{/storage/rdd/json,null,AVAILABLE}
[16:51:22,054] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@61f05988{/environment,null,AVAILABLE}
[16:51:22,054] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7ca33c24{/environment/json,null,AVAILABLE}
[16:51:22,055] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@fade1fc{/executors,null,AVAILABLE}
[16:51:22,055] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@67c2e933{/executors/json,null,AVAILABLE}
[16:51:22,055] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@41dd05a{/executors/threadDump,null,AVAILABLE}
[16:51:22,056] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@613a8ee1{/executors/threadDump/json,null,AVAILABLE}
[16:51:22,069] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@178213b{/static,null,AVAILABLE}
[16:51:22,070] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7103cb56{/,null,AVAILABLE}
[16:51:22,072] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b765a2c{/api,null,AVAILABLE}
[16:51:22,072] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2e8e8225{/stages/stage/kill,null,AVAILABLE}
[16:51:22,089] INFO  {ServerConnector} Started ServerConnector@68ead359{HTTP/1.1}{0.0.0.0:4040}
[16:51:22,089] INFO  {Server} Started @4893ms
[16:51:22,090] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:51:22,099] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:51:22,300] INFO  {Executor} Starting executor ID driver on host localhost
[16:51:22,362] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32853.
[16:51:22,364] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:32853
[16:51:22,368] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 32853)
[16:51:22,375] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:32853 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 32853)
[16:51:22,384] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 32853)
[16:51:22,691] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a8a60bc{/metrics/json,null,AVAILABLE}
[16:51:27,568] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@194d329e{/SQL,null,AVAILABLE}
[16:51:27,569] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7fe6d{/SQL/json,null,AVAILABLE}
[16:51:27,571] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1c9fbb61{/SQL/execution,null,AVAILABLE}
[16:51:27,573] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@15d42ccb{/SQL/execution/json,null,AVAILABLE}
[16:51:27,588] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4c361f63{/static/sql,null,AVAILABLE}
[16:51:27,639] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:51:29,912] INFO  {SparkContext} Starting job: show at Main.scala:111
[16:51:29,933] INFO  {DAGScheduler} Got job 0 (show at Main.scala:111) with 1 output partitions
[16:51:29,934] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:111)
[16:51:29,934] INFO  {DAGScheduler} Parents of final stage: List()
[16:51:29,936] INFO  {DAGScheduler} Missing parents: List()
[16:51:29,946] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:111), which has no missing parents
[16:51:30,078] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 10.9 KB, free 1128.9 MB)
[16:51:30,101] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.9 KB, free 1128.9 MB)
[16:51:30,123] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:32853 (size: 4.9 KB, free: 1128.9 MB)
[16:51:30,126] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:51:30,130] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:111)
[16:51:30,131] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:51:30,202] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:51:30,204] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169333 bytes)
[16:51:30,211] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:51:30,699] INFO  {CodeGenerator} Code generated in 330.697375 ms
[16:51:31,033] INFO  {CodeGenerator} Code generated in 66.52883 ms
[16:51:31,052] ERROR {Executor} Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_5$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more
[16:51:31,078] WARN  {TaskSetManager} Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_5$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more

[16:51:31,086] ERROR {TaskSetManager} Task 0 in stage 0.0 failed 1 times; aborting job
[16:51:31,089] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:51:31,097] INFO  {TaskSchedulerImpl} Cancelling stage 0
[16:51:31,099] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:111) failed in 0.956 s
[16:51:31,100] INFO  {DAGScheduler} Job 0 failed: show at Main.scala:111, took 1.188280 s
[16:51:31,111] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:51:31,117] INFO  {ServerConnector} Stopped ServerConnector@68ead359{HTTP/1.1}{0.0.0.0:4040}
[16:51:31,119] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2e8e8225{/stages/stage/kill,null,UNAVAILABLE}
[16:51:31,120] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1b765a2c{/api,null,UNAVAILABLE}
[16:51:31,120] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7103cb56{/,null,UNAVAILABLE}
[16:51:31,121] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@178213b{/static,null,UNAVAILABLE}
[16:51:31,121] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@613a8ee1{/executors/threadDump/json,null,UNAVAILABLE}
[16:51:31,122] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@41dd05a{/executors/threadDump,null,UNAVAILABLE}
[16:51:31,122] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@67c2e933{/executors/json,null,UNAVAILABLE}
[16:51:31,122] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@fade1fc{/executors,null,UNAVAILABLE}
[16:51:31,123] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7ca33c24{/environment/json,null,UNAVAILABLE}
[16:51:31,123] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@61f05988{/environment,null,UNAVAILABLE}
[16:51:31,123] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59f63e24{/storage/rdd/json,null,UNAVAILABLE}
[16:51:31,124] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@42463763{/storage/rdd,null,UNAVAILABLE}
[16:51:31,124] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1338fb5{/storage/json,null,UNAVAILABLE}
[16:51:31,125] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5aac4250{/storage,null,UNAVAILABLE}
[16:51:31,125] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6b3e12b5{/stages/pool/json,null,UNAVAILABLE}
[16:51:31,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6c45ee6e{/stages/pool,null,UNAVAILABLE}
[16:51:31,126] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/json,null,UNAVAILABLE}
[16:51:31,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/stages/stage,null,UNAVAILABLE}
[16:51:31,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/json,null,UNAVAILABLE}
[16:51:31,127] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/stages,null,UNAVAILABLE}
[16:51:31,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/jobs/job/json,null,UNAVAILABLE}
[16:51:31,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/jobs/job,null,UNAVAILABLE}
[16:51:31,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/jobs/json,null,UNAVAILABLE}
[16:51:31,128] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/jobs,null,UNAVAILABLE}
[16:51:31,129] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:51:31,142] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:51:31,147] INFO  {MemoryStore} MemoryStore cleared
[16:51:31,148] INFO  {BlockManager} BlockManager stopped
[16:51:31,152] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:51:31,156] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:51:31,158] INFO  {SparkContext} Successfully stopped SparkContext
[16:51:31,159] INFO  {ShutdownHookManager} Shutdown hook called
[16:51:31,160] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-e8df6d5a-260f-456f-94a6-740966fb8580
[16:52:42,843] INFO  {SparkContext} Running Spark version 2.0.1
[16:52:43,506] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:52:43,940] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:52:43,942] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:52:44,110] INFO  {SecurityManager} Changing view acls to: victor
[16:52:44,112] INFO  {SecurityManager} Changing modify acls to: victor
[16:52:44,113] INFO  {SecurityManager} Changing view acls groups to: 
[16:52:44,114] INFO  {SecurityManager} Changing modify acls groups to: 
[16:52:44,116] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:52:44,988] INFO  {Utils} Successfully started service 'sparkDriver' on port 33197.
[16:52:45,036] INFO  {SparkEnv} Registering MapOutputTracker
[16:52:45,077] INFO  {SparkEnv} Registering BlockManagerMaster
[16:52:45,110] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-057d5cd3-b47f-4b65-9246-01792d85cbd9
[16:52:45,153] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:52:45,290] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:52:45,498] INFO  {log} Logging initialized @4592ms
[16:52:45,790] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:52:45,833] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5a9d6f02{/jobs,null,AVAILABLE}
[16:52:45,834] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@362045c0{/jobs/json,null,AVAILABLE}
[16:52:45,835] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@112f364d{/jobs/job,null,AVAILABLE}
[16:52:45,836] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5ccbeb64{/jobs/job/json,null,AVAILABLE}
[16:52:45,837] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6d9f7a80{/stages,null,AVAILABLE}
[16:52:45,838] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59252cb6{/stages/json,null,AVAILABLE}
[16:52:45,838] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@31d0e481{/stages/stage,null,AVAILABLE}
[16:52:45,839] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3243b914{/stages/stage/json,null,AVAILABLE}
[16:52:45,840] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@241e8ea6{/stages/pool,null,AVAILABLE}
[16:52:45,841] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@542e560f{/stages/pool/json,null,AVAILABLE}
[16:52:45,841] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/storage,null,AVAILABLE}
[16:52:45,842] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/storage/json,null,AVAILABLE}
[16:52:45,843] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/storage/rdd,null,AVAILABLE}
[16:52:45,843] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/storage/rdd/json,null,AVAILABLE}
[16:52:45,844] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/environment,null,AVAILABLE}
[16:52:45,844] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/environment/json,null,AVAILABLE}
[16:52:45,845] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/executors,null,AVAILABLE}
[16:52:45,845] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/executors/json,null,AVAILABLE}
[16:52:45,845] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6c45ee6e{/executors/threadDump,null,AVAILABLE}
[16:52:45,846] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6b3e12b5{/executors/threadDump/json,null,AVAILABLE}
[16:52:45,860] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5aac4250{/static,null,AVAILABLE}
[16:52:45,860] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1338fb5{/,null,AVAILABLE}
[16:52:45,862] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@42463763{/api,null,AVAILABLE}
[16:52:45,862] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59f63e24{/stages/stage/kill,null,AVAILABLE}
[16:52:45,877] INFO  {ServerConnector} Started ServerConnector@d284c2c{HTTP/1.1}{0.0.0.0:4040}
[16:52:45,878] INFO  {Server} Started @4975ms
[16:52:45,878] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:52:45,882] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:52:46,105] INFO  {Executor} Starting executor ID driver on host localhost
[16:52:46,181] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34145.
[16:52:46,183] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:34145
[16:52:46,190] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 34145)
[16:52:46,198] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:34145 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 34145)
[16:52:46,215] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 34145)
[16:52:46,540] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1cb3ec38{/metrics/json,null,AVAILABLE}
[16:52:51,014] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@410ae5ac{/SQL,null,AVAILABLE}
[16:52:51,017] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7c112f5f{/SQL/json,null,AVAILABLE}
[16:52:51,020] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@194d329e{/SQL/execution,null,AVAILABLE}
[16:52:51,022] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7fe6d{/SQL/execution/json,null,AVAILABLE}
[16:52:51,026] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7b81616b{/static/sql,null,AVAILABLE}
[16:52:51,068] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:52:52,676] INFO  {SparkContext} Starting job: show at Main.scala:111
[16:52:52,719] INFO  {DAGScheduler} Got job 0 (show at Main.scala:111) with 1 output partitions
[16:52:52,720] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:111)
[16:52:52,721] INFO  {DAGScheduler} Parents of final stage: List()
[16:52:52,725] INFO  {DAGScheduler} Missing parents: List()
[16:52:52,747] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:111), which has no missing parents
[16:52:53,081] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 10.9 KB, free 1128.9 MB)
[16:52:53,139] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.8 KB, free 1128.9 MB)
[16:52:53,145] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:34145 (size: 4.8 KB, free: 1128.9 MB)
[16:52:53,151] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:52:53,159] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:111)
[16:52:53,163] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:52:53,292] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:52:53,294] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169333 bytes)
[16:52:53,310] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:52:54,077] INFO  {CodeGenerator} Code generated in 547.587551 ms
[16:52:54,582] INFO  {CodeGenerator} Code generated in 136.954631 ms
[16:52:54,632] ERROR {Executor} Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), DoubleType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), DoubleType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), DoubleType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), DoubleType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more
[16:52:54,698] WARN  {TaskSetManager} Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), DoubleType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), DoubleType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), DoubleType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), DoubleType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more

[16:52:54,703] ERROR {TaskSetManager} Task 0 in stage 0.0 failed 1 times; aborting job
[16:52:54,707] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:52:54,721] INFO  {TaskSchedulerImpl} Cancelling stage 0
[16:52:54,724] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:111) failed in 1.538 s
[16:52:54,726] INFO  {DAGScheduler} Job 0 failed: show at Main.scala:111, took 2.049199 s
[16:52:54,744] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:52:54,753] INFO  {ServerConnector} Stopped ServerConnector@d284c2c{HTTP/1.1}{0.0.0.0:4040}
[16:52:54,758] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59f63e24{/stages/stage/kill,null,UNAVAILABLE}
[16:52:54,759] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@42463763{/api,null,UNAVAILABLE}
[16:52:54,760] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1338fb5{/,null,UNAVAILABLE}
[16:52:54,761] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5aac4250{/static,null,UNAVAILABLE}
[16:52:54,761] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6b3e12b5{/executors/threadDump/json,null,UNAVAILABLE}
[16:52:54,762] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6c45ee6e{/executors/threadDump,null,UNAVAILABLE}
[16:52:54,763] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/executors/json,null,UNAVAILABLE}
[16:52:54,763] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/executors,null,UNAVAILABLE}
[16:52:54,764] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/environment/json,null,UNAVAILABLE}
[16:52:54,764] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/environment,null,UNAVAILABLE}
[16:52:54,765] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/storage/rdd/json,null,UNAVAILABLE}
[16:52:54,765] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/storage/rdd,null,UNAVAILABLE}
[16:52:54,766] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/storage/json,null,UNAVAILABLE}
[16:52:54,766] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/storage,null,UNAVAILABLE}
[16:52:54,767] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@542e560f{/stages/pool/json,null,UNAVAILABLE}
[16:52:54,768] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@241e8ea6{/stages/pool,null,UNAVAILABLE}
[16:52:54,768] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3243b914{/stages/stage/json,null,UNAVAILABLE}
[16:52:54,769] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@31d0e481{/stages/stage,null,UNAVAILABLE}
[16:52:54,769] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59252cb6{/stages/json,null,UNAVAILABLE}
[16:52:54,770] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6d9f7a80{/stages,null,UNAVAILABLE}
[16:52:54,770] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5ccbeb64{/jobs/job/json,null,UNAVAILABLE}
[16:52:54,771] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@112f364d{/jobs/job,null,UNAVAILABLE}
[16:52:54,771] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@362045c0{/jobs/json,null,UNAVAILABLE}
[16:52:54,772] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5a9d6f02{/jobs,null,UNAVAILABLE}
[16:52:54,776] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:52:54,805] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:52:54,815] INFO  {MemoryStore} MemoryStore cleared
[16:52:54,816] INFO  {BlockManager} BlockManager stopped
[16:52:54,827] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:52:54,833] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:52:54,843] INFO  {SparkContext} Successfully stopped SparkContext
[16:52:54,844] INFO  {ShutdownHookManager} Shutdown hook called
[16:52:54,846] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-4d230a74-8264-4480-a4e2-5ec2f5777a37
[16:53:44,288] INFO  {SparkContext} Running Spark version 2.0.1
[16:53:44,942] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:53:45,299] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:53:45,301] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:53:45,542] INFO  {SecurityManager} Changing view acls to: victor
[16:53:45,543] INFO  {SecurityManager} Changing modify acls to: victor
[16:53:45,545] INFO  {SecurityManager} Changing view acls groups to: 
[16:53:45,546] INFO  {SecurityManager} Changing modify acls groups to: 
[16:53:45,547] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:53:46,510] INFO  {Utils} Successfully started service 'sparkDriver' on port 41735.
[16:53:46,553] INFO  {SparkEnv} Registering MapOutputTracker
[16:53:46,594] INFO  {SparkEnv} Registering BlockManagerMaster
[16:53:46,624] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-9b6bb276-d187-41ba-b5c3-4f4d7ac14fc5
[16:53:46,668] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:53:46,779] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:53:46,992] INFO  {log} Logging initialized @4696ms
[16:53:47,261] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:53:47,307] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/jobs,null,AVAILABLE}
[16:53:47,308] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/jobs/json,null,AVAILABLE}
[16:53:47,309] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/jobs/job,null,AVAILABLE}
[16:53:47,310] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/jobs/job/json,null,AVAILABLE}
[16:53:47,311] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/stages,null,AVAILABLE}
[16:53:47,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/json,null,AVAILABLE}
[16:53:47,312] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/stages/stage,null,AVAILABLE}
[16:53:47,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/json,null,AVAILABLE}
[16:53:47,313] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6c45ee6e{/stages/pool,null,AVAILABLE}
[16:53:47,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6b3e12b5{/stages/pool/json,null,AVAILABLE}
[16:53:47,314] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5aac4250{/storage,null,AVAILABLE}
[16:53:47,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1338fb5{/storage/json,null,AVAILABLE}
[16:53:47,315] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@42463763{/storage/rdd,null,AVAILABLE}
[16:53:47,316] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59f63e24{/storage/rdd/json,null,AVAILABLE}
[16:53:47,316] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@61f05988{/environment,null,AVAILABLE}
[16:53:47,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7ca33c24{/environment/json,null,AVAILABLE}
[16:53:47,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@fade1fc{/executors,null,AVAILABLE}
[16:53:47,317] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@67c2e933{/executors/json,null,AVAILABLE}
[16:53:47,318] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@41dd05a{/executors/threadDump,null,AVAILABLE}
[16:53:47,318] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@613a8ee1{/executors/threadDump/json,null,AVAILABLE}
[16:53:47,330] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@178213b{/static,null,AVAILABLE}
[16:53:47,331] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7103cb56{/,null,AVAILABLE}
[16:53:47,332] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b765a2c{/api,null,AVAILABLE}
[16:53:47,333] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2e8e8225{/stages/stage/kill,null,AVAILABLE}
[16:53:47,346] INFO  {ServerConnector} Started ServerConnector@68ead359{HTTP/1.1}{0.0.0.0:4040}
[16:53:47,347] INFO  {Server} Started @5068ms
[16:53:47,348] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:53:47,352] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:53:47,584] INFO  {Executor} Starting executor ID driver on host localhost
[16:53:47,648] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38299.
[16:53:47,650] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:38299
[16:53:47,655] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 38299)
[16:53:47,663] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:38299 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 38299)
[16:53:47,680] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 38299)
[16:53:48,019] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a8a60bc{/metrics/json,null,AVAILABLE}
[16:53:52,388] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@194d329e{/SQL,null,AVAILABLE}
[16:53:52,390] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7fe6d{/SQL/json,null,AVAILABLE}
[16:53:52,393] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1c9fbb61{/SQL/execution,null,AVAILABLE}
[16:53:52,395] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@15d42ccb{/SQL/execution/json,null,AVAILABLE}
[16:53:52,400] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4c361f63{/static/sql,null,AVAILABLE}
[16:53:52,434] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:53:54,092] INFO  {SparkContext} Starting job: show at Main.scala:111
[16:53:54,133] INFO  {DAGScheduler} Got job 0 (show at Main.scala:111) with 1 output partitions
[16:53:54,135] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:111)
[16:53:54,136] INFO  {DAGScheduler} Parents of final stage: List()
[16:53:54,140] INFO  {DAGScheduler} Missing parents: List()
[16:53:54,161] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:111), which has no missing parents
[16:53:54,479] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 10.9 KB, free 1128.9 MB)
[16:53:54,533] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.9 KB, free 1128.9 MB)
[16:53:54,538] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:38299 (size: 4.9 KB, free: 1128.9 MB)
[16:53:54,545] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:53:54,555] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:111)
[16:53:54,559] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:53:54,672] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:53:54,675] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169333 bytes)
[16:53:54,690] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:53:55,439] INFO  {CodeGenerator} Code generated in 532.51645 ms
[16:53:55,793] INFO  {CodeGenerator} Code generated in 50.32943 ms
[16:53:55,817] ERROR {Executor} Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_5$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more
[16:53:55,845] WARN  {TaskSetManager} Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_5$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more

[16:53:55,849] ERROR {TaskSetManager} Task 0 in stage 0.0 failed 1 times; aborting job
[16:53:55,851] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:53:55,859] INFO  {TaskSchedulerImpl} Cancelling stage 0
[16:53:55,861] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:111) failed in 1.281 s
[16:53:55,862] INFO  {DAGScheduler} Job 0 failed: show at Main.scala:111, took 1.769181 s
[16:53:55,869] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:53:55,874] INFO  {ServerConnector} Stopped ServerConnector@68ead359{HTTP/1.1}{0.0.0.0:4040}
[16:53:55,877] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2e8e8225{/stages/stage/kill,null,UNAVAILABLE}
[16:53:55,877] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1b765a2c{/api,null,UNAVAILABLE}
[16:53:55,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7103cb56{/,null,UNAVAILABLE}
[16:53:55,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@178213b{/static,null,UNAVAILABLE}
[16:53:55,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@613a8ee1{/executors/threadDump/json,null,UNAVAILABLE}
[16:53:55,878] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@41dd05a{/executors/threadDump,null,UNAVAILABLE}
[16:53:55,879] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@67c2e933{/executors/json,null,UNAVAILABLE}
[16:53:55,879] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@fade1fc{/executors,null,UNAVAILABLE}
[16:53:55,879] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7ca33c24{/environment/json,null,UNAVAILABLE}
[16:53:55,879] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@61f05988{/environment,null,UNAVAILABLE}
[16:53:55,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59f63e24{/storage/rdd/json,null,UNAVAILABLE}
[16:53:55,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@42463763{/storage/rdd,null,UNAVAILABLE}
[16:53:55,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1338fb5{/storage/json,null,UNAVAILABLE}
[16:53:55,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5aac4250{/storage,null,UNAVAILABLE}
[16:53:55,880] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6b3e12b5{/stages/pool/json,null,UNAVAILABLE}
[16:53:55,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6c45ee6e{/stages/pool,null,UNAVAILABLE}
[16:53:55,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/json,null,UNAVAILABLE}
[16:53:55,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/stages/stage,null,UNAVAILABLE}
[16:53:55,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/json,null,UNAVAILABLE}
[16:53:55,881] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/stages,null,UNAVAILABLE}
[16:53:55,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/jobs/job/json,null,UNAVAILABLE}
[16:53:55,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/jobs/job,null,UNAVAILABLE}
[16:53:55,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/jobs/json,null,UNAVAILABLE}
[16:53:55,882] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/jobs,null,UNAVAILABLE}
[16:53:55,883] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:53:55,894] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:53:55,898] INFO  {MemoryStore} MemoryStore cleared
[16:53:55,898] INFO  {BlockManager} BlockManager stopped
[16:53:55,903] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:53:55,905] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:53:55,907] INFO  {SparkContext} Successfully stopped SparkContext
[16:53:55,908] INFO  {ShutdownHookManager} Shutdown hook called
[16:53:55,908] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-5e1a75ce-45ae-48b3-9162-5f37b9033669
[16:55:13,017] INFO  {SparkContext} Running Spark version 2.0.1
[16:55:13,265] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:55:13,390] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:55:13,391] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:55:13,473] INFO  {SecurityManager} Changing view acls to: victor
[16:55:13,474] INFO  {SecurityManager} Changing modify acls to: victor
[16:55:13,475] INFO  {SecurityManager} Changing view acls groups to: 
[16:55:13,476] INFO  {SecurityManager} Changing modify acls groups to: 
[16:55:13,476] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:55:14,366] INFO  {Utils} Successfully started service 'sparkDriver' on port 33511.
[16:55:14,410] INFO  {SparkEnv} Registering MapOutputTracker
[16:55:14,454] INFO  {SparkEnv} Registering BlockManagerMaster
[16:55:14,497] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-c0527f43-d213-4564-9c4b-381b146eda0a
[16:55:14,535] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:55:14,660] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:55:14,861] INFO  {log} Logging initialized @2597ms
[16:55:15,162] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:55:15,201] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/jobs,null,AVAILABLE}
[16:55:15,202] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/jobs/json,null,AVAILABLE}
[16:55:15,202] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/jobs/job,null,AVAILABLE}
[16:55:15,203] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/jobs/job/json,null,AVAILABLE}
[16:55:15,203] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/stages,null,AVAILABLE}
[16:55:15,204] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/json,null,AVAILABLE}
[16:55:15,204] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/stages/stage,null,AVAILABLE}
[16:55:15,205] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/json,null,AVAILABLE}
[16:55:15,205] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6c45ee6e{/stages/pool,null,AVAILABLE}
[16:55:15,206] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6b3e12b5{/stages/pool/json,null,AVAILABLE}
[16:55:15,207] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5aac4250{/storage,null,AVAILABLE}
[16:55:15,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1338fb5{/storage/json,null,AVAILABLE}
[16:55:15,208] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@42463763{/storage/rdd,null,AVAILABLE}
[16:55:15,209] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59f63e24{/storage/rdd/json,null,AVAILABLE}
[16:55:15,209] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@61f05988{/environment,null,AVAILABLE}
[16:55:15,210] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7ca33c24{/environment/json,null,AVAILABLE}
[16:55:15,210] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@fade1fc{/executors,null,AVAILABLE}
[16:55:15,211] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@67c2e933{/executors/json,null,AVAILABLE}
[16:55:15,211] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@41dd05a{/executors/threadDump,null,AVAILABLE}
[16:55:15,212] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@613a8ee1{/executors/threadDump/json,null,AVAILABLE}
[16:55:15,226] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@178213b{/static,null,AVAILABLE}
[16:55:15,227] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7103cb56{/,null,AVAILABLE}
[16:55:15,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b765a2c{/api,null,AVAILABLE}
[16:55:15,229] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2e8e8225{/stages/stage/kill,null,AVAILABLE}
[16:55:15,243] INFO  {ServerConnector} Started ServerConnector@68ead359{HTTP/1.1}{0.0.0.0:4040}
[16:55:15,243] INFO  {Server} Started @2982ms
[16:55:15,244] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:55:15,247] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:55:15,480] INFO  {Executor} Starting executor ID driver on host localhost
[16:55:15,541] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38049.
[16:55:15,543] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:38049
[16:55:15,550] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 38049)
[16:55:15,560] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:38049 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 38049)
[16:55:15,577] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 38049)
[16:55:15,919] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a8a60bc{/metrics/json,null,AVAILABLE}
[16:55:20,088] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@194d329e{/SQL,null,AVAILABLE}
[16:55:20,089] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7fe6d{/SQL/json,null,AVAILABLE}
[16:55:20,091] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1c9fbb61{/SQL/execution,null,AVAILABLE}
[16:55:20,092] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@15d42ccb{/SQL/execution/json,null,AVAILABLE}
[16:55:20,095] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4c361f63{/static/sql,null,AVAILABLE}
[16:55:20,124] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:55:21,647] INFO  {SparkContext} Starting job: show at Main.scala:111
[16:55:21,685] INFO  {DAGScheduler} Got job 0 (show at Main.scala:111) with 1 output partitions
[16:55:21,686] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:111)
[16:55:21,686] INFO  {DAGScheduler} Parents of final stage: List()
[16:55:21,690] INFO  {DAGScheduler} Missing parents: List()
[16:55:21,708] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:111), which has no missing parents
[16:55:22,024] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 10.9 KB, free 1128.9 MB)
[16:55:22,076] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.9 KB, free 1128.9 MB)
[16:55:22,080] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:38049 (size: 4.9 KB, free: 1128.9 MB)
[16:55:22,085] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:55:22,094] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:111)
[16:55:22,098] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:55:22,233] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:55:22,236] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169333 bytes)
[16:55:22,255] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:55:22,974] INFO  {CodeGenerator} Code generated in 506.268579 ms
[16:55:23,208] INFO  {CodeGenerator} Code generated in 55.333156 ms
[16:55:23,227] ERROR {Executor} Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_5$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more
[16:55:23,254] WARN  {TaskSetManager} Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_5$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more

[16:55:23,256] ERROR {TaskSetManager} Task 0 in stage 0.0 failed 1 times; aborting job
[16:55:23,258] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:55:23,263] INFO  {TaskSchedulerImpl} Cancelling stage 0
[16:55:23,265] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:111) failed in 1.145 s
[16:55:23,266] INFO  {DAGScheduler} Job 0 failed: show at Main.scala:111, took 1.617927 s
[16:55:23,272] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:55:23,277] INFO  {ServerConnector} Stopped ServerConnector@68ead359{HTTP/1.1}{0.0.0.0:4040}
[16:55:23,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2e8e8225{/stages/stage/kill,null,UNAVAILABLE}
[16:55:23,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1b765a2c{/api,null,UNAVAILABLE}
[16:55:23,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7103cb56{/,null,UNAVAILABLE}
[16:55:23,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@178213b{/static,null,UNAVAILABLE}
[16:55:23,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@613a8ee1{/executors/threadDump/json,null,UNAVAILABLE}
[16:55:23,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@41dd05a{/executors/threadDump,null,UNAVAILABLE}
[16:55:23,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@67c2e933{/executors/json,null,UNAVAILABLE}
[16:55:23,279] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@fade1fc{/executors,null,UNAVAILABLE}
[16:55:23,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7ca33c24{/environment/json,null,UNAVAILABLE}
[16:55:23,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@61f05988{/environment,null,UNAVAILABLE}
[16:55:23,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59f63e24{/storage/rdd/json,null,UNAVAILABLE}
[16:55:23,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@42463763{/storage/rdd,null,UNAVAILABLE}
[16:55:23,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1338fb5{/storage/json,null,UNAVAILABLE}
[16:55:23,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5aac4250{/storage,null,UNAVAILABLE}
[16:55:23,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6b3e12b5{/stages/pool/json,null,UNAVAILABLE}
[16:55:23,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6c45ee6e{/stages/pool,null,UNAVAILABLE}
[16:55:23,280] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/json,null,UNAVAILABLE}
[16:55:23,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/stages/stage,null,UNAVAILABLE}
[16:55:23,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/json,null,UNAVAILABLE}
[16:55:23,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/stages,null,UNAVAILABLE}
[16:55:23,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/jobs/job/json,null,UNAVAILABLE}
[16:55:23,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/jobs/job,null,UNAVAILABLE}
[16:55:23,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/jobs/json,null,UNAVAILABLE}
[16:55:23,281] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/jobs,null,UNAVAILABLE}
[16:55:23,283] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:55:23,292] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:55:23,296] INFO  {MemoryStore} MemoryStore cleared
[16:55:23,296] INFO  {BlockManager} BlockManager stopped
[16:55:23,301] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:55:23,304] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:55:23,305] INFO  {SparkContext} Successfully stopped SparkContext
[16:55:23,306] INFO  {ShutdownHookManager} Shutdown hook called
[16:55:23,307] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-a02ca38c-a489-4b63-a534-9b21d9570a89
[16:55:50,606] INFO  {SparkContext} Running Spark version 2.0.1
[16:55:51,298] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:55:51,583] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:55:51,585] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:55:51,815] INFO  {SecurityManager} Changing view acls to: victor
[16:55:51,816] INFO  {SecurityManager} Changing modify acls to: victor
[16:55:51,818] INFO  {SecurityManager} Changing view acls groups to: 
[16:55:51,820] INFO  {SecurityManager} Changing modify acls groups to: 
[16:55:51,822] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:55:52,921] INFO  {Utils} Successfully started service 'sparkDriver' on port 43491.
[16:55:52,966] INFO  {SparkEnv} Registering MapOutputTracker
[16:55:53,005] INFO  {SparkEnv} Registering BlockManagerMaster
[16:55:53,037] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-7af6210f-0135-411d-89e8-69c62926d5c5
[16:55:53,076] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:55:53,202] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:55:53,402] INFO  {log} Logging initialized @4583ms
[16:55:53,720] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:55:53,764] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/jobs,null,AVAILABLE}
[16:55:53,765] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/jobs/json,null,AVAILABLE}
[16:55:53,765] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/jobs/job,null,AVAILABLE}
[16:55:53,766] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/jobs/job/json,null,AVAILABLE}
[16:55:53,766] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/stages,null,AVAILABLE}
[16:55:53,767] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/json,null,AVAILABLE}
[16:55:53,767] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6c45ee6e{/stages/stage,null,AVAILABLE}
[16:55:53,767] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6b3e12b5{/stages/stage/json,null,AVAILABLE}
[16:55:53,768] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5aac4250{/stages/pool,null,AVAILABLE}
[16:55:53,768] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1338fb5{/stages/pool/json,null,AVAILABLE}
[16:55:53,769] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@42463763{/storage,null,AVAILABLE}
[16:55:53,769] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59f63e24{/storage/json,null,AVAILABLE}
[16:55:53,770] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@61f05988{/storage/rdd,null,AVAILABLE}
[16:55:53,770] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7ca33c24{/storage/rdd/json,null,AVAILABLE}
[16:55:53,771] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@fade1fc{/environment,null,AVAILABLE}
[16:55:53,771] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@67c2e933{/environment/json,null,AVAILABLE}
[16:55:53,771] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@41dd05a{/executors,null,AVAILABLE}
[16:55:53,772] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@613a8ee1{/executors/json,null,AVAILABLE}
[16:55:53,772] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@178213b{/executors/threadDump,null,AVAILABLE}
[16:55:53,773] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7103cb56{/executors/threadDump/json,null,AVAILABLE}
[16:55:53,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b765a2c{/static,null,AVAILABLE}
[16:55:53,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2e8e8225{/,null,AVAILABLE}
[16:55:53,788] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ebf0f36{/api,null,AVAILABLE}
[16:55:53,789] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18920cc{/stages/stage/kill,null,AVAILABLE}
[16:55:53,802] INFO  {ServerConnector} Started ServerConnector@180da663{HTTP/1.1}{0.0.0.0:4040}
[16:55:53,803] INFO  {Server} Started @4986ms
[16:55:53,803] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:55:53,807] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:55:54,018] INFO  {Executor} Starting executor ID driver on host localhost
[16:55:54,091] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33003.
[16:55:54,093] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:33003
[16:55:54,099] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 33003)
[16:55:54,106] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:33003 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 33003)
[16:55:54,119] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 33003)
[16:55:54,454] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7859e786{/metrics/json,null,AVAILABLE}
[16:55:58,937] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7fe6d{/SQL,null,AVAILABLE}
[16:55:58,939] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@24386839{/SQL/json,null,AVAILABLE}
[16:55:58,941] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@15d42ccb{/SQL/execution,null,AVAILABLE}
[16:55:58,943] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@46383a78{/SQL/execution/json,null,AVAILABLE}
[16:55:58,947] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4eb166a1{/static/sql,null,AVAILABLE}
[16:55:58,976] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:56:00,615] INFO  {SparkContext} Starting job: show at Main.scala:111
[16:56:00,656] INFO  {DAGScheduler} Got job 0 (show at Main.scala:111) with 1 output partitions
[16:56:00,658] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:111)
[16:56:00,659] INFO  {DAGScheduler} Parents of final stage: List()
[16:56:00,663] INFO  {DAGScheduler} Missing parents: List()
[16:56:00,682] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:111), which has no missing parents
[16:56:01,022] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 10.9 KB, free 1128.9 MB)
[16:56:01,078] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.9 KB, free 1128.9 MB)
[16:56:01,083] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:33003 (size: 4.9 KB, free: 1128.9 MB)
[16:56:01,088] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:56:01,096] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:111)
[16:56:01,099] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:56:01,231] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:56:01,233] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169333 bytes)
[16:56:01,249] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:56:02,016] INFO  {CodeGenerator} Code generated in 533.483114 ms
[16:56:02,488] INFO  {CodeGenerator} Code generated in 131.928349 ms
[16:56:02,538] ERROR {Executor} Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_5$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more
[16:56:02,600] WARN  {TaskSetManager} Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_5$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more

[16:56:02,606] ERROR {TaskSetManager} Task 0 in stage 0.0 failed 1 times; aborting job
[16:56:02,611] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:56:02,620] INFO  {TaskSchedulerImpl} Cancelling stage 0
[16:56:02,624] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:111) failed in 1.500 s
[16:56:02,627] INFO  {DAGScheduler} Job 0 failed: show at Main.scala:111, took 2.011512 s
[16:56:02,645] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:56:02,655] INFO  {ServerConnector} Stopped ServerConnector@180da663{HTTP/1.1}{0.0.0.0:4040}
[16:56:02,659] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@18920cc{/stages/stage/kill,null,UNAVAILABLE}
[16:56:02,661] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6ebf0f36{/api,null,UNAVAILABLE}
[16:56:02,661] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2e8e8225{/,null,UNAVAILABLE}
[16:56:02,662] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1b765a2c{/static,null,UNAVAILABLE}
[16:56:02,663] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7103cb56{/executors/threadDump/json,null,UNAVAILABLE}
[16:56:02,663] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@178213b{/executors/threadDump,null,UNAVAILABLE}
[16:56:02,664] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@613a8ee1{/executors/json,null,UNAVAILABLE}
[16:56:02,664] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@41dd05a{/executors,null,UNAVAILABLE}
[16:56:02,665] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@67c2e933{/environment/json,null,UNAVAILABLE}
[16:56:02,667] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@fade1fc{/environment,null,UNAVAILABLE}
[16:56:02,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7ca33c24{/storage/rdd/json,null,UNAVAILABLE}
[16:56:02,668] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@61f05988{/storage/rdd,null,UNAVAILABLE}
[16:56:02,669] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59f63e24{/storage/json,null,UNAVAILABLE}
[16:56:02,670] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@42463763{/storage,null,UNAVAILABLE}
[16:56:02,671] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1338fb5{/stages/pool/json,null,UNAVAILABLE}
[16:56:02,671] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5aac4250{/stages/pool,null,UNAVAILABLE}
[16:56:02,672] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6b3e12b5{/stages/stage/json,null,UNAVAILABLE}
[16:56:02,672] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6c45ee6e{/stages/stage,null,UNAVAILABLE}
[16:56:02,673] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/json,null,UNAVAILABLE}
[16:56:02,674] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/stages,null,UNAVAILABLE}
[16:56:02,674] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/jobs/job/json,null,UNAVAILABLE}
[16:56:02,674] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/jobs/job,null,UNAVAILABLE}
[16:56:02,675] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/jobs/json,null,UNAVAILABLE}
[16:56:02,675] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/jobs,null,UNAVAILABLE}
[16:56:02,678] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:56:02,705] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:56:02,714] INFO  {MemoryStore} MemoryStore cleared
[16:56:02,715] INFO  {BlockManager} BlockManager stopped
[16:56:02,727] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:56:02,734] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:56:02,739] INFO  {SparkContext} Successfully stopped SparkContext
[16:56:02,740] INFO  {ShutdownHookManager} Shutdown hook called
[16:56:02,742] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-7e9c8542-28e0-4a41-83e9-e63c4737f5d2
[16:57:59,808] INFO  {SparkContext} Running Spark version 2.0.1
[16:58:00,444] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:58:00,849] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:58:00,851] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:58:01,074] INFO  {SecurityManager} Changing view acls to: victor
[16:58:01,076] INFO  {SecurityManager} Changing modify acls to: victor
[16:58:01,078] INFO  {SecurityManager} Changing view acls groups to: 
[16:58:01,080] INFO  {SecurityManager} Changing modify acls groups to: 
[16:58:01,082] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:58:01,945] INFO  {Utils} Successfully started service 'sparkDriver' on port 33349.
[16:58:01,990] INFO  {SparkEnv} Registering MapOutputTracker
[16:58:02,029] INFO  {SparkEnv} Registering BlockManagerMaster
[16:58:02,059] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-8ae95064-5d87-4eb7-ba47-6b9679f9e8d9
[16:58:02,100] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:58:02,219] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:58:02,409] INFO  {log} Logging initialized @4473ms
[16:58:02,714] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:58:02,777] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/jobs,null,AVAILABLE}
[16:58:02,778] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/jobs/json,null,AVAILABLE}
[16:58:02,779] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/jobs/job,null,AVAILABLE}
[16:58:02,780] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/jobs/job/json,null,AVAILABLE}
[16:58:02,781] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/stages,null,AVAILABLE}
[16:58:02,781] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/json,null,AVAILABLE}
[16:58:02,782] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/stages/stage,null,AVAILABLE}
[16:58:02,783] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/json,null,AVAILABLE}
[16:58:02,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6c45ee6e{/stages/pool,null,AVAILABLE}
[16:58:02,784] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6b3e12b5{/stages/pool/json,null,AVAILABLE}
[16:58:02,785] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5aac4250{/storage,null,AVAILABLE}
[16:58:02,786] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1338fb5{/storage/json,null,AVAILABLE}
[16:58:02,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@42463763{/storage/rdd,null,AVAILABLE}
[16:58:02,787] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59f63e24{/storage/rdd/json,null,AVAILABLE}
[16:58:02,788] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@61f05988{/environment,null,AVAILABLE}
[16:58:02,788] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7ca33c24{/environment/json,null,AVAILABLE}
[16:58:02,788] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@fade1fc{/executors,null,AVAILABLE}
[16:58:02,789] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@67c2e933{/executors/json,null,AVAILABLE}
[16:58:02,789] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@41dd05a{/executors/threadDump,null,AVAILABLE}
[16:58:02,790] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@613a8ee1{/executors/threadDump/json,null,AVAILABLE}
[16:58:02,804] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@178213b{/static,null,AVAILABLE}
[16:58:02,804] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7103cb56{/,null,AVAILABLE}
[16:58:02,806] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b765a2c{/api,null,AVAILABLE}
[16:58:02,807] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2e8e8225{/stages/stage/kill,null,AVAILABLE}
[16:58:02,822] INFO  {ServerConnector} Started ServerConnector@68ead359{HTTP/1.1}{0.0.0.0:4040}
[16:58:02,823] INFO  {Server} Started @4889ms
[16:58:02,823] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:58:02,827] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:58:03,088] INFO  {Executor} Starting executor ID driver on host localhost
[16:58:03,172] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42887.
[16:58:03,174] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:42887
[16:58:03,179] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 42887)
[16:58:03,193] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:42887 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 42887)
[16:58:03,201] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 42887)
[16:58:03,555] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a8a60bc{/metrics/json,null,AVAILABLE}
[16:58:08,127] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@194d329e{/SQL,null,AVAILABLE}
[16:58:08,129] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7fe6d{/SQL/json,null,AVAILABLE}
[16:58:08,131] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1c9fbb61{/SQL/execution,null,AVAILABLE}
[16:58:08,134] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@15d42ccb{/SQL/execution/json,null,AVAILABLE}
[16:58:08,139] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4c361f63{/static/sql,null,AVAILABLE}
[16:58:08,177] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:58:09,786] INFO  {SparkContext} Starting job: show at Main.scala:124
[16:58:09,828] INFO  {DAGScheduler} Got job 0 (show at Main.scala:124) with 1 output partitions
[16:58:09,829] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:124)
[16:58:09,830] INFO  {DAGScheduler} Parents of final stage: List()
[16:58:09,833] INFO  {DAGScheduler} Missing parents: List()
[16:58:09,850] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:124), which has no missing parents
[16:58:10,195] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 10.9 KB, free 1128.9 MB)
[16:58:10,253] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.9 KB, free 1128.9 MB)
[16:58:10,259] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:42887 (size: 4.9 KB, free: 1128.9 MB)
[16:58:10,265] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:58:10,275] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:124)
[16:58:10,280] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:58:10,415] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:58:10,417] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169333 bytes)
[16:58:10,432] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:58:11,167] INFO  {CodeGenerator} Code generated in 519.836953 ms
[16:58:11,633] INFO  {CodeGenerator} Code generated in 129.188676 ms
[16:58:11,797] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 1530 bytes result sent to driver
[16:58:11,813] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 1487 ms on localhost (1/1)
[16:58:11,816] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:58:11,824] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:124) finished in 1.524 s
[16:58:11,838] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:124, took 2.051322 s
[16:58:11,918] INFO  {CodeGenerator} Code generated in 47.063093 ms
[16:58:11,973] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:58:11,986] INFO  {ServerConnector} Stopped ServerConnector@68ead359{HTTP/1.1}{0.0.0.0:4040}
[16:58:11,993] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2e8e8225{/stages/stage/kill,null,UNAVAILABLE}
[16:58:11,994] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1b765a2c{/api,null,UNAVAILABLE}
[16:58:11,995] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7103cb56{/,null,UNAVAILABLE}
[16:58:11,996] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@178213b{/static,null,UNAVAILABLE}
[16:58:11,997] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@613a8ee1{/executors/threadDump/json,null,UNAVAILABLE}
[16:58:11,997] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@41dd05a{/executors/threadDump,null,UNAVAILABLE}
[16:58:11,998] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@67c2e933{/executors/json,null,UNAVAILABLE}
[16:58:11,998] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@fade1fc{/executors,null,UNAVAILABLE}
[16:58:11,999] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7ca33c24{/environment/json,null,UNAVAILABLE}
[16:58:11,999] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@61f05988{/environment,null,UNAVAILABLE}
[16:58:12,000] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59f63e24{/storage/rdd/json,null,UNAVAILABLE}
[16:58:12,001] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@42463763{/storage/rdd,null,UNAVAILABLE}
[16:58:12,001] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1338fb5{/storage/json,null,UNAVAILABLE}
[16:58:12,002] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5aac4250{/storage,null,UNAVAILABLE}
[16:58:12,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6b3e12b5{/stages/pool/json,null,UNAVAILABLE}
[16:58:12,003] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6c45ee6e{/stages/pool,null,UNAVAILABLE}
[16:58:12,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/json,null,UNAVAILABLE}
[16:58:12,004] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/stages/stage,null,UNAVAILABLE}
[16:58:12,005] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/json,null,UNAVAILABLE}
[16:58:12,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/stages,null,UNAVAILABLE}
[16:58:12,006] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/jobs/job/json,null,UNAVAILABLE}
[16:58:12,007] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/jobs/job,null,UNAVAILABLE}
[16:58:12,007] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/jobs/json,null,UNAVAILABLE}
[16:58:12,007] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/jobs,null,UNAVAILABLE}
[16:58:12,011] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:58:12,037] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:58:12,049] INFO  {MemoryStore} MemoryStore cleared
[16:58:12,051] INFO  {BlockManager} BlockManager stopped
[16:58:12,064] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:58:12,070] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:58:12,075] INFO  {SparkContext} Successfully stopped SparkContext
[16:58:12,076] INFO  {ShutdownHookManager} Shutdown hook called
[16:58:12,078] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-c057cf46-19e1-41e4-9a80-77ce55512f5f
[16:59:37,217] INFO  {SparkContext} Running Spark version 2.0.1
[16:59:37,750] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:59:38,059] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:59:38,061] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:59:38,291] INFO  {SecurityManager} Changing view acls to: victor
[16:59:38,294] INFO  {SecurityManager} Changing modify acls to: victor
[16:59:38,297] INFO  {SecurityManager} Changing view acls groups to: 
[16:59:38,301] INFO  {SecurityManager} Changing modify acls groups to: 
[16:59:38,303] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[16:59:39,270] INFO  {Utils} Successfully started service 'sparkDriver' on port 34539.
[16:59:39,319] INFO  {SparkEnv} Registering MapOutputTracker
[16:59:39,359] INFO  {SparkEnv} Registering BlockManagerMaster
[16:59:39,389] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-eb9f8976-6828-4f26-aa8f-47ec0b9854b7
[16:59:39,437] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[16:59:39,559] INFO  {SparkEnv} Registering OutputCommitCoordinator
[16:59:39,784] INFO  {log} Logging initialized @4199ms
[16:59:40,053] INFO  {Server} jetty-9.2.z-SNAPSHOT
[16:59:40,096] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@626c44e7{/jobs,null,AVAILABLE}
[16:59:40,097] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4dc8caa7{/jobs/json,null,AVAILABLE}
[16:59:40,098] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/jobs/job,null,AVAILABLE}
[16:59:40,099] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/jobs/job/json,null,AVAILABLE}
[16:59:40,099] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/stages,null,AVAILABLE}
[16:59:40,100] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/stages/json,null,AVAILABLE}
[16:59:40,101] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/stages/stage,null,AVAILABLE}
[16:59:40,102] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/json,null,AVAILABLE}
[16:59:40,102] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6c45ee6e{/stages/pool,null,AVAILABLE}
[16:59:40,103] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6b3e12b5{/stages/pool/json,null,AVAILABLE}
[16:59:40,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5aac4250{/storage,null,AVAILABLE}
[16:59:40,104] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1338fb5{/storage/json,null,AVAILABLE}
[16:59:40,105] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@42463763{/storage/rdd,null,AVAILABLE}
[16:59:40,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59f63e24{/storage/rdd/json,null,AVAILABLE}
[16:59:40,106] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@61f05988{/environment,null,AVAILABLE}
[16:59:40,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7ca33c24{/environment/json,null,AVAILABLE}
[16:59:40,107] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@fade1fc{/executors,null,AVAILABLE}
[16:59:40,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@67c2e933{/executors/json,null,AVAILABLE}
[16:59:40,108] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@41dd05a{/executors/threadDump,null,AVAILABLE}
[16:59:40,109] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@613a8ee1{/executors/threadDump/json,null,AVAILABLE}
[16:59:40,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@178213b{/static,null,AVAILABLE}
[16:59:40,121] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7103cb56{/,null,AVAILABLE}
[16:59:40,123] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b765a2c{/api,null,AVAILABLE}
[16:59:40,124] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2e8e8225{/stages/stage/kill,null,AVAILABLE}
[16:59:40,139] INFO  {ServerConnector} Started ServerConnector@68ead359{HTTP/1.1}{0.0.0.0:4040}
[16:59:40,140] INFO  {Server} Started @4558ms
[16:59:40,141] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[16:59:40,146] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[16:59:40,394] INFO  {Executor} Starting executor ID driver on host localhost
[16:59:40,482] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39367.
[16:59:40,484] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:39367
[16:59:40,490] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 39367)
[16:59:40,497] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:39367 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 39367)
[16:59:40,510] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 39367)
[16:59:40,861] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4a8a60bc{/metrics/json,null,AVAILABLE}
[16:59:46,194] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@194d329e{/SQL,null,AVAILABLE}
[16:59:46,196] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7e7fe6d{/SQL/json,null,AVAILABLE}
[16:59:46,198] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1c9fbb61{/SQL/execution,null,AVAILABLE}
[16:59:46,209] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@15d42ccb{/SQL/execution/json,null,AVAILABLE}
[16:59:46,216] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@4c361f63{/static/sql,null,AVAILABLE}
[16:59:46,263] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[16:59:48,494] INFO  {SparkContext} Starting job: show at Main.scala:119
[16:59:48,536] INFO  {DAGScheduler} Got job 0 (show at Main.scala:119) with 1 output partitions
[16:59:48,537] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:119)
[16:59:48,537] INFO  {DAGScheduler} Parents of final stage: List()
[16:59:48,540] INFO  {DAGScheduler} Missing parents: List()
[16:59:48,560] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:119), which has no missing parents
[16:59:48,899] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 10.9 KB, free 1128.9 MB)
[16:59:48,955] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.9 KB, free 1128.9 MB)
[16:59:48,960] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:39367 (size: 4.9 KB, free: 1128.9 MB)
[16:59:48,966] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[16:59:48,974] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:119)
[16:59:48,978] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[16:59:49,107] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[16:59:49,110] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169333 bytes)
[16:59:49,127] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[16:59:49,915] INFO  {CodeGenerator} Code generated in 565.868157 ms
[16:59:50,421] INFO  {CodeGenerator} Code generated in 140.262078 ms
[16:59:50,472] ERROR {Executor} Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), DoubleType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more
[16:59:50,550] WARN  {TaskSetManager} Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), DoubleType) AS year#0
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, year)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType) AS loudness#1
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 1, loudness)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType) AS tempo#2
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 2, tempo)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType) AS danceability#3
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 3, danceability)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType) AS duration#4
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 4, duration)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType) AS mode#5
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 5, mode)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType) AS start_of_fade_out#6
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 6, start_of_fade_out)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType) AS key#7
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 7, key)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType) AS energy#8
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 8, energy)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType) AS time_signature#9
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature), IntegerType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 9, time_signature)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType) AS end_of_fade_in#10
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 10, end_of_fade_in)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType) AS analysis_sample_rate#11
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 11, analysis_sample_rate)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType) AS song_hotttnesss#12
+- validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss), DoubleType)
   +- getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 12, song_hotttnesss)
      +- assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object)
         +- input[0, org.apache.spark.sql.Row, true]

	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at org.apache.spark.sql.SparkSession$$anonfun$5.apply(SparkSession.scala:537)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:363)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of double
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:276)
	... 17 more

[16:59:50,556] ERROR {TaskSetManager} Task 0 in stage 0.0 failed 1 times; aborting job
[16:59:50,560] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[16:59:50,570] INFO  {TaskSchedulerImpl} Cancelling stage 0
[16:59:50,573] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:119) failed in 1.570 s
[16:59:50,575] INFO  {DAGScheduler} Job 0 failed: show at Main.scala:119, took 2.080308 s
[16:59:50,593] INFO  {SparkContext} Invoking stop() from shutdown hook
[16:59:50,602] INFO  {ServerConnector} Stopped ServerConnector@68ead359{HTTP/1.1}{0.0.0.0:4040}
[16:59:50,606] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2e8e8225{/stages/stage/kill,null,UNAVAILABLE}
[16:59:50,606] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1b765a2c{/api,null,UNAVAILABLE}
[16:59:50,607] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7103cb56{/,null,UNAVAILABLE}
[16:59:50,607] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@178213b{/static,null,UNAVAILABLE}
[16:59:50,607] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@613a8ee1{/executors/threadDump/json,null,UNAVAILABLE}
[16:59:50,608] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@41dd05a{/executors/threadDump,null,UNAVAILABLE}
[16:59:50,608] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@67c2e933{/executors/json,null,UNAVAILABLE}
[16:59:50,608] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@fade1fc{/executors,null,UNAVAILABLE}
[16:59:50,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7ca33c24{/environment/json,null,UNAVAILABLE}
[16:59:50,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@61f05988{/environment,null,UNAVAILABLE}
[16:59:50,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59f63e24{/storage/rdd/json,null,UNAVAILABLE}
[16:59:50,609] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@42463763{/storage/rdd,null,UNAVAILABLE}
[16:59:50,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1338fb5{/storage/json,null,UNAVAILABLE}
[16:59:50,610] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5aac4250{/storage,null,UNAVAILABLE}
[16:59:50,611] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6b3e12b5{/stages/pool/json,null,UNAVAILABLE}
[16:59:50,612] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6c45ee6e{/stages/pool,null,UNAVAILABLE}
[16:59:50,612] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/stage/json,null,UNAVAILABLE}
[16:59:50,612] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/stages/stage,null,UNAVAILABLE}
[16:59:50,613] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/stages/json,null,UNAVAILABLE}
[16:59:50,613] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/stages,null,UNAVAILABLE}
[16:59:50,614] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/jobs/job/json,null,UNAVAILABLE}
[16:59:50,614] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/jobs/job,null,UNAVAILABLE}
[16:59:50,614] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@4dc8caa7{/jobs/json,null,UNAVAILABLE}
[16:59:50,615] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@626c44e7{/jobs,null,UNAVAILABLE}
[16:59:50,621] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[16:59:50,649] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[16:59:50,659] INFO  {MemoryStore} MemoryStore cleared
[16:59:50,660] INFO  {BlockManager} BlockManager stopped
[16:59:50,675] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[16:59:50,684] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[16:59:50,693] INFO  {SparkContext} Successfully stopped SparkContext
[16:59:50,724] INFO  {ShutdownHookManager} Shutdown hook called
[16:59:50,728] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-97db96a8-3ba4-4eb9-8683-09369844a30c
[16:59:58,768] INFO  {SparkContext} Running Spark version 2.0.1
[16:59:59,431] WARN  {NativeCodeLoader} Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[16:59:59,763] WARN  {Utils} Your hostname, victor resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp4s0)
[16:59:59,764] WARN  {Utils} Set SPARK_LOCAL_IP if you need to bind to another address
[16:59:59,982] INFO  {SecurityManager} Changing view acls to: victor
[16:59:59,985] INFO  {SecurityManager} Changing modify acls to: victor
[16:59:59,989] INFO  {SecurityManager} Changing view acls groups to: 
[16:59:59,992] INFO  {SecurityManager} Changing modify acls groups to: 
[16:59:59,995] INFO  {SecurityManager} SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(victor); groups with view permissions: Set(); users  with modify permissions: Set(victor); groups with modify permissions: Set()
[17:00:01,040] INFO  {Utils} Successfully started service 'sparkDriver' on port 36653.
[17:00:01,092] INFO  {SparkEnv} Registering MapOutputTracker
[17:00:01,135] INFO  {SparkEnv} Registering BlockManagerMaster
[17:00:01,172] INFO  {DiskBlockManager} Created local directory at /tmp/blockmgr-4a2d4092-2589-4d2c-9a13-0295cbd47429
[17:00:01,211] INFO  {MemoryStore} MemoryStore started with capacity 1128.9 MB
[17:00:01,350] INFO  {SparkEnv} Registering OutputCommitCoordinator
[17:00:01,544] INFO  {log} Logging initialized @4462ms
[17:00:01,818] INFO  {Server} jetty-9.2.z-SNAPSHOT
[17:00:01,858] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1d730606{/jobs,null,AVAILABLE}
[17:00:01,859] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3bcbb589{/jobs/json,null,AVAILABLE}
[17:00:01,859] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3b00856b{/jobs/job,null,AVAILABLE}
[17:00:01,860] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@3016fd5e{/jobs/job/json,null,AVAILABLE}
[17:00:01,860] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@35d08e6c{/stages,null,AVAILABLE}
[17:00:01,861] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@53d102a2{/stages/json,null,AVAILABLE}
[17:00:01,861] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6c45ee6e{/stages/stage,null,AVAILABLE}
[17:00:01,862] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6b3e12b5{/stages/stage/json,null,AVAILABLE}
[17:00:01,862] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@5aac4250{/stages/pool,null,AVAILABLE}
[17:00:01,863] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1338fb5{/stages/pool/json,null,AVAILABLE}
[17:00:01,863] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@42463763{/storage,null,AVAILABLE}
[17:00:01,864] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@59f63e24{/storage/json,null,AVAILABLE}
[17:00:01,864] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@61f05988{/storage/rdd,null,AVAILABLE}
[17:00:01,864] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7ca33c24{/storage/rdd/json,null,AVAILABLE}
[17:00:01,865] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@fade1fc{/environment,null,AVAILABLE}
[17:00:01,865] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@67c2e933{/environment/json,null,AVAILABLE}
[17:00:01,866] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@41dd05a{/executors,null,AVAILABLE}
[17:00:01,866] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@613a8ee1{/executors/json,null,AVAILABLE}
[17:00:01,867] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@178213b{/executors/threadDump,null,AVAILABLE}
[17:00:01,868] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7103cb56{/executors/threadDump/json,null,AVAILABLE}
[17:00:01,881] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@1b765a2c{/static,null,AVAILABLE}
[17:00:01,881] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@2e8e8225{/,null,AVAILABLE}
[17:00:01,882] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ebf0f36{/api,null,AVAILABLE}
[17:00:01,883] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@18920cc{/stages/stage/kill,null,AVAILABLE}
[17:00:01,897] INFO  {ServerConnector} Started ServerConnector@41051c8d{HTTP/1.1}{0.0.0.0:4040}
[17:00:01,898] INFO  {Server} Started @4820ms
[17:00:01,899] INFO  {Utils} Successfully started service 'SparkUI' on port 4040.
[17:00:01,903] INFO  {SparkUI} Bound SparkUI to 0.0.0.0, and started at http://192.168.0.103:4040
[17:00:02,149] INFO  {Executor} Starting executor ID driver on host localhost
[17:00:02,228] INFO  {Utils} Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46135.
[17:00:02,230] INFO  {NettyBlockTransferService} Server created on 192.168.0.103:46135
[17:00:02,235] INFO  {BlockManagerMaster} Registering BlockManager BlockManagerId(driver, 192.168.0.103, 46135)
[17:00:02,243] INFO  {BlockManagerMasterEndpoint} Registering block manager 192.168.0.103:46135 with 1128.9 MB RAM, BlockManagerId(driver, 192.168.0.103, 46135)
[17:00:02,260] INFO  {BlockManagerMaster} Registered BlockManager BlockManagerId(driver, 192.168.0.103, 46135)
[17:00:02,596] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@361c294e{/metrics/json,null,AVAILABLE}
[17:00:06,856] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@54d1608f{/SQL,null,AVAILABLE}
[17:00:06,858] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@541179e7{/SQL/json,null,AVAILABLE}
[17:00:06,860] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@7b81616b{/SQL/execution,null,AVAILABLE}
[17:00:06,863] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@279dd959{/SQL/execution/json,null,AVAILABLE}
[17:00:06,867] INFO  {ContextHandler} Started o.s.j.s.ServletContextHandler@6ed922e1{/static/sql,null,AVAILABLE}
[17:00:06,903] INFO  {SharedState} Warehouse path is '/home/victor/Desktop/ML/vt17-lab1/spark-warehouse'.
[17:00:08,573] INFO  {SparkContext} Starting job: show at Main.scala:119
[17:00:08,615] INFO  {DAGScheduler} Got job 0 (show at Main.scala:119) with 1 output partitions
[17:00:08,616] INFO  {DAGScheduler} Final stage: ResultStage 0 (show at Main.scala:119)
[17:00:08,617] INFO  {DAGScheduler} Parents of final stage: List()
[17:00:08,620] INFO  {DAGScheduler} Missing parents: List()
[17:00:08,636] INFO  {DAGScheduler} Submitting ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:119), which has no missing parents
[17:00:08,987] INFO  {MemoryStore} Block broadcast_0 stored as values in memory (estimated size 10.9 KB, free 1128.9 MB)
[17:00:09,048] INFO  {MemoryStore} Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.9 KB, free 1128.9 MB)
[17:00:09,052] INFO  {BlockManagerInfo} Added broadcast_0_piece0 in memory on 192.168.0.103:46135 (size: 4.9 KB, free: 1128.9 MB)
[17:00:09,057] INFO  {SparkContext} Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[17:00:09,066] INFO  {DAGScheduler} Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at show at Main.scala:119)
[17:00:09,070] INFO  {TaskSchedulerImpl} Adding task set 0.0 with 1 tasks
[17:00:09,203] WARN  {TaskSetManager} Stage 0 contains a task of very large size (165 KB). The maximum recommended task size is 100 KB.
[17:00:09,205] INFO  {TaskSetManager} Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 169333 bytes)
[17:00:09,223] INFO  {Executor} Running task 0.0 in stage 0.0 (TID 0)
[17:00:09,949] INFO  {CodeGenerator} Code generated in 501.31993 ms
[17:00:10,407] INFO  {CodeGenerator} Code generated in 138.263531 ms
[17:00:10,525] INFO  {Executor} Finished task 0.0 in stage 0.0 (TID 0). 1433 bytes result sent to driver
[17:00:10,540] INFO  {TaskSetManager} Finished task 0.0 in stage 0.0 (TID 0) in 1420 ms on localhost (1/1)
[17:00:10,543] INFO  {TaskSchedulerImpl} Removed TaskSet 0.0, whose tasks have all completed, from pool 
[17:00:10,552] INFO  {DAGScheduler} ResultStage 0 (show at Main.scala:119) finished in 1.458 s
[17:00:10,565] INFO  {DAGScheduler} Job 0 finished: show at Main.scala:119, took 1.990290 s
[17:00:10,647] INFO  {CodeGenerator} Code generated in 45.555625 ms
[17:00:10,702] INFO  {SparkContext} Invoking stop() from shutdown hook
[17:00:10,718] INFO  {ServerConnector} Stopped ServerConnector@41051c8d{HTTP/1.1}{0.0.0.0:4040}
[17:00:10,724] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@18920cc{/stages/stage/kill,null,UNAVAILABLE}
[17:00:10,725] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6ebf0f36{/api,null,UNAVAILABLE}
[17:00:10,726] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@2e8e8225{/,null,UNAVAILABLE}
[17:00:10,727] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1b765a2c{/static,null,UNAVAILABLE}
[17:00:10,728] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7103cb56{/executors/threadDump/json,null,UNAVAILABLE}
[17:00:10,728] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@178213b{/executors/threadDump,null,UNAVAILABLE}
[17:00:10,729] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@613a8ee1{/executors/json,null,UNAVAILABLE}
[17:00:10,730] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@41dd05a{/executors,null,UNAVAILABLE}
[17:00:10,730] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@67c2e933{/environment/json,null,UNAVAILABLE}
[17:00:10,731] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@fade1fc{/environment,null,UNAVAILABLE}
[17:00:10,731] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@7ca33c24{/storage/rdd/json,null,UNAVAILABLE}
[17:00:10,732] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@61f05988{/storage/rdd,null,UNAVAILABLE}
[17:00:10,733] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@59f63e24{/storage/json,null,UNAVAILABLE}
[17:00:10,733] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@42463763{/storage,null,UNAVAILABLE}
[17:00:10,734] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1338fb5{/stages/pool/json,null,UNAVAILABLE}
[17:00:10,736] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@5aac4250{/stages/pool,null,UNAVAILABLE}
[17:00:10,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6b3e12b5{/stages/stage/json,null,UNAVAILABLE}
[17:00:10,737] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@6c45ee6e{/stages/stage,null,UNAVAILABLE}
[17:00:10,738] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@53d102a2{/stages/json,null,UNAVAILABLE}
[17:00:10,739] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@35d08e6c{/stages,null,UNAVAILABLE}
[17:00:10,739] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3016fd5e{/jobs/job/json,null,UNAVAILABLE}
[17:00:10,740] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3b00856b{/jobs/job,null,UNAVAILABLE}
[17:00:10,740] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@3bcbb589{/jobs/json,null,UNAVAILABLE}
[17:00:10,740] INFO  {ContextHandler} Stopped o.s.j.s.ServletContextHandler@1d730606{/jobs,null,UNAVAILABLE}
[17:00:10,744] INFO  {SparkUI} Stopped Spark web UI at http://192.168.0.103:4040
[17:00:10,768] INFO  {MapOutputTrackerMasterEndpoint} MapOutputTrackerMasterEndpoint stopped!
[17:00:10,782] INFO  {MemoryStore} MemoryStore cleared
[17:00:10,783] INFO  {BlockManager} BlockManager stopped
[17:00:10,795] INFO  {BlockManagerMaster} BlockManagerMaster stopped
[17:00:10,801] INFO  {OutputCommitCoordinator$OutputCommitCoordinatorEndpoint} OutputCommitCoordinator stopped!
[17:00:10,806] INFO  {SparkContext} Successfully stopped SparkContext
[17:00:10,807] INFO  {ShutdownHookManager} Shutdown hook called
[17:00:10,809] INFO  {ShutdownHookManager} Deleting directory /tmp/spark-6ffaf0ed-fd22-4de9-87bc-76130a6c2370
